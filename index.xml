<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Be ambitious on Be ambitious</title>
    <link>https://winterwang.github.io/</link>
    <description>Recent content in Be ambitious on Be ambitious</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Chaochen Wang | 王超辰</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>2018_10 todo</title>
      <link>https://winterwang.github.io/post/2018-10-todo/</link>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/2018-10-todo/</guid>
      <description>&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;2018-10-02 ~ 2018-10-17

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Prepare the proposal to JSPS.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-10-02

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Background, key questions&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;objective, importance&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-10-09

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-80.html&#34; target=&#34;_blank&#34;&gt;Bayesian statistics Chapter 1&lt;/a&gt; done;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-10-10

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/MC-estimation.html&#34; target=&#34;_blank&#34;&gt;Bayesian statistics Chapter 2&lt;/a&gt; done;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-10-11~12

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/-conjugate-priors.html&#34; target=&#34;_blank&#34;&gt;Bayesian statistics Chapter 3&lt;/a&gt; done;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-10-13

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Review of the paper about HIV;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-10-15

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Wait for the comments from LP, SA;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-10-16

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Modification of the proposal;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Submission of the proposal;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn how to apply for the data usage of Japan National Nutrional Survey;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-10-17~19

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/mcmcbugs.html&#34; target=&#34;_blank&#34;&gt;Bayesian statistics Chapter 4&lt;/a&gt; done;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-10-23

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-84.html&#34; target=&#34;_blank&#34;&gt;Bayesian statistics Chapter 5&lt;/a&gt; done;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-10-24

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn how to use Stan (just a beginning);&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-10-25

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://github.com/winterwang/PAC_PAM&#34; target=&#34;_blank&#34;&gt;Some preliminary analysis&lt;/a&gt; using vague prior to do &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S1341321X18300783&#34; target=&#34;_blank&#34;&gt;MabeRCT&lt;/a&gt;;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-85.html&#34; target=&#34;_blank&#34;&gt;Bayesian statistics Chapter 6&lt;/a&gt; done;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Talk with LP AS, the next steps of writing the carb paper;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-10-26~30

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-86.html&#34; target=&#34;_blank&#34;&gt;Bayesian statistics Chapter 7&lt;/a&gt; done;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;LCA analyses done stratified by men and women;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; MLCA analyses done stratified by men and women;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Learn Python for beginners;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Search for guideline of eradication among adolescents of H. &lt;em&gt;pylori&lt;/em&gt; in the world;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Prepare poster for &lt;a href=&#34;https://www.bna.org.uk/mediacentre/events/chrononutrition-from-epidemiology-to-molecular-mechanism-symposium-london/&#34; target=&#34;_blank&#34;&gt;conference&lt;/a&gt;.&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Prediction model for pancreatic cancer risk in the general Japanese population</title>
      <link>https://winterwang.github.io/publication/predictionpancreaticgwas/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/publication/predictionpancreaticgwas/</guid>
      <description>

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;Genome-wide association studies (GWASs) have identified many single nucleotide polymorphisms (SNPs) that are significantly associated with pancreatic cancer susceptibility. We sought to replicate the associations of 61 GWAS-identified SNPs at 42 loci with pancreatic
cancer in Japanese and to develop a risk model for the identification of individuals at high risk for pancreatic cancer development in the general Japanese population. The model was based on data including directly determined or imputed SNP genotypes for 664 pancreatic cancer case and 664 age- and sex-matched control subjects. Stepwise logistic regression uncovered five GWAS-identified SNPs at five loci that also showed significant associations in our case-control cohort. These five SNPs were included in the risk model and also applied to calculation of the polygenic risk score (PRS). The area under the curve determined with the leave-one-out cross-validation method was 0.63 (95% confidence interval, 0.60–0.66) or 0.61 (0.58–0.64) for versions of the model that did or did not include cigarette smoking and family history of pancreatic cancer in addition to the five SNPs, respectively. Individuals in the lowest and highest quintiles for the PRS had odds ratios of 0.62 (0.42–0.91) and 1.98 (1.42–2.76), respectively, for pancreatic cancer development compared with those in the middle quintile. We have thus developed a risk model for pancreatic cancer that showed moderately good discriminatory ability with regard to differentiation of pancreatic cancer patients from control individuals. Our findings suggest the potential utility of a risk model that incorporates replicated GWAS-identified SNPs and established demographic or environmental factors for the identification of individuals at increased risk for pancreatic cancer development.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Words, notes, and sentences that may be useful </title>
      <link>https://winterwang.github.io/post/words-notes-and-sentences-that-may-be-useful/</link>
      <pubDate>Tue, 03 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/words-notes-and-sentences-that-may-be-useful/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#words&#34;&gt;Words&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#expressions&#34;&gt;Expressions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sentences&#34;&gt;Sentences&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#terry2017discontinuous&#34;&gt;terry2017discontinuous&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#lanza2007proc&#34;&gt;lanza2007proc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#collins2010latent&#34;&gt;collins2010latent&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;words&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Words&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;discernable [di’sə:nəbl, -’zə:-]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;===== 辞典翻译: discernable ======
adj. 可辨别的；可认识的
============ 网络释义 ============
-------- discernable ---------
可辨别的
方向
分辨
-- discernable recognizable --
可辨别的
--- discernable visible ----
可辨别的&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;abstinence [’æbstinəns]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;====== 辞典翻译: abstinence ======
  n. 节制；节欲；戒酒；禁食
============ 网络释义 ============
--------- abstinence ---------
  节制
  禁欲
  禁戒
----- alcohol abstinence -----
  酒戒断
----- Abstinence theory ------
  节欲论
  弃权
  忍欲说&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;exhaustive [iɡ’zɔ:stiv]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;====== 辞典翻译: exhaustive ======
  adj. 详尽的；彻底的；消耗的
============ 网络释义 ============
--------- Exhaustive ---------
  无遗
  详尽的
  全部
----- Exhaustive search ------
  穷举搜索
  穷举搜索完全搜索
  全程搜索
----- exhaustive voting ------
  淘汰投票
  消耗性投票&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;temperament [’tempərəmənt]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;===== 辞典翻译: temperament ======
  n. 气质，性情，性格；急躁
============ 网络释义 ============
-------- temperament ---------
  气质
  气质 (心理学)
  性格
------ Well Temperament ------
  Well temperament
  Well Temperament
  平均律
---- Musical temperament -----
  律学
  一份音乐的气质
  音乐性&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;trivial [’triviəl]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;======= 辞典翻译: trivial ========
  adj. 不重要的，琐碎的；琐细的
============ 网络释义 ============
---------- trivial -----------
  琐碎的
  微不足道的
  小巫见大巫
------ Trivial Pursuit -------
  棋盘问答
  打破砂锅问到底
  追根究底
-------- trivial name --------
  惯用名
  俗名
  种名&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;prudent [’pru:dənt]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;======= 辞典翻译: prudent ========
  adj. 谨慎的；精明的；节俭的
  n. (Prudent)人名；(法)普吕当
============ 网络释义 ============
---------- prudent -----------
  谨慎的
  明智的
  审慎的
--------- prudent s ----------
  善于经营的
  谨慎
  精明的
----- PRESIDENT PRUDENT ------
  普鲁登特总统城&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;daunting [’dɔ:ntiŋ]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;======= 辞典翻译: daunting =======
adj. 使人畏缩的；使人气馁的；令人怯步的
============ 网络释义 ============
---------- Daunting ----------
令人生畏
使人畏缩的
使人气馁的
------ However Daunting ------
但艰巨
--------- B daunting ---------
使胆怯&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;discern [di’sə:n, -’zə:n]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;======= 辞典翻译: discern ========
  vt. 识别；领悟，认识
  vi. 看清楚，辨别
============ 网络释义 ============
---------- discern -----------
  看出
  辨别
  识别
-------- Discern Lies --------
  辨知谎言
  辨识谎言
  洞悉谎言
------- discern safely -------
  安全识别&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;expressions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Expressions&lt;/h1&gt;
&lt;/div&gt;
&lt;div id=&#34;sentences&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Sentences&lt;/h1&gt;
&lt;div id=&#34;terry2017discontinuous&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;terry2017discontinuous&lt;/h2&gt;
&lt;p&gt;(Discontinuous Patterns of Cigarette Smoking From Ages 18 to 50 in the United States: A Repeated-Measures Latent Class Analysis)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;RMLCA models were fitted in SAS 9.4 using PROC LCA. Parameters were estimated by maximum likelihood using the EM algorithm.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;To ascertain if the same latent class structure was observed for males and females, multiple-group RMLCA models by sex were fitted in PROC LCA using the GROUPS statement (both with and without imposing measurement invariance across males and females).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Model selection (ie, the number of latent classes specified) was determined by model fit, parsimony, and stability.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Simulations have shown that the Bayesian information criterion (BIC) and sample size-adjusted BIC (a-BIC) perform particularly well at selecting the “correct” latent class model.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Improvement in both BIC and consistent Akaike information criterion (CAIC) values continued only through the 12-class model; thus, the 12-class model was selected as optimal.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;lanza2007proc&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;lanza2007proc&lt;/h2&gt;
&lt;p&gt;(PROC LCA: A SAS procedure for latent class analysis)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;In traditional LCA, two sets of parameters are estimated: class membership probabilities and item-response probabilities conditional on class membership.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Latent class models usually involve categorical indicators (although a version of LCA involving continuous indicators called latent profile analysis [Gibson, 1959] is being used increasingly).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;When categorical data are used, the latent class model has the advantage of making no assumptions about the distributions of the indicators other than that of local independence; that is, the assumption that within a latent class the indicators are independent.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In PROC LCA, parameters are estimated by maximum likelihood using an EM (expectation-maximization) type procedure. Missing data on the latent class indicators are handled in this procedure, with data assumed to be missing at random (MAR).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A test of the null hypothesis that data are missing completely at random appears in the output.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;a helpful preliminary step in any LCA is exploring overall relations among pairs of items by conducting cross-tab analyses.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A good starting point for identifying an optimal baseline model is to fit a sequence of models with two classes, three classes, and so on.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A variety of tools can be used together for model selection, including the likelihood-ratio G 2 statis- tic, Akaike’s Information Criterion (AIC; Akaike, 1974) and Bayesian Information Criterion (BIC; Schwarz, 1978).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For example, each class should be distinguishable from the others on the basis of the item-response probabilities, no class should be trivial in size (i.e., with a near-zero probability of membership), and it should be possible to assign a meaningful label to each class.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The AIC and BIC are penalized log-likelihood model information criteria that can be used to compare competing models (e.g., models with different numbers of latent classes) fit to the same data. A smaller AIC and BIC for a particular model suggests that the trade-off between fit and parsimony is preferable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Often when a grouping variable is included it is important to test for measurement invariance across groups. To do this, a model with free estimation of the &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; parameters can be compared to the same model that includes restrictions equating the &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; parameters across groups. A significant p value suggests that the null hypothesis of measurement invariance should be rejected.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Based on a data set, a particular model specification, and starting values for the parameters, the algo- rithm iterates between the Expectation (E) step and the Maximization (M) step until either the convergence criterion is achieved or the maximum number of iterations is reached.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The best way to detect identification problems or local optima (i.e., solutions other than the optimal one) is to fit the same model using multiple sets of starting values. This can be done by calling the procedure repeatedly with different seeds specified.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Even well-identified models can land on a different solution occasionally; if the solution with the smallest log-likelihood is arrived at using the majority of the seeds, one can have confidence that it is the optimal solution.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;collins2010latent&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;collins2010latent&lt;/h2&gt;
&lt;p&gt;(Latent Class and Latent Transition Analysis: With Applications in the Social, Behavioral, and Health Sciences)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;It is particularly noteworthy that the causal flow is &lt;em&gt;from&lt;/em&gt; the latent variable &lt;em&gt;to&lt;/em&gt; the indicator variable, not the other way around. That is, observed indicator variables do not cause the latent variables.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The purpose of LCA is to help the investigator to discern any meaningful, scientifically interesting classes against the noisy background of error.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In LCA, it is the responsibility of the investigator to assign names to the latent classes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The starting point for conducting a latent class analysis on empirical data is a contingency table formed by cross-tabulating all the observed variables to be involved in the analysis.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The local independence assumption refers only to conditioning on the latent variable. It does not imply that in a data set that is to be analyzed, the observed variables are independent. In fact, it is the relations among the observed variables that are explained by the latent classes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;An observed data set is a mixture of all the latent classes. Independence is assumed to hold only within each latent class, which is why it is called “local”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;LCA makes the assumption of local independence, which states that conditional on latent class, observed variables are independent.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A high degree of latent class separation implies a high degree of homogeneity.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;However, a high degree of homegeneity does not necessarily imply a high degree of latent class separation.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Thus, it is possible to have high homogeneity but poor latent class separation.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Some of the latent classes may be characterized by more than one response pattern, but there is no response pattern that appears to be closely associated with more than one latent class. Thus the latent classes are conceptually distinct and can readily be labeled.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Model selection may be challenging. Furtunately, a variety of tools are available to assist, including tests of absolute model fit, assessment of relative fit of competing models, and cross-validation. In addition to the tools discussed, there are two additional consideration that are critically important when evaluating a model: &lt;strong&gt;parsimony and model interpretability&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We see statistical models as lenses through which investigators examine their data in order to gain useful insights.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The likelihood-ratio statistics &lt;span class=&#34;math inline&#34;&gt;\(G^2\)&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[G^2 = 2\sum_{w=1}^W f_w\log(\frac{f_w}{\widehat{f_w}})\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(f_w\)&lt;/span&gt; represents the observed frequency of cell &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\widehat{f_w}\)&lt;/span&gt; represent the expected frequency of cell &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt; according to the model that has been fit.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The larger the value of &lt;span class=&#34;math inline&#34;&gt;\(G^2\)&lt;/span&gt;, the more evidence there is against the null hypothesis. (The larger it is, the worse model fitting it is.)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The degrees of freedom of &lt;span class=&#34;math inline&#34;&gt;\(G^2\)&lt;/span&gt;: &lt;span class=&#34;math display&#34;&gt;\[df = W - P - 1\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt; is the number of estimated parameters.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Sometimes fitting a series of latent class models with different numbers of latent classes to data at a single time point can be helpful as a preliminary step in model selection in LTA. Doing this at each time point can be informative about the latent structrue within times, and how that structure changes accross timie points.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It is important to note that the best-fitting latent class model at any given time may not correspond to the best-fitting latent transition model fit to all occasions of measurements. The best-fitting model based on the data from all occasions of measurement may include a different number of latent stuatuses than the number of latent classes identified at one particular time.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;However, based on the latent status prevalences at each time alone, it is impossible to tell hou and to what extent individuals were moving between latent statuses.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;In 7.11 we used a different empirical example to test the hypothesis that the item-response probabilities in a LTA are equal across times. This type of restriction on the item-response probabilities is commonly used in LTA. It helps with model identification and, importantly, ensures that the meaning of the latent statuses remains constant over time.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Summer Project Schedule</title>
      <link>https://winterwang.github.io/post/summer-project-schedule/</link>
      <pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/summer-project-schedule/</guid>
      <description>&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Data analysis finish by 2018-07-&lt;/del&gt;24&lt;del&gt;31&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Paper structure confirm by 2018-08-01&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Paper draft complete by 2018-08-16&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;2018-06-24

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read and try to repeat Rll&amp;rsquo;s method in R and familarize the dataset ASAP&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Two papers applying Repeated Measures LCA&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-25

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Meeting with supervisor and Susanna&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Confirm the cutoff of carborhydrate consumption&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Talk with Rll ask about the methodology and dataset&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-26

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Send the summarised memo of meeting to Supervisor and etc.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read the first part fundamentals of LCA.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-27

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;a href=&#34;https://www.londonr.org/&#34; target=&#34;_blank&#34;&gt;London R in UCL&lt;/a&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Germany lost their game against South Korea, UNBELIEVEABLE&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-28&lt;br /&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read the book collins2010latent - Latent Class and Latent Transition Analysis: With Applications in the Social, Behavioral, and Health Sciences (Done until 4.2)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn how to do LCA in R&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-29

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read the book collins2010latent - Latent Class and Latent Transition Analysis: With Applications in the Social, Behavioral, and Health Sciences (Done until 4.3)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Data management for NDNS 8 years data (70%)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn how to do LCA in R&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Start to analysis the data according to the discussion on 25th(30%)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Day1 data analysis results summary&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-01

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Relax and do nothing&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Buy some drink to enjoy the night with classmates(HB)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-02/03

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Send some preliminary results to co-authors&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&lt;a href=&#34;http://www.the-afc.com/competitions/fifa-world-cup/latest/news/japan-fa-president-proud-of-blue-samurai&#34; target=&#34;_blank&#34;&gt;Japan lost the game to Belgium, but they are the glory of Asia&amp;ndash;heartbreaking&lt;/a&gt;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-04&lt;br /&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&amp;ldquo;consider separating weekdays from weekends if we are not averaging the four days?&amp;rdquo;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-05

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Test and confirm the availability of LCA in SAS&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn how to do LCA in SAS with NDNS data&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-06&lt;br /&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn how to do LCA with random effects in SAS&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Find whether there is any possibility of conducting the same method in R or STATA (no there is no way)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-07~09

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&amp;ldquo;Maybe we should try with the threshold at 25% only as per the existing guidelines (although those are per meal)?&amp;rdquo;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-10

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; ~~Meet with tutor;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; Start writing about the methodology;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; Try to start writing about the introduction;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-11&lt;br /&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Try to summarise the meeting memo yesterday;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Re-analyse the data with new cut-off values (25, 50, 75);&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Re-analyse the data with new cut-off values (50);&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-12~22

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Use latent class growth analysis;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Use multilevel latent class analysis;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Think about the mathmatical theory behind the mixed LCA, write to PROC LCA group if necessary;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-23~25

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn about the survey package in R&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Finish writing about the methodology;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Write some introduction;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-26&lt;br /&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Let&amp;rsquo;s finish analysis of the classes and health outcomes.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read about the carbo-fibre ratio references.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-08-15

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;PM review&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Finish most of the discussion outlines and 2 pages of them.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-08-31

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Finish revising the report according to comments from LP and SAM;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read RT&amp;rsquo;s report and send the comments;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Confirm the deadline for funding applications;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Prepare the abstract for conferences (UK and JP);&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Start preparing the paper for submit (MLCA part alone);&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Think about the schedules and plans after leaving London;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Finish the post of Scotland trip.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>蘇格蘭高地7日公路之旅</title>
      <link>https://winterwang.github.io/post/scotland-highland-road-trip/</link>
      <pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/scotland-highland-road-trip/</guid>
      <description>

&lt;p&gt;本次高地旅行（2018-06-13～2018-06-20）值得紀念，我們一行三人，在蘇格蘭自駕開了一個圈。沿路看過的高山流水，懸崖峭壁，狂風暴雨，和那些雨過天晴，都讓人久久難以忘懷。我們還經歷了頭一天輪胎爆胎，最後一天在愛丁堡城堡被偷錢包等各種奇葩的經歷。深感有必要在此簡單記錄下這段旅程，為了將來還記得這一年在英國的腳印。&lt;/p&gt;

&lt;video autoplay width=auto height=auto controls allowfullscreen&gt;
  &lt;source src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/scotland.mp4&#34; type=&#34;video/mp4&#34;&gt;
  &lt;source src=&#34;movie.ogg&#34; type=&#34;video/ogg&#34;&gt;
  Your browser does not support the video tag.
&lt;/video&gt;

&lt;video autoplay width=auto height=auto controls allowfullscreen&gt;
  &lt;source src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/scotland02.mp4&#34; type=&#34;video/mp4&#34;&gt;
  &lt;source src=&#34;movie.ogg&#34; type=&#34;video/ogg&#34;&gt;
  Your browser does not support the video tag.
&lt;/video&gt;

&lt;h1 id=&#34;2018-06-13-倫敦出發&#34;&gt;2018-06-13 倫敦出發&lt;/h1&gt;

&lt;p&gt;出發之前，秀一下我們訂的20英鎊的機票（比機場市區往返的火車還便宜&amp;hellip;&amp;hellip;）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/ryanair.png&#34; alt=&#34;&#34; width=&#34;70%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180613.png&#34; alt=&#34;London to Edinburgh&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180613_180804.jpg&#34; alt=&#34;at the airport&#34; /&gt;&lt;/p&gt;

&lt;p&gt;當天無事，我們降落愛丁堡時蘇格蘭展示了北方的大風夾着冰涼的雨水，警告我們即使是夏季的夜晚也是那麼的寒冷。順利在機場取了車（其實花了一個半小時，牆裂&lt;strong&gt;不推薦&lt;/strong&gt;蘇格蘭當地的租車公司 &lt;a href=&#34;https://greenmotion.com/&#34; target=&#34;_blank&#34;&gt;Greenmotion&lt;/a&gt;，效率低下而且合同上陷阱不少，最後我們實在是覺得很煩，直接上了最高等級的整車安心保險&amp;ndash;後來的事實證明我們當初的選擇是那麼的正確），我們終於踏上了蘇格蘭之行的第一步。先在愛丁堡大學附近和多年未見的好友見面聊天吃吃吃了之後，我們找到了本次旅途中的第一家 Airbnb 房東在海邊的家。當晚其實下了一夜的狂風驟雨，透過閣樓的房間房頂上的玻璃，我們可以直接看到外面不停被風吹亂猙獰的樹枝。第二天一早風依然很大，但是我們無法克制想立刻看到大海的慾望，頂着狂風步行到了沙灘，看到那令人窒息的海邊的愛丁堡：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180614_093604.jpg&#34; alt=&#34;Edinburgh beach&#34; /&gt;&lt;/p&gt;

&lt;p&gt;這是我們租來的寶獅（标致）3008 SUV，7天保險全包，每天差不多63英鎊（約10000日元/560軟妹幣）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180707_180344.jpg&#34; alt=&#34;car&#34; width=&#34;70%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;這輛車表面上看起來瀟洒，其實個人感覺不太耐用，華而不實。&lt;/p&gt;

&lt;p&gt;白天離開房東家以後我們車停在愛丁堡車站南的一個立體停車場，之後趁着天氣晴朗（但是大風四起，把許多路人吹得很凌亂），我們參觀了愛丁堡大學神學院：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180614_102441-EFFECTS.jpg&#34; alt=&#34;Edinburgh University01&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180614_102902.jpg&#34; alt=&#34;Edinburgh University&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;天氣雖然好，大風讓愛丁堡城堡關閉了遊客參觀，但是並不妨礙我們感受這座古老城市的藝術氣息：&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ed.ac.uk/visit/museums-galleries/anatomical&#34; target=&#34;_blank&#34;&gt;麥克尤恩大禮堂(McEwan Hall, The University of Edinburgh)&lt;/a&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180614_134359.jpg&#34; alt=&#34;Edingburgh0001&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.stgilescathedral.org.uk/&#34; target=&#34;_blank&#34;&gt;聖基爾斯大教堂(St Giles&amp;rsquo; Cathedral)&lt;/a&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180614_104806.jpg&#34; alt=&#34;Edinburgh0002&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.edinburghmuseums.org.uk/venue/scott-monument&#34; target=&#34;_blank&#34;&gt;斯科特紀念塔(Scott Monument)&lt;/a&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180614_152250.jpg&#34; alt=&#34;scott tower&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;路邊的行為藝術：
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180614_104849.jpg&#34; alt=&#34;Edinburgh0004&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;登上&lt;a href=&#34;https://www.google.com/maps/place/Calton+Hill/@55.9521378,-3.1854529,16.42z/data=!4m5!3m4!1s0x4887c7896e46c799:0x9181b664f75766dd!8m2!3d55.9550468!4d-3.1827414&#34; target=&#34;_blank&#34;&gt;卡爾頓山 (Calton Hill)&lt;/a&gt;俯瞰這座蘇格蘭的首府，安靜而令人嚮往。
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180614_162240.jpg&#34; alt=&#34;Calton Hill&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180614_162650.jpg&#34; alt=&#34;Calton Hill02&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;2018-06-14-爱丁堡到格拉斯哥&#34;&gt;2018-06-14 爱丁堡到格拉斯哥&lt;/h1&gt;

&lt;p&gt;傍晚離開了愛丁堡，我們向西驅車開往另一座老城，格拉斯哥。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180614.png&#34; alt=&#34;one day in Edinburgh and to Glasgow at night&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;這一晚我們預定的 Airbnb 在格拉斯哥的郊區，是一排連排別墅中的一棟。這天入住的時候，由於沒有仔細閱讀房東在 Airbnb 上留下的入住須知，導致用鑰匙打開門之後警報聲大作，直至隔壁鄰居實在是受不了了跑來幫忙關掉警鈴整個世界才安靜。在此友情提醒諸位使用 Airbnb 時注意閱讀房東留下的入住須知。房東當日不在家，所以我們沒有浪費他們家的廚房設施，從超市採購了一大桶雞腿嘗試了白斬雞的做法（味道好極了！多謝 Linda）。&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180614_213555.jpg&#34; alt=&#34;drum&#34; width=&#34;80%&#34; style=&#34;transform:rotate(90deg);&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
這一日主要停留在愛丁堡，晚上我們也很早休息，為了第二天的長途跋涉。&lt;/p&gt;

&lt;h1 id=&#34;2018-06-15-從格拉斯哥離開-飛馳在高地去往天空島&#34;&gt;2018-06-15 從格拉斯哥離開，飛馳在高地去往天空島&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180615.png&#34; alt=&#34;on the way to Skye Isle&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;一早從格拉斯哥離開後要先經過洛蒙德湖泊 (Loch Lomond)，沿着A82號公路，一路上一會兒下雨，一會兒天晴。在湖邊一個叫做路斯 (Luss) 的小鎮，我們在雨中下來看了看湖邊雲霧繚繞的碼頭，水很清澈，水鴨子們也悠閑地在游泳：&lt;/p&gt;

&lt;video width=auto height=auto controls allowfullscreen&gt;
  &lt;source src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/scotland.m4v&#34; type=&#34;video/mp4&#34;&gt;
  &lt;source src=&#34;movie.ogg&#34; type=&#34;video/ogg&#34;&gt;
  Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;樹林里，清澈見底的溪流：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_101538.jpg&#34; alt=&#34;river&#34; width=&#34;80%&#34; style=&#34;transform:rotate(180deg);&#34;/&gt;&lt;/p&gt;

&lt;p&gt;雲霧中，在停車時發現山上是一個水力發電廠：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_110845.jpg&#34; alt=&#34;power&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;洛蒙德湖在籠罩在水氣中：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_100653.jpg&#34; alt=&#34;loch&#34; width=&#34;80%&#34; style=&#34;transform:rotate(180deg);&#34;/&gt;&lt;/p&gt;

&lt;p&gt;之後，我們在路上就經歷了爆胎事件。其經過其實很簡單:離開路斯往北行進的路上，其實道路是十分狹窄的。在某路段我眼角發現左前方路面上有一個拳頭大小的黑色障礙物 (後來想應該是塊山上掉下來的碎石)，當時如果路足夠寬的話，我當然可以躲閃一下。無奈右側迎面而來是一輛大卡車，無法躲閃，後面又有車跟着，不能剎車，於是就只好硬着頭皮前行，心裏希望只是個不太堅硬的小石子。結果過去以後，&amp;rdquo;咣噹&amp;rdquo;一聲，左前方的輪胎明顯下沉，握方向盤的雙手明顯有左右不平衡的感覺，於是滑行了幾百米後在一段正好施工路段的中間處停下查看輪胎狀況。不出所料，左前方輪胎癟了。此時距離我們離開格拉斯哥大概只有一個半小時左右的路程。圖中是我們等待了兩次雷雨，三集 Friends 過後，才姍姍來遲的路上救援小哥。幸好該寶獅（标致）SUV的後備箱里有一個備胎。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_134949.jpg&#34; alt=&#34;tyre&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
換好備胎以後的寶獅。
&lt;br&gt;
&lt;br&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_135950.jpg&#34; alt=&#34;tyre2&#34; width=&#34;80%&#34;
style=&#34;transform:rotate(90deg);&#34;/&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;換備胎的小哥讓我們開車開到前面去找輪胎廠換一個新的輪胎，這樣才不至於一直使用備胎，車速要總是限制在50邁以下。於是我們查了查地圖，確定最近的輪胎店的位置。發現如果往南走要回到格拉斯哥，往北則是越來越荒蕪，只有往西靠海邊有個叫做奧本的小鎮有輪胎修理點。於是我們驅車出發去之前並未計劃要去的這個叫做奧本的海港小鎮。想起來之前在愛丁堡，好友還推薦說你們如果順路可以去奧本的港口吃海鮮路邊攤 (seafood hut)，當時我們還想這樣會繞遠路，就沒有把奧本放進行程裏，結果我們這半路爆胎&amp;rdquo;因禍得福&amp;rdquo;，來到了這個本來並沒有在行程中的西海岸邊的小漁村。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_163435.jpg&#34; alt=&#34;oban01&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;抵達奧本，換了兩三家輪胎廠，都說我們租的這輛寶獅款式太新，並沒有庫存的相同輪胎，真的是運氣不佳。於是我們只好停車在港口的碼頭之後去路邊攤邊吃海鮮，邊思考接下來腫麼辦 (其實主要就是來吃海鮮的)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_163543.jpg&#34; alt=&#34;oban02&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;一盤大龍蝦，就水裏撈上來直接清煮的那種，大約15鎊左右，吃的是大快朵頤！
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_164322.jpg&#34; alt=&#34;oban03&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;後來我們又點了一只麪包蟹，膏滿肉肥。
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_163835.jpg&#34; alt=&#34;oban04&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;搞笑的是我們先飽餐了一頓之後離開海鮮攤位，經過下面的奧本火車站在附近散步一圈，同行的一個小朋友可憐兮兮地說，晚上還能不能再吃海鮮呀。於是我們回過頭第二次又去光顧了同一家 seafood hut. 奧本的海鮮真是讓人一步三回頭。
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_172827.jpg&#34; alt=&#34;oban05&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_172939.jpg&#34; alt=&#34;oban06&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;這是在去往天空島的路上經過的廣闊的高地，我們停車在一個紀念二戰時陣亡英格蘭蘇格蘭將士的廣場:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_193746.jpg&#34; alt=&#34;highland&#34; width=&#34;80%&#34;/&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_195450 (1).jpg&#34; alt=&#34;pond&#34; width=&#34;80%&#34;/&gt;
&lt;br&gt;
紀念雕塑
&lt;br&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180615_194420.jpg&#34; alt=&#34;soldiers&#34; width=&#34;80%&#34; style=&#34;transform:rotate(90deg);/&gt;
&lt;br&gt;&lt;/p&gt;

&lt;h1 id=&#34;2018-06-16-離開時而暴雨傾盆-時而天氣晴朗的天空島-去往德內斯-durness&#34;&gt;2018-06-16 離開時而暴雨傾盆，時而天氣晴朗的天空島，去往德內斯 (Durness)&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180616.png&#34; alt=&#34;Durness&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;在天空島的早上，天氣陰沉沉，我們開車繞着整個半島走了一圈，也沒等到天晴可以看懸崖的時刻。倒是中途發現了一個極爲清澈的海水池&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180616_110819.jpg&#34; alt=&#34;skye pond&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;之後來到蘇格萊最北的懸崖處，這裏名叫德內斯
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180616overnight.jpg&#34; alt=&#34;Durness2&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180617_093639.jpg&#34; alt=&#34;&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;一個陰森森的洞窟在懸崖下&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180617_093852.jpg&#34; alt=&#34;cave&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;我們步行到深藍色海邊的黑色懸崖上，再往北就是北冰洋&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180617_100510.jpg&#34; alt=&#34;durness02&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;2018-06-17-在靠近-shetland-的無路可走的盡頭&#34;&gt;2018-06-17 在靠近 Shetland 的無路可走的盡頭&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180617.png&#34; alt=&#34;Road ends&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180617_165018.jpg&#34; alt=&#34;road ends cafe&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180617_165336.jpg&#34; alt=&#34;colorful houses&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180617_165642.jpg&#34; alt=&#34;&#34; width=&#34;80%&#34;
style=&#34;transform:rotate(90deg);&#34;/&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;確切地說，這裏才能算是蘇格蘭和英格蘭島上地理位置上的最北端。地標在這裏顯示往北是 &lt;a href=&#34;https://zh.wikipedia.org/wiki/%E8%AE%BE%E5%BE%B7%E5%85%B0&#34; target=&#34;_blank&#34;&gt;Shetland&lt;/a&gt; 往南則距離倫敦690英里 (1100公里左右)。許多人來到了這個道路終結的地方，在那一排色彩斑斕的小房子前，面朝大海。估計這裏的春暖花開一年也就幾天時間。抵達這裏，意味着我們脫繮的道路到了終點，天公作美，我們到此一遊相片留下之後，終於開始了往南回到現實的旅程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180617_171016.jpg&#34; alt=&#34;first last&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180617_171136.jpg&#34; alt=&#34;&#34; width=&#34;80%&#34; 
style=&#34;transform:rotate(90deg);&#34;/&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180617noon.jpg&#34; alt=&#34;road ends again&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;晚上到了因弗尼斯 (Inverness)， Airbnb 房東家的廚房又一次發揮了極爲重要的作用:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180617_225146.jpg&#34; alt=&#34;&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180617_225253.jpg&#34; alt=&#34;&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;房東給準備的早餐堪比4星級酒店&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180618_084043.jpg&#34; alt=&#34;breakfast&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;2018-06-18-inverness-和尼斯湖水怪&#34;&gt;2018-06-18 Inverness 和尼斯湖水怪&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180618.png&#34; alt=&#34;Loch Ness&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;尼斯湖是一個顏色暗黑似乎深度內傷的湖，如果你看地圖，它是又細又長的一個小湖泊，這天天氣很冷 (六月)，寒風逼人，不知冬季時這裏的人要如何度過。無法想象。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180618_124333.jpg&#34; alt=&#34;ness&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;湖岸邊有個據說曾經是這附近土地領主的破敗城堡 Urquhart Castle。
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180618_131215.jpg&#34; alt=&#34;Urquhart Castle&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;處處可見飄揚的蘇格蘭旗，然而並沒有人因此逼着誰必須表態然後撕破臉，說你搞蘇獨，社會的包容度差距可見一斑。嘴上不用說，每個人內心都應該首先是個&amp;rdquo;獨立&amp;rdquo;的人，有獨立思想的個體。記得去臺灣的時候，不光有中華民國的青天白日旗，也有人拿着赤色紅旗，海峽對岸流淌着同樣華人血液的社會早已經進步到可以包容各種思想不同的意見的和諧，這一文明的光芒就如同太平洋上的燈塔。盼望有一天，中國，只有一個名字，沒有別的亂七八糟的定語，也不需要在這兩個字中間加各種各樣標新立異的字眼，只有一個 China 去代表這塊土地和有相同認同感的社會。&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180618_131621.jpg&#34; alt=&#34;flags of scotland&#34; width=&#34;80%&#34; style=&#34;transform:rotate(90deg);/&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180618_131652.jpg&#34; alt=&#34;ness lake&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;晚上下榻的農家旅社
&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180619_091058.jpg&#34; alt=&#34;&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;2018-06-19-回到愛丁堡&#34;&gt;2018-06-19 回到愛丁堡&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180619.png&#34; alt=&#34;Back to Edinburgh&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180620_101518.jpg&#34; alt=&#34;&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;回到愛丁堡之後，我們的大廚 Linda 又跟我展示了一手好廚藝&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Todo 2018 June-September</title>
      <link>https://winterwang.github.io/post/todo-2018-june/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/todo-2018-june/</guid>
      <description>&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 大塚敏美財団メールを返信する&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;PCA analysis learning&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Cluster analysis learning&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;建立一個論文日程表格&lt;/del&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;日程計劃包括每周進度&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;分析進度&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;論文寫作進度&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;學習 Latent Class Analysis 方法;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;熟悉 NDNS 數據框架結構，思考分析方法;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Comment and response to AACE&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Test on Ubuntu 18.04&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;尝试从Ubuntu, 日本語を試す&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;更新 &lt;a href=&#34;http://wangcc.me/LSHTMlearningnote/&#34; target=&#34;_blank&#34;&gt;LSHTM 統計學學習筆記&lt;/a&gt; &lt;a href=&#34;http://wangcc.me/LSHTMlearningnote/cox-.html&#34; target=&#34;_blank&#34;&gt;生存分析章節-Cox-models&lt;/a&gt;;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 更新 LSHTM 統計學學習筆記，GLM Multinomial logistic regression model;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 更新 LSHTM 統計學學習筆記，GLM Oridinal logisitic regression model;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 更新 LSHTM 統計學學習筆記，貝葉斯進階章節;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 更新 LSHTM 統計學學習筆記，用 STATA 或者 R 分析 SME 流行病學數據的實踐部分;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 更新生存分析，更多具體細節及練習[Cox];&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 更新生存分析，更多具體細節及練習[AFT];&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;辦理法國簽證所需的材料; 法國行程取消(2018-06-20)&lt;/del&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;大學學生在校證明;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;銀行三個月存款證明&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;歐洲之星(7月)訂票;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;巴黎青年旅館訂房 (聯繫下正好在法國的 なっちゃん家?);&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;旅行保險;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;BRP 複印;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;護照複印;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;[xa] &lt;del&gt;簽證申請書;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;近三个月内的证件照，尺寸3.5cm x 4.5cm，白底&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 把 &lt;a href=&#34;https://github.com/winterwang/overleaf-thesis-template&#34; target=&#34;_blank&#34;&gt;LaTeX 模板&lt;/a&gt; 調整到 &lt;a href=&#34;https://github.com/pzhaonet/bookdownplus&#34; target=&#34;_blank&#34;&gt;Bookdownplus 的模板之一&lt;/a&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Bayesian&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-1;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-3&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-7;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-03 17:00, mean and variance for data transformation]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-03 17:30 linear regression, really need to pay attention in reading the question]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-03 22:30 Binomial exact test]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test done, coefficient and rho, 75% about]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-2;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-3;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-4;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test done, too much to write as a survival question, about 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test done, too much to write about 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-6;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test done, GLM about 90%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-1;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>To do list 2018 May</title>
      <link>https://winterwang.github.io/post/todotest/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/todotest/</guid>
      <description>&lt;p&gt;試試看用 &lt;a href=&#34;https://shrektan.com/post/2018/04/02/blogdown-todo/&#34; target=&#34;_blank&#34;&gt;Blogdown 來管理自己的待辦事項&lt;/a&gt;:&lt;/p&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Causal inference 作業&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-18 12:00]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;學習去年的 Hierarchical discrete data modeling Lecture 1-4;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-08 23:45 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;學習去年的 Generalised linear mixed effect modelling lecture 5-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-12 16:00 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;完成 ASM Edmund 作業;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-18 03:20 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;寫一篇日志回顧最近 LSHTM 的生活;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-06 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Probablity;(2018-05-16 to 17)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Inference;(2018-05-17 to 18)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Clinical Trial;(2018-05-19 to 20)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Basic Epi; (2018-05-20 to 21)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Analytical Technique;(2018-05-22 to 24)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Regression; (2018-05-24 to 25)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Robust statistics; (2018-05-27)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 GLM (2018-05-28 to 29)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Survival Analysis (2018-05-39 to 31)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;反省自己爲什麼效率這麼低。。。。。&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;解決辦法就是把自己的 to do 放在網頁上，刺激自己。(2018-05-06 done)&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2008年 LSHTM 試題 Paper 2-2 (survival question);&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-29 17:01]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2009 年 LSHTM 試題 Paper 2-3 (survival question);&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-29 18:19]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-24 17:01 40 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-18 12:21 done]&lt;/li&gt;
&lt;li&gt;[2018-06-03 12:51 done again 80% 17 min]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 11:15]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-19 22:50 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-19 23:43 done]&lt;/li&gt;
&lt;li&gt;[2018-06-03 16:30 Wald test, MLE, compare the inverse of mean]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-25 21:32 done 35 min]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-27 13:39 done 15 min]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 2012年 LSHTM 試題 Paper 1-8;

&lt;ul&gt;
&lt;li&gt;[2018-05-18 22:00 done]&lt;/li&gt;
&lt;li&gt;[2018-06-04 11:27 done again, when use transformation for MLE, we need to substitute it back to the loglikelihood function to find the standard error of the newly transformed variable]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 35 min but brutally beaten]&lt;/li&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test 90%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-04-30, challenged again 2018-05-25 quadratic term interpration is needed]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-20 01:00 done]&lt;/li&gt;
&lt;li&gt;[done again on 2018-06-04 12:22 score test and comparison with lrt, hard way of doing lrt with binomial data, time consuming, about 80% got]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-4;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-04-30]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 23:38]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-04-30]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-03 15 min 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 14:09 18 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 23:38]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-1&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-07 1800]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-2&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-07 1900]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-3&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-07 2230; challenged again 2018-05-25 20:58 35 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-28 extreeeeeeeemely^99^ difficult GLM]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 21:21 in 37 min]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-28 巨難無比，條件邏輯回歸的推導和證明]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 23:38]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-04-23]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 27 min but only get about 60% poor and brutal&amp;hellip;&amp;hellip; what should I do&amp;hellip;]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-04-23]&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;[done 2018-06-04 done in 29 min 90% got]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-4;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-20 22:56]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 18:33]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-19 13:43]&lt;/li&gt;
&lt;li&gt;[done agian 2018-06-03 11:18 17 min 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 15:07,278 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-21 14:50]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-24 15:01]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-04-23]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-14 23:18; twice challenge 2018-05-25 17:20 better now]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-15 01:30; challenged again 2018-05-28 15:47 much better now]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-15 11:30]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-28 16:50 got 19 points out of 20 I like this one]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 18:38 36 min used, survival questions]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-19 14:53]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-03 00:05 17 min 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-20 13:46 20 min used]&lt;/li&gt;
&lt;li&gt;[done 2018-06-04 14:08 12 min used well done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-20 22:15 20 min used but only get 50%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-4;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-23 21:00]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 12:16]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 12:06 25 min used but only get 60%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 16:57  28 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 12:44]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-24 13:56]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 16:14 29 min used, somewhat easy I can have about 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 13:58]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-28 12:42]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-28 14:15 done within 25 min, Poisson regression model is within my range of ability]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-30 17:07 done. 40 min used. Quite difficult Weibull model with AFT feature.]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 00:58]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-02]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-03 00:04 30 min 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-2;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-02]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-04 14:40 20 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-3;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-02]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-4;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-02]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-5;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-02 and 2018-05-24 22:58 33 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-6;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-03]&lt;/li&gt;
&lt;li&gt;[done 2018-06-02 17:41 about 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-7;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-03]&lt;/li&gt;
&lt;li&gt;[done 2018-06-02 17:41 about 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-8;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-03]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-23 18:00]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 01:03 very difficult competing risk(subdistribution) model]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-01 11:59, more than 80% get, answers improved]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 01:38 40 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-5;&lt;/del&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;[done 2018-05-27 23:58 45 min used]&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 2018-05-31 15:22 challenged again 32 min used, answers improved.&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-6;&lt;/del&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;[done 2018-05-28 11:55 matched case-control study]&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 2018-05-31 16:04 challenged again 27 min used, answers improved.&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 13:09 Weibull model with connection to AFT model]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-01 12:00 more than 80% got, answers improved]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-21 13:00]&lt;/li&gt;
&lt;li&gt;[done 2018-06-02 17:40 again, about 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-19 20:02 done]&lt;/li&gt;
&lt;li&gt;[2018-06-03 00:03 17 min done 80% got]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-20 16:07 史上最難]&lt;/li&gt;
&lt;li&gt;[2018-06-04 20 min 90% got, MSE = Variance + (Bias)^2]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-20 18:30]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-4;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-23 01:45 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-24 21:57 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-21 02:35 被虐慘了]&lt;/li&gt;
&lt;li&gt;[2018-06-02 14:49 largely improved]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-21 11:09 答案可能有錯的 AT?]&lt;/li&gt;
&lt;li&gt;[2018-06-02 14:48 done again, Good]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-27 12:34 done, 28 min used, but only had 60%. &lt;strong&gt;Read your question carefully!!!&lt;/strong&gt;]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-21 12:49 done 17]&lt;/li&gt;
&lt;li&gt;[2018-06-02 14:48 done again, largely improved]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-2;&lt;/del&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;[done 2018-05-27 23:09 extremely difficult GLM]&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; challenged again 2018-05-31 21 min done with quick smash&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-27 20:00 very difficult combined with ordinal logistic regression]&lt;/li&gt;
&lt;li&gt;[2018-05-31 14:35 challenged again, 40 min, still very difficult but improved]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-29 20:11 done, not very difficult survival question, but you only got about 50%]&lt;/li&gt;
&lt;li&gt;[2018-06-01 13:52 challenged again, answers improved, some time-dependent variable in survival analysis is quite interesting]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-29 22:47 done, not very difficult, but less than 50% obtained]&lt;/li&gt;
&lt;li&gt;[2018-06-01 13:55 done again, answers improved.]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-24 18:43 done 45 min used. too much time wasted!!!]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-20]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>你靜靜地睡在琥珀裏</title>
      <link>https://winterwang.github.io/post/sleep/</link>
      <pubDate>Sun, 06 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/sleep/</guid>
      <description>&lt;p&gt;媽在電話裏說，今年要是期末考試考不過，明年把妹妹(我女兒)背去倫敦再考。(T_T) 突然我就想起快離開廈門的前一天，帶着兒子去大榕樹底下玩。他興奮地要玩我新買的乒乓球和乒乓球拍。可我心裏舍不得新的球和球拍弄髒了，就故意拿小汽車和其他的東西分散他的注意力。回到家裏了才給了他一個乒乓球玩。其實那天本來還想帶他去買肉包給他吃，可是領了快遞以後我沒有手再拿東西，就直接帶兒子回家了。那天兒子女兒和妻還要坐火車回榕城外婆家，一路顛簸誰也沒想起來，兒子還沒吃早飯。火車上聽說他也一直沒吃東西，不知道他三歲的心裏在想什麼。到了外婆家裏也很晚了，男孩子興奮哭鬧總是比女孩子激烈。我一聽電話裏他哭的聲音，心裏就不由得難受極了。怎麼就舍不得把乒乓球給他一個呢，我真是個自私極了的爸爸。忘了兒子沒吃早飯，也舍不得把他想玩的乒乓球送給他。也許他早就不記得了，但是我總惦記着這一天發生的事。也許在我心裏，那段美好時光在琥珀中靜止在了廈門開往島外的那列送行的地鐵上。&lt;/p&gt;

&lt;p&gt;我又想起在學習&lt;a href=&#34;http://wangcc.me/LSHTMlearningnote/causal-languages-.html&#34; target=&#34;_blank&#34;&gt;因果推斷&lt;/a&gt;的時候，每次老師都要強調那三個永世不能忘記的推斷前提:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;無相互幹擾 no interference;&lt;/li&gt;
&lt;li&gt;一致性 consistency;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;條件可置換性 conditional exchangeability;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;每當老師提問說，我們現在的前提是什麼？全班同學總能異口同聲地念出上面那三句咒語，場景仿佛間諜與間諜之間對暗號。又有點像黑幫入會時指天發誓的三句誓言。還有就是那個老師可愛的法文味道的英文，標準誤的英文是 standard error，她總是說 standard &amp;ldquo;唉河&amp;rdquo;。另一個教生存分析的法國人老師就更有趣了，每次舉例子都說，比方說我們拿&amp;ndash;法國做例子，隨機選一個國家嘛。。blablabla&amp;hellip;&lt;/p&gt;

&lt;p&gt;今天，響子同學說要去阿根廷完成自己的碩士課題。我們下午坐在 SOAS 的草地上一邊從作業間隙中休息，一邊喝着咖啡，突然意識到，再過一陣子，新學生就又要來了呢。去年這時候我們都還在世界各地，響子在危地馬拉給 JICA 幹活，說着流利的西班牙語; 我在名古屋一邊給日本學生講課，一邊內心充滿了期待快出生的妹妹和快要出發來倫敦的復雜又忐忑的心情，如今我們竟然已經在討論彼此回程的機票訂了幾號，想起3月我們還在寒風中頂着大雪抱怨着留英這一年碰到數十年最嚴重的大學罷課，這一段時光，竟也這樣偷偷溜走，沒有琥珀可以給它定格。&lt;/p&gt;

&lt;p&gt;直到兩天前，同班同學在因果推斷下課後，復習完了我們每次課上對完的暗號，突然有同學提議說，我們去學校門口拍一張集體照片吧，學校年度學生畫冊 (Yearbook) 的內容我們還沒人提交吶，至少要有一張咱們的集體照片吧！ 於是我們有了封面的那張照片。總算是用 LOMO 的隨手拍記錄下這年我們在 LSHTM 待過的證據。這年，我們這十幾個在 LSHTM 推倒公式，背誦&amp;rdquo;間諜暗號&amp;rdquo;，倒騰貝葉斯，糾結着那些回歸模型的殘差，還有那個永遠也搞不懂的似然。一瞬間留在相紙上，一轉眼可能就要各奔四方。傷感不由就從心中涌出，蔓延到大西洋。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>日落在下午四點</title>
      <link>https://winterwang.github.io/post/luan/</link>
      <pubDate>Sun, 14 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/luan/</guid>
      <description>&lt;p&gt;倫敦的生活已經過去四個月，每天和統計學公式打交道的我，今天不想在這裏寫任何公式。說說這四個月想更新一直偷懶沒更新的那些在倫敦衛生與熱帶醫學院度過的平凡的日子。&lt;/p&gt;

&lt;p&gt;寒假時去了普利茅斯，和康沃爾。康沃爾是個很有意思的名字 Cornwall。字面意思是玉米牆。我是去自己本來計劃聖誕節想去的 Homestay。&lt;a href=&#34;http://www.hostuk.org/&#34; target=&#34;_blank&#34;&gt;HOST UK&lt;/a&gt; 本來負責我的人告訴我聖誕節可能有點困難，聖誕節前的週末可以的話就去康沃爾的一對退休的老人家裏去做客吧。於是週五一早踏上了一個多月前就從網上訂好的倫敦的帕丁頓去往卡爾斯托克 (Calstock) 的西大不列顛列車。說來諷刺的是，大英帝國建立了世界上第一條火車，如今我一個老外來到這個國家卻在嫌棄這裏的火車慢如老牛拉車。&lt;/p&gt;

&lt;p&gt;和我一起享受英國農村四天三晚的 Homestay 的還有另一個來自毛里求斯的印度人學生。我們一路同行從倫敦出發。整列火車從離開倫敦時的滿員，乘客隨着車窗外樓房的減少而逐漸減少。&lt;del&gt;腦海裏推算了一下，這絕對是有意義的正相關。&lt;/del&gt; 到了普利茅斯只剩下包括我倆在內，絕對只有個位數的人。&lt;/p&gt;

&lt;p&gt;我也沒打算把整個四天三晚都去了哪裏在這裏記流水帳，印象深刻的是我們和老爺爺老太太每晚每晚的長談。還好來自毛里求斯的印度人英文流利，我一個人跟這些老人肯定是無法聊到深夜的。他們聊他們的老當益壯，用腳丈量非洲大陸的那些經歷和記憶，我們侃我們的年輕氣盛和那些無處發泄的憂國憂民。走時，老爺爺把自己收藏了多年的一個據說來自唐朝中國的佛像給了我，說，我希望你帶它回到它來自的地方。我想起我們都站在康沃爾的大西洋沿岸峭壁懸崖，放眼望着法國的方向，腳下全是泥巴。&lt;/p&gt;

&lt;p&gt;我在老人家的留言本上寫下了我在中國和日本的地址電話，中日英三語，生怕他們真的會在中國或者日本迷路。隔天回到了倫敦的房間，我收到老爺爺發來的郵件，淡然如水，卻彷若那些夜晚我們促膝長談時說的話：“你豐富了我們的人生，在你我的道路重新交集前，保重。You have enriched our lives. Until our paths cross again, take care.”&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;英國冬季的日照時間短得可憐。白天離開宿舍去大學時天黑着，下午下課離開大學時，天依然是黑着的。加上我們統計系的課許多都在地下的教室裏，我跟其他人打趣說，我現在的生活像一隻土撥鼠。我在地下，推導着讓我內心無比踏實的那些數學公式。&lt;/p&gt;

&lt;p&gt;有時候，我會十分的想念日本的生活。有時候，我又會無比的思念廈門的日子。這些落腳過的地方，只有上海的感覺越來越模糊。不知道我懷念的是名古屋乾淨的街道，是廈門的沙茶面的味道，還是那些夜晚打完工以後路邊的便利店門口騎着腳踏車路過的那時的我，也許還有那個在白城沙灘上可以悠閒地聽海浪拍岸聲的那個無腦少年。不清楚緣由地，只有上海的記憶在大腦中逐漸變得不那麼色彩斑斕。我也很好奇多年以後我會怎樣回憶倫敦？ 也許只剩下記憶裏土撥鼠一樣的無聊日子，還有貴死你不償命的宿舍房租。&lt;/p&gt;

&lt;p&gt;跨年那晚我和幾個同學走在滿目瘡痍的倫敦街頭，焰火散去，人去城空，2018年就已經被我們踩在了腳下。眼看着這新的一年在凌亂中開始，但願過程也不要太過殘酷。這一年唯一的目標是順利完成這沒日沒夜 (說好聽是朝思暮想) 的醫學統計學碩士。還有的話就是希望家人孩子平安，待我回到你們身邊，我們再也不要用小的可憐的手機屏幕來看彼此，我要帶你們去看整個世界。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>萬衆期待，英國黑暗料理</title>
      <link>https://winterwang.github.io/post/black-meal/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/black-meal/</guid>
      <description>

&lt;h3 id=&#34;康沃爾的牛肉餡餅-贊-2017-12-16-the-shop-in-the-square-https-www-google-com-maps-place-the-shop-in-the-square-50-3310101-4-2021014-21z-data-4m13-1m7-3m6-1s0x0-0x0-2zntdcsde5jzuyljaitia0wraxmicwny4yilc-3b1-8m2-3d50-3311-4d-4-202-3m4-1s0x486c94411d32061f-0xc6ba3bcac8fcc931-8m2-3d50-331087-4d-4-2021739&#34;&gt;康沃爾的牛肉餡餅！ 贊！ (2017-12-16 @&lt;a href=&#34;https://www.google.com/maps/place/The+Shop+in+the+Square/@50.3310101,-4.2021014,21z/data=!4m13!1m7!3m6!1s0x0:0x0!2zNTDCsDE5JzUyLjAiTiA0wrAxMicwNy4yIlc!3b1!8m2!3d50.3311!4d-4.202!3m4!1s0x486c94411d32061f:0xc6ba3bcac8fcc931!8m2!3d50.331087!4d-4.2021739&#34; target=&#34;_blank&#34;&gt;The Shop in the Square&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1483.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;看起來美味但是甜到牙痛的聖誕蛋糕-2017-12-17-calstock-homestay&#34;&gt;看起來美味但是甜到牙痛的聖誕蛋糕 (2017-12-17 @Calstock Homestay)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1559.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;香腸美味-烤雞美味-洋蔥有點糊但是還是很美味-2017-12-16-jane-ian-s-homestay&#34;&gt;香腸美味！烤雞美味！洋蔥有點糊但是還是很美味！ (2017-12-16 @Jane&amp;amp;Ian&amp;rsquo;s Homestay)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_20171217_045212.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;在中國城買到最贊的國貨-廈門鐵觀音-2017-12-09-london-china-town&#34;&gt;在中國城買到最贊的國貨！廈門鐵觀音 (2017-12-09 @London China Town)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1374.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;貴到無法下手的三文魚壽司-2017-12-06-waitrose&#34;&gt;貴到無法下手的三文魚壽司 (2017-12-06 @Waitrose)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1356.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;和日本一風堂味道一樣但是貴一倍的豚骨拉麵-2017-12-02-london-ippudo-http-www-ippudo-co-uk&#34;&gt;和日本一風堂味道一樣但是貴一倍的豚骨拉麵 (2017-12-02 @&lt;a href=&#34;http://www.ippudo.co.uk/&#34; target=&#34;_blank&#34;&gt;London Ippudo&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1312.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;學校附近和同學一起去喝過最棒的拿鐵-缺點是杯子太小-2017-12-01-tap-caffee-http-www-tapcoffee-co-uk&#34;&gt;學校附近和同學一起去喝過最棒的拿鐵，缺點是杯子太小 (2017-12-01 @&lt;a href=&#34;http://www.tapcoffee.co.uk/&#34; target=&#34;_blank&#34;&gt;Tap Caffee&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1306.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;brunch-在長頸鹿餐廳可以打8折-2017-11-29-giraffe-https-www-giraffe-net&#34;&gt;Brunch 在長頸鹿餐廳可以打8折 (2017-11-29 @&lt;a href=&#34;https://www.giraffe.net/&#34; target=&#34;_blank&#34;&gt;Giraffe&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1293.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;約克郡的傳統午餐-美味牛肉-2017-11-26-the-judge-s-lodging-https-www-thwaites-co-uk-hotels-and-inns-inns-judges-lodging-at-york-food-and-drink-menus&#34;&gt;約克郡的傳統午餐，美味牛肉 (2017-11-26 @&lt;a href=&#34;https://www.thwaites.co.uk/hotels-and-inns/inns/judges-lodging-at-york/food-and-drink/menus/&#34; target=&#34;_blank&#34;&gt;The Judge&amp;rsquo;s Lodging&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1244.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;謝菲爾德的聖誕街市賣的烤香腸-2017-11-25-sheffield&#34;&gt;謝菲爾德的聖誕街市賣的烤香腸 (2017-11-25 @Sheffield)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1143.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;日本同學從日本帶來的速食味增湯-美味至極-2017-11-23-international-hall&#34;&gt;日本同學從日本帶來的速食味增湯，美味至極 (2017-11-23 @International Hall)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1118.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;國王十字車站對面的新加坡華人餐廳-海南雞飯不錯-2017-11-01-chop-chop-noodle-bar-https-www-google-com-maps-place-chop-chop-noodle-bar-51-5303949-0-1226249-19z-data-4m13-1m7-3m6-1s0x0-0x0-2znthcsdmxjzq5ljgitiawwrawnycyms43ilc-3b1-8m2-3d51-5305-4d-0-1227-3m4-1s0x0-0x252e2c027563f1e4-8m2-3d51-5303959-4d-0-122609&#34;&gt;國王十字車站對面的新加坡華人餐廳，海南雞飯不錯 (2017-11-01 @&lt;a href=&#34;https://www.google.com/maps/place/Chop+Chop+Noodle+Bar/@51.5303949,-0.1226249,19z/data=!4m13!1m7!3m6!1s0x0:0x0!2zNTHCsDMxJzQ5LjgiTiAwwrAwNycyMS43Ilc!3b1!8m2!3d51.5305!4d-0.1227!3m4!1s0x0:0x252e2c027563f1e4!8m2!3d51.5303959!4d-0.122609&#34; target=&#34;_blank&#34;&gt;Chop Chop Noodle Bar&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_0649.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;同學宿舍裏的自制小炒-2017-10-21-the-garden-hall&#34;&gt;同學宿舍裏的自制小炒 (2017-10-21 @The Garden Hall)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_0548.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;大英博物館前的中餐館的水煮魚-2017-10-20-chang-s-noodle-https-www-google-com-maps-place-chang-s-noodle-51-517143-0-1256334-21z-data-4m13-1m7-3m6-1s0x0-0x0-2znthcsdmxjzaxljyitiawwrawnyczms44ilc-3b1-8m2-3d51-5171-4d-0-1255-3m4-1s0x48761b3301f99d9d-0x3ba6ded2ee933a5a-8m2-3d51-5172364-4d-0-1254925&#34;&gt;大英博物館前的中餐館的水煮魚 (2017-10-20 @&lt;a href=&#34;https://www.google.com/maps/place/Chang&#39;s+Noodle/@51.517143,-0.1256334,21z/data=!4m13!1m7!3m6!1s0x0:0x0!2zNTHCsDMxJzAxLjYiTiAwwrAwNyczMS44Ilc!3b1!8m2!3d51.5171!4d-0.1255!3m4!1s0x48761b3301f99d9d:0x3ba6ded2ee933a5a!8m2!3d51.5172364!4d-0.1254925&#34; target=&#34;_blank&#34;&gt;Chang&amp;rsquo;s Noodle&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_0537.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;大英博物館前的都可茶飲買到的原味珍珠奶茶-3-5-有學生優惠-2017-10-20-coco-http-en-coco-tea-com&#34;&gt;大英博物館前的都可茶飲買到的原味珍珠奶茶 £3.5 有學生優惠 (2017-10-20 @&lt;a href=&#34;http://en.coco-tea.com/&#34; target=&#34;_blank&#34;&gt;Coco&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_0534.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;雞腿不錯但是旁邊的配菜有點像中藥味的壓縮餅乾-2017-10-08-ihdining-room&#34;&gt;雞腿不錯但是旁邊的配菜有點像中藥味的壓縮餅乾 (2017-10-08 @IHdining room)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/953062095.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;哈利波特特約飲料-butterbeer-奶油啤酒-2017-10-07-warner-bros-studio-tour-london-https-www-wbstudiotour-co-uk&#34;&gt;哈利波特特約飲料 Butterbeer （奶油啤酒）(2017-10-07 @&lt;a href=&#34;https://www.wbstudiotour.co.uk/&#34; target=&#34;_blank&#34;&gt;Warner Bros. Studio Tour London&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/244977493.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;以爲是甜食的派結果裏面包着牛肉的奇怪料理-2017-10-07-ihdining-room&#34;&gt;以爲是甜食的派結果裏面包着牛肉的奇怪料理 (2017-10-07 @IHdining room)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/1959199628.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;羅素廣場地鐵站門口的小攤賣的超划算味道很正的新鮮草莓-2017-10-05-russel-square-station-https-www-google-co-uk-maps-place-russell-square-station-51-523111-0-1265731-17z-data-3m1-4b1-4m5-3m4-1s0x48761b30d8fe5173-0xcf6c5a5908686210-8m2-3d51-523111-4d-0-1243844-hl-en&#34;&gt;羅素廣場地鐵站門口的小攤賣的超划算味道很正的新鮮草莓！(2017-10-05 @&lt;a href=&#34;https://www.google.co.uk/maps/place/Russell+Square+Station/@51.523111,-0.1265731,17z/data=!3m1!4b1!4m5!3m4!1s0x48761b30d8fe5173:0xcf6c5a5908686210!8m2!3d51.523111!4d-0.1243844?hl=en&#34; target=&#34;_blank&#34;&gt;Russel Square Station&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/1040178656.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;价值5镑的食堂素食色拉一盒-2017-10-02-lshtm食堂&#34;&gt;价值5镑的食堂素食色拉一盒 (2017-10-02@LSHTM食堂)&lt;/h3&gt;

&lt;p&gt;新鮮，但是米飯有點夾生。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/41913438.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;味道超讚牛肉披薩-diavolo-2017-09-28-pizza-express-in-charlotte-street-https-www-pizzaexpress-com-charlotte-street-utm-source-google-utm-medium-places-utm-campaign-charlotte-street&#34;&gt;味道超讚牛肉披薩 Diavolo (2017-09-28 @&lt;a href=&#34;https://www.pizzaexpress.com/charlotte-street?utm_source=Google&amp;amp;utm_medium=Places&amp;amp;utm_campaign=charlotte-street&#34; target=&#34;_blank&#34;&gt;Pizza Express in Charlotte Street&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_20170928_184500.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;菜單上的說明是這樣滴：
Hot spiced beef, pepperoni, mozzarella, tomato, green pepper, red onion and Tabasco, with your choice of hot green, Roquito or jalapeño peppers. Available as Classic or Romana&lt;/p&gt;

&lt;h3 id=&#34;羊肉味的奶油夾心三明治-2017-09-24-store-street-espresso-http-www-storestespresso-co-uk&#34;&gt;羊肉味的奶油夾心三明治 (2017-09-24 @&lt;a href=&#34;http://www.storestespresso.co.uk/&#34; target=&#34;_blank&#34;&gt;Store Street Espresso&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;我點菜之前還故意跟收銀員小妹搭訕，讓她推薦一下今天的特色三明治。
她推薦的這個 Goat Cheese Sandwich。 當然我一開始聽到這名字的時候就有點猶豫。但是想說既然是推薦的應該至少不會有什麼怪味道。結果事實證明了，我的想法是多麼的幼稚。&lt;/p&gt;

&lt;p&gt;看這剛出爐的香噴噴的三明治，我咬下第一口就差點吐了。羊羶味在我喉嚨和鼻腔中打轉。後悔也來不及了。另外我同同時還點了 Espresso。就是特濃咖啡。口味超重！不能喝濃咖啡的一定要慎點！！！！&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/1388034054.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;酸酸的不知道怎麼形容的麵包-日期忘了-估計是剛到的第二個早晨的早餐-ihdining-room&#34;&gt;酸酸的不知道怎麼形容的麵包 (日期忘了，估計是剛到的第二個早晨的早餐@IHdining room)&lt;/h3&gt;

&lt;p&gt;這麵包吃起來鬆鬆的，然額，麵的味道有些酸，又不像是過期食品，而像是本來就應該是這樣的味道的酸麵包。讓人不想再嘗試第二次。。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/890249589.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;美味海鮮飯-2017-09-24-ciao-bella-http-ciaobellarestaurant-co-uk&#34;&gt;美味海鮮飯 (2017-09-24 @&lt;a href=&#34;http://ciaobellarestaurant.co.uk/&#34; target=&#34;_blank&#34;&gt;Ciao Bella&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;感謝&lt;a href=&#34;https://kclpure.kcl.ac.uk/portal/li.yan.html&#34; target=&#34;_blank&#34;&gt;顏師兄&lt;/a&gt;帶領，終於找到了一家可以吃到正常大米的飯店了！且海鮮量超足！&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/737031981.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;看起來很奇怪的整魚炸薯條&#34;&gt;看起來很奇怪的整魚炸薯條&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/656438330.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;外觀其實讓人沒什麼食慾的烤魚&#34;&gt;外觀其實讓人沒什麼食慾的烤魚&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/1628745573.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;酸奶放在白煮雞胸肉上&#34;&gt;酸奶放在白煮雞胸肉上&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_0185.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Notes in London School of Hygiene &amp; Tropical Medicine</title>
      <link>https://winterwang.github.io/project/lshtmlearningnote/</link>
      <pubDate>Tue, 14 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/project/lshtmlearningnote/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;We are drowning in information and starving for knowledge.
Click the graph and you can learn what I learnt.&lt;/p&gt;

&lt;p&gt;&amp;mdash; Chaochen Wang in London 2017.09&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://winterwang.github.io/img/cover.jpg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>徒手打造一個假設檢驗</title>
      <link>https://winterwang.github.io/post/construction-of-a-hypothesis-test/</link>
      <pubDate>Wed, 08 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/construction-of-a-hypothesis-test/</guid>
      <description>&lt;div id=&#34;-hypothesis-testing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;什麼是假設檢驗 Hypothesis testing&lt;/h3&gt;
&lt;p&gt;一般來說，我們的&lt;strong&gt;假設&lt;/strong&gt;（或者叫&lt;strong&gt;假說&lt;/strong&gt;）是對與我們實驗觀察數據來自的總體（或人羣）的&lt;strong&gt;概率分佈&lt;/strong&gt;的描述。在參數檢驗的背景下，就是要檢驗描述這個總體（或人羣）的&lt;strong&gt;概率分佈&lt;/strong&gt;的參數 (parameters)。最典型的情況是，我們提出兩個互補的假設，一個叫作&lt;strong&gt;零假設&lt;/strong&gt;（或者叫&lt;strong&gt;原假設&lt;/strong&gt;），null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;)；另一個是與之對應的（互補的）替代假設，althernative hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_1/H_A\)&lt;/span&gt;)。&lt;/p&gt;
&lt;p&gt;例如，若 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 是一個服從二項分佈的隨機離散變量 &lt;span class=&#34;math inline&#34;&gt;\(X\sim Bin(5, \theta)\)&lt;/span&gt;。可以考慮如下的零假設和替代假設：&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\frac{1}{2}; H_1: \theta=\frac{2}{3}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;當建立了零假設和替代假設以後，假設檢驗就是要建立如下的規則以確定：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;從樣本中計算所得的參數估計值爲多少時，拒絕零假設。（接受替代假設爲“真”）&lt;/li&gt;
&lt;li&gt;從樣本中計算所得的參數估計值爲多少時，零假設不被拒絕。（接受零假設爲“真”）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：（這一段很繞）&lt;/p&gt;
&lt;p&gt;上面的例子是零假設和替代假設均爲簡單假設的情況，實際操作中常常會設計更加複雜的（不對稱的）假設：即簡單的 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;，複雜的 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;。如此一來當零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 不被拒絕時，我們並不一定就接受之。因爲無證據證明 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt; 不等於有證據證明 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;。&lt;em&gt;&lt;strong&gt;(Absence of evidence is not evidence of absence).&lt;/strong&gt;&lt;/em&gt; 換句話說，無證據讓我們拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 本身並不成爲支持 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 爲“真”的證據。因爲在實際操作中，當我們設定的簡單的零假設沒有被拒絕，可能還存在其他符合樣本數據的零假設；相反地，當樣本數據的計算結果拒絕了零假設，我們只能接受替代假設。所以，反對零假設的證據，同時就是支持替代假設的證據。&lt;/p&gt;
&lt;p&gt;在樣本空間 sample space 中，決定了零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 會被拒絕的子集 subset，被命名爲拒絕域 rejection region 或者 判別區域 critical region，用 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 來標記。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;錯誤概率和效能方程&lt;/h3&gt;
&lt;p&gt;這一部分可以參考之前&lt;a href=&#34;https://winterwang.github.io/post/sample-size-in-clinical-trial/&#34;&gt;臨牀試驗樣本量計算&lt;/a&gt;的部分。&lt;/p&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Table 1: Definition of Type I and Type II error
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;border-bottom:hidden&#34; colspan=&#34;2&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;&#34; colspan=&#34;2&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px;&#34;&gt;
SAMPLE
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x} \notin \mathfrak{R}\)&lt;/span&gt; Accept &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x} \in \mathfrak{R}\)&lt;/span&gt; Reject &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;vertical-align: middle !important;&#34; rowspan=&#34;2&#34;&gt;
TRUTH
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; is true
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\checkmark\)&lt;/span&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; &lt;br&gt; Type I error
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt; is true
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; &lt;br&gt; Type II error
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\checkmark\)&lt;/span&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;假如一個假設檢驗是關於總體參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0: \theta=\theta_0 \;vs.\; H_1: \theta=\theta_1 \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這個檢驗的效能被定義爲當替代假設爲“真”時，拒絕零假設的概率（能夠檢驗出有真實差別的能力）：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Power&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(=Prob(\underline{x}\in\mathfrak{R}|H_1\; is\; true) = 1-Prob(Type \; II\; error)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;檢驗的顯著性水平用 &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; 來表示。&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; 的直觀意義就是，檢驗結果錯誤的拒絕了零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;，接受了替代假設 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;，即假陽性的概率。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Prob(\underline{x}\in \mathfrak{R} |H_0 \;is\;true)=Prob(Type\;I\;error)\)&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈爲例&lt;/h4&gt;
&lt;p&gt;用本文開頭的例子： &lt;span class=&#34;math inline&#34;&gt;\(X\sim Bin(5,\theta)\)&lt;/span&gt;。和我們建立的零假設和替代假設：&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\frac{1}{2}; H_1: \theta=\frac{2}{3}\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;考慮兩種檢驗方法：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;A 方法：當且僅當5次觀察都爲“成功”時才拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0 (i.e.\; X=5)\)&lt;/span&gt;。所以此時判別區域 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 爲 &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;。檢驗效能爲：&lt;span class=&#34;math inline&#34;&gt;\(Prob(X=5|H_1 \;is\;true)=(\frac{2}{3})^5=0.1317\)&lt;/span&gt;。顯著性水平爲 &lt;span class=&#34;math inline&#34;&gt;\(Prob(X=5|H_0\;is\;true)=(\frac{1}{2})^5=0.03125\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;B 方法：當觀察到3,4,5次“成功”時，拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0 (i.e.\; X=3,4,5)\)&lt;/span&gt;。此時判別區域 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 爲 &lt;span class=&#34;math inline&#34;&gt;\(3,4,5\)&lt;/span&gt;。檢驗效能爲：&lt;span class=&#34;math inline&#34;&gt;\(Prob(X=3,4,or\:5|H_1\;is\;ture)=\sum_{i=3}^5(\frac{2}{3})^i(\frac{1}{3})^{5-i}\approx0.7901\)&lt;/span&gt;；顯著性水平爲：&lt;span class=&#34;math inline&#34;&gt;\(Prob(X=3,4,5|H_0\;is\;true)=\sum_{i=3}^5(\frac{1}{2})^i(\frac{1}{2})^{5-i}=0.5\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the power in test B
dbinom(3,5,2/3)+dbinom(4,5,2/3)+dbinom(5,5,2/3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7901235&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the size in test B
dbinom(3,5,0.5)+dbinom(4,5,0.5)+dbinom(5,5,0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;比較上面兩種檢驗方法，可以看到，用B方法時，我們有更高的概率獲得假陽性結果（第一類錯誤，錯誤地拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;，接受 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;)，但是也有更高的檢驗效能（真陽性更高）。這個例子就說明了，試圖提高檢驗效能的同時，會提高犯第一類錯誤的概率。實際操作中我們常常將第一類錯誤的概率固定，例如 &lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05\)&lt;/span&gt;，然後儘可能選擇效能最高的檢驗方法。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;如何選擇要檢驗的統計量&lt;/h3&gt;
&lt;p&gt;在上面的二項分佈的實驗中，“成功的次數” 是我們感興趣的要檢驗的統計量。但也可能是第一次出現 “成功” 之前的實驗次數，或者，任何與假設相關的統計量。相似的，如果觀察不是離散變量而是連續的，可以拿來檢驗的指標就有很多，如均值，中位數，衆數，幾何平均值等。&lt;/p&gt;
&lt;p&gt;幸運地是，當明確了零假設和替代假設後，我們可以利用 &lt;a href=&#34;https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma&#34;&gt;Neyman-Pearson lemma&lt;/a&gt; 似然比公式&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;來決定使用哪個統計量做檢驗&lt;strong&gt;最有效&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[=\frac{L_{H_0}}{L_{H_1}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這公式很直觀，因爲當數據更加支持 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt; 時 (&lt;span class=&#34;math inline&#34;&gt;\(L_{H_1}\)&lt;/span&gt; 更大)，&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的可能性相對更小，就更應該被拒絕。而且，由於似然比越小，他的對數就越小，使用對數似然比常常更加直觀：&lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;那到底要多小才算小？這個進入拒絕域的閾值由兩個指標來決定：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;被檢驗統計量的樣本分佈&lt;/li&gt;
&lt;li&gt;第一類錯誤概率 &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;以已知方差的正態分佈爲例&lt;/h4&gt;
&lt;p&gt;假如已知 &lt;span class=&#34;math inline&#34;&gt;\(X_1, \cdots, X_n \stackrel{i.i.d}{\sim} N(\mu, \sigma^2)\)&lt;/span&gt; 而且方差 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 也是已知的。如果令 &lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu=5\; ;H_1: \mu=10\)&lt;/span&gt; 可以通過如下的方法找到我們需要的最佳檢驗統計量 &lt;u&gt;best statistic&lt;/u&gt; 根據之前的&lt;a href=&#34;https://winterwang.github.io/post/log-likelihood-ratio/&#34;&gt;推導&lt;/a&gt;可知正態分佈的似然方程如下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\ell(\mu|\underline{x}) =-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以已知 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 時，我們的零假設和替代假設之間的對數似然比 &lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\ell_{H_0}-\ell_{H_1}=-\frac{1}{2\sigma^2}(\sum_{i=1}^n(x_i-5)^2-\sum_{i=1}^n(x_i-10)^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然俄，我們只需要考慮隨着數據變化的部分，所以忽略掉不變的部分&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\ell_{H_0}-\ell_{H_1} &amp;amp; = -(\sum_{i=1}^n(x_i-5)^2-\sum_{i=i}^n(x_i-10)^2)\\
                &amp;amp; = 75n - 2\times(10-5)\sum_{i=1}^nx_i \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以只要樣本和 &lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^nx_i\)&lt;/span&gt; &lt;u&gt;(最佳統計量 best statistic)&lt;/u&gt; 足夠大，零假設就會被拒絕。而且注意到最佳統計量可以乘以任何常數用作新的最佳統計量。所以爲了方便我們就用樣本均數 &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{n}\sum_{i=1}^nx_i\)&lt;/span&gt; 作此處的最佳統計量。所以此時，我們的最佳檢驗就是當樣本均值足夠大，超過某個閾值時，我們拒絕零假設。而且，樣本均值的樣本分佈是可以知道的，這樣就便於我們繼續計算下一步：拒絕域 （判別區域）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-composite-hypotheses&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;複合假設 composite hypotheses&lt;/h3&gt;
&lt;p&gt;目前爲止我們討論的假設檢驗限制太多，實際操作時，我們多考慮類似如下的假設：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\theta_0 \;v.s.\; H_1: \theta&amp;gt;\theta_0\)&lt;/span&gt; [&lt;strong&gt;單側&lt;/strong&gt;的替代假設]&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\theta_0 \;v.s.\; H_1: \theta\neq\theta_0\)&lt;/span&gt; [&lt;strong&gt;雙側&lt;/strong&gt;的替代假設]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以我們面臨的問題是簡單假設中用於判定的最佳統計量，是否還適用？我們一一來看：&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;單側替代假設&lt;/h4&gt;
&lt;p&gt;之前的推導中我們發現，樣本均值越大，零假設和替代假設的對數似然比 &lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt; 越小。所以我們在樣本均值較大時，拒絕零假設，那麼就可以把原來使用的簡單替代假設 &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu=10\)&lt;/span&gt; 擴展爲，任意大於 &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; ，即 &lt;span class=&#34;math inline&#34;&gt;\(\mu&amp;gt;5\)&lt;/span&gt; 。因爲大於 &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; 的任何均值，都提供了更小的對數似然比，都會讓我們拒絕零假設。所以在正態分佈時，單側替代假設的最佳檢驗統計量還是&lt;strong&gt;樣本均值&lt;/strong&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;雙側替代假設&lt;/h4&gt;
&lt;p&gt;雙側替代假設的情況下，我們無法繼續使用樣本均值作爲最佳統計量。因爲當我們想檢驗：&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu=5 \;v.s.\; H_1: \mu&amp;lt;5\)&lt;/span&gt; 時，必須獲得足夠小的樣本均值才能讓我們拒絕零假設。先按下不表。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-how-to-quantify-evidence-against-h_0&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;如何獲得反對零假設的證據 how to quantify evidence against &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;重新再考慮符合假設：&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\theta_0\;v.s.\;H_1: \theta&amp;gt;\theta_0\)&lt;/span&gt; 假如存在一個總是可用的最佳檢驗統計量，用 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 來標記 (或 &lt;span class=&#34;math inline&#34;&gt;\(T(x)\)&lt;/span&gt;)， 這個統計量足夠大時，我們拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;。 別忘了我們還要定義判別區域：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(\underline{x}\in\mathfrak{R}|H_0)=\alpha\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果我們知道 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 的樣本分佈，我們很容易就可以使用一個閾值 &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; 來定義這個判別區域：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(T\geqslant c|H_0)=\alpha\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;更加正式的，我們定義判別區域 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\{\underline{x}:Prob(T(x)\geqslant c|H_0)=\alpha\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;換句話說，當統計量 &lt;span class=&#34;math inline&#34;&gt;\(T&amp;gt;c\)&lt;/span&gt; 時，我們拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 。如果先不考慮拒絕或不拒絕的二元判定，我們可以用一個連續型測量值來量化反對零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的證據。再考慮從觀察數據中獲得的 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; ，即數據告訴我們的 &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; 。所以，當 &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; 值越大，說明觀察值相對零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 越往極端的方向走。因此我們可以用 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 的樣本分佈來計算觀察值大大於等於這個閾值（極端值）時的概率：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p=Prob(T\geqslant t|H_0)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這個概率公式被稱爲是單側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值 &lt;strong&gt;(one-side p-value)&lt;/strong&gt;。單側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值越小，統計量 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 的樣本空間就有越小比例（越強）的證據支持零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;我們把這以思想用到假設檢驗中時，就可以認爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p&amp;lt;\alpha \Leftrightarrow t&amp;gt;c\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以用我們一貫的設定 &lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05\)&lt;/span&gt;，所以如果計算獲得 &lt;span class=&#34;math inline&#34;&gt;\(p&amp;lt;0.05\)&lt;/span&gt; 我們就認爲獲得了足夠強的拒絕零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的證據。&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;回到正態分佈的均值比較問題上來（單側替代假設）&lt;/h4&gt;
&lt;p&gt;繼續考慮 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim} N(\mu, \sigma^2)\)&lt;/span&gt;，假設已知 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2=10\)&lt;/span&gt;，我們要檢驗的是 &lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu=5 \;v.s.\; H_1: \mu&amp;gt;5\)&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;確定最佳檢驗統計量：已經證明過，單側替代假設的最佳檢驗統計量是&lt;strong&gt;樣本均值&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;確定該統計量的樣本分佈：已知樣本均數的樣本分佈是 &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\sim N(\mu,\sigma^2/n)\)&lt;/span&gt; 。&lt;br&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)\)&lt;/span&gt;，所以在 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 條件下，&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow Z=\frac{\bar{X}-5}{\sqrt{10}/\sqrt{n}} \sim N(0,1)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;所以當一個檢驗的一類錯誤概率設定爲 &lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05\)&lt;/span&gt; 時，我們使用的判別區域使統計量據落在該判別區域內的概率爲 &lt;span class=&#34;math inline&#34;&gt;\(0.05\)&lt;/span&gt;：&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(Prob(\bar{X}\geqslant c|H_0) = 0.05\)&lt;/span&gt; &lt;br&gt; 已知在標準正態分佈時，&lt;span class=&#34;math inline&#34;&gt;\(Prob(Z\geqslant1.64)=0.05=Prob(\frac{\bar{X}-5}{\sqrt{10}/\sqrt{n}}\geqslant1.64)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;假設樣本量是 &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;，那麼數據的判別區域 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 就是 &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\geqslant6.64\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;假設觀察數據告訴我們，&lt;span class=&#34;math inline&#34;&gt;\(\bar{X}=7.76\)&lt;/span&gt; 。那麼這一組觀察數據計算得到的統計量落在了判別區域內，所以說是有足夠的證據拒絕接受 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的。&lt;/li&gt;
&lt;li&gt;我們可以給這個觀察數據計算相應的單側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值：&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(p=Prob(\bar{X}\geqslant7.76|H_0)=Prob(Z+5\geqslant7.76)\\=Prob(Z\geqslant2.76)=0.003\)&lt;/span&gt; &lt;br&gt; 所以，數據告訴我們，在 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的前提下，觀察值出現的概率是 &lt;span class=&#34;math inline&#34;&gt;\(0.3\%\)&lt;/span&gt; 。即，在無數次取樣實驗中，僅有 &lt;span class=&#34;math inline&#34;&gt;\(0.3\%\)&lt;/span&gt; 的結果可以給出支持 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的證據。因此我們拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 接受 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-p-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;雙側替代假設情況下，雙側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值的定量方法&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-08-construction-of-a-hypothesis-test_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;此處故意使用一個左右不對稱的概率密度分佈來解釋。&lt;/p&gt;
&lt;p&gt;現在的替代假設是雙側的：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0: \theta=\theta_0 \;v.s.\; H_1:  \theta\neq\theta_0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;正常來說，雙側的假設檢驗應該分成兩個單側檢驗。即：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1: \theta&amp;gt;\theta_0\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1: \theta&amp;lt;\theta_0\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;每個單側檢驗都有自己的最佳檢驗統計量。令 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 是 1. 的最佳檢驗統計量，該統計量的樣本分佈如上圖所示（左右不對稱）。假如觀察數據給出的統計量爲 &lt;span class=&#34;math inline&#34;&gt;\(t2\)&lt;/span&gt;，那麼在概率上反對零假設的情況可以有兩種：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(T\geqslant t2\)&lt;/span&gt; 其中， &lt;span class=&#34;math inline&#34;&gt;\(Prob(T\geqslant t2|H_0)=p1\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(T\leqslant t1\)&lt;/span&gt; 其中， &lt;span class=&#34;math inline&#34;&gt;\(Prob(T\leqslant t1|H_0) =p1\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以概率密度分佈兩側的距離可以不對稱，但是只要左右兩側概率密度分佈的面積(&lt;span class=&#34;math inline&#34;&gt;\(=p1\)&lt;/span&gt;)相同，那麼就可以直接認爲，雙側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值是兩側面積之和 (&lt;span class=&#34;math inline&#34;&gt;\(p=2\times p1\)&lt;/span&gt;)，且觀察數據提供的統計量落在這兩個面積內的話，都足以提供證據拒絕零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;回到上文中單側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值爲&lt;span class=&#34;math inline&#34;&gt;\(0.003\)&lt;/span&gt;，故雙側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值就是它的兩倍：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(p1=Prob(\bar{X}\geqslant7.76|H_0)=Prob(Z+5\geqslant7.76)\\=Prob(Z\geqslant2.76)=0.003\\ \Rightarrow p=2\times p1=0.006\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;區分與&lt;a href=&#34;https://winterwang.github.io/post/log-likelihood-ratio/&#34;&gt;之前討論的似然比&lt;/a&gt;，之前討論的似然比只是所有的似然和極大似然之間的比，此處的似然比只是純粹在探討兩個假設之間可能性之比。&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Rememer that &lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt; is a random variable: the data varies &lt;strong&gt;each time&lt;/strong&gt; we sample, with consequently varying relative support for the hypotheses, and so we are only interested in that part of &lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt; which depends on the results, the data, which vary with each sample (i.e. which contains the random part); the constant part provides no information on the relative support the data give to the hypotheses, so we ignore it.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>二次方程近似法求對數似然比 approximate log-likelihood ratios</title>
      <link>https://winterwang.github.io/post/approximate-log-likelihood-ratios/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/approximate-log-likelihood-ratios/</guid>
      <description>&lt;p&gt;爲什麼要用二次方程近似對數似然比方程？&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;上節也看到，我們會碰上難以用代數學計算獲得對數似然比信賴區間的情況 (&lt;a href=&#34;https://winterwang.github.io/post/log-likelihood-ratio/&#34;&gt;binomial example&lt;/a&gt;)。&lt;/li&gt;
&lt;li&gt;我們同時知道，對數似然比方程會隨着樣本量增加而越來越漸進於二次方程，且左右對稱。&lt;/li&gt;
&lt;li&gt;所以，我們考慮當樣本量足夠大時，用二次方程來近似對數似然比方程從而獲得參數估計的信賴區間。&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;-normal-approximation-to-the-log-likelihood&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;正態近似法求對數似然 Normal approximation to the log-likelihood&lt;/h3&gt;
&lt;p&gt;根據&lt;a href=&#34;https://winterwang.github.io/post/log-likelihood-ratio/&#34;&gt;前一節&lt;/a&gt;，如果樣本均數的分佈符合正態分佈：&lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\sim N(\mu, \sigma^2/n)\)&lt;/span&gt;。那麼樣本均數的對數似然比爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\mu|\bar{X})=\ell(\mu|\bar{X})=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中， &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; 是正態分佈總體均數 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 的極大似然估計 (maximum likelihood estimator, MLE)。如果已知總體的方差參數，那麼 &lt;span class=&#34;math inline&#34;&gt;\(\sigma/\sqrt{n}\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; 的標準誤 (standard error)。&lt;/p&gt;
&lt;p&gt;因此，假設 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 是我們想尋找的總體參數。有些人提議可以使用下面的關於 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的二次方程來做近似：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(\theta|data)=-\frac{1}{2}(\frac{\theta-M}{S})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;上述方程具有一個正態二次對數似然 (比) 的形式，而且該方程的極大似然估計(MLE)， &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 的標準誤爲 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;。如果我們正確地選用 &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;，那我們就可以用這樣的方程來近似求真實觀察數據的似然 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;通過近似正態對數似然比，&lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 應當選用使方程取最大值時，參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的極大似然估計 &lt;span class=&#34;math inline&#34;&gt;\(M=\hat{\Theta}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;但是在選用標準誤 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 上必須滿足下列條件：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 是極大似然估計 &lt;span class=&#34;math inline&#34;&gt;\(\hat{\Theta}\)&lt;/span&gt; 的標準誤。&lt;/li&gt;
&lt;li&gt;被選擇的 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 必須儘可能的使該二次方程形成一個十分接近真實的對數似然比方程。特別是在最大值的部分必須與之無限接近或者一致。所以二者在 MLE 的位置應當有相同的曲率（二階導數）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由於，一個方程的曲率是該方程的二階導數（斜線斜率變化的速度）。所以對數似然比方程在 MLE 取最大值時的曲率（二階導數）爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left.\frac{d^2}{d\theta^2}\ell(\theta)\right\vert_{\theta=\hat{\theta}}=\ell^{\prime\prime}(\hat{\theta})=-\frac{1}{S^2}\\
\Rightarrow S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;在正態分佈的例子下，&lt;span class=&#34;math inline&#34;&gt;\(M=\bar{x}, S=\sigma/\sqrt{n}\)&lt;/span&gt;。對數似然比方程最大值時的曲率（二階導數）恰好就爲標準誤的平方的負倒數：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\ell^{\prime\prime}(\theta)=-\frac{1}{SE^2}\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow\)&lt;/span&gt; 被叫做 &lt;strong&gt;Fisher information&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;稍微總結一下：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;任意的對數似然比方程 &lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)\)&lt;/span&gt; 都可以考慮用一個二次方程來近似：
&lt;span class=&#34;math display&#34;&gt;\[f(\theta|data)=-\frac{1}{2}(\frac{\theta-M}{S})^2\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;其中&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  &amp;amp;M=\hat\theta\\  &amp;amp;S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}\\  &amp;amp;when \\  &amp;amp; n\rightarrow\infty \Rightarrow  \begin{cases}  S^2\rightarrow Var(\hat\theta) \\  S\rightarrow SE(\hat\theta)  \end{cases}  \end{aligned}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;近似法估算對數似然比的信賴區間&lt;/h4&gt;
&lt;p&gt;一旦我們決定了使用正態近似法來模擬對數似然比方程，對數似然比的信賴區間算法就回到了前一節中我們算過的方法，也就是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2f(\theta)&amp;lt;\mathcal{X}_{1,(1-\alpha)}^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;故信賴區間爲： &lt;span class=&#34;math inline&#34;&gt;\(m\pm\sqrt{\mathcal{X}_{1,(1-\alpha)}^2}S\)&lt;/span&gt;。求&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 水平的信賴區間時，&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{X}_{1,0.95}^2=3.84\)&lt;/span&gt;，所以就又看到了熟悉的 &lt;span class=&#34;math inline&#34;&gt;\(M\pm1.96S\)&lt;/span&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;以泊松分佈爲例&lt;/h4&gt;
&lt;p&gt;一個被追蹤的樣本，經過了 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 人年的觀察，記錄到了 &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; 個我們要研究的事件：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[D\sim Poi(\mu), where \mu=\lambda p\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 1. 找極大似然估計 (MLE)，&lt;a href=&#34;https://winterwang.github.io/post/likelihood/&#34;&gt;之前介紹似然方程時推導過的泊松分佈的似然方程&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
P(D=d|\lambda) &amp;amp;= \frac{e^{-\mu}\cdot\mu^d}{d!} \\
 &amp;amp;=\frac{e^{-\lambda p}\cdot\lambda^d p^d}{d!} \\
omitting&amp;amp;\;terms\;not\;in\;\mu \\
&amp;amp;\Rightarrow \ell(\lambda) = dlog\lambda - \lambda p \\
&amp;amp;\Rightarrow \ell^\prime(\lambda) = \frac{d}{\lambda} -p \\
&amp;amp;\Rightarrow \hat\lambda=\frac{d}{p} = \textbf{M}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 2. 求似然方程的二階導數，確認 MLE 是使方程獲得最大值的點，然後確定 &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
&amp;amp; \ell^\prime(\lambda) = \frac{d}{\lambda} -p \\
&amp;amp; \Rightarrow \ell^{\prime\prime}(\lambda) = -\frac{d}{\lambda^2}&amp;lt;0 \Rightarrow \textbf{MLE is maximum} \\
&amp;amp; S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\lambda)}\right\vert_{\lambda=\hat{\lambda}=d/p} = -\frac{1}{-d/\hat\lambda^2} = -\frac{1}{-d/(d/p)^2} \\
&amp;amp;\Rightarrow S^2 = \frac{d}{p^2} \\
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 3. 把前兩部求得的 &lt;span class=&#34;math inline&#34;&gt;\(MLE\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt; 代入近似的二次方程：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
&amp;amp; \hat\lambda=\frac{d}{p}=M,\; S^2 = \frac{d}{p^2}  \\
&amp;amp; using\;approximate\;quadratic\;llr \\
&amp;amp; q(\lambda) = -\frac{1}{2}(\frac{\lambda-M}{S})^2\\
&amp;amp;\Rightarrow q(\lambda) = -\frac{1}{2}(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2\\
&amp;amp; let \; q(\lambda)=-1.92\\
&amp;amp;\Rightarrow -\frac{1}{2}(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2=-1.92\\
&amp;amp;(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2=3.84\\
&amp;amp;\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}} = \pm1.96\\
&amp;amp;\Rightarrow 95\%CI \;for \;\lambda = \frac{d}{p}\pm1.96\frac{\sqrt{d}}{p}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;結論就是： 發病（死亡）率 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間爲： &lt;span class=&#34;math inline&#34;&gt;\(M\pm1.96S\)&lt;/span&gt;。所以我們不需要每次都代入對數似然比方程，只要算出 &lt;span class=&#34;math inline&#34;&gt;\(MLE = M\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 之後代入這個公式就可以用二次方程近似法算出信賴區間。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈爲例&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[K\sim Bin(n,\pi)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 1. 找極大似然估計 (MLE)：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
&amp;amp; Prob(K=k) = \pi^k(1-\pi)\binom{n}{k}\\
&amp;amp;\Rightarrow L(\pi|k) = \pi^k(1-\pi)\binom{n}{k}\\
&amp;amp;omitting\;terms\;not\;in\;\pi \\
&amp;amp;\Rightarrow \ell(\pi) = k\:log\pi+(n-k)log(1-\pi) \\
&amp;amp;\ell^\prime(\pi) = \frac{k}{\pi}-\frac{n-k}{1-\pi} \\
&amp;amp; let\;\ell^\prime(\hat\pi) =0 \\
&amp;amp;\Rightarrow \frac{k}{\hat\pi}-\frac{n-k}{1-\hat\pi}=0\\
&amp;amp;\Rightarrow \frac{\hat\pi}{1-\hat\pi}=\frac{k}{n-k}\\
&amp;amp;\Rightarrow \frac{\hat\pi}{1-\hat\pi}=\frac{k/n}{1-k/n}\\
&amp;amp;\Rightarrow \hat\pi=\frac{k}{n} = p = \textbf{M}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 2. 將對數似然方程的二次微分 (二階導數)，確認在 MLE 爲極大值，並確認 &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
&amp;amp;\ell^\prime(\pi) = \frac{k}{\pi}-\frac{n-k}{1-\pi} \\
&amp;amp;\ell^{\prime\prime}(\pi)=\frac{-k}{\pi^2}-\frac{n-k}{(1-\pi)^2} &amp;lt;0 \\
&amp;amp;\therefore at\;\textbf{MLE}\;\ell(\pi)\;has\;maximum \\
S^2&amp;amp;=\left.-\frac{1}{\ell^{\prime\prime}(\pi)}\right\vert_{\pi=\hat\pi=k/n=p}\\
&amp;amp;=\frac{1}{\frac{k}{\hat\pi^2}+\frac{n-k}{(1-\hat\pi)^2}}\\
&amp;amp;=\frac{\hat\pi^2(1-\hat\pi)^2}{k(1-\hat\pi)^2+(n-k)\hat\pi^2}\\
&amp;amp;=\frac{P^2(1-P)^2}{np(1-p)^2+(n-np)p^2}\\
&amp;amp;=\frac{p(1-p)}{n(1-p)+np}\\
&amp;amp;=\frac{p(1-p)}{n}\\
&amp;amp;\Rightarrow S=\sqrt{\frac{p(1-p)}{n}}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 3. 將求得的 MLE 和 &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt; 代入近似信賴區間：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
95\% CI \;for \; \pi:\\
M\pm1.96S=p\pm1.96\sqrt{\frac{p(1-p)}{n}}\\
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-parameter-transformations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;參數轉化 parameter transformations&lt;/h3&gt;
&lt;p&gt;如果將參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 通過某種數學方程轉化成 &lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;，那麼我們可以認爲，轉化後的方程的 MLE 爲 &lt;span class=&#34;math inline&#34;&gt;\(g(\hat\theta)\)&lt;/span&gt;，其中 &lt;span class=&#34;math inline&#34;&gt;\(\hat\theta\)&lt;/span&gt; 是參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的 MLE。&lt;/p&gt;
&lt;p&gt;類似地，如果 &lt;span class=&#34;math inline&#34;&gt;\(\theta_1 \sim \theta_2\)&lt;/span&gt; 是參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的似然比信賴區間，那麼 &lt;span class=&#34;math inline&#34;&gt;\(g(\theta_1)\sim g(\theta_2)\)&lt;/span&gt; 就是 &lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt; 的似然比信賴區間。&lt;/p&gt;
&lt;p&gt;以下爲轉換參數以後獲取信賴區間的步驟：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;將參數通過某些數學方程（通常是取對數）轉化，使新的對數似然比方程更加接近二次方程的對稱圖形。&lt;br&gt; Transform parameter so that &lt;span class=&#34;math inline&#34;&gt;\(llr\)&lt;/span&gt; is closer to a quadratic shape.&lt;/li&gt;
&lt;li&gt;用本節學到的二次方程近似法，求得轉化後的參數的似然比信賴區間。 &lt;br&gt; Use our quadratic approximation on the transformed parameter to calculate our likelihood ratio confidence intervals.&lt;/li&gt;
&lt;li&gt;將第2步計算獲得的似然比信賴區間再通過轉化參數時的逆函數轉換回去，以獲得原參數的似然比信賴區間。&lt;br&gt; Transform the confidence intervals back, or to any scale we wish – they remain valid.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以泊松分佈爲例&lt;/h4&gt;
&lt;p&gt;當我們用泊松分佈模擬事件在某段時間內發生率 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 時，注意到這個事件發生率必須滿足 &lt;span class=&#34;math inline&#34;&gt;\(\lambda&amp;gt;0\)&lt;/span&gt;。當事件發生次數較低時，會讓似然方程的圖形被擠壓在低值附近。如果嘗試用對數轉換 &lt;span class=&#34;math inline&#34;&gt;\(\lambda \rightarrow log(\lambda)\)&lt;/span&gt; 此時 &lt;span class=&#34;math inline&#34;&gt;\(log(\lambda)\)&lt;/span&gt; 就不再被限制與 &lt;span class=&#34;math inline&#34;&gt;\(&amp;gt;0\)&lt;/span&gt;。下面我們嘗試尋找對數轉換過後的 &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(\beta=log(\lambda), \Rightarrow e^\beta=\lambda\)&lt;/span&gt; 從本文上半部分中我們已知 &lt;span class=&#34;math inline&#34;&gt;\(\hat\lambda=\frac{d}{p}\)&lt;/span&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對數轉換以後的 &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 是什麼? &lt;br&gt;根據定義，&lt;span class=&#34;math inline&#34;&gt;\(MLE(\beta)=MLE[log(\lambda)]=log(\hat\lambda)\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow M=\hat\beta=log(\frac{d}{p})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;對數轉換以後的 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 是什麼? &lt;br&gt; 泊松分佈的對數似然方程是：&lt;span class=&#34;math inline&#34;&gt;\(\ell(\lambda|d)=d log(\lambda) - \lambda p\)&lt;/span&gt; 用 &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; 替換掉 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;&lt;/p&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  &amp;amp; \ell(\beta|d)=d \beta - pe^\beta\\  &amp;amp; \Rightarrow \ell^\prime(\beta)=d-pe^\beta \Rightarrow \ell^{\prime\prime}(\beta)=-pe^\beta \\  &amp;amp; S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\beta)}\right\vert_{\beta=\hat{\beta}} = \left.\frac{1}{pe^\beta}\right\vert_{\beta=\hat{\beta}} = \frac{1}{pe^{log(d/p)}}\\  &amp;amp;\Rightarrow S^2=\frac{1}{d} \therefore S=\frac{1}{\sqrt{d}} \end{aligned}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;轉換後的近似二次方程：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  &amp;amp; q(\beta) = -\frac{1}{2}(\frac{\beta-M}{S})^2 = -\frac{1}{2}(\frac{\beta-log(\frac{d}{p})}{\frac{1}{\sqrt{d}}})^2  \end{aligned}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間 &lt;span class=&#34;math inline&#34;&gt;\(=log(\frac{d}{p})\pm1.96\frac{1}{\sqrt{d}}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間 &lt;span class=&#34;math inline&#34;&gt;\(=exp(log(\frac{d}{p})\pm1.96\frac{1}{\sqrt{d}})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈爲例&lt;/h4&gt;
&lt;p&gt;在研究對象 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 人中觀察到 &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; 個人患有某種疾病。&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(\beta=log(\pi) \Rightarrow \pi=e^\beta\)&lt;/span&gt; 從上文的推倒也已知 &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=\frac{k}{n}=p\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned} &amp;amp;\Rightarrow \ell(\beta)=klog\pi+(n-k)log(1-\pi)=k\beta+(n-k)log(1-e^\beta) \\ &amp;amp;\Rightarrow \ell^{\prime}(\beta)=k-\frac{(n-k)(e^\beta)}{1-e^\beta} \\ &amp;amp;\Rightarrow \ell^{\prime\prime}(\beta)=-(n-k)\frac{e^\beta(1-e^\beta)+e^{2\beta}}{(1-e^\beta)^2} \\ &amp;amp; \ell^{\prime\prime}(\beta)= -(n-k)\frac{e^\beta}{(1-e^\beta)^2}\\ &amp;amp;\Rightarrow S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\beta)}\right\vert_{\beta=\hat{\beta}} = \frac{(1-e^{\hat\beta})^2}{(n-k)e^{\hat\beta}} \\ &amp;amp;\because \hat\beta=log(\hat\pi) \\ &amp;amp;\therefore e^{\hat\beta} = \frac{k}{n}\\ &amp;amp;\Rightarrow S^2=\frac{(1-\frac{k}{n})^2}{(n-k)\frac{k}{n}}=\frac{n-k}{nk}=\frac{1}{k}-\frac{1}{n}\\ &amp;amp; \Rightarrow S=\sqrt{\frac{1}{k}-\frac{1}{n}}\\ \end{aligned}\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exercise&lt;/h3&gt;
&lt;div id=&#34;q1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q1&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;在&lt;span class=&#34;math inline&#34;&gt;\(n=100\)&lt;/span&gt;人中觀察到有&lt;span class=&#34;math inline&#34;&gt;\(k=40\)&lt;/span&gt;人患病，假設每個人只有患病，不患病兩個狀態，用二項分佈來模擬這個數據，&lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 爲患病的概率。下面是 &lt;span class=&#34;math inline&#34;&gt;\(\pi \in [0.2,0.6]\)&lt;/span&gt; 區間的對數似然比方程曲線。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pi &amp;lt;- seq(0.2, 0.6, by=0.01)
L &amp;lt;- (pi^40)*((1-pi)^60)
Lmax &amp;lt;- rep(max(L), 41)
LR &amp;lt;- L/Lmax
logLR &amp;lt;- log(LR)

plot(pi, logLR, type = &amp;quot;l&amp;quot;, ylim = c(-11, 0),yaxt=&amp;quot;n&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;logLR(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
grid(NA, 5, lwd = 2) # add some horizontal grid on the background
axis(2, at=seq(-12,0,2), las=2)
title(main = &amp;quot;Figure 1. Binomial log-likelihood ratio&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;用一個二次方程來模擬上面的對數似然比曲線：&lt;span class=&#34;math inline&#34;&gt;\(f(\pi)=-\frac{(\pi-M)^2}{2S^2}\)&lt;/span&gt;，其中 &lt;span class=&#34;math inline&#34;&gt;\(M=\hat\pi=\frac{k}{n}=0.4\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(S^2=\frac{p(1-p)}{n}=0.0024\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mai = c(1.2, 0.5, 1, 0.7))
quad &amp;lt;- -(pi-0.4)^2/(2*0.0024)
plot(pi, quad, type = &amp;quot;l&amp;quot;, ylim = c(-4, 0),yaxt=&amp;quot;n&amp;quot;, col=&amp;quot;red&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
lines(pi, logLR, col=&amp;quot;black&amp;quot;)
grid(NA, 4, lwd = 1) # add some horizontal grid on the background
axis(2, at=seq(-4,0,1), las=2)
title(main = &amp;quot;Figure 2. Quadratic approximation\n of binomial log-likelihood ratio \n 40 out of 100 subjects&amp;quot;)
abline(h=-1.92, lty=1, col=&amp;quot;red&amp;quot;)
axis(4, at=-1.92, las=2)

legend(x=0.27, y= -5.5 ,xpd = TRUE,  legend=c(&amp;quot;logLR&amp;quot;,&amp;quot;Quadratic&amp;quot;), bty = &amp;quot;n&amp;quot;,
       col=c(&amp;quot;black&amp;quot;,&amp;quot;red&amp;quot;), lty=c(1,1), horiz = TRUE) #the legend is below the graph&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q2&lt;/h4&gt;
&lt;p&gt;依舊使用二項分佈數據來模擬，觀察不同的事件數量和樣本量對近似計算的影響。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;類比上面的問題，用同樣的 &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.4\)&lt;/span&gt;，但是 &lt;span class=&#34;math inline&#34;&gt;\(n=10, k=4\)&lt;/span&gt; 時的圖形：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.4, n=1000, k=400\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.01, n=100, k=1\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意此圖中紅線提示的近似二次曲線，信賴區間的下限已經低於0，是無法接受的近似。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.01, n=1000, k=10\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.01, n=10000, k=100\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.99, n=100, k=99\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意此圖中紅線提示的近似二次曲線，信賴區間的上限已經大於1，和上面的 Figure 5. 一樣也是無法接受的近似。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;總結： 二次方程近似時，在二項分佈的情況下，隨着 &lt;span class=&#34;math inline&#34;&gt;\(n, k\)&lt;/span&gt; 增加，近似越理想。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>對數似然比 Log-likelihood ratio</title>
      <link>https://winterwang.github.io/post/log-likelihood-ratio/</link>
      <pubDate>Sun, 05 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/log-likelihood-ratio/</guid>
      <description>&lt;script src=&#34;https://winterwang.github.io/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;-log-likelihood-ratio&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;對數似然比 Log-likelihood ratio&lt;/h3&gt;
&lt;p&gt;對數似然比的想法來自於將對數似然方程圖形的 &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 軸重新調節 (rescale) 使之最大值爲零。這可以通過計算該分佈方程的&lt;strong&gt;對數似然比 (log-likelihood ratio)&lt;/strong&gt; 來獲得：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\theta)=\ell(\theta|data)-\ell(\hat{\theta}|data)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由於 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta)\)&lt;/span&gt; 的最大值在 &lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}\)&lt;/span&gt; 時， 所以，&lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)\)&lt;/span&gt; 就是個當 &lt;span class=&#34;math inline&#34;&gt;\(\theta=\hat{\theta}\)&lt;/span&gt; 時取最大值，且最大值爲零的方程。很容易理解我們叫這個方程爲對數似然比，因爲這個方程就是將似然比 &lt;span class=&#34;math inline&#34;&gt;\(LR(\theta)=\frac{L(\theta)}{L(\hat{\theta})}\)&lt;/span&gt; 取對數而已。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/post/likelihood/&#34;&gt;之前&lt;/a&gt;我們也確證了，不包含我們感興趣的參數的方程部分可以忽略掉。還是用上一節 10人中4人患病的例子：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\pi|X=4)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\\
\Rightarrow \ell(\pi)=log[\pi^4(1-\pi)^{10-4}]\\
\Rightarrow llr(\pi)=\ell(\pi)-\ell(\hat{\pi})=log\frac{\pi^4(1-\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其實由上也可以看出 &lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)\)&lt;/span&gt; 只是將對應的似然方程的 &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 軸重新調節了一下而已。形狀是沒有改變的：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow=c(1,2))
x &amp;lt;- seq(0,1,by=0.001)
y &amp;lt;- (x^4)*((1-x)^6)/(0.4^4*0.6^6)
z &amp;lt;- log((x^4)*((1-x)^6))-log(0.4^4*0.6^6)
plot(x, y, type = &amp;quot;l&amp;quot;, ylim = c(0,1.1),yaxt=&amp;quot;n&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;LR(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
axis(2, at=seq(0,1, 0.2), las=2)
title(main = &amp;quot;Binomial likelihood ratio&amp;quot;)
abline(h=1.0, lty=2)
segments(x0=0.4, y0=0, x1=0.4, y1=1, lty = 2)
plot(x, z, type = &amp;quot;l&amp;quot;, ylim = c(-10, 1), yaxt=&amp;quot;n&amp;quot;, frame.plot = FALSE,
     ylab = &amp;quot;llr(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot; )
axis(2, at=seq(-10, 0, 2), las=2)
title(main = &amp;quot;Binomial log-likelihood ratio&amp;quot;)
abline(h=0, lty=2)
segments(x0=0.4, y0=-10, x1=0.4, y1=0, lty = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;正態分佈數據的最大似然和對數似然比&lt;/h4&gt;
&lt;p&gt;假設單個樣本 &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 是來自一組服從正態分佈數據的觀察值：&lt;span class=&#34;math inline&#34;&gt;\(Y\sim N(\mu, \tau^2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那麼有：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
f(y|\mu) &amp;amp;= \frac{1}{\sqrt{2\pi\tau^2}}e^{(-\frac{1}{2}(\frac{y-\mu}{\tau})^2)} \\
\Rightarrow L(\mu|y) &amp;amp;=\frac{1}{\sqrt{2\pi\tau^2}}e^{(-\frac{1}{2}(\frac{y-\mu}{\tau})^2)} \\
\Rightarrow \ell(\mu)&amp;amp;=log(\frac{1}{\sqrt{2\pi\tau^2}})-\frac{1}{2}(\frac{y-\mu}{\tau})^2\\
omitting&amp;amp;\;terms\;not\;in\;\mu \\
&amp;amp;= -\frac{1}{2}(\frac{y-\mu}{\tau})^2 \\
\Rightarrow \ell^\prime(\mu) &amp;amp;= 2\cdot[-\frac{1}{2}(\frac{y-\mu}{\tau})\cdot\frac{-1}{\tau}] \\
&amp;amp;=\frac{y-\mu}{\tau^2} \\
let \; \ell^\prime(\mu) &amp;amp;= 0 \\
\Rightarrow \frac{y-\mu}{\tau^2} &amp;amp;= 0 \Rightarrow \hat{\mu} = y\\
\because \ell^{\prime\prime}(\mu) &amp;amp;=  \frac{-1}{\tau^2} &amp;lt; 0 \\
\therefore \hat{\mu} &amp;amp;= y \Rightarrow \ell(\hat{\mu}=y)_{max}=0 \\
llr(\mu)&amp;amp;=\ell(\mu)-\ell(\hat{\mu})=\ell(\mu)\\
&amp;amp;=-\frac{1}{2}(\frac{y-\mu}{\tau})^2
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;n-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立正態分佈樣本的對數似然比&lt;/h3&gt;
&lt;p&gt;假設一組觀察值來自正態分佈 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu,\sigma^2)\)&lt;/span&gt;，先假設 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 已知。將觀察數據 &lt;span class=&#34;math inline&#34;&gt;\(x_1,\cdots, x_n\)&lt;/span&gt; 標記爲 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt;。 那麼：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
L(\mu|\underline{x}) &amp;amp;=\prod_{i=1}^nf(x_i|\mu)\\
\Rightarrow \ell(\mu|\underline{x}) &amp;amp;=\sum_{i=1}^nlogf(x_i|\mu)\\
&amp;amp;=\sum_{i=1}^n[-\frac{1}{2}(\frac{x_i-\mu}{\sigma})^2]\\
&amp;amp;=-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\\
&amp;amp;=-\frac{1}{2\sigma^2}[\sum_{i=1}^n(x_i-\bar{x})^2+\sum_{i=1}^n(\bar{x}-\mu)^2]\\
omitting&amp;amp;\;terms\;not\;in\;\mu \\
&amp;amp;=-\frac{1}{2\sigma^2}\sum_{i=1}^n(\bar{x}-\mu)^2\\
&amp;amp;=-\frac{n}{2\sigma^2}(\bar{x}-\mu)^2 \\
&amp;amp;=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\\
\because \ell(\hat{\mu}) &amp;amp;= 0 \\
\therefore llr(\mu) &amp;amp;= \ell(\mu)-\ell(\hat{\mu}) = \ell(\mu)
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;n-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立正態分佈樣本的對數似然比的分佈&lt;/h3&gt;
&lt;p&gt;假設我們用 &lt;span class=&#34;math inline&#34;&gt;\(\mu_0\)&lt;/span&gt; 表示總體均數這一參數的值。要注意的是，每當樣本被重新取樣，似然，對數似然方程，對數似然比都隨着觀察值而變 (即有自己的分佈)。&lt;/p&gt;
&lt;p&gt;考慮一個服從正態分佈的單樣本 &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(Y\sim N(\mu_0,\tau^2)\)&lt;/span&gt;。那麼它的對數似然比：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\mu_0|Y)=\ell(\mu_0)-\ell(\hat{\mu})=-\frac{1}{2}(\frac{Y-\mu_0}{\tau})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;根據&lt;a href=&#34;https://winterwang.github.io/post/chi-square-distribution/&#34;&gt;卡方分佈&lt;/a&gt;的定義：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\because \frac{Y-\mu_0}{\tau}\sim N(0,1)\\
\Rightarrow (\frac{Y-\mu_0}{\tau})^2 \sim \mathcal{X}_1^2\\
\therefore -2llr(\mu_0|Y) \sim \mathcal{X}_1^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，如果有一組服從正態分佈的觀察值：&lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu_0,\sigma^2)\)&lt;/span&gt;，且 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 已知的話：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2llr(\mu_0|\bar{X})\sim \mathcal{X}_1^2\]&lt;/span&gt;&lt;/p&gt;
根據&lt;a href=&#34;https://winterwang.github.io/post/central-limit-theory/&#34;&gt;中心極限定理&lt;/a&gt;，可以將上面的結論一般化：

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-2&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 1  &lt;/strong&gt;&lt;/span&gt;如果 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}f(x|\theta)\)&lt;/span&gt;。 那麼當重複多次從參數爲 &lt;span class=&#34;math inline&#34;&gt;\(\theta_0\)&lt;/span&gt; 的總體中取樣時，那麼統計量 &lt;span class=&#34;math inline&#34;&gt;\(-2llr(\theta_0)\)&lt;/span&gt; 會漸進於自由度爲 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; 的卡方分佈： &lt;span class=&#34;math display&#34;&gt;\[-2llr(\theta_0)=-2\{\ell(\theta_0)-\ell(\hat{\theta})\}\xrightarrow[n\rightarrow\infty]{}\;\sim \mathcal{X}_1^2\]&lt;/span&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;似然比信賴區間&lt;/h3&gt;
&lt;p&gt;如果樣本量 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 足夠大 (通常應該大於 &lt;span class=&#34;math inline&#34;&gt;\(30\)&lt;/span&gt;)，根據上面的定理：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2llr(\theta_0)=-2\{\ell(\theta_0)-\ell(\hat{\theta})\}\sim \mathcal{X}_1^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(-2llr(\theta_0)\leqslant \mathcal{X}_{1,0.95}^2=3.84) = 0.95\\
\Rightarrow Prob(llr(\theta_0)\geqslant-3.84/2=-1.92) = 0.95\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;故似然比的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間就是能夠滿足 &lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)=-1.92\)&lt;/span&gt; 的兩個 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 值。&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈數據爲例&lt;/h4&gt;
&lt;p&gt;繼續用本文開頭的例子：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\pi)=\ell(\pi)-\ell(\hat{\pi})=log\frac{\pi^4(1-\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果令 &lt;span class=&#34;math inline&#34;&gt;\(llr(\pi)=-1.92\)&lt;/span&gt; 在代數上可能較難獲得答案。然而從圖形上，如果我們在 &lt;span class=&#34;math inline&#34;&gt;\(y=-1.92\)&lt;/span&gt; 畫一條橫線，和該似然比方程曲線相交的兩個點就是我們想要求的信賴區間的上限和下限：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(0,1,by=0.001)
z &amp;lt;- log((x^4)*((1-x)^6))-log(0.4^4*0.6^6)
plot(x, z, type = &amp;quot;l&amp;quot;, ylim = c(-10, 1), yaxt=&amp;quot;n&amp;quot;, frame.plot = FALSE,
     ylab = &amp;quot;llr(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot; )
axis(2, at=seq(-10, 0, 2), las=2)
abline(h=0, lty=2)
abline(h=-1.92, lty=2)
segments(x0=0.15, y0=-12, x1=0.15, y1=-1.92, lty = 2)
segments(x0=0.7, y0=-12, x1=0.7, y1=-1.92, lty = 2)
axis(1, at=c(0.15,0.7))
text(0.9, -1, &amp;quot;-1.92&amp;quot;)
arrows(0.8, -1.92, 0.8, 0, lty = 1, length = 0.08)
arrows( 0.8, 0, 0.8, -1.92, lty = 1, length = 0.08)
title(main = &amp;quot;Log-likelihood ratio for binomial example, \n with 95% likelihood confidence interval shown&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;從上圖中可以讀出，&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 對數似然比信賴區間就是 &lt;span class=&#34;math inline&#34;&gt;\((0.15, 0.7)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;以正態分佈數據爲例&lt;/h4&gt;
&lt;p&gt;本文前半部分證明過，
&lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu,\sigma^2)\)&lt;/span&gt;，先假設 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 已知。將觀察數據 &lt;span class=&#34;math inline&#34;&gt;\(x_1,\cdots, x_n\)&lt;/span&gt; 標記爲 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt;。 那麼：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\mu|\underline{x}) = \ell(\mu|\underline{x})-\ell(\hat{\mu}) = \ell(\mu|\underline{x}) \\
=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;很顯然，這是一個關於 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 的二次方程，且最大值在 MLE &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mu}=\bar{x}\)&lt;/span&gt; 時取值 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;。所以可以通過對數似然比法求出均值的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間公式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2\times[-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2]=3.84\\
\Rightarrow L=\bar{x}-\sqrt{3.84}\frac{\sigma}{\sqrt{n}} \\
U=\bar{x}+\sqrt{3.84}\frac{\sigma}{\sqrt{n}} \\
note: \;\sqrt{3.84}=1.96\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注意到這和我們&lt;a href=&#34;https://winterwang.github.io/post/frequentist-statistical-inference02/&#34;&gt;之前&lt;/a&gt;求的正態分佈均值的信賴區間公式完全一致。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exercise&lt;/h3&gt;
&lt;div id=&#34;q1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q1&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;假設十個對象中有三人死亡，用二項分佈模型來模擬這個例子，求這個例子中參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 的似然方程和圖形 (likelihood) ?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  L(\pi|3) &amp;amp;= \binom{10}{3}\pi^3(1-\pi)^{10-3} \\  omitting\;&amp;amp;terms\;not\;in\;\mu \\  \Rightarrow \ell(\pi|3) &amp;amp;= log[\pi^3(1-\pi)^7] \\  &amp;amp;= 3log\pi+7log(1-\pi)\\  \Rightarrow \ell^\prime(\pi|3)&amp;amp;= \frac{3}{\pi}-\frac{7}{1-\pi} \\  let \; \ell^\prime&amp;amp; =0\\  &amp;amp;\frac{3}{\pi}-\frac{7}{1-\pi} = 0 \\  &amp;amp;\frac{3-10\pi}{\pi(1-\pi)} = 0 \\  \Rightarrow MLE &amp;amp;= \hat\pi = 0.3 \end{aligned}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;計算似然比，並作圖，注意方程圖形未變，&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 軸的變化；取對數似然比，並作圖&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;LR &amp;lt;- L/max(L) ; head(LR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0000000000 0.0004191759 0.0031233631 0.0098110584 0.0216286076
## [6] 0.0392577320&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(pi, LR, type = &amp;quot;l&amp;quot;, ylim = c(0, 1),yaxt=&amp;quot;n&amp;quot;, col=&amp;quot;darkblue&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
grid(NA, 5, lwd = 1)
axis(2, at=seq(0,1,0.2), las=2)
title(main = &amp;quot;Binomial likelihood ratio function\n 3 out of 10 subjects&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;logLR &amp;lt;- log(L/max(L))
plot(pi, logLR, type = &amp;quot;l&amp;quot;, ylim = c(-4, 0),yaxt=&amp;quot;n&amp;quot;, col=&amp;quot;darkblue&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
grid(NA, 5, lwd = 1)
axis(2, at=seq(-4,0,1), las=2)
title(main = &amp;quot;Binomial log-likelihood ratio function\n 3 out of 10 subjects&amp;quot;)
abline(h=-1.92, lty=1, col=&amp;quot;red&amp;quot;)
axis(4, at=-1.92, las=0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q2&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;與上面用同樣的模型，但是觀察人數變爲 &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; 人 患病人數爲 &lt;span class=&#34;math inline&#34;&gt;\(30\)&lt;/span&gt; 人，試作對數似然比方程之圖形，與上圖對比：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;可以看出，兩組數據的 MLE 都是一致的， &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.3\)&lt;/span&gt;，但是對數似然比方程圖形在 樣本量爲 &lt;span class=&#34;math inline&#34;&gt;\(n=100\)&lt;/span&gt; 時比 &lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt; 時窄很多，由此產生的似然比信賴區間也就窄很多（精確很多）。所以對數似然比方程的曲率（二階導數），反映了觀察獲得數據提供的對總體參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 推斷過程中的信息量。而且當樣本量較大時，對數似然比方程也更加接近左右對稱的二次方程曲線。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q3&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q3&lt;/h4&gt;
&lt;p&gt;在一個實施了160人年的追蹤調查中，觀察到8個死亡案例。使用泊松分佈模型，繪製對數似然比方程圖形，從圖形上目視推測極大似然比的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  d = 8, \;p &amp;amp;= 160\; person\cdot year \\  \Rightarrow D\sim Poi(\mu &amp;amp;=\lambda p) \\  L(\lambda|data) &amp;amp;= Prob(D=d=8) \\  &amp;amp;= e^{-\mu}\frac{\mu^d}{d!} \\  &amp;amp;= e^{-\lambda p}\frac{\lambda^d p^d}{d!} \\  omitting&amp;amp;\;terms\;not\;in\;\lambda \\  &amp;amp;= e^{-\lambda p}\lambda^d \\ \Rightarrow \ell(\lambda|data)&amp;amp;= log(e^{-\lambda p}\lambda^d) \\  &amp;amp;= d\cdot log(\lambda)-\lambda p \\  &amp;amp; = 8\times log(\lambda) - 160\times\lambda \end{aligned}\)&lt;/span&gt;&lt;/p&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;480&#34; /&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
lambda
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
LogLR
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.010
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-6.4755033
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.011
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-5.8730219
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.012
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-5.3369308
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.013
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.8565892
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.014
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.4237254
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.015
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.0317824
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.016
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.6754743
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.017
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.3504773
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.018
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.0532100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.019
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.7806722
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.020
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.5303259
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.021
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.3000045
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
0.022
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
-2.0878444
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
0.023
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
-1.8922303
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.024
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.7117534
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.025
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.5451774
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.026
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.3914117
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.027
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.2494891
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.028
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.1185480
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.029
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.9978174
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.030
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.8866050
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.031
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.7842864
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6902968
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.033
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6041236
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.034
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5252998
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.035
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.4533996
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.036
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3880325
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.037
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3288407
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.038
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2754948
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.039
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2276909
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.040
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1851484
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.041
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1476075
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.042
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1148271
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.043
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0865831
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.044
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0626670
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.045
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0428841
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.046
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0270529
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.047
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0150032
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.048
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0065760
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0016217
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.050
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.051
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0015790
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.052
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0062343
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.053
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0138487
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.054
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0243117
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.055
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0375186
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.056
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0533705
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.057
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0717739
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.058
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0926400
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.059
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1158845
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.060
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1414275
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.061
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1691931
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.062
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1991090
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.063
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2311062
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.064
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2651194
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.065
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3010859
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.066
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3389461
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.067
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3786431
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.068
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.4201224
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.069
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.4633320
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.070
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5082221
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.071
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5547450
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.072
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6028551
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.073
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6525085
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.074
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.7036633
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.075
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.7562791
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.076
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.8103173
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.077
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.8657407
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.078
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.9225134
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.079
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.9806012
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.080
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.0399710
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.081
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.1005908
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.082
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.1624301
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.083
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.2254592
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.084
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.2896497
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.085
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.3549740
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.086
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.4214057
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.087
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.4889191
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.088
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.5574895
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.089
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.6270931
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.090
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.6977067
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.091
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.7693080
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.092
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.8418754
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
0.093
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
-1.9153881
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
0.094
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
-1.9898258
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.095
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.0651689
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.096
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.1413985
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.097
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.2184962
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.098
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.2964442
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.099
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.3752252
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.100
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.4548226
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;所以從列表數據結合圖形， 可以找到信賴區間的下限在 0.022~0.023 之間， 上限在 0.093～0.094 之間。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>似然非然 Likelihood</title>
      <link>https://winterwang.github.io/post/likelihood/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/likelihood/</guid>
      <description>&lt;div id=&#34;-vs.probability-vs.inference&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;概率 vs. 推斷/Probability vs. Inference&lt;/h3&gt;
&lt;p&gt;在概率論的環境下，我們常常被告知的前提是：某某事件發生的概率是多少。例如： 一枚硬幣正面朝上的概率是 &lt;span class=&#34;math inline&#34;&gt;\(0.5\; Prob(coin\;landing\;heads)=0.5\)&lt;/span&gt;。然後在這個前提下，我們又繼續去計算複雜的事件發生的概率（例如，10次投擲硬幣以後4次正面朝上的概率是多少？）。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\binom{10}{4}\times(0.5^4)\times(0.5^{10-4}) = 0.205
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dbinom(4, 10, 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2050781&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# or you can calculate by hand:
factorial(10)*(0.5^10)/(factorial(4)*(factorial(6)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2050781&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在統計推斷的理論中，我們考慮實際的情況，這樣的實際情況就是，我們通過觀察獲得數據，然而我們並不知道某事件發生的概率到底是多少（神如果存在話，只有神知道）。故這個 &lt;span class=&#34;math inline&#34;&gt;\(Prob(coin\;landing\;heads)\)&lt;/span&gt; 的概率大小對於“人類”來說是未知的。我們可能觀察到投擲了10次硬幣，其中有4次是正面朝上的。那麼我們從這一次觀察實驗中，需要計算的是能夠符合觀察結果的“最佳”概率估計 (best estimate)。在這種情況下，&lt;strong&gt;似然法 (likelihood)&lt;/strong&gt; 就是我們進行參數估計的最佳手段。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;似然和極大似然估計&lt;/h3&gt;
&lt;p&gt;此處用二項分佈的例子來理解似然法的概念：假設我們觀察到10個對象中有4個患病，我們假定這個患病的概率爲 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;。於是我們就有了下面的模型：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型：&lt;/strong&gt; 我們假定患病與否是一個服從&lt;strong&gt;二項分佈的隨機變量&lt;/strong&gt;，&lt;span class=&#34;math inline&#34;&gt;\(X\sim Bin(10,\pi)\)&lt;/span&gt;。同時也默認每個人之間是否患病是相互獨立的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;數據：&lt;/strong&gt; 觀察到的數據是，10人中有4人患病。於是 &lt;span class=&#34;math inline&#34;&gt;\(x=4\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;現在按照觀察到的數據，參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 變成了未知數：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(X=4|\pi)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;此時我們會很自然的考慮，當 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 是未知數的時候，&lt;strong&gt;它取值爲多大的時候才能讓這個事件（即：10人中4人患病）發生的概率最大？&lt;/strong&gt; 所以我們可以將不同的數值代入 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 來計算該事件在不同概率的情況下發生的可能性到底是多少：&lt;/p&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Table 1: The probability of observing &lt;span class=&#34;math inline&#34;&gt;\(X=4\)&lt;/span&gt;
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
事件 &lt;span class=&#34;math inline&#34;&gt;\(X=4\)&lt;/span&gt; 發生的概率
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.088
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;0.4&lt;/strong&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;0.251&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.5
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.205
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.111
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.006
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;很顯然，如果 &lt;span class=&#34;math inline&#34;&gt;\(\pi=0.4\)&lt;/span&gt; 時，我們觀察到的事件發生的概率要比 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 取其它值時更大。於是小總結一下目前爲止的步驟如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;觀察到實驗數據（10人中4個患病）；&lt;/li&gt;
&lt;li&gt;假定這數據服從二項分佈的概率模型，計算不同（&lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 的取值不同的）情況下，該事件按照假定模型發生的概率；&lt;/li&gt;
&lt;li&gt;通過比較，我們選擇了能夠讓觀察事件發生概率最高的參數取值 (&lt;span class=&#34;math inline&#34;&gt;\(\pi=0.4\)&lt;/span&gt;)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;至此，我們可以知道，似然方程，是一個關於未知參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 的函數，我們目前位置做的就是找到這個函數的最大值 (maximised)，和使之成爲最大值時的 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; ：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\pi|X=4)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;我們可以畫出這個似然方程的形狀， &lt;span class=&#34;math inline&#34;&gt;\(\pi\in[0,1]\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(0,1,by=0.001)
y &amp;lt;- (factorial(10)/(factorial(4)*(factorial(6))))*(x^4)*((1-x)^6)
plot(x, y, type = &amp;quot;l&amp;quot;, ylim = c(0,0.3), ylab = &amp;quot;L(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
title(&amp;quot;Figure 1. Binomial Likelihood&amp;quot;)
abline(h=0.251, lty=2)
abline(v=0.4, lty=2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-02-likelihood_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;從圖形上我們也能確認，&lt;span class=&#34;math inline&#34;&gt;\(\pi=0.4\)&lt;/span&gt; 時能夠讓這個似然方程取得最大值。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;似然方程的一般化定義&lt;/h3&gt;
&lt;p&gt;對於一個概率模型，如果其參數爲 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;，那麼在給定觀察數據 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 時，該參數的似然方程被定義爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(L(\theta|\underline{x})=P(\underline{x}|\theta)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(\underline{x}|\theta)\)&lt;/span&gt; 可以是概率（離散分佈）方程，也可以是概率密度（連續型變量）方程。對於此方程，&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 是給定的，然後再計算某些事件發生的概率。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(L(\theta|\underline{x})\)&lt;/span&gt; 是一個關於參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的方程，此時，&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 是固定不變的（觀察值）。我們希望通過這個方程求出能夠使觀察到的事件發生概率最大的參數值。&lt;/li&gt;
&lt;li&gt;似然方程&lt;strong&gt;不是&lt;/strong&gt;一個概率密度方程。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另一個例子：&lt;/p&gt;
&lt;p&gt;有一組觀察數據是離散型隨機變量 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;，它符合概率方程 &lt;span class=&#34;math inline&#34;&gt;\(f(x|\theta)\)&lt;/span&gt;。下表羅列了當 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 分別取值 &lt;span class=&#34;math inline&#34;&gt;\(1,2,3\)&lt;/span&gt; 時的概率方程的值，試求每個觀察值 &lt;span class=&#34;math inline&#34;&gt;\(X = 0,1,2,3,4\)&lt;/span&gt; 的最大似然參數估計：&lt;/p&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Exercise 1
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|1)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|2)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|3)\)&lt;/span&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Exercise 1 answer
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|1)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|2)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|3)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;1&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;1&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;2&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;3&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;3&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;-log-likelihood&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;對數似然方程 log-likelihood&lt;/h3&gt;
&lt;p&gt;似然方程的最大值，可通過求 &lt;span class=&#34;math inline&#34;&gt;\(L(\theta|data)\)&lt;/span&gt; 的最大值獲得，也可以通過求該方程的對數方程 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt; 的最大值獲得。傳統上，我們估計最大方程的最大值的時候，會給參數戴一頂“帽子”（因爲這是觀察獲得的數據告訴我們的參數）： &lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}\)&lt;/span&gt;。並且我們發現對數似然方程比一般的似然方程更加容易微分，因此求似然方程的最大值就變成了求對數似然方程的最大值：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{d\ell}{d\theta}=\ell^\prime(\theta)=0\\
AND\\
\frac{d^2\ell}{d\theta^2}&amp;lt;0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;要注意的是，微分不一定總是能幫助我們求得似然方程的最大值。如果說參數本身的定義域是有界限的話，微分就行不通了：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(0,3,by=0.001)
y &amp;lt;- (x-1)^2-5
plot(x, y, type = &amp;quot;l&amp;quot;, ylim = c(-5,0-1), ylab = &amp;quot;L(\U03B8)&amp;quot;, xlab = &amp;quot;\U03B8&amp;quot;)
title(&amp;quot;Figure 2. Likelihood function with \n a limited domain&amp;quot;)
abline(v=3, lty=2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-02-likelihood_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;-lthetadata--ellthetadata-&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明：當 &lt;span class=&#34;math inline&#34;&gt;\(L(\theta|data)\)&lt;/span&gt; 取最大值時，該方程的對數方程 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt; 也是最大值：&lt;/h4&gt;
&lt;p&gt;如果似然方程是連續可導，只有一個最大值，且可以二次求導，假設 &lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}\)&lt;/span&gt; 使該方程取最大值，那麼：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{dL}{d\theta}=0, \frac{d^2L}{d\theta^2}&amp;lt;0 \Rightarrow \theta=\hat{\theta}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(\ell=logL\)&lt;/span&gt; 那麼 &lt;span class=&#34;math inline&#34;&gt;\(\frac{d\ell}{dL}=\ell^\prime=\frac{1}{L}\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{d\ell}{d\theta}=\frac{d\ell}{dL}\cdot\frac{dL}{d\theta}=\frac{1}{L}\cdot\frac{dL}{d\theta}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt; 取最大值時：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{d\ell}{d\theta}=0\Leftrightarrow\frac{1}{L}\cdot\frac{dL}{d\theta}=0\\
\because \frac{1}{L}\neq0 \\
\therefore \frac{dL}{d\theta}=0\\
\Leftrightarrow \theta=\hat{\theta}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\frac{d^2\ell}{d\theta^2} &amp;amp;= \frac{d}{d\theta}(\frac{d\ell}{dL}\cdot\frac{dL}{d\theta})\\
 &amp;amp;= \frac{d\ell}{dL}\cdot\frac{d^2L}{d\theta^2} + \frac{dL}{d\theta}\cdot\frac{d}{d\theta}(\frac{d\ell}{dL})
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(\theta=\hat{\theta}\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(\frac{dL}{d\theta}=0\)&lt;/span&gt; 且 &lt;span class=&#34;math inline&#34;&gt;\(\frac{d^2L}{d\theta^2}&amp;lt;0 \Rightarrow \frac{d^2\ell}{d\theta^2}&amp;lt;0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，求獲得 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt; 最大值的 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 即可令 &lt;span class=&#34;math inline&#34;&gt;\(L(\theta|data)\)&lt;/span&gt; 獲得最大值。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-maximum-likelihood-estimator-mle-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;極大似然估計 (maximum likelihood estimator, MLE) 的性質：&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;漸進無偏 Asymptotically unbiased: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow \infty \Rightarrow E(\hat{\Theta}) \rightarrow \theta\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;漸進最高效能 Asymptotically efficient: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow \infty \Rightarrow Var(\hat{\Theta})\)&lt;/span&gt; 是所有參數中方差最小的估計&lt;/li&gt;
&lt;li&gt;漸進正態分佈 Asymptotically normal: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow \infty \Rightarrow \hat{\Theta} \sim N(\theta, Var(\hat{\Theta}))\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;變形後依然保持不變 Transformation invariant: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(\hat{\Theta}\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的MLE時 &lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow g(\hat{\Theta})\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt; 的 MLE&lt;/li&gt;
&lt;li&gt;信息足夠充分 Sufficient：&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(\hat{\Theta}\)&lt;/span&gt; 包含了觀察數據中所有的能夠用於估計參數的信息&lt;/li&gt;
&lt;li&gt;始終不變 consistent: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow\infty\Rightarrow\hat{\Theta}\rightarrow\theta\)&lt;/span&gt; 或者可以寫成：&lt;span class=&#34;math inline&#34;&gt;\(\varepsilon&amp;gt;0, lim_{n\rightarrow\infty}P(|\hat{\Theta}-\theta|&amp;gt;\varepsilon)=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;-likelihood-for-a-rate&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;率的似然估計 Likelihood for a rate&lt;/h3&gt;
&lt;p&gt;如果在一項研究中，參與者有各自不同的追蹤隨訪時間（長度），那麼我們應該把事件（疾病）的發病率用率的形式（多少事件每單位人年, e.g. per person year of observation）。如果這個發病率的參數用 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 來表示，所有參與對象的隨訪時間之和爲 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 人年。那麼這段時間內的期望事件（疾病發病）次數爲：&lt;span class=&#34;math inline&#34;&gt;\(\mu=\lambda p\)&lt;/span&gt;。假設事件（疾病發病）發生是相互獨立的，可以使用泊松分佈來模擬期望事件（疾病發病）次數 &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[D\sim Poi(\mu)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;假設我們觀察到了 &lt;span class=&#34;math inline&#34;&gt;\(D=d\)&lt;/span&gt; 個事件，我們獲得這個觀察值的概率應該用以下的模型：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(D=d)=e^{-\mu}\frac{\mu^d}{d!}=e^{-\lambda p}\frac{\lambda^dp^d}{d!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;因此，&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的似然方程是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\lambda|observed \;data)=e^{-\lambda p}\frac{\lambda^dp^d}{d!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的對數似然方程是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\ell(\lambda|observed\;data) &amp;amp;= log(e^{-\lambda p}\frac{\lambda^dp^d}{d!}) \\
  &amp;amp;= -\lambda p+d\:log(\lambda)+d\:log(p)-log(d!) \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;解 &lt;span class=&#34;math inline&#34;&gt;\(\ell^\prime(\lambda|data)=0\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\ell^\prime(\lambda|data) &amp;amp;= -p+\frac{d}{\lambda}=0\\
\Rightarrow \hat{\lambda} &amp;amp;= \frac{d}{p} \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;
在對數似然方程中，不包含參數的部分，對與似然方程的形狀不產生任何影響，我們在微分對數似然方程的時候，這部分也都自動消失。所以不包含參數的部分，與我們如何獲得極大似然估計是無關的。因此，我們常常在寫對數似然方程的時候就把其中沒有參數的部分直接忽略了。例如上面泊松分佈的似然方程中，&lt;span class=&#34;math inline&#34;&gt;\(d\:log(p)-log(d!)\)&lt;/span&gt; 不包含參數 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 可以直接不寫出來。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-n-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;有 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立觀察時的似然方程和對數似然方程&lt;/h3&gt;
&lt;p&gt;當有多個獨立觀察時，總體的似然方程等於各個觀察值的似然方程之&lt;strong&gt;乘積&lt;/strong&gt;。如果 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\stackrel{i.i.d}{\sim}f(\cdot|\theta)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\theta|x_1,\cdots,x_n)=f(x_1,\cdots,x_n|\theta)=\prod_{i=1}^nf(x_i|\theta)\\
\Rightarrow \ell(\theta|x_1,\cdots,x_n)=\sum_{i=1}^nlog(f(x_i|\theta))\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
