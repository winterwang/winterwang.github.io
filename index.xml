<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Be ambitious on Be ambitious</title>
    <link>https://winterwang.github.io/</link>
    <description>Recent content in Be ambitious on Be ambitious</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Chaochen Wang | 王超辰</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Summer Project Schedule</title>
      <link>https://winterwang.github.io/post/summer-project-schedule/</link>
      <pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/summer-project-schedule/</guid>
      <description>&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Data analysis finish by 2018-07-24&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Paper structure confirm by 2018-08-01&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Paper draft complete by 2018-08-24&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;2018-06-24

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read and try to repeat Rll&amp;rsquo;s method in R and familarize the dataset ASAP&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Two papers applying Repeated Measures LCA&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-25

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Meeting with supervisor and Susanna&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Confirm the cutoff of carborhydrate consumption&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Talk with Rll ask about the methodology and dataset&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-26

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Send the summarised memo of meeting to Supervisor and etc.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read the first part fundamentals of LCA.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-27

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;a href=&#34;https://www.londonr.org/&#34; target=&#34;_blank&#34;&gt;London R in UCL&lt;/a&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Germany lost their game against South Korea, UNBELIEVEABLE&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-28&lt;br /&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read the book collins2010latent - Latent Class and Latent Transition Analysis: With Applications in the Social, Behavioral, and Health Sciences (Done until 4.2)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn how to do LCA in R&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-29

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read the book collins2010latent - Latent Class and Latent Transition Analysis: With Applications in the Social, Behavioral, and Health Sciences (Done until 4.3)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Data management for NDNS 8 years data (70%)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn how to do LCA in R&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Start to analysis the data according to the discussion on 25th(30%)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-30&lt;br /&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Learn how to do LCA in SAS with repeated measurement&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Find whether there is any possibility of conducting the same method in R or STATA&lt;br /&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Try to start writing about the introduction;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Start writing about the methodology;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>蘇格蘭高地7日公路之旅</title>
      <link>https://winterwang.github.io/post/scotland-highland-road-trip/</link>
      <pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/scotland-highland-road-trip/</guid>
      <description>

&lt;p&gt;高地旅行2018-06-13～2018-06-20&lt;/p&gt;

&lt;h1 id=&#34;2018-06-13-倫敦出發&#34;&gt;2018-06-13 倫敦出發&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180613.png&#34; alt=&#34;London to Edinburgh&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;2018-06-14-爱丁堡到格拉斯哥&#34;&gt;2018-06-14 爱丁堡到格拉斯哥&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180614.png&#34; alt=&#34;one day in Edinburgh and to Glasgow at night&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;2018-06-15-從格拉斯哥離開飛馳在高地去往天空島&#34;&gt;2018-06-15 從格拉斯哥離開飛馳在高地去往天空島&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180615.png&#34; alt=&#34;on the way to Skye Isle&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;2018-06-16-離開暴雨傾盆的天空島抵達極北德內斯-durness&#34;&gt;2018-06-16 離開暴雨傾盆的天空島抵達極北德內斯 (Durness)&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180616.png&#34; alt=&#34;Durness&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180616overnight.jpg&#34; alt=&#34;Durness2&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;2018-06-17-在靠近-shetland-的無路可走的盡頭&#34;&gt;2018-06-17 在靠近 Shetland 的無路可走的盡頭&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180617.png&#34; alt=&#34;Road ends&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180617noon.jpg&#34; alt=&#34;road ends again&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;2018-06-18-inverness-和尼斯湖水怪&#34;&gt;2018-06-18 Inverness 和尼斯湖水怪&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180618.png&#34; alt=&#34;Loch Ness&#34; width=&#34;60%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;2018-06-19-回到愛丁堡&#34;&gt;2018-06-19 回到愛丁堡&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2018-06-24-scotland-highland-road-trip_files/20180619.png&#34; alt=&#34;Back to Edinburgh&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Todo 2018 June</title>
      <link>https://winterwang.github.io/post/todo-2018-june/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/todo-2018-june/</guid>
      <description>&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 大塚敏美財団メールを返信する&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;PCA analysis learning&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Cluster analysis learning&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 建立一個論文日程表格

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 日程計劃包括每周進度&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 分析進度&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 論文寫作進度&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 學習 Latent Class Analysis 方法;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 熟悉 NDNS 數據框架結構，思考分析方法;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Comment and response to AACE&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Test on Ubuntu 18.04&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;尝试从Ubuntu, 日本語を試す&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;更新 &lt;a href=&#34;http://wangcc.me/LSHTMlearningnote/&#34; target=&#34;_blank&#34;&gt;LSHTM 統計學學習筆記&lt;/a&gt; &lt;a href=&#34;http://wangcc.me/LSHTMlearningnote/cox-.html&#34; target=&#34;_blank&#34;&gt;生存分析章節-Cox-models&lt;/a&gt;;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 更新 LSHTM 統計學學習筆記，GLM Multinomial logistic regression model;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 更新 LSHTM 統計學學習筆記，GLM Oridinal logisitic regression model;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 更新 LSHTM 統計學學習筆記，貝葉斯進階章節;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 更新 LSHTM 統計學學習筆記，用 STATA 或者 R 分析 SME 流行病學數據的實踐部分;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 更新生存分析，更多具體細節及練習[Cox];&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 更新生存分析，更多具體細節及練習[AFT];&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;辦理法國簽證所需的材料; 法國行程取消&lt;/del&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;大學學生在校證明;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;銀行三個月存款證明&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;歐洲之星(7月)訂票;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;巴黎青年旅館訂房 (聯繫下正好在法國的 なっちゃん家?);&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;旅行保險;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;BRP 複印;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;護照複印;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;[xa] &lt;del&gt;簽證申請書;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;近三个月内的证件照，尺寸3.5cm x 4.5cm，白底&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; 把 &lt;a href=&#34;https://github.com/winterwang/overleaf-thesis-template&#34; target=&#34;_blank&#34;&gt;LaTeX 模板&lt;/a&gt; 調整到 &lt;a href=&#34;https://github.com/pzhaonet/bookdownplus&#34; target=&#34;_blank&#34;&gt;Bookdownplus 的模板之一&lt;/a&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Bayesian&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-1;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-3&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-7;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-03 17:00, mean and variance for data transformation]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-03 17:30 linear regression, really need to pay attention in reading the question]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-03 22:30 Binomial exact test]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test done, coefficient and rho, 75% about]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-2;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-3;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-4;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test done, too much to write as a survival question, about 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test done, too much to write about 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-6;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test done, GLM about 90%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-1;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>To do list 2018 May</title>
      <link>https://winterwang.github.io/post/todotest/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/todotest/</guid>
      <description>&lt;p&gt;試試看用 &lt;a href=&#34;https://shrektan.com/post/2018/04/02/blogdown-todo/&#34; target=&#34;_blank&#34;&gt;Blogdown 來管理自己的待辦事項&lt;/a&gt;:&lt;/p&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Causal inference 作業&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-18 12:00]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;學習去年的 Hierarchical discrete data modeling Lecture 1-4;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-08 23:45 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;學習去年的 Generalised linear mixed effect modelling lecture 5-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-12 16:00 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;完成 ASM Edmund 作業;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-18 03:20 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;寫一篇日志回顧最近 LSHTM 的生活;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-06 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Probablity;(2018-05-16 to 17)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Inference;(2018-05-17 to 18)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Clinical Trial;(2018-05-19 to 20)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Basic Epi; (2018-05-20 to 21)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Analytical Technique;(2018-05-22 to 24)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Regression; (2018-05-24 to 25)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Robust statistics; (2018-05-27)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 GLM (2018-05-28 to 29)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;複習 Survival Analysis (2018-05-39 to 31)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;反省自己爲什麼效率這麼低。。。。。&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;解決辦法就是把自己的 to do 放在網頁上，刺激自己。(2018-05-06 done)&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2008年 LSHTM 試題 Paper 2-2 (survival question);&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-29 17:01]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2009 年 LSHTM 試題 Paper 2-3 (survival question);&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-29 18:19]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-24 17:01 40 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-18 12:21 done]&lt;/li&gt;
&lt;li&gt;[2018-06-03 12:51 done again 80% 17 min]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 11:15]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-19 22:50 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-19 23:43 done]&lt;/li&gt;
&lt;li&gt;[2018-06-03 16:30 Wald test, MLE, compare the inverse of mean]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-25 21:32 done 35 min]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-27 13:39 done 15 min]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 2012年 LSHTM 試題 Paper 1-8;

&lt;ul&gt;
&lt;li&gt;[2018-05-18 22:00 done]&lt;/li&gt;
&lt;li&gt;[2018-06-04 11:27 done again, when use transformation for MLE, we need to substitute it back to the loglikelihood function to find the standard error of the newly transformed variable]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 35 min but brutally beaten]&lt;/li&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test 90%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-04-30, challenged again 2018-05-25 quadratic term interpration is needed]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-20 01:00 done]&lt;/li&gt;
&lt;li&gt;[done again on 2018-06-04 12:22 score test and comparison with lrt, hard way of doing lrt with binomial data, time consuming, about 80% got]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-4;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-04-30]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 23:38]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-04-30]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-03 15 min 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 14:09 18 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 23:38]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-1&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-07 1800]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-2&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-07 1900]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-3&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-07 2230; challenged again 2018-05-25 20:58 35 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-28 extreeeeeeeemely^99^ difficult GLM]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 21:21 in 37 min]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-28 巨難無比，條件邏輯回歸的推導和證明]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 23:38]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-04-23]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 27 min but only get about 60% poor and brutal&amp;hellip;&amp;hellip; what should I do&amp;hellip;]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-04-23]&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;[done 2018-06-04 done in 29 min 90% got]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-4;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-20 22:56]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 18:33]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-19 13:43]&lt;/li&gt;
&lt;li&gt;[done agian 2018-06-03 11:18 17 min 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 15:07,278 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-21 14:50]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-24 15:01]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-04-23]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-14 23:18; twice challenge 2018-05-25 17:20 better now]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-15 01:30; challenged again 2018-05-28 15:47 much better now]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-15 11:30]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-28 16:50 got 19 points out of 20 I like this one]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 18:38 36 min used, survival questions]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-19 14:53]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-03 00:05 17 min 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-20 13:46 20 min used]&lt;/li&gt;
&lt;li&gt;[done 2018-06-04 14:08 12 min used well done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-20 22:15 20 min used but only get 50%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-4;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-23 21:00]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 12:16]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 12:06 25 min used but only get 60%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 16:57  28 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 12:44]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-24 13:56]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 16:14 29 min used, somewhat easy I can have about 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 13:58]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-28 12:42]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-28 14:15 done within 25 min, Poisson regression model is within my range of ability]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-30 17:07 done. 40 min used. Quite difficult Weibull model with AFT feature.]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 00:58]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-02]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-03 00:04 30 min 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-2;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-02]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-04 14:40 20 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-3;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-02]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-4;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-02]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-5;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-02 and 2018-05-24 22:58 33 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-6;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-03]&lt;/li&gt;
&lt;li&gt;[done 2018-06-02 17:41 about 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-7;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-03]&lt;/li&gt;
&lt;li&gt;[done 2018-06-02 17:41 about 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-8;&lt;/del&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-03]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-23 18:00]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 01:03 very difficult competing risk(subdistribution) model]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-01 11:59, more than 80% get, answers improved]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 01:38 40 min used]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-5;&lt;/del&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;[done 2018-05-27 23:58 45 min used]&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 2018-05-31 15:22 challenged again 32 min used, answers improved.&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-6;&lt;/del&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;[done 2018-05-28 11:55 matched case-control study]&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 2018-05-31 16:04 challenged again 27 min used, answers improved.&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 13:09 Weibull model with connection to AFT model]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-01 12:00 more than 80% got, answers improved]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[done 2018-05-21 13:00]&lt;/li&gt;
&lt;li&gt;[done 2018-06-02 17:40 again, about 80%]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-19 20:02 done]&lt;/li&gt;
&lt;li&gt;[2018-06-03 00:03 17 min done 80% got]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-2;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-20 16:07 史上最難]&lt;/li&gt;
&lt;li&gt;[2018-06-04 20 min 90% got, MSE = Variance + (Bias)^2]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-20 18:30]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-4;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-23 01:45 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-24 21:57 done]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-21 02:35 被虐慘了]&lt;/li&gt;
&lt;li&gt;[2018-06-02 14:49 largely improved]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-21 11:09 答案可能有錯的 AT?]&lt;/li&gt;
&lt;li&gt;[2018-06-02 14:48 done again, Good]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-27 12:34 done, 28 min used, but only had 60%. &lt;strong&gt;Read your question carefully!!!&lt;/strong&gt;]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-1;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-21 12:49 done 17]&lt;/li&gt;
&lt;li&gt;[2018-06-02 14:48 done again, largely improved]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-2;&lt;/del&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;[done 2018-05-27 23:09 extremely difficult GLM]&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; challenged again 2018-05-31 21 min done with quick smash&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-3;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-27 20:00 very difficult combined with ordinal logistic regression]&lt;/li&gt;
&lt;li&gt;[2018-05-31 14:35 challenged again, 40 min, still very difficult but improved]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-5;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-29 20:11 done, not very difficult survival question, but you only got about 50%]&lt;/li&gt;
&lt;li&gt;[2018-06-01 13:52 challenged again, answers improved, some time-dependent variable in survival analysis is quite interesting]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-6;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-29 22:47 done, not very difficult, but less than 50% obtained]&lt;/li&gt;
&lt;li&gt;[2018-06-01 13:55 done again, answers improved.]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-7;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-24 18:43 done 45 min used. too much time wasted!!!]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-8;&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;[2018-05-20]&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>你靜靜地睡在琥珀裏</title>
      <link>https://winterwang.github.io/post/sleep/</link>
      <pubDate>Sun, 06 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/sleep/</guid>
      <description>&lt;p&gt;媽在電話裏說，今年要是期末考試考不過，明年把妹妹(我女兒)背去倫敦再考。(T_T) 突然我就想起快離開廈門的前一天，帶着兒子去大榕樹底下玩。他興奮地要玩我新買的乒乓球和乒乓球拍。可我心裏舍不得新的球和球拍弄髒了，就故意拿小汽車和其他的東西分散他的注意力。回到家裏了才給了他一個乒乓球玩。其實那天本來還想帶他去買肉包給他吃，可是領了快遞以後我沒有手再拿東西，就直接帶兒子回家了。那天兒子女兒和妻還要坐火車回榕城外婆家，一路顛簸誰也沒想起來，兒子還沒吃早飯。火車上聽說他也一直沒吃東西，不知道他三歲的心裏在想什麼。到了外婆家裏也很晚了，男孩子興奮哭鬧總是比女孩子激烈。我一聽電話裏他哭的聲音，心裏就不由得難受極了。怎麼就舍不得把乒乓球給他一個呢，我真是個自私極了的爸爸。忘了兒子沒吃早飯，也舍不得把他想玩的乒乓球送給他。也許他早就不記得了，但是我總惦記着這一天發生的事。也許在我心裏，那段美好時光在琥珀中靜止在了廈門開往島外的那列送行的地鐵上。&lt;/p&gt;

&lt;p&gt;我又想起在學習&lt;a href=&#34;http://wangcc.me/LSHTMlearningnote/causal-languages-.html&#34; target=&#34;_blank&#34;&gt;因果推斷&lt;/a&gt;的時候，每次老師都要強調那三個永世不能忘記的推斷前提:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;無相互幹擾 no interference;&lt;/li&gt;
&lt;li&gt;一致性 consistency;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;條件可置換性 conditional exchangeability;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;每當老師提問說，我們現在的前提是什麼？全班同學總能異口同聲地念出上面那三句咒語，場景仿佛間諜與間諜之間對暗號。又有點像黑幫入會時指天發誓的三句誓言。還有就是那個老師可愛的法文味道的英文，標準誤的英文是 standard error，她總是說 standard &amp;ldquo;唉河&amp;rdquo;。另一個教生存分析的法國人老師就更有趣了，每次舉例子都說，比方說我們拿&amp;ndash;法國做例子，隨機選一個國家嘛。。blablabla&amp;hellip;&lt;/p&gt;

&lt;p&gt;今天，響子同學說要去阿根廷完成自己的碩士課題。我們下午坐在 SOAS 的草地上一邊從作業間隙中休息，一邊喝着咖啡，突然意識到，再過一陣子，新學生就又要來了呢。去年這時候我們都還在世界各地，響子在危地馬拉給 JICA 幹活，說着流利的西班牙語; 我在名古屋一邊給日本學生講課，一邊內心充滿了期待快出生的妹妹和快要出發來倫敦的復雜又忐忑的心情，如今我們竟然已經在討論彼此回程的機票訂了幾號，想起3月我們還在寒風中頂着大雪抱怨着留英這一年碰到數十年最嚴重的大學罷課，這一段時光，竟也這樣偷偷溜走，沒有琥珀可以給它定格。&lt;/p&gt;

&lt;p&gt;直到兩天前，同班同學在因果推斷下課後，復習完了我們每次課上對完的暗號，突然有同學提議說，我們去學校門口拍一張集體照片吧，學校年度學生畫冊 (Yearbook) 的內容我們還沒人提交吶，至少要有一張咱們的集體照片吧！ 於是我們有了封面的那張照片。總算是用 LOMO 的隨手拍記錄下這年我們在 LSHTM 待過的證據。這年，我們這十幾個在 LSHTM 推倒公式，背誦&amp;rdquo;間諜暗號&amp;rdquo;，倒騰貝葉斯，糾結着那些回歸模型的殘差，還有那個永遠也搞不懂的似然。一瞬間留在相紙上，一轉眼可能就要各奔四方。傷感不由就從心中涌出，蔓延到大西洋。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>日落在下午四點</title>
      <link>https://winterwang.github.io/post/luan/</link>
      <pubDate>Sun, 14 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/luan/</guid>
      <description>&lt;p&gt;倫敦的生活已經過去四個月，每天和統計學公式打交道的我，今天不想在這裏寫任何公式。說說這四個月想更新一直偷懶沒更新的那些在倫敦衛生與熱帶醫學院度過的平凡的日子。&lt;/p&gt;

&lt;p&gt;寒假時去了普利茅斯，和康沃爾。康沃爾是個很有意思的名字 Cornwall。字面意思是玉米牆。我是去自己本來計劃聖誕節想去的 Homestay。&lt;a href=&#34;http://www.hostuk.org/&#34; target=&#34;_blank&#34;&gt;HOST UK&lt;/a&gt; 本來負責我的人告訴我聖誕節可能有點困難，聖誕節前的週末可以的話就去康沃爾的一對退休的老人家裏去做客吧。於是週五一早踏上了一個多月前就從網上訂好的倫敦的帕丁頓去往卡爾斯托克 (Calstock) 的西大不列顛列車。說來諷刺的是，大英帝國建立了世界上第一條火車，如今我一個老外來到這個國家卻在嫌棄這裏的火車慢如老牛拉車。&lt;/p&gt;

&lt;p&gt;和我一起享受英國農村四天三晚的 Homestay 的還有另一個來自毛里求斯的印度人學生。我們一路同行從倫敦出發。整列火車從離開倫敦時的滿員，乘客隨着車窗外樓房的減少而逐漸減少。&lt;del&gt;腦海裏推算了一下，這絕對是有意義的正相關。&lt;/del&gt; 到了普利茅斯只剩下包括我倆在內，絕對只有個位數的人。&lt;/p&gt;

&lt;p&gt;我也沒打算把整個四天三晚都去了哪裏在這裏記流水帳，印象深刻的是我們和老爺爺老太太每晚每晚的長談。還好來自毛里求斯的印度人英文流利，我一個人跟這些老人肯定是無法聊到深夜的。他們聊他們的老當益壯，用腳丈量非洲大陸的那些經歷和記憶，我們侃我們的年輕氣盛和那些無處發泄的憂國憂民。走時，老爺爺把自己收藏了多年的一個據說來自唐朝中國的佛像給了我，說，我希望你帶它回到它來自的地方。我想起我們都站在康沃爾的大西洋沿岸峭壁懸崖，放眼望着法國的方向，腳下全是泥巴。&lt;/p&gt;

&lt;p&gt;我在老人家的留言本上寫下了我在中國和日本的地址電話，中日英三語，生怕他們真的會在中國或者日本迷路。隔天回到了倫敦的房間，我收到老爺爺發來的郵件，淡然如水，卻彷若那些夜晚我們促膝長談時說的話：“你豐富了我們的人生，在你我的道路重新交集前，保重。You have enriched our lives. Until our paths cross again, take care.”&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;英國冬季的日照時間短得可憐。白天離開宿舍去大學時天黑着，下午下課離開大學時，天依然是黑着的。加上我們統計系的課許多都在地下的教室裏，我跟其他人打趣說，我現在的生活像一隻土撥鼠。我在地下，推導着讓我內心無比踏實的那些數學公式。&lt;/p&gt;

&lt;p&gt;有時候，我會十分的想念日本的生活。有時候，我又會無比的思念廈門的日子。這些落腳過的地方，只有上海的感覺越來越模糊。不知道我懷念的是名古屋乾淨的街道，是廈門的沙茶面的味道，還是那些夜晚打完工以後路邊的便利店門口騎着腳踏車路過的那時的我，也許還有那個在白城沙灘上可以悠閒地聽海浪拍岸聲的那個無腦少年。不清楚緣由地，只有上海的記憶在大腦中逐漸變得不那麼色彩斑斕。我也很好奇多年以後我會怎樣回憶倫敦？ 也許只剩下記憶裏土撥鼠一樣的無聊日子，還有貴死你不償命的宿舍房租。&lt;/p&gt;

&lt;p&gt;跨年那晚我和幾個同學走在滿目瘡痍的倫敦街頭，焰火散去，人去城空，2018年就已經被我們踩在了腳下。眼看着這新的一年在凌亂中開始，但願過程也不要太過殘酷。這一年唯一的目標是順利完成這沒日沒夜 (說好聽是朝思暮想) 的醫學統計學碩士。還有的話就是希望家人孩子平安，待我回到你們身邊，我們再也不要用小的可憐的手機屏幕來看彼此，我要帶你們去看整個世界。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>萬衆期待，英國黑暗料理</title>
      <link>https://winterwang.github.io/post/black-meal/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/black-meal/</guid>
      <description>

&lt;h3 id=&#34;康沃爾的牛肉餡餅-贊-2017-12-16-the-shop-in-the-square-https-www-google-com-maps-place-the-shop-in-the-square-50-3310101-4-2021014-21z-data-4m13-1m7-3m6-1s0x0-0x0-2zntdcsde5jzuyljaitia0wraxmicwny4yilc-3b1-8m2-3d50-3311-4d-4-202-3m4-1s0x486c94411d32061f-0xc6ba3bcac8fcc931-8m2-3d50-331087-4d-4-2021739&#34;&gt;康沃爾的牛肉餡餅！ 贊！ (2017-12-16 @&lt;a href=&#34;https://www.google.com/maps/place/The+Shop+in+the+Square/@50.3310101,-4.2021014,21z/data=!4m13!1m7!3m6!1s0x0:0x0!2zNTDCsDE5JzUyLjAiTiA0wrAxMicwNy4yIlc!3b1!8m2!3d50.3311!4d-4.202!3m4!1s0x486c94411d32061f:0xc6ba3bcac8fcc931!8m2!3d50.331087!4d-4.2021739&#34; target=&#34;_blank&#34;&gt;The Shop in the Square&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1483.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;看起來美味但是甜到牙痛的聖誕蛋糕-2017-12-17-calstock-homestay&#34;&gt;看起來美味但是甜到牙痛的聖誕蛋糕 (2017-12-17 @Calstock Homestay)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1559.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;香腸美味-烤雞美味-洋蔥有點糊但是還是很美味-2017-12-16-jane-ian-s-homestay&#34;&gt;香腸美味！烤雞美味！洋蔥有點糊但是還是很美味！ (2017-12-16 @Jane&amp;amp;Ian&amp;rsquo;s Homestay)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_20171217_045212.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;在中國城買到最贊的國貨-廈門鐵觀音-2017-12-09-london-china-town&#34;&gt;在中國城買到最贊的國貨！廈門鐵觀音 (2017-12-09 @London China Town)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1374.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;貴到無法下手的三文魚壽司-2017-12-06-waitrose&#34;&gt;貴到無法下手的三文魚壽司 (2017-12-06 @Waitrose)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1356.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;和日本一風堂味道一樣但是貴一倍的豚骨拉麵-2017-12-02-london-ippudo-http-www-ippudo-co-uk&#34;&gt;和日本一風堂味道一樣但是貴一倍的豚骨拉麵 (2017-12-02 @&lt;a href=&#34;http://www.ippudo.co.uk/&#34; target=&#34;_blank&#34;&gt;London Ippudo&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1312.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;學校附近和同學一起去喝過最棒的拿鐵-缺點是杯子太小-2017-12-01-tap-caffee-http-www-tapcoffee-co-uk&#34;&gt;學校附近和同學一起去喝過最棒的拿鐵，缺點是杯子太小 (2017-12-01 @&lt;a href=&#34;http://www.tapcoffee.co.uk/&#34; target=&#34;_blank&#34;&gt;Tap Caffee&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1306.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;brunch-在長頸鹿餐廳可以打8折-2017-11-29-giraffe-https-www-giraffe-net&#34;&gt;Brunch 在長頸鹿餐廳可以打8折 (2017-11-29 @&lt;a href=&#34;https://www.giraffe.net/&#34; target=&#34;_blank&#34;&gt;Giraffe&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1293.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;約克郡的傳統午餐-美味牛肉-2017-11-26-the-judge-s-lodging-https-www-thwaites-co-uk-hotels-and-inns-inns-judges-lodging-at-york-food-and-drink-menus&#34;&gt;約克郡的傳統午餐，美味牛肉 (2017-11-26 @&lt;a href=&#34;https://www.thwaites.co.uk/hotels-and-inns/inns/judges-lodging-at-york/food-and-drink/menus/&#34; target=&#34;_blank&#34;&gt;The Judge&amp;rsquo;s Lodging&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1244.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;謝菲爾德的聖誕街市賣的烤香腸-2017-11-25-sheffield&#34;&gt;謝菲爾德的聖誕街市賣的烤香腸 (2017-11-25 @Sheffield)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1143.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;日本同學從日本帶來的速食味增湯-美味至極-2017-11-23-international-hall&#34;&gt;日本同學從日本帶來的速食味增湯，美味至極 (2017-11-23 @International Hall)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_1118.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;國王十字車站對面的新加坡華人餐廳-海南雞飯不錯-2017-11-01-chop-chop-noodle-bar-https-www-google-com-maps-place-chop-chop-noodle-bar-51-5303949-0-1226249-19z-data-4m13-1m7-3m6-1s0x0-0x0-2znthcsdmxjzq5ljgitiawwrawnycyms43ilc-3b1-8m2-3d51-5305-4d-0-1227-3m4-1s0x0-0x252e2c027563f1e4-8m2-3d51-5303959-4d-0-122609&#34;&gt;國王十字車站對面的新加坡華人餐廳，海南雞飯不錯 (2017-11-01 @&lt;a href=&#34;https://www.google.com/maps/place/Chop+Chop+Noodle+Bar/@51.5303949,-0.1226249,19z/data=!4m13!1m7!3m6!1s0x0:0x0!2zNTHCsDMxJzQ5LjgiTiAwwrAwNycyMS43Ilc!3b1!8m2!3d51.5305!4d-0.1227!3m4!1s0x0:0x252e2c027563f1e4!8m2!3d51.5303959!4d-0.122609&#34; target=&#34;_blank&#34;&gt;Chop Chop Noodle Bar&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_0649.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;同學宿舍裏的自制小炒-2017-10-21-the-garden-hall&#34;&gt;同學宿舍裏的自制小炒 (2017-10-21 @The Garden Hall)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_0548.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;大英博物館前的中餐館的水煮魚-2017-10-20-chang-s-noodle-https-www-google-com-maps-place-chang-s-noodle-51-517143-0-1256334-21z-data-4m13-1m7-3m6-1s0x0-0x0-2znthcsdmxjzaxljyitiawwrawnyczms44ilc-3b1-8m2-3d51-5171-4d-0-1255-3m4-1s0x48761b3301f99d9d-0x3ba6ded2ee933a5a-8m2-3d51-5172364-4d-0-1254925&#34;&gt;大英博物館前的中餐館的水煮魚 (2017-10-20 @&lt;a href=&#34;https://www.google.com/maps/place/Chang&#39;s+Noodle/@51.517143,-0.1256334,21z/data=!4m13!1m7!3m6!1s0x0:0x0!2zNTHCsDMxJzAxLjYiTiAwwrAwNyczMS44Ilc!3b1!8m2!3d51.5171!4d-0.1255!3m4!1s0x48761b3301f99d9d:0x3ba6ded2ee933a5a!8m2!3d51.5172364!4d-0.1254925&#34; target=&#34;_blank&#34;&gt;Chang&amp;rsquo;s Noodle&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_0537.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;大英博物館前的都可茶飲買到的原味珍珠奶茶-3-5-有學生優惠-2017-10-20-coco-http-en-coco-tea-com&#34;&gt;大英博物館前的都可茶飲買到的原味珍珠奶茶 £3.5 有學生優惠 (2017-10-20 @&lt;a href=&#34;http://en.coco-tea.com/&#34; target=&#34;_blank&#34;&gt;Coco&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_0534.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;雞腿不錯但是旁邊的配菜有點像中藥味的壓縮餅乾-2017-10-08-ihdining-room&#34;&gt;雞腿不錯但是旁邊的配菜有點像中藥味的壓縮餅乾 (2017-10-08 @IHdining room)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/953062095.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;哈利波特特約飲料-butterbeer-奶油啤酒-2017-10-07-warner-bros-studio-tour-london-https-www-wbstudiotour-co-uk&#34;&gt;哈利波特特約飲料 Butterbeer （奶油啤酒）(2017-10-07 @&lt;a href=&#34;https://www.wbstudiotour.co.uk/&#34; target=&#34;_blank&#34;&gt;Warner Bros. Studio Tour London&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/244977493.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;以爲是甜食的派結果裏面包着牛肉的奇怪料理-2017-10-07-ihdining-room&#34;&gt;以爲是甜食的派結果裏面包着牛肉的奇怪料理 (2017-10-07 @IHdining room)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/1959199628.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;羅素廣場地鐵站門口的小攤賣的超划算味道很正的新鮮草莓-2017-10-05-russel-square-station-https-www-google-co-uk-maps-place-russell-square-station-51-523111-0-1265731-17z-data-3m1-4b1-4m5-3m4-1s0x48761b30d8fe5173-0xcf6c5a5908686210-8m2-3d51-523111-4d-0-1243844-hl-en&#34;&gt;羅素廣場地鐵站門口的小攤賣的超划算味道很正的新鮮草莓！(2017-10-05 @&lt;a href=&#34;https://www.google.co.uk/maps/place/Russell+Square+Station/@51.523111,-0.1265731,17z/data=!3m1!4b1!4m5!3m4!1s0x48761b30d8fe5173:0xcf6c5a5908686210!8m2!3d51.523111!4d-0.1243844?hl=en&#34; target=&#34;_blank&#34;&gt;Russel Square Station&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/1040178656.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;价值5镑的食堂素食色拉一盒-2017-10-02-lshtm食堂&#34;&gt;价值5镑的食堂素食色拉一盒 (2017-10-02@LSHTM食堂)&lt;/h3&gt;

&lt;p&gt;新鮮，但是米飯有點夾生。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/41913438.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;味道超讚牛肉披薩-diavolo-2017-09-28-pizza-express-in-charlotte-street-https-www-pizzaexpress-com-charlotte-street-utm-source-google-utm-medium-places-utm-campaign-charlotte-street&#34;&gt;味道超讚牛肉披薩 Diavolo (2017-09-28 @&lt;a href=&#34;https://www.pizzaexpress.com/charlotte-street?utm_source=Google&amp;amp;utm_medium=Places&amp;amp;utm_campaign=charlotte-street&#34; target=&#34;_blank&#34;&gt;Pizza Express in Charlotte Street&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_20170928_184500.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;菜單上的說明是這樣滴：
Hot spiced beef, pepperoni, mozzarella, tomato, green pepper, red onion and Tabasco, with your choice of hot green, Roquito or jalapeño peppers. Available as Classic or Romana&lt;/p&gt;

&lt;h3 id=&#34;羊肉味的奶油夾心三明治-2017-09-24-store-street-espresso-http-www-storestespresso-co-uk&#34;&gt;羊肉味的奶油夾心三明治 (2017-09-24 @&lt;a href=&#34;http://www.storestespresso.co.uk/&#34; target=&#34;_blank&#34;&gt;Store Street Espresso&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;我點菜之前還故意跟收銀員小妹搭訕，讓她推薦一下今天的特色三明治。
她推薦的這個 Goat Cheese Sandwich。 當然我一開始聽到這名字的時候就有點猶豫。但是想說既然是推薦的應該至少不會有什麼怪味道。結果事實證明了，我的想法是多麼的幼稚。&lt;/p&gt;

&lt;p&gt;看這剛出爐的香噴噴的三明治，我咬下第一口就差點吐了。羊羶味在我喉嚨和鼻腔中打轉。後悔也來不及了。另外我同同時還點了 Espresso。就是特濃咖啡。口味超重！不能喝濃咖啡的一定要慎點！！！！&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/1388034054.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;酸酸的不知道怎麼形容的麵包-日期忘了-估計是剛到的第二個早晨的早餐-ihdining-room&#34;&gt;酸酸的不知道怎麼形容的麵包 (日期忘了，估計是剛到的第二個早晨的早餐@IHdining room)&lt;/h3&gt;

&lt;p&gt;這麵包吃起來鬆鬆的，然額，麵的味道有些酸，又不像是過期食品，而像是本來就應該是這樣的味道的酸麵包。讓人不想再嘗試第二次。。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/890249589.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;美味海鮮飯-2017-09-24-ciao-bella-http-ciaobellarestaurant-co-uk&#34;&gt;美味海鮮飯 (2017-09-24 @&lt;a href=&#34;http://ciaobellarestaurant.co.uk/&#34; target=&#34;_blank&#34;&gt;Ciao Bella&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;感謝&lt;a href=&#34;https://kclpure.kcl.ac.uk/portal/li.yan.html&#34; target=&#34;_blank&#34;&gt;顏師兄&lt;/a&gt;帶領，終於找到了一家可以吃到正常大米的飯店了！且海鮮量超足！&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/737031981.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;看起來很奇怪的整魚炸薯條&#34;&gt;看起來很奇怪的整魚炸薯條&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/656438330.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;外觀其實讓人沒什麼食慾的烤魚&#34;&gt;外觀其實讓人沒什麼食慾的烤魚&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/1628745573.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;酸奶放在白煮雞胸肉上&#34;&gt;酸奶放在白煮雞胸肉上&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/img/IMG_0185.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Notes in London School of Hygiene &amp; Tropical Medicine</title>
      <link>https://winterwang.github.io/project/lshtmlearningnote/</link>
      <pubDate>Tue, 14 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/project/lshtmlearningnote/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;We are drowning in information and starving for knowledge.
Click the graph and you can learn what I learnt.&lt;/p&gt;

&lt;p&gt;&amp;mdash; Chaochen Wang in London 2017.09&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/LSHTMlearningnote/&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://winterwang.github.io/img/cover.jpg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>徒手打造一個假設檢驗</title>
      <link>https://winterwang.github.io/post/construction-of-a-hypothesis-test/</link>
      <pubDate>Wed, 08 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/construction-of-a-hypothesis-test/</guid>
      <description>&lt;div id=&#34;-hypothesis-testing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;什麼是假設檢驗 Hypothesis testing&lt;/h3&gt;
&lt;p&gt;一般來說，我們的&lt;strong&gt;假設&lt;/strong&gt;（或者叫&lt;strong&gt;假說&lt;/strong&gt;）是對與我們實驗觀察數據來自的總體（或人羣）的&lt;strong&gt;概率分佈&lt;/strong&gt;的描述。在參數檢驗的背景下，就是要檢驗描述這個總體（或人羣）的&lt;strong&gt;概率分佈&lt;/strong&gt;的參數 (parameters)。最典型的情況是，我們提出兩個互補的假設，一個叫作&lt;strong&gt;零假設&lt;/strong&gt;（或者叫&lt;strong&gt;原假設&lt;/strong&gt;），null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;)；另一個是與之對應的（互補的）替代假設，althernative hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_1/H_A\)&lt;/span&gt;)。&lt;/p&gt;
&lt;p&gt;例如，若 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 是一個服從二項分佈的隨機離散變量 &lt;span class=&#34;math inline&#34;&gt;\(X\sim Bin(5, \theta)\)&lt;/span&gt;。可以考慮如下的零假設和替代假設：&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\frac{1}{2}; H_1: \theta=\frac{2}{3}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;當建立了零假設和替代假設以後，假設檢驗就是要建立如下的規則以確定：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;從樣本中計算所得的參數估計值爲多少時，拒絕零假設。（接受替代假設爲“真”）&lt;/li&gt;
&lt;li&gt;從樣本中計算所得的參數估計值爲多少時，零假設不被拒絕。（接受零假設爲“真”）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：（這一段很繞）&lt;/p&gt;
&lt;p&gt;上面的例子是零假設和替代假設均爲簡單假設的情況，實際操作中常常會設計更加複雜的（不對稱的）假設：即簡單的 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;，複雜的 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;。如此一來當零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 不被拒絕時，我們並不一定就接受之。因爲無證據證明 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt; 不等於有證據證明 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;。&lt;em&gt;&lt;strong&gt;(Absence of evidence is not evidence of absence).&lt;/strong&gt;&lt;/em&gt; 換句話說，無證據讓我們拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 本身並不成爲支持 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 爲“真”的證據。因爲在實際操作中，當我們設定的簡單的零假設沒有被拒絕，可能還存在其他符合樣本數據的零假設；相反地，當樣本數據的計算結果拒絕了零假設，我們只能接受替代假設。所以，反對零假設的證據，同時就是支持替代假設的證據。&lt;/p&gt;
&lt;p&gt;在樣本空間 sample space 中，決定了零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 會被拒絕的子集 subset，被命名爲拒絕域 rejection region 或者 判別區域 critical region，用 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 來標記。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;錯誤概率和效能方程&lt;/h3&gt;
&lt;p&gt;這一部分可以參考之前&lt;a href=&#34;https://winterwang.github.io/post/sample-size-in-clinical-trial/&#34;&gt;臨牀試驗樣本量計算&lt;/a&gt;的部分。&lt;/p&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Table 1: Definition of Type I and Type II error
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;border-bottom:hidden&#34; colspan=&#34;2&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;&#34; colspan=&#34;2&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px;&#34;&gt;
SAMPLE
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x} \notin \mathfrak{R}\)&lt;/span&gt; Accept &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x} \in \mathfrak{R}\)&lt;/span&gt; Reject &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;vertical-align: middle !important;&#34; rowspan=&#34;2&#34;&gt;
TRUTH
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; is true
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\checkmark\)&lt;/span&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; &lt;br&gt; Type I error
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt; is true
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; &lt;br&gt; Type II error
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\checkmark\)&lt;/span&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;假如一個假設檢驗是關於總體參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0: \theta=\theta_0 \;vs.\; H_1: \theta=\theta_1 \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這個檢驗的效能被定義爲當替代假設爲“真”時，拒絕零假設的概率（能夠檢驗出有真實差別的能力）：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Power&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(=Prob(\underline{x}\in\mathfrak{R}|H_1\; is\; true) = 1-Prob(Type \; II\; error)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;檢驗的顯著性水平用 &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; 來表示。&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; 的直觀意義就是，檢驗結果錯誤的拒絕了零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;，接受了替代假設 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;，即假陽性的概率。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Prob(\underline{x}\in \mathfrak{R} |H_0 \;is\;true)=Prob(Type\;I\;error)\)&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈爲例&lt;/h4&gt;
&lt;p&gt;用本文開頭的例子： &lt;span class=&#34;math inline&#34;&gt;\(X\sim Bin(5,\theta)\)&lt;/span&gt;。和我們建立的零假設和替代假設：&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\frac{1}{2}; H_1: \theta=\frac{2}{3}\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;考慮兩種檢驗方法：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;A 方法：當且僅當5次觀察都爲“成功”時才拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0 (i.e.\; X=5)\)&lt;/span&gt;。所以此時判別區域 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 爲 &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;。檢驗效能爲：&lt;span class=&#34;math inline&#34;&gt;\(Prob(X=5|H_1 \;is\;true)=(\frac{2}{3})^5=0.1317\)&lt;/span&gt;。顯著性水平爲 &lt;span class=&#34;math inline&#34;&gt;\(Prob(X=5|H_0\;is\;true)=(\frac{1}{2})^5=0.03125\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;B 方法：當觀察到3,4,5次“成功”時，拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0 (i.e.\; X=3,4,5)\)&lt;/span&gt;。此時判別區域 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 爲 &lt;span class=&#34;math inline&#34;&gt;\(3,4,5\)&lt;/span&gt;。檢驗效能爲：&lt;span class=&#34;math inline&#34;&gt;\(Prob(X=3,4,or\:5|H_1\;is\;ture)=\sum_{i=3}^5(\frac{2}{3})^i(\frac{1}{3})^{5-i}\approx0.7901\)&lt;/span&gt;；顯著性水平爲：&lt;span class=&#34;math inline&#34;&gt;\(Prob(X=3,4,5|H_0\;is\;true)=\sum_{i=3}^5(\frac{1}{2})^i(\frac{1}{2})^{5-i}=0.5\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the power in test B
dbinom(3,5,2/3)+dbinom(4,5,2/3)+dbinom(5,5,2/3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7901235&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the size in test B
dbinom(3,5,0.5)+dbinom(4,5,0.5)+dbinom(5,5,0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;比較上面兩種檢驗方法，可以看到，用B方法時，我們有更高的概率獲得假陽性結果（第一類錯誤，錯誤地拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;，接受 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;)，但是也有更高的檢驗效能（真陽性更高）。這個例子就說明了，試圖提高檢驗效能的同時，會提高犯第一類錯誤的概率。實際操作中我們常常將第一類錯誤的概率固定，例如 &lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05\)&lt;/span&gt;，然後儘可能選擇效能最高的檢驗方法。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;如何選擇要檢驗的統計量&lt;/h3&gt;
&lt;p&gt;在上面的二項分佈的實驗中，“成功的次數” 是我們感興趣的要檢驗的統計量。但也可能是第一次出現 “成功” 之前的實驗次數，或者，任何與假設相關的統計量。相似的，如果觀察不是離散變量而是連續的，可以拿來檢驗的指標就有很多，如均值，中位數，衆數，幾何平均值等。&lt;/p&gt;
&lt;p&gt;幸運地是，當明確了零假設和替代假設後，我們可以利用 &lt;a href=&#34;https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma&#34;&gt;Neyman-Pearson lemma&lt;/a&gt; 似然比公式&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;來決定使用哪個統計量做檢驗&lt;strong&gt;最有效&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[=\frac{L_{H_0}}{L_{H_1}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這公式很直觀，因爲當數據更加支持 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt; 時 (&lt;span class=&#34;math inline&#34;&gt;\(L_{H_1}\)&lt;/span&gt; 更大)，&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的可能性相對更小，就更應該被拒絕。而且，由於似然比越小，他的對數就越小，使用對數似然比常常更加直觀：&lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;那到底要多小才算小？這個進入拒絕域的閾值由兩個指標來決定：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;被檢驗統計量的樣本分佈&lt;/li&gt;
&lt;li&gt;第一類錯誤概率 &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;以已知方差的正態分佈爲例&lt;/h4&gt;
&lt;p&gt;假如已知 &lt;span class=&#34;math inline&#34;&gt;\(X_1, \cdots, X_n \stackrel{i.i.d}{\sim} N(\mu, \sigma^2)\)&lt;/span&gt; 而且方差 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 也是已知的。如果令 &lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu=5\; ;H_1: \mu=10\)&lt;/span&gt; 可以通過如下的方法找到我們需要的最佳檢驗統計量 &lt;u&gt;best statistic&lt;/u&gt; 根據之前的&lt;a href=&#34;https://winterwang.github.io/post/log-likelihood-ratio/&#34;&gt;推導&lt;/a&gt;可知正態分佈的似然方程如下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\ell(\mu|\underline{x}) =-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以已知 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 時，我們的零假設和替代假設之間的對數似然比 &lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\ell_{H_0}-\ell_{H_1}=-\frac{1}{2\sigma^2}(\sum_{i=1}^n(x_i-5)^2-\sum_{i=1}^n(x_i-10)^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然俄，我們只需要考慮隨着數據變化的部分，所以忽略掉不變的部分&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\ell_{H_0}-\ell_{H_1} &amp;amp; = -(\sum_{i=1}^n(x_i-5)^2-\sum_{i=i}^n(x_i-10)^2)\\
                &amp;amp; = 75n - 2\times(10-5)\sum_{i=1}^nx_i \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以只要樣本和 &lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^nx_i\)&lt;/span&gt; &lt;u&gt;(最佳統計量 best statistic)&lt;/u&gt; 足夠大，零假設就會被拒絕。而且注意到最佳統計量可以乘以任何常數用作新的最佳統計量。所以爲了方便我們就用樣本均數 &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{n}\sum_{i=1}^nx_i\)&lt;/span&gt; 作此處的最佳統計量。所以此時，我們的最佳檢驗就是當樣本均值足夠大，超過某個閾值時，我們拒絕零假設。而且，樣本均值的樣本分佈是可以知道的，這樣就便於我們繼續計算下一步：拒絕域 （判別區域）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-composite-hypotheses&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;複合假設 composite hypotheses&lt;/h3&gt;
&lt;p&gt;目前爲止我們討論的假設檢驗限制太多，實際操作時，我們多考慮類似如下的假設：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\theta_0 \;v.s.\; H_1: \theta&amp;gt;\theta_0\)&lt;/span&gt; [&lt;strong&gt;單側&lt;/strong&gt;的替代假設]&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\theta_0 \;v.s.\; H_1: \theta\neq\theta_0\)&lt;/span&gt; [&lt;strong&gt;雙側&lt;/strong&gt;的替代假設]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以我們面臨的問題是簡單假設中用於判定的最佳統計量，是否還適用？我們一一來看：&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;單側替代假設&lt;/h4&gt;
&lt;p&gt;之前的推導中我們發現，樣本均值越大，零假設和替代假設的對數似然比 &lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt; 越小。所以我們在樣本均值較大時，拒絕零假設，那麼就可以把原來使用的簡單替代假設 &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu=10\)&lt;/span&gt; 擴展爲，任意大於 &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; ，即 &lt;span class=&#34;math inline&#34;&gt;\(\mu&amp;gt;5\)&lt;/span&gt; 。因爲大於 &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; 的任何均值，都提供了更小的對數似然比，都會讓我們拒絕零假設。所以在正態分佈時，單側替代假設的最佳檢驗統計量還是&lt;strong&gt;樣本均值&lt;/strong&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;雙側替代假設&lt;/h4&gt;
&lt;p&gt;雙側替代假設的情況下，我們無法繼續使用樣本均值作爲最佳統計量。因爲當我們想檢驗：&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu=5 \;v.s.\; H_1: \mu&amp;lt;5\)&lt;/span&gt; 時，必須獲得足夠小的樣本均值才能讓我們拒絕零假設。先按下不表。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-how-to-quantify-evidence-against-h_0&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;如何獲得反對零假設的證據 how to quantify evidence against &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;重新再考慮符合假設：&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\theta_0\;v.s.\;H_1: \theta&amp;gt;\theta_0\)&lt;/span&gt; 假如存在一個總是可用的最佳檢驗統計量，用 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 來標記 (或 &lt;span class=&#34;math inline&#34;&gt;\(T(x)\)&lt;/span&gt;)， 這個統計量足夠大時，我們拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;。 別忘了我們還要定義判別區域：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(\underline{x}\in\mathfrak{R}|H_0)=\alpha\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果我們知道 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 的樣本分佈，我們很容易就可以使用一個閾值 &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; 來定義這個判別區域：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(T\geqslant c|H_0)=\alpha\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;更加正式的，我們定義判別區域 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\{\underline{x}:Prob(T(x)\geqslant c|H_0)=\alpha\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;換句話說，當統計量 &lt;span class=&#34;math inline&#34;&gt;\(T&amp;gt;c\)&lt;/span&gt; 時，我們拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 。如果先不考慮拒絕或不拒絕的二元判定，我們可以用一個連續型測量值來量化反對零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的證據。再考慮從觀察數據中獲得的 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; ，即數據告訴我們的 &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; 。所以，當 &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; 值越大，說明觀察值相對零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 越往極端的方向走。因此我們可以用 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 的樣本分佈來計算觀察值大大於等於這個閾值（極端值）時的概率：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p=Prob(T\geqslant t|H_0)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這個概率公式被稱爲是單側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值 &lt;strong&gt;(one-side p-value)&lt;/strong&gt;。單側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值越小，統計量 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 的樣本空間就有越小比例（越強）的證據支持零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;我們把這以思想用到假設檢驗中時，就可以認爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p&amp;lt;\alpha \Leftrightarrow t&amp;gt;c\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以用我們一貫的設定 &lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05\)&lt;/span&gt;，所以如果計算獲得 &lt;span class=&#34;math inline&#34;&gt;\(p&amp;lt;0.05\)&lt;/span&gt; 我們就認爲獲得了足夠強的拒絕零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的證據。&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;回到正態分佈的均值比較問題上來（單側替代假設）&lt;/h4&gt;
&lt;p&gt;繼續考慮 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim} N(\mu, \sigma^2)\)&lt;/span&gt;，假設已知 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2=10\)&lt;/span&gt;，我們要檢驗的是 &lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu=5 \;v.s.\; H_1: \mu&amp;gt;5\)&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;確定最佳檢驗統計量：已經證明過，單側替代假設的最佳檢驗統計量是&lt;strong&gt;樣本均值&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;確定該統計量的樣本分佈：已知樣本均數的樣本分佈是 &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\sim N(\mu,\sigma^2/n)\)&lt;/span&gt; 。&lt;br&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)\)&lt;/span&gt;，所以在 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 條件下，&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow Z=\frac{\bar{X}-5}{\sqrt{10}/\sqrt{n}} \sim N(0,1)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;所以當一個檢驗的一類錯誤概率設定爲 &lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05\)&lt;/span&gt; 時，我們使用的判別區域使統計量據落在該判別區域內的概率爲 &lt;span class=&#34;math inline&#34;&gt;\(0.05\)&lt;/span&gt;：&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(Prob(\bar{X}\geqslant c|H_0) = 0.05\)&lt;/span&gt; &lt;br&gt; 已知在標準正態分佈時，&lt;span class=&#34;math inline&#34;&gt;\(Prob(Z\geqslant1.64)=0.05=Prob(\frac{\bar{X}-5}{\sqrt{10}/\sqrt{n}}\geqslant1.64)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;假設樣本量是 &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;，那麼數據的判別區域 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 就是 &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\geqslant6.64\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;假設觀察數據告訴我們，&lt;span class=&#34;math inline&#34;&gt;\(\bar{X}=7.76\)&lt;/span&gt; 。那麼這一組觀察數據計算得到的統計量落在了判別區域內，所以說是有足夠的證據拒絕接受 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的。&lt;/li&gt;
&lt;li&gt;我們可以給這個觀察數據計算相應的單側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值：&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(p=Prob(\bar{X}\geqslant7.76|H_0)=Prob(Z+5\geqslant7.76)\\=Prob(Z\geqslant2.76)=0.003\)&lt;/span&gt; &lt;br&gt; 所以，數據告訴我們，在 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的前提下，觀察值出現的概率是 &lt;span class=&#34;math inline&#34;&gt;\(0.3\%\)&lt;/span&gt; 。即，在無數次取樣實驗中，僅有 &lt;span class=&#34;math inline&#34;&gt;\(0.3\%\)&lt;/span&gt; 的結果可以給出支持 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的證據。因此我們拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 接受 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-p-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;雙側替代假設情況下，雙側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值的定量方法&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-08-construction-of-a-hypothesis-test_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;此處故意使用一個左右不對稱的概率密度分佈來解釋。&lt;/p&gt;
&lt;p&gt;現在的替代假設是雙側的：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0: \theta=\theta_0 \;v.s.\; H_1:  \theta\neq\theta_0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;正常來說，雙側的假設檢驗應該分成兩個單側檢驗。即：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1: \theta&amp;gt;\theta_0\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1: \theta&amp;lt;\theta_0\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;每個單側檢驗都有自己的最佳檢驗統計量。令 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 是 1. 的最佳檢驗統計量，該統計量的樣本分佈如上圖所示（左右不對稱）。假如觀察數據給出的統計量爲 &lt;span class=&#34;math inline&#34;&gt;\(t2\)&lt;/span&gt;，那麼在概率上反對零假設的情況可以有兩種：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(T\geqslant t2\)&lt;/span&gt; 其中， &lt;span class=&#34;math inline&#34;&gt;\(Prob(T\geqslant t2|H_0)=p1\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(T\leqslant t1\)&lt;/span&gt; 其中， &lt;span class=&#34;math inline&#34;&gt;\(Prob(T\leqslant t1|H_0) =p1\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以概率密度分佈兩側的距離可以不對稱，但是只要左右兩側概率密度分佈的面積(&lt;span class=&#34;math inline&#34;&gt;\(=p1\)&lt;/span&gt;)相同，那麼就可以直接認爲，雙側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值是兩側面積之和 (&lt;span class=&#34;math inline&#34;&gt;\(p=2\times p1\)&lt;/span&gt;)，且觀察數據提供的統計量落在這兩個面積內的話，都足以提供證據拒絕零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;回到上文中單側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值爲&lt;span class=&#34;math inline&#34;&gt;\(0.003\)&lt;/span&gt;，故雙側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值就是它的兩倍：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(p1=Prob(\bar{X}\geqslant7.76|H_0)=Prob(Z+5\geqslant7.76)\\=Prob(Z\geqslant2.76)=0.003\\ \Rightarrow p=2\times p1=0.006\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;區分與&lt;a href=&#34;https://winterwang.github.io/post/log-likelihood-ratio/&#34;&gt;之前討論的似然比&lt;/a&gt;，之前討論的似然比只是所有的似然和極大似然之間的比，此處的似然比只是純粹在探討兩個假設之間可能性之比。&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Rememer that &lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt; is a random variable: the data varies &lt;strong&gt;each time&lt;/strong&gt; we sample, with consequently varying relative support for the hypotheses, and so we are only interested in that part of &lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt; which depends on the results, the data, which vary with each sample (i.e. which contains the random part); the constant part provides no information on the relative support the data give to the hypotheses, so we ignore it.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>二次方程近似法求對數似然比 approximate log-likelihood ratios</title>
      <link>https://winterwang.github.io/post/approximate-log-likelihood-ratios/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/approximate-log-likelihood-ratios/</guid>
      <description>&lt;p&gt;爲什麼要用二次方程近似對數似然比方程？&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;上節也看到，我們會碰上難以用代數學計算獲得對數似然比信賴區間的情況 (&lt;a href=&#34;https://winterwang.github.io/post/log-likelihood-ratio/&#34;&gt;binomial example&lt;/a&gt;)。&lt;/li&gt;
&lt;li&gt;我們同時知道，對數似然比方程會隨着樣本量增加而越來越漸進於二次方程，且左右對稱。&lt;/li&gt;
&lt;li&gt;所以，我們考慮當樣本量足夠大時，用二次方程來近似對數似然比方程從而獲得參數估計的信賴區間。&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;-normal-approximation-to-the-log-likelihood&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;正態近似法求對數似然 Normal approximation to the log-likelihood&lt;/h3&gt;
&lt;p&gt;根據&lt;a href=&#34;https://winterwang.github.io/post/log-likelihood-ratio/&#34;&gt;前一節&lt;/a&gt;，如果樣本均數的分佈符合正態分佈：&lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\sim N(\mu, \sigma^2/n)\)&lt;/span&gt;。那麼樣本均數的對數似然比爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\mu|\bar{X})=\ell(\mu|\bar{X})=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中， &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; 是正態分佈總體均數 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 的極大似然估計 (maximum likelihood estimator, MLE)。如果已知總體的方差參數，那麼 &lt;span class=&#34;math inline&#34;&gt;\(\sigma/\sqrt{n}\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; 的標準誤 (standard error)。&lt;/p&gt;
&lt;p&gt;因此，假設 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 是我們想尋找的總體參數。有些人提議可以使用下面的關於 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的二次方程來做近似：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(\theta|data)=-\frac{1}{2}(\frac{\theta-M}{S})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;上述方程具有一個正態二次對數似然 (比) 的形式，而且該方程的極大似然估計(MLE)， &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 的標準誤爲 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;。如果我們正確地選用 &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;，那我們就可以用這樣的方程來近似求真實觀察數據的似然 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;通過近似正態對數似然比，&lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 應當選用使方程取最大值時，參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的極大似然估計 &lt;span class=&#34;math inline&#34;&gt;\(M=\hat{\Theta}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;但是在選用標準誤 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 上必須滿足下列條件：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 是極大似然估計 &lt;span class=&#34;math inline&#34;&gt;\(\hat{\Theta}\)&lt;/span&gt; 的標準誤。&lt;/li&gt;
&lt;li&gt;被選擇的 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 必須儘可能的使該二次方程形成一個十分接近真實的對數似然比方程。特別是在最大值的部分必須與之無限接近或者一致。所以二者在 MLE 的位置應當有相同的曲率（二階導數）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由於，一個方程的曲率是該方程的二階導數（斜線斜率變化的速度）。所以對數似然比方程在 MLE 取最大值時的曲率（二階導數）爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left.\frac{d^2}{d\theta^2}\ell(\theta)\right\vert_{\theta=\hat{\theta}}=\ell^{\prime\prime}(\hat{\theta})=-\frac{1}{S^2}\\
\Rightarrow S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;在正態分佈的例子下，&lt;span class=&#34;math inline&#34;&gt;\(M=\bar{x}, S=\sigma/\sqrt{n}\)&lt;/span&gt;。對數似然比方程最大值時的曲率（二階導數）恰好就爲標準誤的平方的負倒數：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\ell^{\prime\prime}(\theta)=-\frac{1}{SE^2}\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow\)&lt;/span&gt; 被叫做 &lt;strong&gt;Fisher information&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;稍微總結一下：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;任意的對數似然比方程 &lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)\)&lt;/span&gt; 都可以考慮用一個二次方程來近似：
&lt;span class=&#34;math display&#34;&gt;\[f(\theta|data)=-\frac{1}{2}(\frac{\theta-M}{S})^2\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;其中&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  &amp;amp;M=\hat\theta\\  &amp;amp;S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}\\  &amp;amp;when \\  &amp;amp; n\rightarrow\infty \Rightarrow  \begin{cases}  S^2\rightarrow Var(\hat\theta) \\  S\rightarrow SE(\hat\theta)  \end{cases}  \end{aligned}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;近似法估算對數似然比的信賴區間&lt;/h4&gt;
&lt;p&gt;一旦我們決定了使用正態近似法來模擬對數似然比方程，對數似然比的信賴區間算法就回到了前一節中我們算過的方法，也就是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2f(\theta)&amp;lt;\mathcal{X}_{1,(1-\alpha)}^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;故信賴區間爲： &lt;span class=&#34;math inline&#34;&gt;\(m\pm\sqrt{\mathcal{X}_{1,(1-\alpha)}^2}S\)&lt;/span&gt;。求&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 水平的信賴區間時，&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{X}_{1,0.95}^2=3.84\)&lt;/span&gt;，所以就又看到了熟悉的 &lt;span class=&#34;math inline&#34;&gt;\(M\pm1.96S\)&lt;/span&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;以泊松分佈爲例&lt;/h4&gt;
&lt;p&gt;一個被追蹤的樣本，經過了 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 人年的觀察，記錄到了 &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; 個我們要研究的事件：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[D\sim Poi(\mu), where \mu=\lambda p\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 1. 找極大似然估計 (MLE)，&lt;a href=&#34;https://winterwang.github.io/post/likelihood/&#34;&gt;之前介紹似然方程時推導過的泊松分佈的似然方程&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
P(D=d|\lambda) &amp;amp;= \frac{e^{-\mu}\cdot\mu^d}{d!} \\
 &amp;amp;=\frac{e^{-\lambda p}\cdot\lambda^d p^d}{d!} \\
omitting&amp;amp;\;terms\;not\;in\;\mu \\
&amp;amp;\Rightarrow \ell(\lambda) = dlog\lambda - \lambda p \\
&amp;amp;\Rightarrow \ell^\prime(\lambda) = \frac{d}{\lambda} -p \\
&amp;amp;\Rightarrow \hat\lambda=\frac{d}{p} = \textbf{M}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 2. 求似然方程的二階導數，確認 MLE 是使方程獲得最大值的點，然後確定 &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
&amp;amp; \ell^\prime(\lambda) = \frac{d}{\lambda} -p \\
&amp;amp; \Rightarrow \ell^{\prime\prime}(\lambda) = -\frac{d}{\lambda^2}&amp;lt;0 \Rightarrow \textbf{MLE is maximum} \\
&amp;amp; S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\lambda)}\right\vert_{\lambda=\hat{\lambda}=d/p} = -\frac{1}{-d/\hat\lambda^2} = -\frac{1}{-d/(d/p)^2} \\
&amp;amp;\Rightarrow S^2 = \frac{d}{p^2} \\
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 3. 把前兩部求得的 &lt;span class=&#34;math inline&#34;&gt;\(MLE\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt; 代入近似的二次方程：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
&amp;amp; \hat\lambda=\frac{d}{p}=M,\; S^2 = \frac{d}{p^2}  \\
&amp;amp; using\;approximate\;quadratic\;llr \\
&amp;amp; q(\lambda) = -\frac{1}{2}(\frac{\lambda-M}{S})^2\\
&amp;amp;\Rightarrow q(\lambda) = -\frac{1}{2}(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2\\
&amp;amp; let \; q(\lambda)=-1.92\\
&amp;amp;\Rightarrow -\frac{1}{2}(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2=-1.92\\
&amp;amp;(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2=3.84\\
&amp;amp;\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}} = \pm1.96\\
&amp;amp;\Rightarrow 95\%CI \;for \;\lambda = \frac{d}{p}\pm1.96\frac{\sqrt{d}}{p}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;結論就是： 發病（死亡）率 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間爲： &lt;span class=&#34;math inline&#34;&gt;\(M\pm1.96S\)&lt;/span&gt;。所以我們不需要每次都代入對數似然比方程，只要算出 &lt;span class=&#34;math inline&#34;&gt;\(MLE = M\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 之後代入這個公式就可以用二次方程近似法算出信賴區間。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈爲例&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[K\sim Bin(n,\pi)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 1. 找極大似然估計 (MLE)：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
&amp;amp; Prob(K=k) = \pi^k(1-\pi)\binom{n}{k}\\
&amp;amp;\Rightarrow L(\pi|k) = \pi^k(1-\pi)\binom{n}{k}\\
&amp;amp;omitting\;terms\;not\;in\;\pi \\
&amp;amp;\Rightarrow \ell(\pi) = k\:log\pi+(n-k)log(1-\pi) \\
&amp;amp;\ell^\prime(\pi) = \frac{k}{\pi}-\frac{n-k}{1-\pi} \\
&amp;amp; let\;\ell^\prime(\hat\pi) =0 \\
&amp;amp;\Rightarrow \frac{k}{\hat\pi}-\frac{n-k}{1-\hat\pi}=0\\
&amp;amp;\Rightarrow \frac{\hat\pi}{1-\hat\pi}=\frac{k}{n-k}\\
&amp;amp;\Rightarrow \frac{\hat\pi}{1-\hat\pi}=\frac{k/n}{1-k/n}\\
&amp;amp;\Rightarrow \hat\pi=\frac{k}{n} = p = \textbf{M}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 2. 將對數似然方程的二次微分 (二階導數)，確認在 MLE 爲極大值，並確認 &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
&amp;amp;\ell^\prime(\pi) = \frac{k}{\pi}-\frac{n-k}{1-\pi} \\
&amp;amp;\ell^{\prime\prime}(\pi)=\frac{-k}{\pi^2}-\frac{n-k}{(1-\pi)^2} &amp;lt;0 \\
&amp;amp;\therefore at\;\textbf{MLE}\;\ell(\pi)\;has\;maximum \\
S^2&amp;amp;=\left.-\frac{1}{\ell^{\prime\prime}(\pi)}\right\vert_{\pi=\hat\pi=k/n=p}\\
&amp;amp;=\frac{1}{\frac{k}{\hat\pi^2}+\frac{n-k}{(1-\hat\pi)^2}}\\
&amp;amp;=\frac{\hat\pi^2(1-\hat\pi)^2}{k(1-\hat\pi)^2+(n-k)\hat\pi^2}\\
&amp;amp;=\frac{P^2(1-P)^2}{np(1-p)^2+(n-np)p^2}\\
&amp;amp;=\frac{p(1-p)}{n(1-p)+np}\\
&amp;amp;=\frac{p(1-p)}{n}\\
&amp;amp;\Rightarrow S=\sqrt{\frac{p(1-p)}{n}}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 3. 將求得的 MLE 和 &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt; 代入近似信賴區間：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
95\% CI \;for \; \pi:\\
M\pm1.96S=p\pm1.96\sqrt{\frac{p(1-p)}{n}}\\
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-parameter-transformations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;參數轉化 parameter transformations&lt;/h3&gt;
&lt;p&gt;如果將參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 通過某種數學方程轉化成 &lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;，那麼我們可以認爲，轉化後的方程的 MLE 爲 &lt;span class=&#34;math inline&#34;&gt;\(g(\hat\theta)\)&lt;/span&gt;，其中 &lt;span class=&#34;math inline&#34;&gt;\(\hat\theta\)&lt;/span&gt; 是參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的 MLE。&lt;/p&gt;
&lt;p&gt;類似地，如果 &lt;span class=&#34;math inline&#34;&gt;\(\theta_1 \sim \theta_2\)&lt;/span&gt; 是參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的似然比信賴區間，那麼 &lt;span class=&#34;math inline&#34;&gt;\(g(\theta_1)\sim g(\theta_2)\)&lt;/span&gt; 就是 &lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt; 的似然比信賴區間。&lt;/p&gt;
&lt;p&gt;以下爲轉換參數以後獲取信賴區間的步驟：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;將參數通過某些數學方程（通常是取對數）轉化，使新的對數似然比方程更加接近二次方程的對稱圖形。&lt;br&gt; Transform parameter so that &lt;span class=&#34;math inline&#34;&gt;\(llr\)&lt;/span&gt; is closer to a quadratic shape.&lt;/li&gt;
&lt;li&gt;用本節學到的二次方程近似法，求得轉化後的參數的似然比信賴區間。 &lt;br&gt; Use our quadratic approximation on the transformed parameter to calculate our likelihood ratio confidence intervals.&lt;/li&gt;
&lt;li&gt;將第2步計算獲得的似然比信賴區間再通過轉化參數時的逆函數轉換回去，以獲得原參數的似然比信賴區間。&lt;br&gt; Transform the confidence intervals back, or to any scale we wish – they remain valid.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以泊松分佈爲例&lt;/h4&gt;
&lt;p&gt;當我們用泊松分佈模擬事件在某段時間內發生率 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 時，注意到這個事件發生率必須滿足 &lt;span class=&#34;math inline&#34;&gt;\(\lambda&amp;gt;0\)&lt;/span&gt;。當事件發生次數較低時，會讓似然方程的圖形被擠壓在低值附近。如果嘗試用對數轉換 &lt;span class=&#34;math inline&#34;&gt;\(\lambda \rightarrow log(\lambda)\)&lt;/span&gt; 此時 &lt;span class=&#34;math inline&#34;&gt;\(log(\lambda)\)&lt;/span&gt; 就不再被限制與 &lt;span class=&#34;math inline&#34;&gt;\(&amp;gt;0\)&lt;/span&gt;。下面我們嘗試尋找對數轉換過後的 &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(\beta=log(\lambda), \Rightarrow e^\beta=\lambda\)&lt;/span&gt; 從本文上半部分中我們已知 &lt;span class=&#34;math inline&#34;&gt;\(\hat\lambda=\frac{d}{p}\)&lt;/span&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對數轉換以後的 &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 是什麼? &lt;br&gt;根據定義，&lt;span class=&#34;math inline&#34;&gt;\(MLE(\beta)=MLE[log(\lambda)]=log(\hat\lambda)\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow M=\hat\beta=log(\frac{d}{p})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;對數轉換以後的 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 是什麼? &lt;br&gt; 泊松分佈的對數似然方程是：&lt;span class=&#34;math inline&#34;&gt;\(\ell(\lambda|d)=d log(\lambda) - \lambda p\)&lt;/span&gt; 用 &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; 替換掉 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;&lt;/p&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  &amp;amp; \ell(\beta|d)=d \beta - pe^\beta\\  &amp;amp; \Rightarrow \ell^\prime(\beta)=d-pe^\beta \Rightarrow \ell^{\prime\prime}(\beta)=-pe^\beta \\  &amp;amp; S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\beta)}\right\vert_{\beta=\hat{\beta}} = \left.\frac{1}{pe^\beta}\right\vert_{\beta=\hat{\beta}} = \frac{1}{pe^{log(d/p)}}\\  &amp;amp;\Rightarrow S^2=\frac{1}{d} \therefore S=\frac{1}{\sqrt{d}} \end{aligned}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;轉換後的近似二次方程：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  &amp;amp; q(\beta) = -\frac{1}{2}(\frac{\beta-M}{S})^2 = -\frac{1}{2}(\frac{\beta-log(\frac{d}{p})}{\frac{1}{\sqrt{d}}})^2  \end{aligned}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間 &lt;span class=&#34;math inline&#34;&gt;\(=log(\frac{d}{p})\pm1.96\frac{1}{\sqrt{d}}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間 &lt;span class=&#34;math inline&#34;&gt;\(=exp(log(\frac{d}{p})\pm1.96\frac{1}{\sqrt{d}})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈爲例&lt;/h4&gt;
&lt;p&gt;在研究對象 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 人中觀察到 &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; 個人患有某種疾病。&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(\beta=log(\pi) \Rightarrow \pi=e^\beta\)&lt;/span&gt; 從上文的推倒也已知 &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=\frac{k}{n}=p\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned} &amp;amp;\Rightarrow \ell(\beta)=klog\pi+(n-k)log(1-\pi)=k\beta+(n-k)log(1-e^\beta) \\ &amp;amp;\Rightarrow \ell^{\prime}(\beta)=k-\frac{(n-k)(e^\beta)}{1-e^\beta} \\ &amp;amp;\Rightarrow \ell^{\prime\prime}(\beta)=-(n-k)\frac{e^\beta(1-e^\beta)+e^{2\beta}}{(1-e^\beta)^2} \\ &amp;amp; \ell^{\prime\prime}(\beta)= -(n-k)\frac{e^\beta}{(1-e^\beta)^2}\\ &amp;amp;\Rightarrow S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\beta)}\right\vert_{\beta=\hat{\beta}} = \frac{(1-e^{\hat\beta})^2}{(n-k)e^{\hat\beta}} \\ &amp;amp;\because \hat\beta=log(\hat\pi) \\ &amp;amp;\therefore e^{\hat\beta} = \frac{k}{n}\\ &amp;amp;\Rightarrow S^2=\frac{(1-\frac{k}{n})^2}{(n-k)\frac{k}{n}}=\frac{n-k}{nk}=\frac{1}{k}-\frac{1}{n}\\ &amp;amp; \Rightarrow S=\sqrt{\frac{1}{k}-\frac{1}{n}}\\ \end{aligned}\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exercise&lt;/h3&gt;
&lt;div id=&#34;q1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q1&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;在&lt;span class=&#34;math inline&#34;&gt;\(n=100\)&lt;/span&gt;人中觀察到有&lt;span class=&#34;math inline&#34;&gt;\(k=40\)&lt;/span&gt;人患病，假設每個人只有患病，不患病兩個狀態，用二項分佈來模擬這個數據，&lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 爲患病的概率。下面是 &lt;span class=&#34;math inline&#34;&gt;\(\pi \in [0.2,0.6]\)&lt;/span&gt; 區間的對數似然比方程曲線。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pi &amp;lt;- seq(0.2, 0.6, by=0.01)
L &amp;lt;- (pi^40)*((1-pi)^60)
Lmax &amp;lt;- rep(max(L), 41)
LR &amp;lt;- L/Lmax
logLR &amp;lt;- log(LR)

plot(pi, logLR, type = &amp;quot;l&amp;quot;, ylim = c(-11, 0),yaxt=&amp;quot;n&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;logLR(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
grid(NA, 5, lwd = 2) # add some horizontal grid on the background
axis(2, at=seq(-12,0,2), las=2)
title(main = &amp;quot;Figure 1. Binomial log-likelihood ratio&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;用一個二次方程來模擬上面的對數似然比曲線：&lt;span class=&#34;math inline&#34;&gt;\(f(\pi)=-\frac{(\pi-M)^2}{2S^2}\)&lt;/span&gt;，其中 &lt;span class=&#34;math inline&#34;&gt;\(M=\hat\pi=\frac{k}{n}=0.4\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(S^2=\frac{p(1-p)}{n}=0.0024\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mai = c(1.2, 0.5, 1, 0.7))
quad &amp;lt;- -(pi-0.4)^2/(2*0.0024)
plot(pi, quad, type = &amp;quot;l&amp;quot;, ylim = c(-4, 0),yaxt=&amp;quot;n&amp;quot;, col=&amp;quot;red&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
lines(pi, logLR, col=&amp;quot;black&amp;quot;)
grid(NA, 4, lwd = 1) # add some horizontal grid on the background
axis(2, at=seq(-4,0,1), las=2)
title(main = &amp;quot;Figure 2. Quadratic approximation\n of binomial log-likelihood ratio \n 40 out of 100 subjects&amp;quot;)
abline(h=-1.92, lty=1, col=&amp;quot;red&amp;quot;)
axis(4, at=-1.92, las=2)

legend(x=0.27, y= -5.5 ,xpd = TRUE,  legend=c(&amp;quot;logLR&amp;quot;,&amp;quot;Quadratic&amp;quot;), bty = &amp;quot;n&amp;quot;,
       col=c(&amp;quot;black&amp;quot;,&amp;quot;red&amp;quot;), lty=c(1,1), horiz = TRUE) #the legend is below the graph&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q2&lt;/h4&gt;
&lt;p&gt;依舊使用二項分佈數據來模擬，觀察不同的事件數量和樣本量對近似計算的影響。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;類比上面的問題，用同樣的 &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.4\)&lt;/span&gt;，但是 &lt;span class=&#34;math inline&#34;&gt;\(n=10, k=4\)&lt;/span&gt; 時的圖形：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.4, n=1000, k=400\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.01, n=100, k=1\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意此圖中紅線提示的近似二次曲線，信賴區間的下限已經低於0，是無法接受的近似。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.01, n=1000, k=10\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.01, n=10000, k=100\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.99, n=100, k=99\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意此圖中紅線提示的近似二次曲線，信賴區間的上限已經大於1，和上面的 Figure 5. 一樣也是無法接受的近似。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;總結： 二次方程近似時，在二項分佈的情況下，隨着 &lt;span class=&#34;math inline&#34;&gt;\(n, k\)&lt;/span&gt; 增加，近似越理想。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>對數似然比 Log-likelihood ratio</title>
      <link>https://winterwang.github.io/post/log-likelihood-ratio/</link>
      <pubDate>Sun, 05 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/log-likelihood-ratio/</guid>
      <description>&lt;script src=&#34;https://winterwang.github.io/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;-log-likelihood-ratio&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;對數似然比 Log-likelihood ratio&lt;/h3&gt;
&lt;p&gt;對數似然比的想法來自於將對數似然方程圖形的 &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 軸重新調節 (rescale) 使之最大值爲零。這可以通過計算該分佈方程的&lt;strong&gt;對數似然比 (log-likelihood ratio)&lt;/strong&gt; 來獲得：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\theta)=\ell(\theta|data)-\ell(\hat{\theta}|data)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由於 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta)\)&lt;/span&gt; 的最大值在 &lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}\)&lt;/span&gt; 時， 所以，&lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)\)&lt;/span&gt; 就是個當 &lt;span class=&#34;math inline&#34;&gt;\(\theta=\hat{\theta}\)&lt;/span&gt; 時取最大值，且最大值爲零的方程。很容易理解我們叫這個方程爲對數似然比，因爲這個方程就是將似然比 &lt;span class=&#34;math inline&#34;&gt;\(LR(\theta)=\frac{L(\theta)}{L(\hat{\theta})}\)&lt;/span&gt; 取對數而已。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/post/likelihood/&#34;&gt;之前&lt;/a&gt;我們也確證了，不包含我們感興趣的參數的方程部分可以忽略掉。還是用上一節 10人中4人患病的例子：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\pi|X=4)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\\
\Rightarrow \ell(\pi)=log[\pi^4(1-\pi)^{10-4}]\\
\Rightarrow llr(\pi)=\ell(\pi)-\ell(\hat{\pi})=log\frac{\pi^4(1-\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其實由上也可以看出 &lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)\)&lt;/span&gt; 只是將對應的似然方程的 &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 軸重新調節了一下而已。形狀是沒有改變的：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow=c(1,2))
x &amp;lt;- seq(0,1,by=0.001)
y &amp;lt;- (x^4)*((1-x)^6)/(0.4^4*0.6^6)
z &amp;lt;- log((x^4)*((1-x)^6))-log(0.4^4*0.6^6)
plot(x, y, type = &amp;quot;l&amp;quot;, ylim = c(0,1.1),yaxt=&amp;quot;n&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;LR(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
axis(2, at=seq(0,1, 0.2), las=2)
title(main = &amp;quot;Binomial likelihood ratio&amp;quot;)
abline(h=1.0, lty=2)
segments(x0=0.4, y0=0, x1=0.4, y1=1, lty = 2)
plot(x, z, type = &amp;quot;l&amp;quot;, ylim = c(-10, 1), yaxt=&amp;quot;n&amp;quot;, frame.plot = FALSE,
     ylab = &amp;quot;llr(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot; )
axis(2, at=seq(-10, 0, 2), las=2)
title(main = &amp;quot;Binomial log-likelihood ratio&amp;quot;)
abline(h=0, lty=2)
segments(x0=0.4, y0=-10, x1=0.4, y1=0, lty = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;正態分佈數據的最大似然和對數似然比&lt;/h4&gt;
&lt;p&gt;假設單個樣本 &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 是來自一組服從正態分佈數據的觀察值：&lt;span class=&#34;math inline&#34;&gt;\(Y\sim N(\mu, \tau^2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那麼有：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
f(y|\mu) &amp;amp;= \frac{1}{\sqrt{2\pi\tau^2}}e^{(-\frac{1}{2}(\frac{y-\mu}{\tau})^2)} \\
\Rightarrow L(\mu|y) &amp;amp;=\frac{1}{\sqrt{2\pi\tau^2}}e^{(-\frac{1}{2}(\frac{y-\mu}{\tau})^2)} \\
\Rightarrow \ell(\mu)&amp;amp;=log(\frac{1}{\sqrt{2\pi\tau^2}})-\frac{1}{2}(\frac{y-\mu}{\tau})^2\\
omitting&amp;amp;\;terms\;not\;in\;\mu \\
&amp;amp;= -\frac{1}{2}(\frac{y-\mu}{\tau})^2 \\
\Rightarrow \ell^\prime(\mu) &amp;amp;= 2\cdot[-\frac{1}{2}(\frac{y-\mu}{\tau})\cdot\frac{-1}{\tau}] \\
&amp;amp;=\frac{y-\mu}{\tau^2} \\
let \; \ell^\prime(\mu) &amp;amp;= 0 \\
\Rightarrow \frac{y-\mu}{\tau^2} &amp;amp;= 0 \Rightarrow \hat{\mu} = y\\
\because \ell^{\prime\prime}(\mu) &amp;amp;=  \frac{-1}{\tau^2} &amp;lt; 0 \\
\therefore \hat{\mu} &amp;amp;= y \Rightarrow \ell(\hat{\mu}=y)_{max}=0 \\
llr(\mu)&amp;amp;=\ell(\mu)-\ell(\hat{\mu})=\ell(\mu)\\
&amp;amp;=-\frac{1}{2}(\frac{y-\mu}{\tau})^2
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;n-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立正態分佈樣本的對數似然比&lt;/h3&gt;
&lt;p&gt;假設一組觀察值來自正態分佈 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu,\sigma^2)\)&lt;/span&gt;，先假設 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 已知。將觀察數據 &lt;span class=&#34;math inline&#34;&gt;\(x_1,\cdots, x_n\)&lt;/span&gt; 標記爲 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt;。 那麼：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
L(\mu|\underline{x}) &amp;amp;=\prod_{i=1}^nf(x_i|\mu)\\
\Rightarrow \ell(\mu|\underline{x}) &amp;amp;=\sum_{i=1}^nlogf(x_i|\mu)\\
&amp;amp;=\sum_{i=1}^n[-\frac{1}{2}(\frac{x_i-\mu}{\sigma})^2]\\
&amp;amp;=-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\\
&amp;amp;=-\frac{1}{2\sigma^2}[\sum_{i=1}^n(x_i-\bar{x})^2+\sum_{i=1}^n(\bar{x}-\mu)^2]\\
omitting&amp;amp;\;terms\;not\;in\;\mu \\
&amp;amp;=-\frac{1}{2\sigma^2}\sum_{i=1}^n(\bar{x}-\mu)^2\\
&amp;amp;=-\frac{n}{2\sigma^2}(\bar{x}-\mu)^2 \\
&amp;amp;=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\\
\because \ell(\hat{\mu}) &amp;amp;= 0 \\
\therefore llr(\mu) &amp;amp;= \ell(\mu)-\ell(\hat{\mu}) = \ell(\mu)
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;n-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立正態分佈樣本的對數似然比的分佈&lt;/h3&gt;
&lt;p&gt;假設我們用 &lt;span class=&#34;math inline&#34;&gt;\(\mu_0\)&lt;/span&gt; 表示總體均數這一參數的值。要注意的是，每當樣本被重新取樣，似然，對數似然方程，對數似然比都隨着觀察值而變 (即有自己的分佈)。&lt;/p&gt;
&lt;p&gt;考慮一個服從正態分佈的單樣本 &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(Y\sim N(\mu_0,\tau^2)\)&lt;/span&gt;。那麼它的對數似然比：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\mu_0|Y)=\ell(\mu_0)-\ell(\hat{\mu})=-\frac{1}{2}(\frac{Y-\mu_0}{\tau})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;根據&lt;a href=&#34;https://winterwang.github.io/post/chi-square-distribution/&#34;&gt;卡方分佈&lt;/a&gt;的定義：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\because \frac{Y-\mu_0}{\tau}\sim N(0,1)\\
\Rightarrow (\frac{Y-\mu_0}{\tau})^2 \sim \mathcal{X}_1^2\\
\therefore -2llr(\mu_0|Y) \sim \mathcal{X}_1^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，如果有一組服從正態分佈的觀察值：&lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu_0,\sigma^2)\)&lt;/span&gt;，且 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 已知的話：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2llr(\mu_0|\bar{X})\sim \mathcal{X}_1^2\]&lt;/span&gt;&lt;/p&gt;
根據&lt;a href=&#34;https://winterwang.github.io/post/central-limit-theory/&#34;&gt;中心極限定理&lt;/a&gt;，可以將上面的結論一般化：

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-2&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 1  &lt;/strong&gt;&lt;/span&gt;如果 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}f(x|\theta)\)&lt;/span&gt;。 那麼當重複多次從參數爲 &lt;span class=&#34;math inline&#34;&gt;\(\theta_0\)&lt;/span&gt; 的總體中取樣時，那麼統計量 &lt;span class=&#34;math inline&#34;&gt;\(-2llr(\theta_0)\)&lt;/span&gt; 會漸進於自由度爲 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; 的卡方分佈： &lt;span class=&#34;math display&#34;&gt;\[-2llr(\theta_0)=-2\{\ell(\theta_0)-\ell(\hat{\theta})\}\xrightarrow[n\rightarrow\infty]{}\;\sim \mathcal{X}_1^2\]&lt;/span&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;似然比信賴區間&lt;/h3&gt;
&lt;p&gt;如果樣本量 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 足夠大 (通常應該大於 &lt;span class=&#34;math inline&#34;&gt;\(30\)&lt;/span&gt;)，根據上面的定理：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2llr(\theta_0)=-2\{\ell(\theta_0)-\ell(\hat{\theta})\}\sim \mathcal{X}_1^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(-2llr(\theta_0)\leqslant \mathcal{X}_{1,0.95}^2=3.84) = 0.95\\
\Rightarrow Prob(llr(\theta_0)\geqslant-3.84/2=-1.92) = 0.95\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;故似然比的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間就是能夠滿足 &lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)=-1.92\)&lt;/span&gt; 的兩個 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 值。&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈數據爲例&lt;/h4&gt;
&lt;p&gt;繼續用本文開頭的例子：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\pi)=\ell(\pi)-\ell(\hat{\pi})=log\frac{\pi^4(1-\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果令 &lt;span class=&#34;math inline&#34;&gt;\(llr(\pi)=-1.92\)&lt;/span&gt; 在代數上可能較難獲得答案。然而從圖形上，如果我們在 &lt;span class=&#34;math inline&#34;&gt;\(y=-1.92\)&lt;/span&gt; 畫一條橫線，和該似然比方程曲線相交的兩個點就是我們想要求的信賴區間的上限和下限：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(0,1,by=0.001)
z &amp;lt;- log((x^4)*((1-x)^6))-log(0.4^4*0.6^6)
plot(x, z, type = &amp;quot;l&amp;quot;, ylim = c(-10, 1), yaxt=&amp;quot;n&amp;quot;, frame.plot = FALSE,
     ylab = &amp;quot;llr(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot; )
axis(2, at=seq(-10, 0, 2), las=2)
abline(h=0, lty=2)
abline(h=-1.92, lty=2)
segments(x0=0.15, y0=-12, x1=0.15, y1=-1.92, lty = 2)
segments(x0=0.7, y0=-12, x1=0.7, y1=-1.92, lty = 2)
axis(1, at=c(0.15,0.7))
text(0.9, -1, &amp;quot;-1.92&amp;quot;)
arrows(0.8, -1.92, 0.8, 0, lty = 1, length = 0.08)
arrows( 0.8, 0, 0.8, -1.92, lty = 1, length = 0.08)
title(main = &amp;quot;Log-likelihood ratio for binomial example, \n with 95% likelihood confidence interval shown&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;從上圖中可以讀出，&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 對數似然比信賴區間就是 &lt;span class=&#34;math inline&#34;&gt;\((0.15, 0.7)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;以正態分佈數據爲例&lt;/h4&gt;
&lt;p&gt;本文前半部分證明過，
&lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu,\sigma^2)\)&lt;/span&gt;，先假設 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 已知。將觀察數據 &lt;span class=&#34;math inline&#34;&gt;\(x_1,\cdots, x_n\)&lt;/span&gt; 標記爲 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt;。 那麼：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\mu|\underline{x}) = \ell(\mu|\underline{x})-\ell(\hat{\mu}) = \ell(\mu|\underline{x}) \\
=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;很顯然，這是一個關於 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 的二次方程，且最大值在 MLE &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mu}=\bar{x}\)&lt;/span&gt; 時取值 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;。所以可以通過對數似然比法求出均值的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間公式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2\times[-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2]=3.84\\
\Rightarrow L=\bar{x}-\sqrt{3.84}\frac{\sigma}{\sqrt{n}} \\
U=\bar{x}+\sqrt{3.84}\frac{\sigma}{\sqrt{n}} \\
note: \;\sqrt{3.84}=1.96\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注意到這和我們&lt;a href=&#34;https://winterwang.github.io/post/frequentist-statistical-inference02/&#34;&gt;之前&lt;/a&gt;求的正態分佈均值的信賴區間公式完全一致。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exercise&lt;/h3&gt;
&lt;div id=&#34;q1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q1&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;假設十個對象中有三人死亡，用二項分佈模型來模擬這個例子，求這個例子中參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 的似然方程和圖形 (likelihood) ?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  L(\pi|3) &amp;amp;= \binom{10}{3}\pi^3(1-\pi)^{10-3} \\  omitting\;&amp;amp;terms\;not\;in\;\mu \\  \Rightarrow \ell(\pi|3) &amp;amp;= log[\pi^3(1-\pi)^7] \\  &amp;amp;= 3log\pi+7log(1-\pi)\\  \Rightarrow \ell^\prime(\pi|3)&amp;amp;= \frac{3}{\pi}-\frac{7}{1-\pi} \\  let \; \ell^\prime&amp;amp; =0\\  &amp;amp;\frac{3}{\pi}-\frac{7}{1-\pi} = 0 \\  &amp;amp;\frac{3-10\pi}{\pi(1-\pi)} = 0 \\  \Rightarrow MLE &amp;amp;= \hat\pi = 0.3 \end{aligned}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;計算似然比，並作圖，注意方程圖形未變，&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 軸的變化；取對數似然比，並作圖&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;LR &amp;lt;- L/max(L) ; head(LR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0000000000 0.0004191759 0.0031233631 0.0098110584 0.0216286076
## [6] 0.0392577320&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(pi, LR, type = &amp;quot;l&amp;quot;, ylim = c(0, 1),yaxt=&amp;quot;n&amp;quot;, col=&amp;quot;darkblue&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
grid(NA, 5, lwd = 1)
axis(2, at=seq(0,1,0.2), las=2)
title(main = &amp;quot;Binomial likelihood ratio function\n 3 out of 10 subjects&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;logLR &amp;lt;- log(L/max(L))
plot(pi, logLR, type = &amp;quot;l&amp;quot;, ylim = c(-4, 0),yaxt=&amp;quot;n&amp;quot;, col=&amp;quot;darkblue&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
grid(NA, 5, lwd = 1)
axis(2, at=seq(-4,0,1), las=2)
title(main = &amp;quot;Binomial log-likelihood ratio function\n 3 out of 10 subjects&amp;quot;)
abline(h=-1.92, lty=1, col=&amp;quot;red&amp;quot;)
axis(4, at=-1.92, las=0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q2&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;與上面用同樣的模型，但是觀察人數變爲 &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; 人 患病人數爲 &lt;span class=&#34;math inline&#34;&gt;\(30\)&lt;/span&gt; 人，試作對數似然比方程之圖形，與上圖對比：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;可以看出，兩組數據的 MLE 都是一致的， &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.3\)&lt;/span&gt;，但是對數似然比方程圖形在 樣本量爲 &lt;span class=&#34;math inline&#34;&gt;\(n=100\)&lt;/span&gt; 時比 &lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt; 時窄很多，由此產生的似然比信賴區間也就窄很多（精確很多）。所以對數似然比方程的曲率（二階導數），反映了觀察獲得數據提供的對總體參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 推斷過程中的信息量。而且當樣本量較大時，對數似然比方程也更加接近左右對稱的二次方程曲線。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q3&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q3&lt;/h4&gt;
&lt;p&gt;在一個實施了160人年的追蹤調查中，觀察到8個死亡案例。使用泊松分佈模型，繪製對數似然比方程圖形，從圖形上目視推測極大似然比的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  d = 8, \;p &amp;amp;= 160\; person\cdot year \\  \Rightarrow D\sim Poi(\mu &amp;amp;=\lambda p) \\  L(\lambda|data) &amp;amp;= Prob(D=d=8) \\  &amp;amp;= e^{-\mu}\frac{\mu^d}{d!} \\  &amp;amp;= e^{-\lambda p}\frac{\lambda^d p^d}{d!} \\  omitting&amp;amp;\;terms\;not\;in\;\lambda \\  &amp;amp;= e^{-\lambda p}\lambda^d \\ \Rightarrow \ell(\lambda|data)&amp;amp;= log(e^{-\lambda p}\lambda^d) \\  &amp;amp;= d\cdot log(\lambda)-\lambda p \\  &amp;amp; = 8\times log(\lambda) - 160\times\lambda \end{aligned}\)&lt;/span&gt;&lt;/p&gt;
&lt;img src=&#34;https://winterwang.github.io/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;480&#34; /&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
lambda
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
LogLR
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.010
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-6.4755033
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.011
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-5.8730219
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.012
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-5.3369308
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.013
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.8565892
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.014
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.4237254
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.015
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.0317824
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.016
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.6754743
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.017
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.3504773
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.018
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.0532100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.019
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.7806722
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.020
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.5303259
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.021
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.3000045
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
0.022
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
-2.0878444
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
0.023
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
-1.8922303
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.024
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.7117534
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.025
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.5451774
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.026
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.3914117
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.027
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.2494891
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.028
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.1185480
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.029
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.9978174
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.030
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.8866050
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.031
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.7842864
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6902968
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.033
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6041236
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.034
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5252998
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.035
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.4533996
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.036
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3880325
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.037
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3288407
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.038
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2754948
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.039
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2276909
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.040
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1851484
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.041
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1476075
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.042
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1148271
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.043
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0865831
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.044
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0626670
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.045
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0428841
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.046
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0270529
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.047
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0150032
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.048
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0065760
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0016217
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.050
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.051
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0015790
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.052
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0062343
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.053
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0138487
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.054
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0243117
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.055
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0375186
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.056
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0533705
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.057
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0717739
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.058
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0926400
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.059
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1158845
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.060
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1414275
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.061
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1691931
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.062
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1991090
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.063
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2311062
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.064
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2651194
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.065
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3010859
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.066
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3389461
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.067
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3786431
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.068
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.4201224
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.069
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.4633320
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.070
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5082221
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.071
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5547450
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.072
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6028551
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.073
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6525085
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.074
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.7036633
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.075
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.7562791
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.076
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.8103173
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.077
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.8657407
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.078
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.9225134
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.079
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.9806012
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.080
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.0399710
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.081
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.1005908
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.082
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.1624301
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.083
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.2254592
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.084
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.2896497
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.085
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.3549740
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.086
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.4214057
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.087
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.4889191
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.088
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.5574895
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.089
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.6270931
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.090
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.6977067
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.091
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.7693080
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.092
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.8418754
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
0.093
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
-1.9153881
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
0.094
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white;background-color: #D7261E;&#34;&gt;
-1.9898258
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.095
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.0651689
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.096
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.1413985
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.097
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.2184962
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.098
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.2964442
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.099
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.3752252
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.100
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.4548226
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;所以從列表數據結合圖形， 可以找到信賴區間的下限在 0.022~0.023 之間， 上限在 0.093～0.094 之間。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>似然非然 Likelihood</title>
      <link>https://winterwang.github.io/post/likelihood/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/likelihood/</guid>
      <description>&lt;div id=&#34;-vs.probability-vs.inference&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;概率 vs. 推斷/Probability vs. Inference&lt;/h3&gt;
&lt;p&gt;在概率論的環境下，我們常常被告知的前提是：某某事件發生的概率是多少。例如： 一枚硬幣正面朝上的概率是 &lt;span class=&#34;math inline&#34;&gt;\(0.5\; Prob(coin\;landing\;heads)=0.5\)&lt;/span&gt;。然後在這個前提下，我們又繼續去計算複雜的事件發生的概率（例如，10次投擲硬幣以後4次正面朝上的概率是多少？）。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\binom{10}{4}\times(0.5^4)\times(0.5^{10-4}) = 0.205
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dbinom(4, 10, 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2050781&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# or you can calculate by hand:
factorial(10)*(0.5^10)/(factorial(4)*(factorial(6)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2050781&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在統計推斷的理論中，我們考慮實際的情況，這樣的實際情況就是，我們通過觀察獲得數據，然而我們並不知道某事件發生的概率到底是多少（神如果存在話，只有神知道）。故這個 &lt;span class=&#34;math inline&#34;&gt;\(Prob(coin\;landing\;heads)\)&lt;/span&gt; 的概率大小對於“人類”來說是未知的。我們可能觀察到投擲了10次硬幣，其中有4次是正面朝上的。那麼我們從這一次觀察實驗中，需要計算的是能夠符合觀察結果的“最佳”概率估計 (best estimate)。在這種情況下，&lt;strong&gt;似然法 (likelihood)&lt;/strong&gt; 就是我們進行參數估計的最佳手段。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;似然和極大似然估計&lt;/h3&gt;
&lt;p&gt;此處用二項分佈的例子來理解似然法的概念：假設我們觀察到10個對象中有4個患病，我們假定這個患病的概率爲 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;。於是我們就有了下面的模型：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型：&lt;/strong&gt; 我們假定患病與否是一個服從&lt;strong&gt;二項分佈的隨機變量&lt;/strong&gt;，&lt;span class=&#34;math inline&#34;&gt;\(X\sim Bin(10,\pi)\)&lt;/span&gt;。同時也默認每個人之間是否患病是相互獨立的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;數據：&lt;/strong&gt; 觀察到的數據是，10人中有4人患病。於是 &lt;span class=&#34;math inline&#34;&gt;\(x=4\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;現在按照觀察到的數據，參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 變成了未知數：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(X=4|\pi)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;此時我們會很自然的考慮，當 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 是未知數的時候，&lt;strong&gt;它取值爲多大的時候才能讓這個事件（即：10人中4人患病）發生的概率最大？&lt;/strong&gt; 所以我們可以將不同的數值代入 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 來計算該事件在不同概率的情況下發生的可能性到底是多少：&lt;/p&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Table 1: The probability of observing &lt;span class=&#34;math inline&#34;&gt;\(X=4\)&lt;/span&gt;
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
事件 &lt;span class=&#34;math inline&#34;&gt;\(X=4\)&lt;/span&gt; 發生的概率
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.088
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;0.4&lt;/strong&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;0.251&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.5
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.205
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.111
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.006
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;很顯然，如果 &lt;span class=&#34;math inline&#34;&gt;\(\pi=0.4\)&lt;/span&gt; 時，我們觀察到的事件發生的概率要比 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 取其它值時更大。於是小總結一下目前爲止的步驟如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;觀察到實驗數據（10人中4個患病）；&lt;/li&gt;
&lt;li&gt;假定這數據服從二項分佈的概率模型，計算不同（&lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 的取值不同的）情況下，該事件按照假定模型發生的概率；&lt;/li&gt;
&lt;li&gt;通過比較，我們選擇了能夠讓觀察事件發生概率最高的參數取值 (&lt;span class=&#34;math inline&#34;&gt;\(\pi=0.4\)&lt;/span&gt;)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;至此，我們可以知道，似然方程，是一個關於未知參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 的函數，我們目前位置做的就是找到這個函數的最大值 (maximised)，和使之成爲最大值時的 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; ：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\pi|X=4)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;我們可以畫出這個似然方程的形狀， &lt;span class=&#34;math inline&#34;&gt;\(\pi\in[0,1]\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(0,1,by=0.001)
y &amp;lt;- (factorial(10)/(factorial(4)*(factorial(6))))*(x^4)*((1-x)^6)
plot(x, y, type = &amp;quot;l&amp;quot;, ylim = c(0,0.3), ylab = &amp;quot;L(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
title(&amp;quot;Figure 1. Binomial Likelihood&amp;quot;)
abline(h=0.251, lty=2)
abline(v=0.4, lty=2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-02-likelihood_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;從圖形上我們也能確認，&lt;span class=&#34;math inline&#34;&gt;\(\pi=0.4\)&lt;/span&gt; 時能夠讓這個似然方程取得最大值。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;似然方程的一般化定義&lt;/h3&gt;
&lt;p&gt;對於一個概率模型，如果其參數爲 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;，那麼在給定觀察數據 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 時，該參數的似然方程被定義爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(L(\theta|\underline{x})=P(\underline{x}|\theta)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(\underline{x}|\theta)\)&lt;/span&gt; 可以是概率（離散分佈）方程，也可以是概率密度（連續型變量）方程。對於此方程，&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 是給定的，然後再計算某些事件發生的概率。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(L(\theta|\underline{x})\)&lt;/span&gt; 是一個關於參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的方程，此時，&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 是固定不變的（觀察值）。我們希望通過這個方程求出能夠使觀察到的事件發生概率最大的參數值。&lt;/li&gt;
&lt;li&gt;似然方程&lt;strong&gt;不是&lt;/strong&gt;一個概率密度方程。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另一個例子：&lt;/p&gt;
&lt;p&gt;有一組觀察數據是離散型隨機變量 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;，它符合概率方程 &lt;span class=&#34;math inline&#34;&gt;\(f(x|\theta)\)&lt;/span&gt;。下表羅列了當 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 分別取值 &lt;span class=&#34;math inline&#34;&gt;\(1,2,3\)&lt;/span&gt; 時的概率方程的值，試求每個觀察值 &lt;span class=&#34;math inline&#34;&gt;\(X = 0,1,2,3,4\)&lt;/span&gt; 的最大似然參數估計：&lt;/p&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Exercise 1
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|1)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|2)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|3)\)&lt;/span&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Exercise 1 answer
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|1)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|2)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|3)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;1&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;1&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;2&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;3&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;3&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;-log-likelihood&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;對數似然方程 log-likelihood&lt;/h3&gt;
&lt;p&gt;似然方程的最大值，可通過求 &lt;span class=&#34;math inline&#34;&gt;\(L(\theta|data)\)&lt;/span&gt; 的最大值獲得，也可以通過求該方程的對數方程 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt; 的最大值獲得。傳統上，我們估計最大方程的最大值的時候，會給參數戴一頂“帽子”（因爲這是觀察獲得的數據告訴我們的參數）： &lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}\)&lt;/span&gt;。並且我們發現對數似然方程比一般的似然方程更加容易微分，因此求似然方程的最大值就變成了求對數似然方程的最大值：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{d\ell}{d\theta}=\ell^\prime(\theta)=0\\
AND\\
\frac{d^2\ell}{d\theta^2}&amp;lt;0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;要注意的是，微分不一定總是能幫助我們求得似然方程的最大值。如果說參數本身的定義域是有界限的話，微分就行不通了：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(0,3,by=0.001)
y &amp;lt;- (x-1)^2-5
plot(x, y, type = &amp;quot;l&amp;quot;, ylim = c(-5,0-1), ylab = &amp;quot;L(\U03B8)&amp;quot;, xlab = &amp;quot;\U03B8&amp;quot;)
title(&amp;quot;Figure 2. Likelihood function with \n a limited domain&amp;quot;)
abline(v=3, lty=2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://winterwang.github.io/post/2017-11-02-likelihood_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;-lthetadata--ellthetadata-&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明：當 &lt;span class=&#34;math inline&#34;&gt;\(L(\theta|data)\)&lt;/span&gt; 取最大值時，該方程的對數方程 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt; 也是最大值：&lt;/h4&gt;
&lt;p&gt;如果似然方程是連續可導，只有一個最大值，且可以二次求導，假設 &lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}\)&lt;/span&gt; 使該方程取最大值，那麼：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{dL}{d\theta}=0, \frac{d^2L}{d\theta^2}&amp;lt;0 \Rightarrow \theta=\hat{\theta}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(\ell=logL\)&lt;/span&gt; 那麼 &lt;span class=&#34;math inline&#34;&gt;\(\frac{d\ell}{dL}=\ell^\prime=\frac{1}{L}\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{d\ell}{d\theta}=\frac{d\ell}{dL}\cdot\frac{dL}{d\theta}=\frac{1}{L}\cdot\frac{dL}{d\theta}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt; 取最大值時：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{d\ell}{d\theta}=0\Leftrightarrow\frac{1}{L}\cdot\frac{dL}{d\theta}=0\\
\because \frac{1}{L}\neq0 \\
\therefore \frac{dL}{d\theta}=0\\
\Leftrightarrow \theta=\hat{\theta}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\frac{d^2\ell}{d\theta^2} &amp;amp;= \frac{d}{d\theta}(\frac{d\ell}{dL}\cdot\frac{dL}{d\theta})\\
 &amp;amp;= \frac{d\ell}{dL}\cdot\frac{d^2L}{d\theta^2} + \frac{dL}{d\theta}\cdot\frac{d}{d\theta}(\frac{d\ell}{dL})
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(\theta=\hat{\theta}\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(\frac{dL}{d\theta}=0\)&lt;/span&gt; 且 &lt;span class=&#34;math inline&#34;&gt;\(\frac{d^2L}{d\theta^2}&amp;lt;0 \Rightarrow \frac{d^2\ell}{d\theta^2}&amp;lt;0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，求獲得 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt; 最大值的 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 即可令 &lt;span class=&#34;math inline&#34;&gt;\(L(\theta|data)\)&lt;/span&gt; 獲得最大值。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-maximum-likelihood-estimator-mle-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;極大似然估計 (maximum likelihood estimator, MLE) 的性質：&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;漸進無偏 Asymptotically unbiased: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow \infty \Rightarrow E(\hat{\Theta}) \rightarrow \theta\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;漸進最高效能 Asymptotically efficient: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow \infty \Rightarrow Var(\hat{\Theta})\)&lt;/span&gt; 是所有參數中方差最小的估計&lt;/li&gt;
&lt;li&gt;漸進正態分佈 Asymptotically normal: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow \infty \Rightarrow \hat{\Theta} \sim N(\theta, Var(\hat{\Theta}))\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;變形後依然保持不變 Transformation invariant: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(\hat{\Theta}\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的MLE時 &lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow g(\hat{\Theta})\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt; 的 MLE&lt;/li&gt;
&lt;li&gt;信息足夠充分 Sufficient：&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(\hat{\Theta}\)&lt;/span&gt; 包含了觀察數據中所有的能夠用於估計參數的信息&lt;/li&gt;
&lt;li&gt;始終不變 consistent: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow\infty\Rightarrow\hat{\Theta}\rightarrow\theta\)&lt;/span&gt; 或者可以寫成：&lt;span class=&#34;math inline&#34;&gt;\(\varepsilon&amp;gt;0, lim_{n\rightarrow\infty}P(|\hat{\Theta}-\theta|&amp;gt;\varepsilon)=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;-likelihood-for-a-rate&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;率的似然估計 Likelihood for a rate&lt;/h3&gt;
&lt;p&gt;如果在一項研究中，參與者有各自不同的追蹤隨訪時間（長度），那麼我們應該把事件（疾病）的發病率用率的形式（多少事件每單位人年, e.g. per person year of observation）。如果這個發病率的參數用 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 來表示，所有參與對象的隨訪時間之和爲 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 人年。那麼這段時間內的期望事件（疾病發病）次數爲：&lt;span class=&#34;math inline&#34;&gt;\(\mu=\lambda p\)&lt;/span&gt;。假設事件（疾病發病）發生是相互獨立的，可以使用泊松分佈來模擬期望事件（疾病發病）次數 &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[D\sim Poi(\mu)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;假設我們觀察到了 &lt;span class=&#34;math inline&#34;&gt;\(D=d\)&lt;/span&gt; 個事件，我們獲得這個觀察值的概率應該用以下的模型：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(D=d)=e^{-\mu}\frac{\mu^d}{d!}=e^{-\lambda p}\frac{\lambda^dp^d}{d!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;因此，&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的似然方程是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\lambda|observed \;data)=e^{-\lambda p}\frac{\lambda^dp^d}{d!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的對數似然方程是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\ell(\lambda|observed\;data) &amp;amp;= log(e^{-\lambda p}\frac{\lambda^dp^d}{d!}) \\
  &amp;amp;= -\lambda p+d\:log(\lambda)+d\:log(p)-log(d!) \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;解 &lt;span class=&#34;math inline&#34;&gt;\(\ell^\prime(\lambda|data)=0\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\ell^\prime(\lambda|data) &amp;amp;= -p+\frac{d}{\lambda}=0\\
\Rightarrow \hat{\lambda} &amp;amp;= \frac{d}{p} \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;
在對數似然方程中，不包含參數的部分，對與似然方程的形狀不產生任何影響，我們在微分對數似然方程的時候，這部分也都自動消失。所以不包含參數的部分，與我們如何獲得極大似然估計是無關的。因此，我們常常在寫對數似然方程的時候就把其中沒有參數的部分直接忽略了。例如上面泊松分佈的似然方程中，&lt;span class=&#34;math inline&#34;&gt;\(d\:log(p)-log(d!)\)&lt;/span&gt; 不包含參數 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 可以直接不寫出來。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-n-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;有 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立觀察時的似然方程和對數似然方程&lt;/h3&gt;
&lt;p&gt;當有多個獨立觀察時，總體的似然方程等於各個觀察值的似然方程之&lt;strong&gt;乘積&lt;/strong&gt;。如果 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\stackrel{i.i.d}{\sim}f(\cdot|\theta)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\theta|x_1,\cdots,x_n)=f(x_1,\cdots,x_n|\theta)=\prod_{i=1}^nf(x_i|\theta)\\
\Rightarrow \ell(\theta|x_1,\cdots,x_n)=\sum_{i=1}^nlog(f(x_i|\theta))\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>臨牀實驗的樣本量計算問題 Sample Size in Clinical Trial</title>
      <link>https://winterwang.github.io/post/sample-size-in-clinical-trial/</link>
      <pubDate>Sun, 29 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/sample-size-in-clinical-trial/</guid>
      <description>&lt;script src=&#34;https://winterwang.github.io/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;背景&lt;/h3&gt;
&lt;p&gt;計劃臨牀實驗的時候，爲了避免偏倚和帶有偏見的結論，應當將注意力放在&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;如何將實驗對象隨機分配 (randomisation)&lt;/li&gt;
&lt;li&gt;設計對照組 (control group)&lt;/li&gt;
&lt;li&gt;合適（且必須）的貫徹盲法 (blinding)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另外一個同樣重要的問題是–&lt;strong&gt;“我到底需要多少樣本?”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一項臨牀實驗，應該提供足夠的證據來證明新藥物（新治療方法）是否有效，是否安全。影響一個實驗設計的樣本量的因素可能有如下幾種：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;統計學方案。&lt;/strong&gt;
&lt;br&gt; 從統計學上可以推算出，需要多少樣本來獲得一個堅實可信的證據來證明藥物的實際有效性。&lt;/li&gt;
&lt;li&gt;經濟上的因素。
&lt;br&gt; 然而實際上可能還有經濟上，時間上，人力物力資源上的現實因素，會制約到底一個實驗能夠收集到多少樣本量。&lt;/li&gt;
&lt;li&gt;倫理道德上的因素。
&lt;br&gt; 許多臨牀實驗還必須受制於醫學倫理因素。在倫理上一個實驗到底可以維持多久。或者說，要考慮當實驗中一些受試者的結果不理想，或者是有副作用的時候，我們何時該及時停止該實驗？&lt;/li&gt;
&lt;li&gt;實驗本身的可信度。
&lt;br&gt; 如果一個臨牀實驗的規模在設計上就很小，可能它本身的可信度就很低。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這裏我們只考慮沒有其他任何因素的影響下，&lt;strong&gt;1. 統計學方案&lt;/strong&gt;上該如何計算準確的所需樣本量的大小。&lt;/p&gt;
比較下列兩個同樣比較了溶栓酶和安慰劑在預防心肌梗塞患者死亡的臨牀實驗：
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-1&#34;&gt;Table 1: &lt;/span&gt;Results from the 1st Australian and ISIS-2 trials for reducing mortality from post-MI
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
治療組
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
溶栓酶
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
安慰劑
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
p.values
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1st Australian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
n=264
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
n=253
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
死亡人數
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
26 (9.8%)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
32 (12.6%)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
p = 0.32
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
評價指標
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Risk ratio
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.78 (95% CI: 0.48 to 1.27)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ISIS-2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
n=8592
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
n=8595
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
死亡人數
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
791 (9.2%)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1029 (12.0%)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
p &amp;lt; 0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
評價指標
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Risk ratio
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.77 (95% CI: 0.70 to 0.84)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;這兩個臨牀實驗獲得的治療效果 (treatment effect)，在數字的百分比上幾乎十分接近。然而由於樣本兩巨大的差距，可以看到第一個實驗的信賴區間十分的大，使得實驗結果是無意義的。而第二個大樣本的實驗結果就告訴我們，溶栓酶的治療效果是有效降低了心肌梗死患者死亡概率（降低了23%）。第一個實驗收集了近500個病例，卻仍然不能提供確實有效的證據證明溶栓酶的治療效果（提供了強的關聯結果，卻是極弱的證據。strong correlation, but weak evidence) 。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;決定所需樣本量大小的統計學因素&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;實驗主要結果的測量/比較方法是什麼？ What is the principal outcome measure of the trial?
&lt;br&gt; 一項臨牀實驗的主要結果，應該是切合該實驗的主要目的的。並且應當能夠客觀評價。(如死亡率的改善，治癒率的提高等等)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;實驗數據準備分析的方案是什麼？ How will the data be analysed to detect a treatment difference?
&lt;br&gt; 實驗結果獲得的數據是連續型的 (血壓，血糖值，BMI)？還是分類的離散變量 (死亡的發生與否，疾病的治癒與否)？統計學上認爲的，治療結果提示有意義的差別時的概率。通常定爲 5%。(p &amp;lt; 0.05)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;對照組的試驗期望結果是怎樣的？ What results are expected in the control group?
&lt;br&gt; 當然我們不可能事先預知實驗對照組可能出現的結果。此處只討論我們的預期結果。大多數情況下，我們可以從已經進行過的類似臨牀試驗報告中獲得，或者是從非臨牀干預型研究（觀察型研究）報告中獲得對照組的期望結果。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;如果實驗藥物在治療上確實有差異，當這個差異最小爲多少時希望能從設計的實驗中被檢測到？ How small a treatment difference, if it exists, is important to detect?
&lt;br&gt; 這一條恐怕是每個臨牀實驗在設計階段最重要，最敏感也是最難做出決定的。如果我們已知這個藥物療效和對照相比差別很大，那麼樣本量不用很大，就足以提供值得信賴的證據。不過臨牀上常常會認爲療效差距不必&lt;strong&gt;非常的&lt;/strong&gt;顯著，但是在臨牀意義上也是十分重要的。
&lt;br&gt; 常常在這個問題上會引起衆多討論，因爲醫生和患者可能認爲任何一點差異都是有臨牀意義的。但是如果我們想檢測出較小的差距，會需要非常巨大的樣本量，這將會是十分不切合實際的。&lt;strong&gt;What needs to be decided upon is the smallest clinically relevant difference that would be important to detect if it were true.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在上面第 4 條被決定了以後，還要確定的是我們需要多大的把握來相信這個被檢測出來的療效差別？ With what degree of certainty is needed to be able to detect the treatment difference in 4?
&lt;br&gt; 在實際臨牀實驗中，結論是從觀察數據中得來的，而不是從我們預想的那個“未知的實驗效果”。觀察獲得的療效差別，可能比預想的大（有效），也很可能比預想的小（無效）。設計較好的臨牀實驗應該有足夠機率觀察到有意義的療效差別，即使觀察得到的結果不如預期的大。當然要增加我們觀察到有意義的療效差別，最簡單的辦法是增加樣本量。這個條件的含義是，當療效真差別真實存在，我們要有足夠大的把握把它通過實驗觀察到。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;-type-i-and-type-ii-errors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;第一類和第二類錯誤 Type I and type II errors&lt;/h3&gt;
&lt;p&gt;下面羅列一下我們在進行實驗設計時要用到的概念和相應的標記，注意雖然我們無法知道真正的人羣裏真實參數 (parameter) 的大小，但是我們需要用一些估計 (estimator) 來代替：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(p_1=\)&lt;/span&gt; the &lt;strong&gt;observed percentage&lt;/strong&gt; in those on standard treatment &lt;br&gt; 意爲施行標準治療法時觀察到的（治癒/有效）百分比&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(p_2=\)&lt;/span&gt; the &lt;strong&gt;observed percentage&lt;/strong&gt; in those on “new” treatment &lt;br&gt; 意爲施行“新療法”時觀察到的（治癒/有效）的百分比&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow p_1-p_2=\)&lt;/span&gt; &lt;strong&gt;observed treatment effect&lt;/strong&gt; &lt;br&gt; 意爲可以觀察到的治療效果。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\pi_1=\)&lt;/span&gt; the &lt;strong&gt;anticipated percentage&lt;/strong&gt; in those on standard treatment &lt;br&gt; 意爲施行標準治療法時，我們預期的（治癒/有效）百分比&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\pi_2=\)&lt;/span&gt; the &lt;strong&gt;anticipated percentage&lt;/strong&gt; in those on “new” treatment &lt;br&gt; 意爲施行“新療法”時，我們預期的（治療/有效）百分比&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow \pi_1-\pi_2=\)&lt;/span&gt; is the true difference which has been decided it is important to detect &lt;br&gt; 意爲上面第 4 條中我們設定好的希望通過實驗證實的真實的療效差別。&lt;/p&gt;
&lt;p&gt;其餘的數學標記包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha=\)&lt;/span&gt; 有意義的療效差異，在統計學上的水平 (概率水平，通常設定爲 0.05 or 5%)&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(1-\beta=\)&lt;/span&gt; Degree of certainty that a true difference of &lt;span class=&#34;math inline&#34;&gt;\(\pi_1 - \pi_2\)&lt;/span&gt; would be detected. &lt;br&gt; 效能, power。意爲有多大的把握能通過實驗檢測出療效差別。（通常將目標值設定爲 &lt;span class=&#34;math inline&#34;&gt;\(1-\beta=90\%\)&lt;/span&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Table 2: Observed trial results compared to the &lt;code&gt;truth&lt;/code&gt; of 1) no difference; 2) a true &lt;span class=&#34;math inline&#34;&gt;\(\pi_1-\pi_2\)&lt;/span&gt; diffrence
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;border-bottom:hidden&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;&#34; colspan=&#34;2&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px;&#34;&gt;
真實情況 &lt;br&gt; Truth
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
無差別
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
真實差別存在 &lt;span class=&#34;math inline&#34;&gt;\(\pi_1-\pi_2\)&lt;/span&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
觀察到不存在有意義差別
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(1−\alpha\)&lt;/span&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; &lt;br&gt; Type II error
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
觀察到存在有意義差別
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; &lt;br&gt; Type I error
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(1-\beta\)&lt;/span&gt; &lt;br&gt; Power
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;考慮上面這個表格，可以很容易想到，一個理想的實驗設計，我們希望這個臨牀實驗獲得的結果儘可能地落在上表中的&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;左上角：即如果真實情況是無差別的，實驗結果也應該觀察到不存在有意義的差別。&lt;/li&gt;
&lt;li&gt;右下角：即如果真實情況是是存在真實差別 &lt;span class=&#34;math inline&#34;&gt;\(\pi_1-\pi_2\)&lt;/span&gt; 的，試驗結果也應該觀察到有意義的差別。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;然而，我們在獲得臨牀實驗結果之後常常犯的兩類錯誤，同樣在上面的表格中顯示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Type I error:&lt;/strong&gt; A type I error is when a treatment difference is claimed based on a statistically significant observed result when in truth no such difference exists, i.e. a false positive result. &lt;br&gt; 左下角爲&lt;strong&gt;一類錯誤&lt;/strong&gt;，即實驗結果觀察到有顯著的療效差異，然而，真實情況是並沒有差異的話，被認爲是假陽性判斷。&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; 表示一類錯誤發生的概率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type II error:&lt;/strong&gt; A type II error is when in truth there exists a difference of &lt;span class=&#34;math inline&#34;&gt;\(\pi_1-\pi_2\)&lt;/span&gt; but the observed results fail to reach statistical significance, i.e. a false negative result. &lt;br&gt; 右上角爲&lt;strong&gt;二類錯誤&lt;/strong&gt;，即實驗結果觀察到沒有顯著的療效差異，然而，真實情況是有差異的話，被認爲是假陰性判斷。&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; 表示二類錯誤發生的概率。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Alternative ways of describing &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the risk of a Type I error; &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; 也被叫做檢驗的顯著水平, significant level。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the risk of a Type II error. &lt;span class=&#34;math inline&#34;&gt;\(1-\beta\)&lt;/span&gt; is termed statistical power. 其中 &lt;span class=&#34;math inline&#34;&gt;\(1-\beta\)&lt;/span&gt; 被叫做檢驗效能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha, 1-\beta\)&lt;/span&gt; 的水平需要事先被確定，否則無法進行進一步的樣本量的計算。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-percentages-or-proportions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;比較兩組之間的百分比 (percentages or proportions)&lt;/h3&gt;
&lt;div id=&#34;--5--90&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n=10.5\times\frac{[\pi_1\times(100-\pi_1)+\pi_2\times(100-\pi_2)]}{(\pi_1-\pi_2)^2}\times2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上面的公式後面有 &lt;span class=&#34;math inline&#34;&gt;\(\times2\)&lt;/span&gt; 是因爲前一半公式計算的只是一組（治療或對照組）所需的樣本量。&lt;/li&gt;
&lt;li&gt;這裏使用的是百分比。所以當使用比例的時候，要把 &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; 改成 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;使用公式計算的所需樣本量，並不是說我們需要的病例數就是計算出來的結果。上面的公式獲得的結果只是對所需樣本量的估算。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;-&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n=f(\alpha, \beta)\times\frac{[\pi_1\times(100-\pi_1)+\pi_2\times(100-\pi_2)]}{(\pi_1-\pi_2)^2}\times2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中， &lt;span class=&#34;math inline&#34;&gt;\(f(\alpha, \beta)\)&lt;/span&gt; 指的是關於檢驗顯著水平 &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; 和檢驗效能 &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; 的函數。 可以參考下面的表格：&lt;/p&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Table 3: Values of &lt;span class=&#34;math inline&#34;&gt;\(f(\alpha, \beta)\)&lt;/span&gt; for different levels of &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;&#34; colspan=&#34;1&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;
&lt;/div&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;&#34; colspan=&#34;4&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0.1
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0.2
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0.5
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; power)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(&lt;span class=&#34;math inline&#34;&gt;\(90\%\)&lt;/span&gt; power)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(&lt;span class=&#34;math inline&#34;&gt;\(80\%\)&lt;/span&gt; power)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(&lt;span class=&#34;math inline&#34;&gt;\(50\%\)&lt;/span&gt; power)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
13.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
10.5
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7.85
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.84
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
17.8
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
14.9
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
11.7
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6.63
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;要注意的是，除了上面表格中提供的 &lt;span class=&#34;math inline&#34;&gt;\(f(\alpha, \beta)\)&lt;/span&gt; 數值，可以通過以下公式計算得出：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(\alpha, \beta)=(Z_{1-\frac{\alpha}{2}}+Z_{1-\beta})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05, \beta=0.1\)&lt;/span&gt; 時：&lt;span class=&#34;math inline&#34;&gt;\(f(\alpha, \beta)=(1.96+1.282)^2=10.5\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05, \beta=0.2\)&lt;/span&gt; 時：&lt;span class=&#34;math inline&#34;&gt;\(f(\alpha, \beta)=(1.96+0.84)^2=7.85\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;比較兩組之間的均值&lt;/h3&gt;
&lt;p&gt;許多臨牀實驗不光關心患者是否被治癒或者死亡，另外還有許多實驗的主要結果是連續變量：例如，腎功能（腎小球濾過率），或收縮期血壓。然而背後的原理其實還是一樣的。&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;樣本量計算公式&lt;/h4&gt;
&lt;p&gt;然而，另外一個必須考慮的因素：治療組對照組測量結果的標準差 (standard deviation, &lt;span class=&#34;math inline&#34;&gt;\(sd, \sigma\)&lt;/span&gt;)。這裏先考慮兩者標準差相同的情況。標準差的數據通常來自與先行研究的科學文獻，有些（土豪）實驗會先進行預實驗獲得想要的實驗數據–標準差。通常，建議像比較百分比那樣，調整改變一下不同的檢驗顯著水品和檢驗效能，計算多個所需樣本量來互相比較參考。&lt;/p&gt;
&lt;p&gt;比較兩組均值時需要用到的數學標記：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_1=\)&lt;/span&gt; 標準治療法（對照組）的期待平均值；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_2=\)&lt;/span&gt; 新治療法（治療組）的期待平均值；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma=\)&lt;/span&gt; 兩組的標準差（假設兩組標準差相同）；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha=\)&lt;/span&gt; 一類錯誤發生的概率，檢驗顯著水平；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta=\)&lt;/span&gt; 二類錯誤發生的概率，&lt;span class=&#34;math inline&#34;&gt;\(1-\beta\)&lt;/span&gt; 是檢驗效能。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;用上面標記表示的公式如下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n=f(\alpha, \beta)\times\frac{2\sigma^2}{(\mu_1-\mu_2)^2}\times2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;可以認爲，上面的公式中 &lt;span class=&#34;math inline&#34;&gt;\(\mu_1-\mu_2\)&lt;/span&gt; ，各組的平均值本身並不重要，兩組之間均值的差是我們關心的。如果用 &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; 表示兩組之間均值差的期待值，那麼公式可以改寫爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n=f(\alpha, \beta)\times\frac{2\sigma^2}{\delta^2}\times2\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;樣本量計算的調整&lt;/h3&gt;
&lt;p&gt;如果我們無法成功隨訪部分患者，那麼這部分人的數據就無法獲得，實驗數據的說服力就會下降。如果我們預估計有 &lt;span class=&#34;math inline&#34;&gt;\(Q\%\)&lt;/span&gt; 的人會失去隨訪，那麼我們可以將之前步驟中計算獲得的數字乘以 &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{1-Q\%}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;如果實驗設計是我們會在某個時間點允許治療組或對照組中的部分人變更自己的實驗方案（即治療組的參與者改進入對照組，反之亦然）。那麼所需樣本量的計算調整的方法爲：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(Q_1=\)&lt;/span&gt; 第一組中改成第二組治療方案的人數比例；&lt;/li&gt;
&lt;li&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(Q_2=\)&lt;/span&gt; 第二組中改成第一組治療方案的人數比例；&lt;/li&gt;
&lt;li&gt;將之前步驟中計算獲得的樣本量數字乘以 &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{(1-Q_1-Q_2)^2}\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果預期參與實驗治療組（而不是對照組）的人中有部分人（比例爲 &lt;span class=&#34;math inline&#34;&gt;\(Q\)&lt;/span&gt;）會中斷實驗進程，那麼調整公式爲：&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{(1-Q)^2}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;還有的實驗會使用大於 &lt;span class=&#34;math inline&#34;&gt;\(1:1\)&lt;/span&gt; 的比例設計對照組和實驗組的人數。假設這一比例爲 &lt;span class=&#34;math inline&#34;&gt;\(r:1\)&lt;/span&gt; 那麼調整的樣本量數字還要乘以：&lt;span class=&#34;math inline&#34;&gt;\(\frac{(r+1)^2}{4r}\)&lt;/span&gt;。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Changing trends in the prevalence of H. pylori infection in Japan (1908-2003): a systematic review and meta-regression analysis of 170,752 individuals</title>
      <link>https://winterwang.github.io/publication/hpylorimeta/</link>
      <pubDate>Fri, 27 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/publication/hpylorimeta/</guid>
      <description>

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;Changing trends in the prevalence of H. pylori infection in the general population over time are thought to be the main driving force behind the declining gastric cancer mortality in Japan. However, whether the prevalence of H. pylori infection itself shows a birth-cohort pattern needs to be corroborated. We performed a systematic review of studies that reported the prevalence of H. pylori infection among Japanese individuals. Meta-regression was conducted in the framework of a generalized additive mixed model (GAMM) to account for heterogeneity in the prevalence of H. pylori infection as a function of birth year. The prevalence of H. pylori infection confirmed a clear birth cohort pattern: the predicted prevalence (%, 95% CI) was 60.9 (56.3-65.4), 65.9 (63.9-67.9), 67.4 (66.0-68.7), 64.1 (63.1-65.1), 59.1 (58.2-60.0), 49.1 (49.0-49.2), 34.9 (34.0-35.8), 24.6 (23.5-25.8), 15.6 (14.0-17.3), and 6.6 (4.8-8.9) among those who were born in the year 1910, 1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990, and 2000, respectively. The present study demonstrated a clear birth-cohort pattern of H. pylori infection in the Japanese population. The decreased prevalence of H. pylori infection in successive generations should be weighed in future gastric cancer control programs.&lt;/p&gt;

&lt;h4 id=&#34;click-the-graph-to-see-the-interactive-version&#34;&gt;Click the graph to see the interactive version&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://rpubs.com/winterwang/bubbleplot&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://winterwang.github.io/img/Hpylori.png&#34; alt=&#34;Click for interactive version&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;summary-statistics-from-fitting-meta-regression-in-the-best-model-click-to-see-the-table-http-rpubs-com-winterwang-table3&#34;&gt;&lt;a href=&#34;http://rpubs.com/winterwang/table3&#34; target=&#34;_blank&#34;&gt;Summary statistics from fitting meta-regression in the best model.(click to see the table)&lt;/a&gt;&lt;/h4&gt;

&lt;h4 id=&#34;table-of-risk-of-bias-diagnosis-click-to-see-the-table-http-rpubs-com-winterwang-riskofbias&#34;&gt;&lt;a href=&#34;http://rpubs.com/winterwang/riskofbias&#34; target=&#34;_blank&#34;&gt;Table of risk of bias diagnosis. (click to see the table)&lt;/a&gt;&lt;/h4&gt;
</description>
    </item>
    
    <item>
      <title>卡方分佈 chi square distribution</title>
      <link>https://winterwang.github.io/post/chi-square-distribution/</link>
      <pubDate>Thu, 26 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/chi-square-distribution/</guid>
      <description>&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;卡方分佈的期望和方差的證明：&lt;/h3&gt;
&lt;p&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(X\sim N(0,1)\)&lt;/span&gt; 時， &lt;span class=&#34;math inline&#34;&gt;\(X^2\sim \mathcal{X}_1^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果 &lt;span class=&#34;math inline&#34;&gt;\(X_1, \dots, X_n\stackrel{i.i.d}{\sim} N(0,1)\)&lt;/span&gt;，
那麼 &lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^nX_i^2\sim\mathcal{X}_n^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中： &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{X}_n^2\)&lt;/span&gt; 表示自由度爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 的卡方分佈。&lt;/p&gt;
&lt;p&gt;且 &lt;span class=&#34;math inline&#34;&gt;\(X_m^2+X_n^2=\mathcal{X}_{m+n}^2\)&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;卡方分佈的期望：&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(X_1^2)=Var(X)+[E(X)]^2=1+0=1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Rightarrow E(X_n^2)=n\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;卡方分佈的方差：&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
Var(X_1^2) &amp;amp;= E(X_1^{2^2}) - E(X_1^2)^2 \\
           &amp;amp;= E(X_1^4)-1
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;-ex_14&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;下面來求 &lt;span class=&#34;math inline&#34;&gt;\(E(X_1^4)\)&lt;/span&gt;&lt;/h5&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\because E(X_1) &amp;amp;= \int_{-\infty}^{+\infty} xf(x)dx \\
\therefore E(X_1^4) &amp;amp;= \int_{-\infty}^{+\infty} x^4f(x)dx
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;已知： &lt;span class=&#34;math inline&#34;&gt;\(f(x)=\frac{1}{\sqrt{2\pi}}e^{(-\frac{x^2}{2})}\)&lt;/span&gt; 代入上式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E(X_1^4) &amp;amp;= \int_{-\infty}^{+\infty} x^4f(x)dx \\
         &amp;amp;= \int_{-\infty}^{+\infty} x^4\frac{1}{\sqrt{2\pi}}e^{(-\frac{x^2}{2})}dx\\
         &amp;amp;=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^4e^{(-\frac{x^2}{2})}dx\\
         &amp;amp;=\frac{-1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^3(-x)e^{(-\frac{x^2}{2})}dx
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(u=x^3, v=e^{(-\frac{x^2}{2})},t=-\frac{x^2}{2}\)&lt;/span&gt;
可以推導：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\frac{dv}{dx} &amp;amp;= \frac{dv}{dt}\frac{dt}{dx} \\
              &amp;amp;= e^t(-\frac{1}{2}\times2x) \\
              &amp;amp;= (-x)e^{(-\frac{x^2}{2})} \\
\Rightarrow dv &amp;amp;= (-x)e^{(-\frac{x^2}{2})}dx
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;再代入上面的式子：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E(X_1^4) &amp;amp;= \frac{-1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}u\:dv \\
integrate\; &amp;amp;by\; parts:\\
E(X_1^4) &amp;amp;= \frac{-1}{\sqrt{2\pi}}\{[u\:v] \rvert_{-\infty}^{+\infty}-\int_{-\infty}^{+\infty}v\:du\} \\
&amp;amp;= \frac{-1}{\sqrt{2\pi}}\{[x^3e^{(-\frac{x^2}{2})}]\rvert_{-\infty}^{+\infty} -\int_{-\infty}^{+\infty}v\:du\} \\
&amp;amp;=\frac{-1}{\sqrt{2\pi}}\{0-0-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx^3\} \\
&amp;amp;=\frac{-1}{\sqrt{2\pi}}[-3\int_{-\infty}^{+\infty}x^2e^{(-\frac{x^2}{2})}dx] \\
&amp;amp;=\frac{-3}{\sqrt{2\pi}}[\int_{-\infty}^{+\infty}x(-x)e^{(-\frac{x^2}{2})}dx] \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;再來一次分部積分：&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(a=x,b=e^{(-\frac{x^2}{2})},d\:b = (-x)e^{(-\frac{x^2}{2})}dx\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E(X_1^4) &amp;amp;= \frac{-3}{\sqrt{2\pi}}\{[a\:b] \rvert_{-\infty}^{+\infty} - \int_{-\infty}^{+\infty}b\:da\} \\
&amp;amp;=\frac{-3}{\sqrt{2\pi}}\{[xe^{(-\frac{x^2}{2})}]\rvert_{-\infty}^{+\infty} -\int_{-\infty}^{+\infty}b\:da\} \\
&amp;amp;=\frac{-3}{\sqrt{2\pi}}\{0-0-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx\} \\
&amp;amp;=\frac{-3}{\sqrt{2\pi}}[-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx] \\
&amp;amp;=\frac{3}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;下面令 &lt;span class=&#34;math inline&#34;&gt;\(I=\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx\\ \Rightarrow I^2=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{(-\frac{x^2+y^2}{2})}dxdy\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;接下來需要用到 &lt;a href=&#34;https://www.youtube.com/watch?v=r0fv9V9GHdo&#34;&gt;座標轉換&lt;/a&gt;的知識，將 &lt;span class=&#34;math inline&#34;&gt;\(x,y\)&lt;/span&gt; 表示的笛卡爾座標，轉換爲用角度 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 和半徑 &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; 表示的形式。之後的證明可以在&lt;a href=&#34;https://www.youtube.com/watch?v=fWOGfzC3IeY&#34;&gt;油管&lt;/a&gt;上看到，但是我還是繼續證明下去。&lt;/p&gt;
&lt;p&gt;直角座標系 (cartesian coordinators) 和
極座標系 (polar coordinators) 之間轉換的關係如下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
x&amp;amp;=r\:cos\theta\\
y&amp;amp;=r\:sin\theta\\
r^2&amp;amp;=x^2+y^2\\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;座標轉換以後可以繼續求 &lt;span class=&#34;math inline&#34;&gt;\(E(X_1^4)\)&lt;/span&gt;。 在那之前我們先求 &lt;span class=&#34;math inline&#34;&gt;\(I^2\)&lt;/span&gt;。
注意轉換座標系統以後，&lt;span class=&#34;math inline&#34;&gt;\(\theta\in[0,2\pi], r\in[0,+\infty]\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
I^2 &amp;amp;= \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{(-\frac{x^2+y^2}{2})}dxdy \\
&amp;amp;= \int_{0}^{+\infty}\int_{0}^{2\pi}e^{(-\frac{r^2}{2})}rd\theta dr \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由於先從中間的 &lt;span class=&#34;math inline&#34;&gt;\(\int_{0}^{2\pi}e^{(-\frac{r^2}{2})}rd\theta\)&lt;/span&gt; 開始積分，&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 以外都可以視爲常數，那麼這個 &lt;span class=&#34;math inline&#34;&gt;\([0,2\pi]\)&lt;/span&gt; 上的積分就的等於 &lt;span class=&#34;math inline&#34;&gt;\(2\pi e^{(-\frac{r^2}{2})}r\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;因此上面的式子又變爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
I^2 &amp;amp;=  2\pi\int_{0}^{+\infty}e^{(-\frac{r^2}{2})}r\:dr \\
\because \frac{d(e^{\frac{-r^2}{2}})}{dr} &amp;amp;= -e^{(-\frac{r^2}{2})}r \\
\therefore I^2 &amp;amp;= 2\pi(-e^{\frac{-r^2}{2}})\rvert_0^{+\infty} \\
               &amp;amp;= 0-(2\pi\times(-1)) \\
               &amp;amp;= 2\pi\\
\Rightarrow I  &amp;amp;= \sqrt{2\pi}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E(X_1^4) &amp;amp;= \frac{3}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx \\
&amp;amp;= \frac{3}{\sqrt{2\pi}}\times I \\
&amp;amp;= 3 \\
\Rightarrow Var(X_1^2) &amp;amp;= E(X_1^4) - 1 \\
                       &amp;amp;= 3-1 =2 \\
\Rightarrow Var(X_n^2) &amp;amp;= 2n
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;結論：&lt;span class=&#34;math inline&#34;&gt;\(X_1, \dots, X_n\stackrel{i.i.d}{\sim} N(0,1)\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^nX_i^2\sim\mathcal{X}_n^2\)&lt;/span&gt; 服從卡方分佈，其期望 &lt;span class=&#34;math inline&#34;&gt;\(E(X_n^2)=n\)&lt;/span&gt;，方差 &lt;span class=&#34;math inline&#34;&gt;\(Var(X_n^2)=2n\)&lt;/span&gt;。
根據&lt;a href=&#34;https://winterwang.github.io/post/central-limit-theory/&#34;&gt;中心極限定理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n\rightarrow \infty, X_n^2\sim N(n, 2n)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
