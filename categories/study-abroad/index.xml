<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>study abroad | Be Ambitious</title>
    <link>https://wangcc.me/categories/study-abroad/</link>
      <atom:link href="https://wangcc.me/categories/study-abroad/index.xml" rel="self" type="application/rss+xml" />
    <description>study abroad</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2017-2019 Chaochen Wang | 王超辰</copyright><lastBuildDate>Tue, 03 Jul 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://wangcc.me/img/icon-192.png</url>
      <title>study abroad</title>
      <link>https://wangcc.me/categories/study-abroad/</link>
    </image>
    
    <item>
      <title>Words, notes, and sentences that may be useful </title>
      <link>https://wangcc.me/post/words-notes-and-sentences-that-may-be-useful/</link>
      <pubDate>Tue, 03 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/words-notes-and-sentences-that-may-be-useful/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#words&#34;&gt;Words&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#expressions&#34;&gt;Expressions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sentences&#34;&gt;Sentences&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#terry2017discontinuous&#34;&gt;terry2017discontinuous&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#lanza2007proc&#34;&gt;lanza2007proc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#collins2010latent&#34;&gt;collins2010latent&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;words&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Words&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;discernable [di’sə:nəbl, -’zə:-]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;===== 辞典翻译: discernable ======
adj. 可辨别的；可认识的
============ 网络释义 ============
-------- discernable ---------
可辨别的
方向
分辨
-- discernable recognizable --
可辨别的
--- discernable visible ----
可辨别的&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;abstinence [’æbstinəns]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;====== 辞典翻译: abstinence ======
  n. 节制；节欲；戒酒；禁食
============ 网络释义 ============
--------- abstinence ---------
  节制
  禁欲
  禁戒
----- alcohol abstinence -----
  酒戒断
----- Abstinence theory ------
  节欲论
  弃权
  忍欲说&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;exhaustive [iɡ’zɔ:stiv]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;====== 辞典翻译: exhaustive ======
  adj. 详尽的；彻底的；消耗的
============ 网络释义 ============
--------- Exhaustive ---------
  无遗
  详尽的
  全部
----- Exhaustive search ------
  穷举搜索
  穷举搜索完全搜索
  全程搜索
----- exhaustive voting ------
  淘汰投票
  消耗性投票&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;temperament [’tempərəmənt]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;===== 辞典翻译: temperament ======
  n. 气质，性情，性格；急躁
============ 网络释义 ============
-------- temperament ---------
  气质
  气质 (心理学)
  性格
------ Well Temperament ------
  Well temperament
  Well Temperament
  平均律
---- Musical temperament -----
  律学
  一份音乐的气质
  音乐性&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;trivial [’triviəl]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;======= 辞典翻译: trivial ========
  adj. 不重要的，琐碎的；琐细的
============ 网络释义 ============
---------- trivial -----------
  琐碎的
  微不足道的
  小巫见大巫
------ Trivial Pursuit -------
  棋盘问答
  打破砂锅问到底
  追根究底
-------- trivial name --------
  惯用名
  俗名
  种名&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;prudent [’pru:dənt]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;======= 辞典翻译: prudent ========
  adj. 谨慎的；精明的；节俭的
  n. (Prudent)人名；(法)普吕当
============ 网络释义 ============
---------- prudent -----------
  谨慎的
  明智的
  审慎的
--------- prudent s ----------
  善于经营的
  谨慎
  精明的
----- PRESIDENT PRUDENT ------
  普鲁登特总统城&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;daunting [’dɔ:ntiŋ]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;======= 辞典翻译: daunting =======
adj. 使人畏缩的；使人气馁的；令人怯步的
============ 网络释义 ============
---------- Daunting ----------
令人生畏
使人畏缩的
使人气馁的
------ However Daunting ------
但艰巨
--------- B daunting ---------
使胆怯&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;discern [di’sə:n, -’zə:n]&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;======= 辞典翻译: discern ========
  vt. 识别；领悟，认识
  vi. 看清楚，辨别
============ 网络释义 ============
---------- discern -----------
  看出
  辨别
  识别
-------- Discern Lies --------
  辨知谎言
  辨识谎言
  洞悉谎言
------- discern safely -------
  安全识别&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;expressions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Expressions&lt;/h1&gt;
&lt;/div&gt;
&lt;div id=&#34;sentences&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Sentences&lt;/h1&gt;
&lt;div id=&#34;terry2017discontinuous&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;terry2017discontinuous&lt;/h2&gt;
&lt;p&gt;(Discontinuous Patterns of Cigarette Smoking From Ages 18 to 50 in the United States: A Repeated-Measures Latent Class Analysis)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;RMLCA models were fitted in SAS 9.4 using PROC LCA. Parameters were estimated by maximum likelihood using the EM algorithm.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;To ascertain if the same latent class structure was observed for males and females, multiple-group RMLCA models by sex were fitted in PROC LCA using the GROUPS statement (both with and without imposing measurement invariance across males and females).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Model selection (ie, the number of latent classes specified) was determined by model fit, parsimony, and stability.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Simulations have shown that the Bayesian information criterion (BIC) and sample size-adjusted BIC (a-BIC) perform particularly well at selecting the “correct” latent class model.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Improvement in both BIC and consistent Akaike information criterion (CAIC) values continued only through the 12-class model; thus, the 12-class model was selected as optimal.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;lanza2007proc&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;lanza2007proc&lt;/h2&gt;
&lt;p&gt;(PROC LCA: A SAS procedure for latent class analysis)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;In traditional LCA, two sets of parameters are estimated: class membership probabilities and item-response probabilities conditional on class membership.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Latent class models usually involve categorical indicators (although a version of LCA involving continuous indicators called latent profile analysis [Gibson, 1959] is being used increasingly).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;When categorical data are used, the latent class model has the advantage of making no assumptions about the distributions of the indicators other than that of local independence; that is, the assumption that within a latent class the indicators are independent.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In PROC LCA, parameters are estimated by maximum likelihood using an EM (expectation-maximization) type procedure. Missing data on the latent class indicators are handled in this procedure, with data assumed to be missing at
random (MAR).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A test of the null hypothesis that data are missing completely at random appears in the output.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;a helpful preliminary step in any LCA is exploring overall relations among pairs of items by conducting cross-tab analyses.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A good starting point for identifying an optimal baseline model is to fit a sequence of models with two classes, three classes, and so on.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A variety of tools can be used together for model selection, including the likelihood-ratio G 2 statis-
tic, Akaike’s Information Criterion (AIC; Akaike, 1974) and Bayesian Information Criterion (BIC; Schwarz, 1978).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For example, each class should be distinguishable from the others on the basis of the item-response probabilities, no class should be trivial in size (i.e., with a near-zero probability of membership), and it should be possible to assign a meaningful label to each class.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The AIC and BIC are penalized log-likelihood model information criteria that can be used to compare competing models (e.g., models with different numbers of latent classes) fit to the same data. A smaller AIC and BIC for a particular model suggests that the trade-off between fit and parsimony is preferable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Often when a grouping variable is included it is important to test for measurement invariance across groups. To do this, a model with free estimation of the &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; parameters can be compared to the same model that includes restrictions equating the &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; parameters across groups. A significant p value suggests that the null hypothesis of measurement invariance should be rejected.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Based on a data set, a particular model specification, and starting values for the parameters, the algo-
rithm iterates between the Expectation (E) step and the Maximization (M) step until either the convergence criterion is achieved or the maximum number of iterations is reached.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The best way to detect identification problems or local optima (i.e., solutions other than the optimal one) is to fit the same model using multiple sets of starting values. This can be done by calling the procedure repeatedly with different seeds specified.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Even well-identified models can land on a different solution occasionally; if the solution with the smallest log-likelihood is arrived at using the majority of the seeds, one can have confidence that it is the optimal solution.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;collins2010latent&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;collins2010latent&lt;/h2&gt;
&lt;p&gt;(Latent Class and Latent Transition Analysis: With Applications in the Social, Behavioral, and Health Sciences)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;It is particularly noteworthy that the causal flow is &lt;em&gt;from&lt;/em&gt; the latent variable &lt;em&gt;to&lt;/em&gt; the indicator variable, not the other way around. That is, observed indicator variables do not cause the latent variables.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The purpose of LCA is to help the investigator to discern any meaningful, scientifically interesting classes against the noisy background of error.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In LCA, it is the responsibility of the investigator to assign names to the latent classes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The starting point for conducting a latent class analysis on empirical data is a contingency table formed by cross-tabulating all the observed variables to be involved in the analysis.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The local independence assumption refers only to conditioning on the latent variable. It does not imply that in a data set that is to be analyzed, the observed variables are independent. In fact, it is the relations among the observed variables that are explained by the latent classes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;An observed data set is a mixture of all the latent classes. Independence is assumed to hold only within each latent class, which is why it is called “local”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;LCA makes the assumption of local independence, which states that conditional on latent class, observed variables are independent.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A high degree of latent class separation implies a high degree of homogeneity.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;However, a high degree of homegeneity does not necessarily imply a high degree of latent class separation.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Thus, it is possible to have high homogeneity but poor latent class separation.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Some of the latent classes may be characterized by more than one response pattern, but there is no response pattern that appears to be closely associated with more than one latent class. Thus the latent classes are conceptually distinct and can readily be labeled.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Model selection may be challenging. Furtunately, a variety of tools are available to assist, including tests of absolute model fit, assessment of relative fit of competing models, and cross-validation. In addition to the tools discussed, there are two additional consideration that are critically important when evaluating a model: &lt;strong&gt;parsimony and model interpretability&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We see statistical models as lenses through which investigators examine their data in order to gain useful insights.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The likelihood-ratio statistics &lt;span class=&#34;math inline&#34;&gt;\(G^2\)&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[G^2 = 2\sum_{w=1}^W f_w\log(\frac{f_w}{\widehat{f_w}})\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(f_w\)&lt;/span&gt; represents the observed frequency of cell &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\widehat{f_w}\)&lt;/span&gt; represent the expected frequency of cell &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt; according to the model that has been fit.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The larger the value of &lt;span class=&#34;math inline&#34;&gt;\(G^2\)&lt;/span&gt;, the more evidence there is against the null hypothesis. (The larger it is, the worse model fitting it is.)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The degrees of freedom of &lt;span class=&#34;math inline&#34;&gt;\(G^2\)&lt;/span&gt;: &lt;span class=&#34;math display&#34;&gt;\[df = W - P - 1\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt; is the number of estimated parameters.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Sometimes fitting a series of latent class models with different numbers of latent classes to data at a single time point can be helpful as a preliminary step in model selection in LTA. Doing this at each time point can be informative about the latent structrue within times, and how that structure changes accross timie points.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It is important to note that the best-fitting latent class model at any given time may not correspond to the best-fitting latent transition model fit to all occasions of measurements. The best-fitting model based on the data from all occasions of measurement may include a different number of latent stuatuses than the number of latent classes identified at one particular time.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;However, based on the latent status prevalences at each time alone, it is impossible to tell hou and to what extent individuals were moving between latent statuses.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;In 7.11 we used a different empirical example to test the hypothesis that the item-response probabilities in a LTA are equal across times. This type of restriction on the item-response probabilities is commonly used in LTA. It helps with model identification and, importantly, ensures that the meaning of the latent statuses remains constant over time.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Summer Project Schedule</title>
      <link>https://wangcc.me/post/summer-project-schedule/</link>
      <pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/summer-project-schedule/</guid>
      <description>&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Data analysis finish by 2018-07-&lt;/del&gt;24&lt;del&gt;31&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Paper structure confirm by 2018-08-01&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Paper draft complete by 2018-08-16&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;2018-06-24

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read and try to repeat Rll&amp;rsquo;s method in R and familarize the dataset ASAP&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Two papers applying Repeated Measures LCA&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-25

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Meeting with supervisor and Susanna&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Confirm the cutoff of carborhydrate consumption&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Talk with Rll ask about the methodology and dataset&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-26

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Send the summarised memo of meeting to Supervisor and etc.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read the first part fundamentals of LCA.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-27

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;a href=&#34;https://www.londonr.org/&#34; target=&#34;_blank&#34;&gt;London R in UCL&lt;/a&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Germany lost their game against South Korea, UNBELIEVEABLE&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-28&lt;br /&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read the book collins2010latent - Latent Class and Latent Transition Analysis: With Applications in the Social, Behavioral, and Health Sciences (Done until 4.2)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn how to do LCA in R&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-06-29

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read the book collins2010latent - Latent Class and Latent Transition Analysis: With Applications in the Social, Behavioral, and Health Sciences (Done until 4.3)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Data management for NDNS 8 years data (70%)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn how to do LCA in R&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Start to analysis the data according to the discussion on 25th(30%)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Day1 data analysis results summary&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-01

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Relax and do nothing&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Buy some drink to enjoy the night with classmates(HB)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-02/03

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Send some preliminary results to co-authors&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&lt;a href=&#34;http://www.the-afc.com/competitions/fifa-world-cup/latest/news/japan-fa-president-proud-of-blue-samurai&#34; target=&#34;_blank&#34;&gt;Japan lost the game to Belgium, but they are the glory of Asia&amp;ndash;heartbreaking&lt;/a&gt;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-04&lt;br /&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&amp;ldquo;consider separating weekdays from weekends if we are not averaging the four days?&amp;rdquo;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-05

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Test and confirm the availability of LCA in SAS&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn how to do LCA in SAS with NDNS data&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-06&lt;br /&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn how to do LCA with random effects in SAS&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Find whether there is any possibility of conducting the same method in R or STATA (no there is no way)&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-07~09

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;&amp;ldquo;Maybe we should try with the threshold at 25% only as per the existing guidelines (although those are per meal)?&amp;rdquo;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-10

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; ~~Meet with tutor;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; Start writing about the methodology;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; Try to start writing about the introduction;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-11&lt;br /&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Try to summarise the meeting memo yesterday;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Re-analyse the data with new cut-off values (25, 50, 75);&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Re-analyse the data with new cut-off values (50);&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-12~22

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Use latent class growth analysis;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Use multilevel latent class analysis;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Think about the mathmatical theory behind the mixed LCA, write to PROC LCA group if necessary;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-23~25

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Learn about the survey package in R&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Finish writing about the methodology;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Write some introduction;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-07-26&lt;br /&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Let&amp;rsquo;s finish analysis of the classes and health outcomes.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read about the carbo-fibre ratio references.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-08-15

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;PM review&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Finish most of the discussion outlines and 2 pages of them.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2018-08-31

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Finish revising the report according to comments from LP and SAM;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Read RT&amp;rsquo;s report and send the comments;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Confirm the deadline for funding applications;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Prepare the abstract for conferences (UK and JP);&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Start preparing the paper for submit (MLCA part alone);&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Think about the schedules and plans after leaving London;&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; &lt;del&gt;Finish the post of Scotland trip.&lt;/del&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>你靜靜地睡在琥珀裏</title>
      <link>https://wangcc.me/post/sleep/</link>
      <pubDate>Sun, 06 May 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/sleep/</guid>
      <description>&lt;p&gt;媽在電話裏說，今年要是期末考試考不過，明年把妹妹(我女兒)背去倫敦再考。(T_T) 突然我就想起快離開廈門的前一天，帶着兒子去大榕樹底下玩。他興奮地要玩我新買的乒乓球和乒乓球拍。可我心裏舍不得新的球和球拍弄髒了，就故意拿小汽車和其他的東西分散他的注意力。回到家裏了才給了他一個乒乓球玩。其實那天本來還想帶他去買肉包給他吃，可是領了快遞以後我沒有手再拿東西，就直接帶兒子回家了。那天兒子女兒和妻還要坐火車回榕城外婆家，一路顛簸誰也沒想起來，兒子還沒吃早飯。火車上聽說他也一直沒吃東西，不知道他三歲的心裏在想什麼。到了外婆家裏也很晚了，男孩子興奮哭鬧總是比女孩子激烈。我一聽電話裏他哭的聲音，心裏就不由得難受極了。怎麼就舍不得把乒乓球給他一個呢，我真是個自私極了的爸爸。忘了兒子沒吃早飯，也舍不得把他想玩的乒乓球送給他。也許他早就不記得了，但是我總惦記着這一天發生的事。也許在我心裏，那段美好時光在琥珀中靜止在了廈門開往島外的那列送行的地鐵上。&lt;/p&gt;

&lt;p&gt;我又想起在學習&lt;a href=&#34;http://wangcc.me/LSHTMlearningnote/causal-languages-.html&#34; target=&#34;_blank&#34;&gt;因果推斷&lt;/a&gt;的時候，每次老師都要強調那三個永世不能忘記的推斷前提:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;無相互幹擾 no interference;&lt;/li&gt;
&lt;li&gt;一致性 consistency;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;條件可置換性 conditional exchangeability;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;每當老師提問說，我們現在的前提是什麼？全班同學總能異口同聲地念出上面那三句咒語，場景仿佛間諜與間諜之間對暗號。又有點像黑幫入會時指天發誓的三句誓言。還有就是那個老師可愛的法文味道的英文，標準誤的英文是 standard error，她總是說 standard &amp;ldquo;唉河&amp;rdquo;。另一個教生存分析的法國人老師就更有趣了，每次舉例子都說，比方說我們拿&amp;ndash;法國做例子，隨機選一個國家嘛。。blablabla&amp;hellip;&lt;/p&gt;

&lt;p&gt;今天，響子同學說要去阿根廷完成自己的碩士課題。我們下午坐在 SOAS 的草地上一邊從作業間隙中休息，一邊喝着咖啡，突然意識到，再過一陣子，新學生就又要來了呢。去年這時候我們都還在世界各地，響子在危地馬拉給 JICA 幹活，說着流利的西班牙語; 我在名古屋一邊給日本學生講課，一邊內心充滿了期待快出生的妹妹和快要出發來倫敦的復雜又忐忑的心情，如今我們竟然已經在討論彼此回程的機票訂了幾號，想起3月我們還在寒風中頂着大雪抱怨着留英這一年碰到數十年最嚴重的大學罷課，這一段時光，竟也這樣偷偷溜走，沒有琥珀可以給它定格。&lt;/p&gt;

&lt;p&gt;直到兩天前，同班同學在因果推斷下課後，復習完了我們每次課上對完的暗號，突然有同學提議說，我們去學校門口拍一張集體照片吧，學校年度學生畫冊 (Yearbook) 的內容我們還沒人提交吶，至少要有一張咱們的集體照片吧！ 於是我們有了封面的那張照片。總算是用 LOMO 的隨手拍記錄下這年我們在 LSHTM 待過的證據。這年，我們這十幾個在 LSHTM 推倒公式，背誦&amp;rdquo;間諜暗號&amp;rdquo;，倒騰貝葉斯，糾結着那些回歸模型的殘差，還有那個永遠也搞不懂的似然。一瞬間留在相紙上，一轉眼可能就要各奔四方。傷感不由就從心中涌出，蔓延到大西洋。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>萬衆期待，英國黑暗料理</title>
      <link>https://wangcc.me/post/black-meal/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/black-meal/</guid>
      <description>

&lt;h3 id=&#34;康沃爾的牛肉餡餅-贊-2017-12-16-the-shop-in-the-square-https-www-google-com-maps-place-the-shop-in-the-square-50-3310101-4-2021014-21z-data-4m13-1m7-3m6-1s0x0-0x0-2zntdcsde5jzuyljaitia0wraxmicwny4yilc-3b1-8m2-3d50-3311-4d-4-202-3m4-1s0x486c94411d32061f-0xc6ba3bcac8fcc931-8m2-3d50-331087-4d-4-2021739&#34;&gt;康沃爾的牛肉餡餅！ 贊！ (2017-12-16 @&lt;a href=&#34;https://www.google.com/maps/place/The+Shop+in+the+Square/@50.3310101,-4.2021014,21z/data=!4m13!1m7!3m6!1s0x0:0x0!2zNTDCsDE5JzUyLjAiTiA0wrAxMicwNy4yIlc!3b1!8m2!3d50.3311!4d-4.202!3m4!1s0x486c94411d32061f:0xc6ba3bcac8fcc931!8m2!3d50.331087!4d-4.2021739&#34; target=&#34;_blank&#34;&gt;The Shop in the Square&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1483.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;看起來美味但是甜到牙痛的聖誕蛋糕-2017-12-17-calstock-homestay&#34;&gt;看起來美味但是甜到牙痛的聖誕蛋糕 (2017-12-17 @Calstock Homestay)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1559.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;香腸美味-烤雞美味-洋蔥有點糊但是還是很美味-2017-12-16-jane-ian-s-homestay&#34;&gt;香腸美味！烤雞美味！洋蔥有點糊但是還是很美味！ (2017-12-16 @Jane&amp;amp;Ian&amp;rsquo;s Homestay)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_20171217_045212.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;在中國城買到最贊的國貨-廈門鐵觀音-2017-12-09-london-china-town&#34;&gt;在中國城買到最贊的國貨！廈門鐵觀音 (2017-12-09 @London China Town)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1374.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;貴到無法下手的三文魚壽司-2017-12-06-waitrose&#34;&gt;貴到無法下手的三文魚壽司 (2017-12-06 @Waitrose)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1356.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;和日本一風堂味道一樣但是貴一倍的豚骨拉麵-2017-12-02-london-ippudo-http-www-ippudo-co-uk&#34;&gt;和日本一風堂味道一樣但是貴一倍的豚骨拉麵 (2017-12-02 @&lt;a href=&#34;http://www.ippudo.co.uk/&#34; target=&#34;_blank&#34;&gt;London Ippudo&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1312.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;學校附近和同學一起去喝過最棒的拿鐵-缺點是杯子太小-2017-12-01-tap-caffee-http-www-tapcoffee-co-uk&#34;&gt;學校附近和同學一起去喝過最棒的拿鐵，缺點是杯子太小 (2017-12-01 @&lt;a href=&#34;http://www.tapcoffee.co.uk/&#34; target=&#34;_blank&#34;&gt;Tap Caffee&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1306.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;brunch-在長頸鹿餐廳可以打8折-2017-11-29-giraffe-https-www-giraffe-net&#34;&gt;Brunch 在長頸鹿餐廳可以打8折 (2017-11-29 @&lt;a href=&#34;https://www.giraffe.net/&#34; target=&#34;_blank&#34;&gt;Giraffe&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1293.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;約克郡的傳統午餐-美味牛肉-2017-11-26-the-judge-s-lodging-https-www-thwaites-co-uk-hotels-and-inns-inns-judges-lodging-at-york-food-and-drink-menus&#34;&gt;約克郡的傳統午餐，美味牛肉 (2017-11-26 @&lt;a href=&#34;https://www.thwaites.co.uk/hotels-and-inns/inns/judges-lodging-at-york/food-and-drink/menus/&#34; target=&#34;_blank&#34;&gt;The Judge&amp;rsquo;s Lodging&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1244.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;謝菲爾德的聖誕街市賣的烤香腸-2017-11-25-sheffield&#34;&gt;謝菲爾德的聖誕街市賣的烤香腸 (2017-11-25 @Sheffield)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1143.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;日本同學從日本帶來的速食味增湯-美味至極-2017-11-23-international-hall&#34;&gt;日本同學從日本帶來的速食味增湯，美味至極 (2017-11-23 @International Hall)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1118.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;國王十字車站對面的新加坡華人餐廳-海南雞飯不錯-2017-11-01-chop-chop-noodle-bar-https-www-google-com-maps-place-chop-chop-noodle-bar-51-5303949-0-1226249-19z-data-4m13-1m7-3m6-1s0x0-0x0-2znthcsdmxjzq5ljgitiawwrawnycyms43ilc-3b1-8m2-3d51-5305-4d-0-1227-3m4-1s0x0-0x252e2c027563f1e4-8m2-3d51-5303959-4d-0-122609&#34;&gt;國王十字車站對面的新加坡華人餐廳，海南雞飯不錯 (2017-11-01 @&lt;a href=&#34;https://www.google.com/maps/place/Chop+Chop+Noodle+Bar/@51.5303949,-0.1226249,19z/data=!4m13!1m7!3m6!1s0x0:0x0!2zNTHCsDMxJzQ5LjgiTiAwwrAwNycyMS43Ilc!3b1!8m2!3d51.5305!4d-0.1227!3m4!1s0x0:0x252e2c027563f1e4!8m2!3d51.5303959!4d-0.122609&#34; target=&#34;_blank&#34;&gt;Chop Chop Noodle Bar&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0649.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;同學宿舍裏的自制小炒-2017-10-21-the-garden-hall&#34;&gt;同學宿舍裏的自制小炒 (2017-10-21 @The Garden Hall)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0548.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;大英博物館前的中餐館的水煮魚-2017-10-20-chang-s-noodle-https-www-google-com-maps-place-chang-s-noodle-51-517143-0-1256334-21z-data-4m13-1m7-3m6-1s0x0-0x0-2znthcsdmxjzaxljyitiawwrawnyczms44ilc-3b1-8m2-3d51-5171-4d-0-1255-3m4-1s0x48761b3301f99d9d-0x3ba6ded2ee933a5a-8m2-3d51-5172364-4d-0-1254925&#34;&gt;大英博物館前的中餐館的水煮魚 (2017-10-20 @&lt;a href=&#34;https://www.google.com/maps/place/Chang&#39;s+Noodle/@51.517143,-0.1256334,21z/data=!4m13!1m7!3m6!1s0x0:0x0!2zNTHCsDMxJzAxLjYiTiAwwrAwNyczMS44Ilc!3b1!8m2!3d51.5171!4d-0.1255!3m4!1s0x48761b3301f99d9d:0x3ba6ded2ee933a5a!8m2!3d51.5172364!4d-0.1254925&#34; target=&#34;_blank&#34;&gt;Chang&amp;rsquo;s Noodle&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0537.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;大英博物館前的都可茶飲買到的原味珍珠奶茶-3-5-有學生優惠-2017-10-20-coco-http-en-coco-tea-com&#34;&gt;大英博物館前的都可茶飲買到的原味珍珠奶茶 £3.5 有學生優惠 (2017-10-20 @&lt;a href=&#34;http://en.coco-tea.com/&#34; target=&#34;_blank&#34;&gt;Coco&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0534.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;雞腿不錯但是旁邊的配菜有點像中藥味的壓縮餅乾-2017-10-08-ihdining-room&#34;&gt;雞腿不錯但是旁邊的配菜有點像中藥味的壓縮餅乾 (2017-10-08 @IHdining room)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/953062095.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;哈利波特特約飲料-butterbeer-奶油啤酒-2017-10-07-warner-bros-studio-tour-london-https-www-wbstudiotour-co-uk&#34;&gt;哈利波特特約飲料 Butterbeer （奶油啤酒）(2017-10-07 @&lt;a href=&#34;https://www.wbstudiotour.co.uk/&#34; target=&#34;_blank&#34;&gt;Warner Bros. Studio Tour London&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/244977493.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;以爲是甜食的派結果裏面包着牛肉的奇怪料理-2017-10-07-ihdining-room&#34;&gt;以爲是甜食的派結果裏面包着牛肉的奇怪料理 (2017-10-07 @IHdining room)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1959199628.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;羅素廣場地鐵站門口的小攤賣的超划算味道很正的新鮮草莓-2017-10-05-russel-square-station-https-www-google-co-uk-maps-place-russell-square-station-51-523111-0-1265731-17z-data-3m1-4b1-4m5-3m4-1s0x48761b30d8fe5173-0xcf6c5a5908686210-8m2-3d51-523111-4d-0-1243844-hl-en&#34;&gt;羅素廣場地鐵站門口的小攤賣的超划算味道很正的新鮮草莓！(2017-10-05 @&lt;a href=&#34;https://www.google.co.uk/maps/place/Russell+Square+Station/@51.523111,-0.1265731,17z/data=!3m1!4b1!4m5!3m4!1s0x48761b30d8fe5173:0xcf6c5a5908686210!8m2!3d51.523111!4d-0.1243844?hl=en&#34; target=&#34;_blank&#34;&gt;Russel Square Station&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1040178656.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;价值5镑的食堂素食色拉一盒-2017-10-02-lshtm食堂&#34;&gt;价值5镑的食堂素食色拉一盒 (2017-10-02@LSHTM食堂)&lt;/h3&gt;

&lt;p&gt;新鮮，但是米飯有點夾生。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/41913438.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;味道超讚牛肉披薩-diavolo-2017-09-28-pizza-express-in-charlotte-street-https-www-pizzaexpress-com-charlotte-street-utm-source-google-utm-medium-places-utm-campaign-charlotte-street&#34;&gt;味道超讚牛肉披薩 Diavolo (2017-09-28 @&lt;a href=&#34;https://www.pizzaexpress.com/charlotte-street?utm_source=Google&amp;amp;utm_medium=Places&amp;amp;utm_campaign=charlotte-street&#34; target=&#34;_blank&#34;&gt;Pizza Express in Charlotte Street&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_20170928_184500.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;菜單上的說明是這樣滴：
Hot spiced beef, pepperoni, mozzarella, tomato, green pepper, red onion and Tabasco, with your choice of hot green, Roquito or jalapeño peppers. Available as Classic or Romana&lt;/p&gt;

&lt;h3 id=&#34;羊肉味的奶油夾心三明治-2017-09-24-store-street-espresso-http-www-storestespresso-co-uk&#34;&gt;羊肉味的奶油夾心三明治 (2017-09-24 @&lt;a href=&#34;http://www.storestespresso.co.uk/&#34; target=&#34;_blank&#34;&gt;Store Street Espresso&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;我點菜之前還故意跟收銀員小妹搭訕，讓她推薦一下今天的特色三明治。
她推薦的這個 Goat Cheese Sandwich。 當然我一開始聽到這名字的時候就有點猶豫。但是想說既然是推薦的應該至少不會有什麼怪味道。結果事實證明了，我的想法是多麼的幼稚。&lt;/p&gt;

&lt;p&gt;看這剛出爐的香噴噴的三明治，我咬下第一口就差點吐了。羊羶味在我喉嚨和鼻腔中打轉。後悔也來不及了。另外我同同時還點了 Espresso。就是特濃咖啡。口味超重！不能喝濃咖啡的一定要慎點！！！！&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1388034054.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;酸酸的不知道怎麼形容的麵包-日期忘了-估計是剛到的第二個早晨的早餐-ihdining-room&#34;&gt;酸酸的不知道怎麼形容的麵包 (日期忘了，估計是剛到的第二個早晨的早餐@IHdining room)&lt;/h3&gt;

&lt;p&gt;這麵包吃起來鬆鬆的，然額，麵的味道有些酸，又不像是過期食品，而像是本來就應該是這樣的味道的酸麵包。讓人不想再嘗試第二次。。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/890249589.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;美味海鮮飯-2017-09-24-ciao-bella-http-ciaobellarestaurant-co-uk&#34;&gt;美味海鮮飯 (2017-09-24 @&lt;a href=&#34;http://ciaobellarestaurant.co.uk/&#34; target=&#34;_blank&#34;&gt;Ciao Bella&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;感謝&lt;a href=&#34;https://kclpure.kcl.ac.uk/portal/li.yan.html&#34; target=&#34;_blank&#34;&gt;顏師兄&lt;/a&gt;帶領，終於找到了一家可以吃到正常大米的飯店了！且海鮮量超足！&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/737031981.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;看起來很奇怪的整魚炸薯條&#34;&gt;看起來很奇怪的整魚炸薯條&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/656438330.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;外觀其實讓人沒什麼食慾的烤魚&#34;&gt;外觀其實讓人沒什麼食慾的烤魚&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1628745573.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;酸奶放在白煮雞胸肉上&#34;&gt;酸奶放在白煮雞胸肉上&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0185.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>徒手打造一個假設檢驗</title>
      <link>https://wangcc.me/post/construction-of-a-hypothesis-test/</link>
      <pubDate>Wed, 08 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/construction-of-a-hypothesis-test/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#什麼是假設檢驗-hypothesis-testing&#34;&gt;什麼是假設檢驗 Hypothesis testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#錯誤概率和效能方程&#34;&gt;錯誤概率和效能方程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#如何選擇要檢驗的統計量&#34;&gt;如何選擇要檢驗的統計量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#複合假設-composite-hypotheses&#34;&gt;複合假設 composite hypotheses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#如何獲得反對零假設的證據-how-to-quantify-evidence-against-h_0&#34;&gt;如何獲得反對零假設的證據 how to quantify evidence against &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#雙側替代假設情況下雙側-p-值的定量方法&#34;&gt;雙側替代假設情況下，雙側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值的定量方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;什麼是假設檢驗-hypothesis-testing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;什麼是假設檢驗 Hypothesis testing&lt;/h3&gt;
&lt;p&gt;一般來說，我們的&lt;strong&gt;假設&lt;/strong&gt;（或者叫&lt;strong&gt;假說&lt;/strong&gt;）是對與我們實驗觀察數據來自的總體（或人羣）的&lt;strong&gt;概率分佈&lt;/strong&gt;的描述。在參數檢驗的背景下，就是要檢驗描述這個總體（或人羣）的&lt;strong&gt;概率分佈&lt;/strong&gt;的參數 (parameters)。最典型的情況是，我們提出兩個互補的假設，一個叫作&lt;strong&gt;零假設&lt;/strong&gt;（或者叫&lt;strong&gt;原假設&lt;/strong&gt;），null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;)；另一個是與之對應的（互補的）替代假設，althernative hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_1/H_A\)&lt;/span&gt;)。&lt;/p&gt;
&lt;p&gt;例如，若 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 是一個服從二項分佈的隨機離散變量 &lt;span class=&#34;math inline&#34;&gt;\(X\sim Bin(5, \theta)\)&lt;/span&gt;。可以考慮如下的零假設和替代假設：&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\frac{1}{2}; H_1: \theta=\frac{2}{3}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;當建立了零假設和替代假設以後，假設檢驗就是要建立如下的規則以確定：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;從樣本中計算所得的參數估計值爲多少時，拒絕零假設。（接受替代假設爲“真”）&lt;/li&gt;
&lt;li&gt;從樣本中計算所得的參數估計值爲多少時，零假設不被拒絕。（接受零假設爲“真”）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：（這一段很繞）&lt;/p&gt;
&lt;p&gt;上面的例子是零假設和替代假設均爲簡單假設的情況，實際操作中常常會設計更加複雜的（不對稱的）假設：即簡單的 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;，複雜的 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;。如此一來當零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 不被拒絕時，我們並不一定就接受之。因爲無證據證明 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt; 不等於有證據證明 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;。&lt;em&gt;&lt;strong&gt;(Absence of evidence is not evidence of absence).&lt;/strong&gt;&lt;/em&gt; 換句話說，無證據讓我們拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 本身並不成爲支持 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 爲“真”的證據。因爲在實際操作中，當我們設定的簡單的零假設沒有被拒絕，可能還存在其他符合樣本數據的零假設；相反地，當樣本數據的計算結果拒絕了零假設，我們只能接受替代假設。所以，反對零假設的證據，同時就是支持替代假設的證據。&lt;/p&gt;
&lt;p&gt;在樣本空間 sample space 中，決定了零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 會被拒絕的子集 subset，被命名爲拒絕域 rejection region 或者 判別區域 critical region，用 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 來標記。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;錯誤概率和效能方程&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;錯誤概率和效能方程&lt;/h3&gt;
&lt;p&gt;這一部分可以參考之前&lt;a href=&#34;https://winterwang.github.io/post/sample-size-in-clinical-trial/&#34;&gt;臨牀試驗樣本量計算&lt;/a&gt;的部分。&lt;/p&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Table 1: Definition of Type I and Type II error
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;border-bottom:hidden&#34; colspan=&#34;2&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;&#34; colspan=&#34;2&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px;&#34;&gt;
SAMPLE
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x} \notin \mathfrak{R}\)&lt;/span&gt; Accept &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x} \in \mathfrak{R}\)&lt;/span&gt; Reject &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;vertical-align: middle !important;&#34; rowspan=&#34;2&#34;&gt;
TRUTH
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; is true
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\checkmark\)&lt;/span&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; &lt;br&gt; Type I error
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt; is true
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; &lt;br&gt; Type II error
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\checkmark\)&lt;/span&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;假如一個假設檢驗是關於總體參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0: \theta=\theta_0 \;vs.\; H_1: \theta=\theta_1 \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這個檢驗的效能被定義爲當替代假設爲“真”時，拒絕零假設的概率（能夠檢驗出有真實差別的能力）：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Power&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(=Prob(\underline{x}\in\mathfrak{R}|H_1\; is\; true) = 1-Prob(Type \; II\; error)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;檢驗的顯著性水平用 &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; 來表示。&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; 的直觀意義就是，檢驗結果錯誤的拒絕了零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;，接受了替代假設 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;，即假陽性的概率。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Prob(\underline{x}\in \mathfrak{R} |H_0 \;is\;true)=Prob(Type\;I\;error)\)&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;以二項分佈爲例&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈爲例&lt;/h4&gt;
&lt;p&gt;用本文開頭的例子： &lt;span class=&#34;math inline&#34;&gt;\(X\sim Bin(5,\theta)\)&lt;/span&gt;。和我們建立的零假設和替代假設：&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\frac{1}{2}; H_1: \theta=\frac{2}{3}\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;考慮兩種檢驗方法：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;A 方法：當且僅當5次觀察都爲“成功”時才拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0 (i.e.\; X=5)\)&lt;/span&gt;。所以此時判別區域 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 爲 &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;。檢驗效能爲：&lt;span class=&#34;math inline&#34;&gt;\(Prob(X=5|H_1 \;is\;true)=(\frac{2}{3})^5=0.1317\)&lt;/span&gt;。顯著性水平爲 &lt;span class=&#34;math inline&#34;&gt;\(Prob(X=5|H_0\;is\;true)=(\frac{1}{2})^5=0.03125\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;B 方法：當觀察到3,4,5次“成功”時，拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0 (i.e.\; X=3,4,5)\)&lt;/span&gt;。此時判別區域 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 爲 &lt;span class=&#34;math inline&#34;&gt;\(3,4,5\)&lt;/span&gt;。檢驗效能爲：&lt;span class=&#34;math inline&#34;&gt;\(Prob(X=3,4,or\:5|H_1\;is\;ture)=\sum_{i=3}^5(\frac{2}{3})^i(\frac{1}{3})^{5-i}\approx0.7901\)&lt;/span&gt;；顯著性水平爲：&lt;span class=&#34;math inline&#34;&gt;\(Prob(X=3,4,5|H_0\;is\;true)=\sum_{i=3}^5(\frac{1}{2})^i(\frac{1}{2})^{5-i}=0.5\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the power in test B
dbinom(3,5,2/3)+dbinom(4,5,2/3)+dbinom(5,5,2/3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7901235&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the size in test B
dbinom(3,5,0.5)+dbinom(4,5,0.5)+dbinom(5,5,0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;比較上面兩種檢驗方法，可以看到，用B方法時，我們有更高的概率獲得假陽性結果（第一類錯誤，錯誤地拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;，接受 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;)，但是也有更高的檢驗效能（真陽性更高）。這個例子就說明了，試圖提高檢驗效能的同時，會提高犯第一類錯誤的概率。實際操作中我們常常將第一類錯誤的概率固定，例如 &lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05\)&lt;/span&gt;，然後儘可能選擇效能最高的檢驗方法。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;如何選擇要檢驗的統計量&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;如何選擇要檢驗的統計量&lt;/h3&gt;
&lt;p&gt;在上面的二項分佈的實驗中，“成功的次數” 是我們感興趣的要檢驗的統計量。但也可能是第一次出現 “成功” 之前的實驗次數，或者，任何與假設相關的統計量。相似的，如果觀察不是離散變量而是連續的，可以拿來檢驗的指標就有很多，如均值，中位數，衆數，幾何平均值等。&lt;/p&gt;
&lt;p&gt;幸運地是，當明確了零假設和替代假設後，我們可以利用 &lt;a href=&#34;https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma&#34;&gt;Neyman-Pearson lemma&lt;/a&gt; 似然比公式&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;來決定使用哪個統計量做檢驗&lt;strong&gt;最有效&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[=\frac{L_{H_0}}{L_{H_1}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這公式很直觀，因爲當數據更加支持 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt; 時 (&lt;span class=&#34;math inline&#34;&gt;\(L_{H_1}\)&lt;/span&gt; 更大)，&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的可能性相對更小，就更應該被拒絕。而且，由於似然比越小，他的對數就越小，使用對數似然比常常更加直觀：&lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;那到底要多小才算小？這個進入拒絕域的閾值由兩個指標來決定：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;被檢驗統計量的樣本分佈&lt;/li&gt;
&lt;li&gt;第一類錯誤概率 &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;以已知方差的正態分佈爲例&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以已知方差的正態分佈爲例&lt;/h4&gt;
&lt;p&gt;假如已知 &lt;span class=&#34;math inline&#34;&gt;\(X_1, \cdots, X_n \stackrel{i.i.d}{\sim} N(\mu, \sigma^2)\)&lt;/span&gt; 而且方差 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 也是已知的。如果令 &lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu=5\; ;H_1: \mu=10\)&lt;/span&gt; 可以通過如下的方法找到我們需要的最佳檢驗統計量 &lt;u&gt;best statistic&lt;/u&gt; 根據之前的&lt;a href=&#34;https://winterwang.github.io/post/log-likelihood-ratio/&#34;&gt;推導&lt;/a&gt;可知正態分佈的似然方程如下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\ell(\mu|\underline{x}) =-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以已知 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 時，我們的零假設和替代假設之間的對數似然比 &lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\ell_{H_0}-\ell_{H_1}=-\frac{1}{2\sigma^2}(\sum_{i=1}^n(x_i-5)^2-\sum_{i=1}^n(x_i-10)^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然俄，我們只需要考慮隨着數據變化的部分，所以忽略掉不變的部分&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\ell_{H_0}-\ell_{H_1} &amp;amp; = -(\sum_{i=1}^n(x_i-5)^2-\sum_{i=i}^n(x_i-10)^2)\\
                &amp;amp; = 75n - 2\times(10-5)\sum_{i=1}^nx_i \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以只要樣本和 &lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^nx_i\)&lt;/span&gt; &lt;u&gt;(最佳統計量 best statistic)&lt;/u&gt; 足夠大，零假設就會被拒絕。而且注意到最佳統計量可以乘以任何常數用作新的最佳統計量。所以爲了方便我們就用樣本均數 &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{n}\sum_{i=1}^nx_i\)&lt;/span&gt; 作此處的最佳統計量。所以此時，我們的最佳檢驗就是當樣本均值足夠大，超過某個閾值時，我們拒絕零假設。而且，樣本均值的樣本分佈是可以知道的，這樣就便於我們繼續計算下一步：拒絕域 （判別區域）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;複合假設-composite-hypotheses&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;複合假設 composite hypotheses&lt;/h3&gt;
&lt;p&gt;目前爲止我們討論的假設檢驗限制太多，實際操作時，我們多考慮類似如下的假設：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\theta_0 \;v.s.\; H_1: \theta&amp;gt;\theta_0\)&lt;/span&gt; [&lt;strong&gt;單側&lt;/strong&gt;的替代假設]&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\theta_0 \;v.s.\; H_1: \theta\neq\theta_0\)&lt;/span&gt; [&lt;strong&gt;雙側&lt;/strong&gt;的替代假設]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以我們面臨的問題是簡單假設中用於判定的最佳統計量，是否還適用？我們一一來看：&lt;/p&gt;
&lt;div id=&#34;單側替代假設&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;單側替代假設&lt;/h4&gt;
&lt;p&gt;之前的推導中我們發現，樣本均值越大，零假設和替代假設的對數似然比 &lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt; 越小。所以我們在樣本均值較大時，拒絕零假設，那麼就可以把原來使用的簡單替代假設 &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu=10\)&lt;/span&gt; 擴展爲，任意大於 &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; ，即 &lt;span class=&#34;math inline&#34;&gt;\(\mu&amp;gt;5\)&lt;/span&gt; 。因爲大於 &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; 的任何均值，都提供了更小的對數似然比，都會讓我們拒絕零假設。所以在正態分佈時，單側替代假設的最佳檢驗統計量還是&lt;strong&gt;樣本均值&lt;/strong&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;雙側替代假設&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;雙側替代假設&lt;/h4&gt;
&lt;p&gt;雙側替代假設的情況下，我們無法繼續使用樣本均值作爲最佳統計量。因爲當我們想檢驗：&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu=5 \;v.s.\; H_1: \mu&amp;lt;5\)&lt;/span&gt; 時，必須獲得足夠小的樣本均值才能讓我們拒絕零假設。先按下不表。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;如何獲得反對零假設的證據-how-to-quantify-evidence-against-h_0&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;如何獲得反對零假設的證據 how to quantify evidence against &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;重新再考慮符合假設：&lt;span class=&#34;math inline&#34;&gt;\(H_0: \theta=\theta_0\;v.s.\;H_1: \theta&amp;gt;\theta_0\)&lt;/span&gt; 假如存在一個總是可用的最佳檢驗統計量，用 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 來標記 (或 &lt;span class=&#34;math inline&#34;&gt;\(T(x)\)&lt;/span&gt;)， 這個統計量足夠大時，我們拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;。 別忘了我們還要定義判別區域：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(\underline{x}\in\mathfrak{R}|H_0)=\alpha\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果我們知道 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 的樣本分佈，我們很容易就可以使用一個閾值 &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; 來定義這個判別區域：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(T\geqslant c|H_0)=\alpha\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;更加正式的，我們定義判別區域 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\{\underline{x}:Prob(T(x)\geqslant c|H_0)=\alpha\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;換句話說，當統計量 &lt;span class=&#34;math inline&#34;&gt;\(T&amp;gt;c\)&lt;/span&gt; 時，我們拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 。如果先不考慮拒絕或不拒絕的二元判定，我們可以用一個連續型測量值來量化反對零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的證據。再考慮從觀察數據中獲得的 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; ，即數據告訴我們的 &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; 。所以，當 &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; 值越大，說明觀察值相對零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 越往極端的方向走。因此我們可以用 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 的樣本分佈來計算觀察值大大於等於這個閾值（極端值）時的概率：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p=Prob(T\geqslant t|H_0)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這個概率公式被稱爲是單側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值 &lt;strong&gt;(one-side p-value)&lt;/strong&gt;。單側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值越小，統計量 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 的樣本空間就有越小比例（越強）的證據支持零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;我們把這以思想用到假設檢驗中時，就可以認爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p&amp;lt;\alpha \Leftrightarrow t&amp;gt;c\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以用我們一貫的設定 &lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05\)&lt;/span&gt;，所以如果計算獲得 &lt;span class=&#34;math inline&#34;&gt;\(p&amp;lt;0.05\)&lt;/span&gt; 我們就認爲獲得了足夠強的拒絕零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的證據。&lt;/p&gt;
&lt;div id=&#34;回到正態分佈的均值比較問題上來單側替代假設&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;回到正態分佈的均值比較問題上來（單側替代假設）&lt;/h4&gt;
&lt;p&gt;繼續考慮 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim} N(\mu, \sigma^2)\)&lt;/span&gt;，假設已知 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2=10\)&lt;/span&gt;，我們要檢驗的是 &lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu=5 \;v.s.\; H_1: \mu&amp;gt;5\)&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;確定最佳檢驗統計量：已經證明過，單側替代假設的最佳檢驗統計量是&lt;strong&gt;樣本均值&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;確定該統計量的樣本分佈：已知樣本均數的樣本分佈是 &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\sim N(\mu,\sigma^2/n)\)&lt;/span&gt; 。&lt;br&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)\)&lt;/span&gt;，所以在 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 條件下，&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow Z=\frac{\bar{X}-5}{\sqrt{10}/\sqrt{n}} \sim N(0,1)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;所以當一個檢驗的一類錯誤概率設定爲 &lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05\)&lt;/span&gt; 時，我們使用的判別區域使統計量據落在該判別區域內的概率爲 &lt;span class=&#34;math inline&#34;&gt;\(0.05\)&lt;/span&gt;：&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(Prob(\bar{X}\geqslant c|H_0) = 0.05\)&lt;/span&gt; &lt;br&gt; 已知在標準正態分佈時，&lt;span class=&#34;math inline&#34;&gt;\(Prob(Z\geqslant1.64)=0.05=Prob(\frac{\bar{X}-5}{\sqrt{10}/\sqrt{n}}\geqslant1.64)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;假設樣本量是 &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;，那麼數據的判別區域 &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{R}\)&lt;/span&gt; 就是 &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\geqslant6.64\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;假設觀察數據告訴我們，&lt;span class=&#34;math inline&#34;&gt;\(\bar{X}=7.76\)&lt;/span&gt; 。那麼這一組觀察數據計算得到的統計量落在了判別區域內，所以說是有足夠的證據拒絕接受 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的。&lt;/li&gt;
&lt;li&gt;我們可以給這個觀察數據計算相應的單側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值：&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(p=Prob(\bar{X}\geqslant7.76|H_0)=Prob(Z+5\geqslant7.76)\\=Prob(Z\geqslant2.76)=0.003\)&lt;/span&gt; &lt;br&gt; 所以，數據告訴我們，在 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的前提下，觀察值出現的概率是 &lt;span class=&#34;math inline&#34;&gt;\(0.3\%\)&lt;/span&gt; 。即，在無數次取樣實驗中，僅有 &lt;span class=&#34;math inline&#34;&gt;\(0.3\%\)&lt;/span&gt; 的結果可以給出支持 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 的證據。因此我們拒絕 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; 接受 &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;雙側替代假設情況下雙側-p-值的定量方法&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;雙側替代假設情況下，雙側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值的定量方法&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-08-construction-of-a-hypothesis-test_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;此處故意使用一個左右不對稱的概率密度分佈來解釋。&lt;/p&gt;
&lt;p&gt;現在的替代假設是雙側的：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0: \theta=\theta_0 \;v.s.\; H_1:  \theta\neq\theta_0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;正常來說，雙側的假設檢驗應該分成兩個單側檢驗。即：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1: \theta&amp;gt;\theta_0\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1: \theta&amp;lt;\theta_0\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;每個單側檢驗都有自己的最佳檢驗統計量。令 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 是 1. 的最佳檢驗統計量，該統計量的樣本分佈如上圖所示（左右不對稱）。假如觀察數據給出的統計量爲 &lt;span class=&#34;math inline&#34;&gt;\(t2\)&lt;/span&gt;，那麼在概率上反對零假設的情況可以有兩種：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(T\geqslant t2\)&lt;/span&gt; 其中， &lt;span class=&#34;math inline&#34;&gt;\(Prob(T\geqslant t2|H_0)=p1\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(T\leqslant t1\)&lt;/span&gt; 其中， &lt;span class=&#34;math inline&#34;&gt;\(Prob(T\leqslant t1|H_0) =p1\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以概率密度分佈兩側的距離可以不對稱，但是只要左右兩側概率密度分佈的面積(&lt;span class=&#34;math inline&#34;&gt;\(=p1\)&lt;/span&gt;)相同，那麼就可以直接認爲，雙側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值是兩側面積之和 (&lt;span class=&#34;math inline&#34;&gt;\(p=2\times p1\)&lt;/span&gt;)，且觀察數據提供的統計量落在這兩個面積內的話，都足以提供證據拒絕零假設 &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;回到上文中單側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值爲&lt;span class=&#34;math inline&#34;&gt;\(0.003\)&lt;/span&gt;，故雙側 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 值就是它的兩倍：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(p1=Prob(\bar{X}\geqslant7.76|H_0)=Prob(Z+5\geqslant7.76)\\=Prob(Z\geqslant2.76)=0.003\\ \Rightarrow p=2\times p1=0.006\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;區分與&lt;a href=&#34;https://winterwang.github.io/post/log-likelihood-ratio/&#34;&gt;之前討論的似然比&lt;/a&gt;，之前討論的似然比只是所有的似然和極大似然之間的比，此處的似然比只是純粹在探討兩個假設之間可能性之比。&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Rememer that &lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt; is a random variable: the data varies &lt;strong&gt;each time&lt;/strong&gt; we sample, with consequently varying relative support for the hypotheses, and so we are only interested in that part of &lt;span class=&#34;math inline&#34;&gt;\(\ell_{H_0}-\ell_{H_1}\)&lt;/span&gt; which depends on the results, the data, which vary with each sample (i.e. which contains the random part); the constant part provides no information on the relative support the data give to the hypotheses, so we ignore it.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>二次方程近似法求對數似然比 approximate log-likelihood ratios</title>
      <link>https://wangcc.me/post/approximate-log-likelihood-ratios/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/approximate-log-likelihood-ratios/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#正態近似法求對數似然-normal-approximation-to-the-log-likelihood&#34;&gt;正態近似法求對數似然 Normal approximation to the log-likelihood&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#參數轉化-parameter-transformations&#34;&gt;參數轉化 parameter transformations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exercise&#34;&gt;Exercise&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;爲什麼要用二次方程近似對數似然比方程？&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;上節也看到，我們會碰上難以用代數學計算獲得對數似然比信賴區間的情況 (&lt;a href=&#34;https://winterwang.github.io/post/log-likelihood-ratio/&#34;&gt;binomial example&lt;/a&gt;)。&lt;/li&gt;
&lt;li&gt;我們同時知道，對數似然比方程會隨着樣本量增加而越來越漸進於二次方程，且左右對稱。&lt;/li&gt;
&lt;li&gt;所以，我們考慮當樣本量足夠大時，用二次方程來近似對數似然比方程從而獲得參數估計的信賴區間。&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;正態近似法求對數似然-normal-approximation-to-the-log-likelihood&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;正態近似法求對數似然 Normal approximation to the log-likelihood&lt;/h3&gt;
&lt;p&gt;根據&lt;a href=&#34;https://winterwang.github.io/post/log-likelihood-ratio/&#34;&gt;前一節&lt;/a&gt;，如果樣本均數的分佈符合正態分佈：&lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\sim N(\mu, \sigma^2/n)\)&lt;/span&gt;。那麼樣本均數的對數似然比爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\mu|\bar{X})=\ell(\mu|\bar{X})=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中， &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; 是正態分佈總體均數 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 的極大似然估計 (maximum likelihood estimator, MLE)。如果已知總體的方差參數，那麼 &lt;span class=&#34;math inline&#34;&gt;\(\sigma/\sqrt{n}\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; 的標準誤 (standard error)。&lt;/p&gt;
&lt;p&gt;因此，假設 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 是我們想尋找的總體參數。有些人提議可以使用下面的關於 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的二次方程來做近似：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(\theta|data)=-\frac{1}{2}(\frac{\theta-M}{S})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;上述方程具有一個正態二次對數似然 (比) 的形式，而且該方程的極大似然估計(MLE)， &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 的標準誤爲 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;。如果我們正確地選用 &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;，那我們就可以用這樣的方程來近似求真實觀察數據的似然 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;通過近似正態對數似然比，&lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 應當選用使方程取最大值時，參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的極大似然估計 &lt;span class=&#34;math inline&#34;&gt;\(M=\hat{\Theta}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;但是在選用標準誤 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 上必須滿足下列條件：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 是極大似然估計 &lt;span class=&#34;math inline&#34;&gt;\(\hat{\Theta}\)&lt;/span&gt; 的標準誤。&lt;/li&gt;
&lt;li&gt;被選擇的 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 必須儘可能的使該二次方程形成一個十分接近真實的對數似然比方程。特別是在最大值的部分必須與之無限接近或者一致。所以二者在 MLE 的位置應當有相同的曲率（二階導數）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由於，一個方程的曲率是該方程的二階導數（斜線斜率變化的速度）。所以對數似然比方程在 MLE 取最大值時的曲率（二階導數）爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left.\frac{d^2}{d\theta^2}\ell(\theta)\right\vert_{\theta=\hat{\theta}}=\ell^{\prime\prime}(\hat{\theta})=-\frac{1}{S^2}\\
\Rightarrow S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;在正態分佈的例子下，&lt;span class=&#34;math inline&#34;&gt;\(M=\bar{x}, S=\sigma/\sqrt{n}\)&lt;/span&gt;。對數似然比方程最大值時的曲率（二階導數）恰好就爲標準誤的平方的負倒數：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\ell^{\prime\prime}(\theta)=-\frac{1}{SE^2}\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow\)&lt;/span&gt; 被叫做 &lt;strong&gt;Fisher information&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;稍微總結一下：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;任意的對數似然比方程 &lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)\)&lt;/span&gt; 都可以考慮用一個二次方程來近似：
&lt;span class=&#34;math display&#34;&gt;\[f(\theta|data)=-\frac{1}{2}(\frac{\theta-M}{S})^2\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;其中&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  &amp;amp;M=\hat\theta\\  &amp;amp;S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}\\  &amp;amp;when \\  &amp;amp; n\rightarrow\infty \Rightarrow  \begin{cases}  S^2\rightarrow Var(\hat\theta) \\  S\rightarrow SE(\hat\theta)  \end{cases}  \end{aligned}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;近似法估算對數似然比的信賴區間&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;近似法估算對數似然比的信賴區間&lt;/h4&gt;
&lt;p&gt;一旦我們決定了使用正態近似法來模擬對數似然比方程，對數似然比的信賴區間算法就回到了前一節中我們算過的方法，也就是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2f(\theta)&amp;lt;\mathcal{X}_{1,(1-\alpha)}^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;故信賴區間爲： &lt;span class=&#34;math inline&#34;&gt;\(m\pm\sqrt{\mathcal{X}_{1,(1-\alpha)}^2}S\)&lt;/span&gt;。求&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 水平的信賴區間時，&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{X}_{1,0.95}^2=3.84\)&lt;/span&gt;，所以就又看到了熟悉的 &lt;span class=&#34;math inline&#34;&gt;\(M\pm1.96S\)&lt;/span&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;以泊松分佈爲例&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以泊松分佈爲例&lt;/h4&gt;
&lt;p&gt;一個被追蹤的樣本，經過了 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 人年的觀察，記錄到了 &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; 個我們要研究的事件：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[D\sim Poi(\mu), where \mu=\lambda p\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 1. 找極大似然估計 (MLE)，&lt;a href=&#34;https://winterwang.github.io/post/likelihood/&#34;&gt;之前介紹似然方程時推導過的泊松分佈的似然方程&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
P(D=d|\lambda) &amp;amp;= \frac{e^{-\mu}\cdot\mu^d}{d!} \\
 &amp;amp;=\frac{e^{-\lambda p}\cdot\lambda^d p^d}{d!} \\
omitting&amp;amp;\;terms\;not\;in\;\mu \\
&amp;amp;\Rightarrow \ell(\lambda) = dlog\lambda - \lambda p \\
&amp;amp;\Rightarrow \ell^\prime(\lambda) = \frac{d}{\lambda} -p \\
&amp;amp;\Rightarrow \hat\lambda=\frac{d}{p} = \textbf{M}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 2. 求似然方程的二階導數，確認 MLE 是使方程獲得最大值的點，然後確定 &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
&amp;amp; \ell^\prime(\lambda) = \frac{d}{\lambda} -p \\
&amp;amp; \Rightarrow \ell^{\prime\prime}(\lambda) = -\frac{d}{\lambda^2}&amp;lt;0 \Rightarrow \textbf{MLE is maximum} \\
&amp;amp; S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\lambda)}\right\vert_{\lambda=\hat{\lambda}=d/p} = -\frac{1}{-d/\hat\lambda^2} = -\frac{1}{-d/(d/p)^2} \\
&amp;amp;\Rightarrow S^2 = \frac{d}{p^2} \\
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 3. 把前兩部求得的 &lt;span class=&#34;math inline&#34;&gt;\(MLE\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt; 代入近似的二次方程：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
&amp;amp; \hat\lambda=\frac{d}{p}=M,\; S^2 = \frac{d}{p^2}  \\
&amp;amp; using\;approximate\;quadratic\;llr \\
&amp;amp; q(\lambda) = -\frac{1}{2}(\frac{\lambda-M}{S})^2\\
&amp;amp;\Rightarrow q(\lambda) = -\frac{1}{2}(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2\\
&amp;amp; let \; q(\lambda)=-1.92\\
&amp;amp;\Rightarrow -\frac{1}{2}(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2=-1.92\\
&amp;amp;(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2=3.84\\
&amp;amp;\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}} = \pm1.96\\
&amp;amp;\Rightarrow 95\%CI \;for \;\lambda = \frac{d}{p}\pm1.96\frac{\sqrt{d}}{p}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;結論就是： 發病（死亡）率 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間爲： &lt;span class=&#34;math inline&#34;&gt;\(M\pm1.96S\)&lt;/span&gt;。所以我們不需要每次都代入對數似然比方程，只要算出 &lt;span class=&#34;math inline&#34;&gt;\(MLE = M\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 之後代入這個公式就可以用二次方程近似法算出信賴區間。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;以二項分佈爲例&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈爲例&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[K\sim Bin(n,\pi)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 1. 找極大似然估計 (MLE)：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
&amp;amp; Prob(K=k) = \pi^k(1-\pi)\binom{n}{k}\\
&amp;amp;\Rightarrow L(\pi|k) = \pi^k(1-\pi)\binom{n}{k}\\
&amp;amp;omitting\;terms\;not\;in\;\pi \\
&amp;amp;\Rightarrow \ell(\pi) = k\:log\pi+(n-k)log(1-\pi) \\
&amp;amp;\ell^\prime(\pi) = \frac{k}{\pi}-\frac{n-k}{1-\pi} \\
&amp;amp; let\;\ell^\prime(\hat\pi) =0 \\
&amp;amp;\Rightarrow \frac{k}{\hat\pi}-\frac{n-k}{1-\hat\pi}=0\\
&amp;amp;\Rightarrow \frac{\hat\pi}{1-\hat\pi}=\frac{k}{n-k}\\
&amp;amp;\Rightarrow \frac{\hat\pi}{1-\hat\pi}=\frac{k/n}{1-k/n}\\
&amp;amp;\Rightarrow \hat\pi=\frac{k}{n} = p = \textbf{M}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 2. 將對數似然方程的二次微分 (二階導數)，確認在 MLE 爲極大值，並確認 &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
&amp;amp;\ell^\prime(\pi) = \frac{k}{\pi}-\frac{n-k}{1-\pi} \\
&amp;amp;\ell^{\prime\prime}(\pi)=\frac{-k}{\pi^2}-\frac{n-k}{(1-\pi)^2} &amp;lt;0 \\
&amp;amp;\therefore at\;\textbf{MLE}\;\ell(\pi)\;has\;maximum \\
S^2&amp;amp;=\left.-\frac{1}{\ell^{\prime\prime}(\pi)}\right\vert_{\pi=\hat\pi=k/n=p}\\
&amp;amp;=\frac{1}{\frac{k}{\hat\pi^2}+\frac{n-k}{(1-\hat\pi)^2}}\\
&amp;amp;=\frac{\hat\pi^2(1-\hat\pi)^2}{k(1-\hat\pi)^2+(n-k)\hat\pi^2}\\
&amp;amp;=\frac{P^2(1-P)^2}{np(1-p)^2+(n-np)p^2}\\
&amp;amp;=\frac{p(1-p)}{n(1-p)+np}\\
&amp;amp;=\frac{p(1-p)}{n}\\
&amp;amp;\Rightarrow S=\sqrt{\frac{p(1-p)}{n}}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 3. 將求得的 MLE 和 &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt; 代入近似信賴區間：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
95\% CI \;for \; \pi:\\
M\pm1.96S=p\pm1.96\sqrt{\frac{p(1-p)}{n}}\\
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;參數轉化-parameter-transformations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;參數轉化 parameter transformations&lt;/h3&gt;
&lt;p&gt;如果將參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 通過某種數學方程轉化成 &lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;，那麼我們可以認爲，轉化後的方程的 MLE 爲 &lt;span class=&#34;math inline&#34;&gt;\(g(\hat\theta)\)&lt;/span&gt;，其中 &lt;span class=&#34;math inline&#34;&gt;\(\hat\theta\)&lt;/span&gt; 是參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的 MLE。&lt;/p&gt;
&lt;p&gt;類似地，如果 &lt;span class=&#34;math inline&#34;&gt;\(\theta_1 \sim \theta_2\)&lt;/span&gt; 是參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的似然比信賴區間，那麼 &lt;span class=&#34;math inline&#34;&gt;\(g(\theta_1)\sim g(\theta_2)\)&lt;/span&gt; 就是 &lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt; 的似然比信賴區間。&lt;/p&gt;
&lt;p&gt;以下爲轉換參數以後獲取信賴區間的步驟：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;將參數通過某些數學方程（通常是取對數）轉化，使新的對數似然比方程更加接近二次方程的對稱圖形。&lt;br&gt; Transform parameter so that &lt;span class=&#34;math inline&#34;&gt;\(llr\)&lt;/span&gt; is closer to a quadratic shape.&lt;/li&gt;
&lt;li&gt;用本節學到的二次方程近似法，求得轉化後的參數的似然比信賴區間。 &lt;br&gt; Use our quadratic approximation on the transformed parameter to calculate our likelihood ratio confidence intervals.&lt;/li&gt;
&lt;li&gt;將第2步計算獲得的似然比信賴區間再通過轉化參數時的逆函數轉換回去，以獲得原參數的似然比信賴區間。&lt;br&gt; Transform the confidence intervals back, or to any scale we wish – they remain valid.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;以泊松分佈爲例-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以泊松分佈爲例&lt;/h4&gt;
&lt;p&gt;當我們用泊松分佈模擬事件在某段時間內發生率 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 時，注意到這個事件發生率必須滿足 &lt;span class=&#34;math inline&#34;&gt;\(\lambda&amp;gt;0\)&lt;/span&gt;。當事件發生次數較低時，會讓似然方程的圖形被擠壓在低值附近。如果嘗試用對數轉換 &lt;span class=&#34;math inline&#34;&gt;\(\lambda \rightarrow log(\lambda)\)&lt;/span&gt; 此時 &lt;span class=&#34;math inline&#34;&gt;\(log(\lambda)\)&lt;/span&gt; 就不再被限制與 &lt;span class=&#34;math inline&#34;&gt;\(&amp;gt;0\)&lt;/span&gt;。下面我們嘗試尋找對數轉換過後的 &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(\beta=log(\lambda), \Rightarrow e^\beta=\lambda\)&lt;/span&gt; 從本文上半部分中我們已知 &lt;span class=&#34;math inline&#34;&gt;\(\hat\lambda=\frac{d}{p}\)&lt;/span&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對數轉換以後的 &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 是什麼? &lt;br&gt;根據定義，&lt;span class=&#34;math inline&#34;&gt;\(MLE(\beta)=MLE[log(\lambda)]=log(\hat\lambda)\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow M=\hat\beta=log(\frac{d}{p})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;對數轉換以後的 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 是什麼? &lt;br&gt; 泊松分佈的對數似然方程是：&lt;span class=&#34;math inline&#34;&gt;\(\ell(\lambda|d)=d log(\lambda) - \lambda p\)&lt;/span&gt; 用 &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; 替換掉 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;&lt;/p&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  &amp;amp; \ell(\beta|d)=d \beta - pe^\beta\\  &amp;amp; \Rightarrow \ell^\prime(\beta)=d-pe^\beta \Rightarrow \ell^{\prime\prime}(\beta)=-pe^\beta \\  &amp;amp; S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\beta)}\right\vert_{\beta=\hat{\beta}} = \left.\frac{1}{pe^\beta}\right\vert_{\beta=\hat{\beta}} = \frac{1}{pe^{log(d/p)}}\\  &amp;amp;\Rightarrow S^2=\frac{1}{d} \therefore S=\frac{1}{\sqrt{d}} \end{aligned}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;轉換後的近似二次方程：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  &amp;amp; q(\beta) = -\frac{1}{2}(\frac{\beta-M}{S})^2 = -\frac{1}{2}(\frac{\beta-log(\frac{d}{p})}{\frac{1}{\sqrt{d}}})^2  \end{aligned}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間 &lt;span class=&#34;math inline&#34;&gt;\(=log(\frac{d}{p})\pm1.96\frac{1}{\sqrt{d}}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間 &lt;span class=&#34;math inline&#34;&gt;\(=exp(log(\frac{d}{p})\pm1.96\frac{1}{\sqrt{d}})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;以二項分佈爲例-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈爲例&lt;/h4&gt;
&lt;p&gt;在研究對象 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 人中觀察到 &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; 個人患有某種疾病。&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(\beta=log(\pi) \Rightarrow \pi=e^\beta\)&lt;/span&gt; 從上文的推倒也已知 &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=\frac{k}{n}=p\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned} &amp;amp;\Rightarrow \ell(\beta)=klog\pi+(n-k)log(1-\pi)=k\beta+(n-k)log(1-e^\beta) \\ &amp;amp;\Rightarrow \ell^{\prime}(\beta)=k-\frac{(n-k)(e^\beta)}{1-e^\beta} \\ &amp;amp;\Rightarrow \ell^{\prime\prime}(\beta)=-(n-k)\frac{e^\beta(1-e^\beta)+e^{2\beta}}{(1-e^\beta)^2} \\ &amp;amp; \ell^{\prime\prime}(\beta)= -(n-k)\frac{e^\beta}{(1-e^\beta)^2}\\ &amp;amp;\Rightarrow S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\beta)}\right\vert_{\beta=\hat{\beta}} = \frac{(1-e^{\hat\beta})^2}{(n-k)e^{\hat\beta}} \\ &amp;amp;\because \hat\beta=log(\hat\pi) \\ &amp;amp;\therefore e^{\hat\beta} = \frac{k}{n}\\ &amp;amp;\Rightarrow S^2=\frac{(1-\frac{k}{n})^2}{(n-k)\frac{k}{n}}=\frac{n-k}{nk}=\frac{1}{k}-\frac{1}{n}\\ &amp;amp; \Rightarrow S=\sqrt{\frac{1}{k}-\frac{1}{n}}\\ \end{aligned}\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exercise&lt;/h3&gt;
&lt;div id=&#34;q1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q1&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;在&lt;span class=&#34;math inline&#34;&gt;\(n=100\)&lt;/span&gt;人中觀察到有&lt;span class=&#34;math inline&#34;&gt;\(k=40\)&lt;/span&gt;人患病，假設每個人只有患病，不患病兩個狀態，用二項分佈來模擬這個數據，&lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 爲患病的概率。下面是 &lt;span class=&#34;math inline&#34;&gt;\(\pi \in [0.2,0.6]\)&lt;/span&gt; 區間的對數似然比方程曲線。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pi &amp;lt;- seq(0.2, 0.6, by=0.01)
L &amp;lt;- (pi^40)*((1-pi)^60)
Lmax &amp;lt;- rep(max(L), 41)
LR &amp;lt;- L/Lmax
logLR &amp;lt;- log(LR)

plot(pi, logLR, type = &amp;quot;l&amp;quot;, ylim = c(-11, 0),yaxt=&amp;quot;n&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;logLR(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
grid(NA, 5, lwd = 2) # add some horizontal grid on the background
axis(2, at=seq(-12,0,2), las=2)
title(main = &amp;quot;Figure 1. Binomial log-likelihood ratio&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;用一個二次方程來模擬上面的對數似然比曲線：&lt;span class=&#34;math inline&#34;&gt;\(f(\pi)=-\frac{(\pi-M)^2}{2S^2}\)&lt;/span&gt;，其中 &lt;span class=&#34;math inline&#34;&gt;\(M=\hat\pi=\frac{k}{n}=0.4\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(S^2=\frac{p(1-p)}{n}=0.0024\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mai = c(1.2, 0.5, 1, 0.7))
quad &amp;lt;- -(pi-0.4)^2/(2*0.0024)
plot(pi, quad, type = &amp;quot;l&amp;quot;, ylim = c(-4, 0),yaxt=&amp;quot;n&amp;quot;, col=&amp;quot;red&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
lines(pi, logLR, col=&amp;quot;black&amp;quot;)
grid(NA, 4, lwd = 1) # add some horizontal grid on the background
axis(2, at=seq(-4,0,1), las=2)
title(main = &amp;quot;Figure 2. Quadratic approximation\n of binomial log-likelihood ratio \n 40 out of 100 subjects&amp;quot;)
abline(h=-1.92, lty=1, col=&amp;quot;red&amp;quot;)
axis(4, at=-1.92, las=2)

legend(x=0.27, y= -5.5 ,xpd = TRUE,  legend=c(&amp;quot;logLR&amp;quot;,&amp;quot;Quadratic&amp;quot;), bty = &amp;quot;n&amp;quot;,
       col=c(&amp;quot;black&amp;quot;,&amp;quot;red&amp;quot;), lty=c(1,1), horiz = TRUE) #the legend is below the graph&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q2&lt;/h4&gt;
&lt;p&gt;依舊使用二項分佈數據來模擬，觀察不同的事件數量和樣本量對近似計算的影響。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;類比上面的問題，用同樣的 &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.4\)&lt;/span&gt;，但是 &lt;span class=&#34;math inline&#34;&gt;\(n=10, k=4\)&lt;/span&gt; 時的圖形：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.4, n=1000, k=400\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.01, n=100, k=1\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意此圖中紅線提示的近似二次曲線，信賴區間的下限已經低於0，是無法接受的近似。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.01, n=1000, k=10\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.01, n=10000, k=100\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.99, n=100, k=99\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意此圖中紅線提示的近似二次曲線，信賴區間的上限已經大於1，和上面的 Figure 5. 一樣也是無法接受的近似。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;總結： 二次方程近似時，在二項分佈的情況下，隨着 &lt;span class=&#34;math inline&#34;&gt;\(n, k\)&lt;/span&gt; 增加，近似越理想。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>對數似然比 Log-likelihood ratio</title>
      <link>https://wangcc.me/post/log-likelihood-ratio/</link>
      <pubDate>Sun, 05 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/log-likelihood-ratio/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;對數似然比-log-likelihood-ratio&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;對數似然比 Log-likelihood ratio&lt;/h3&gt;
&lt;p&gt;對數似然比的想法來自於將對數似然方程圖形的 &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 軸重新調節 (rescale) 使之最大值爲零。這可以通過計算該分佈方程的&lt;strong&gt;對數似然比 (log-likelihood ratio)&lt;/strong&gt; 來獲得：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\theta)=\ell(\theta|data)-\ell(\hat{\theta}|data)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由於 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta)\)&lt;/span&gt; 的最大值在 &lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}\)&lt;/span&gt; 時， 所以，&lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)\)&lt;/span&gt; 就是個當 &lt;span class=&#34;math inline&#34;&gt;\(\theta=\hat{\theta}\)&lt;/span&gt; 時取最大值，且最大值爲零的方程。很容易理解我們叫這個方程爲對數似然比，因爲這個方程就是將似然比 &lt;span class=&#34;math inline&#34;&gt;\(LR(\theta)=\frac{L(\theta)}{L(\hat{\theta})}\)&lt;/span&gt; 取對數而已。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/post/likelihood/&#34;&gt;之前&lt;/a&gt;我們也確證了，不包含我們感興趣的參數的方程部分可以忽略掉。還是用上一節 10人中4人患病的例子：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\pi|X=4)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\\
\Rightarrow \ell(\pi)=log[\pi^4(1-\pi)^{10-4}]\\
\Rightarrow llr(\pi)=\ell(\pi)-\ell(\hat{\pi})=log\frac{\pi^4(1-\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其實由上也可以看出 &lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)\)&lt;/span&gt; 只是將對應的似然方程的 &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 軸重新調節了一下而已。形狀是沒有改變的：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow=c(1,2))
x &amp;lt;- seq(0,1,by=0.001)
y &amp;lt;- (x^4)*((1-x)^6)/(0.4^4*0.6^6)
z &amp;lt;- log((x^4)*((1-x)^6))-log(0.4^4*0.6^6)
plot(x, y, type = &amp;quot;l&amp;quot;, ylim = c(0,1.1),yaxt=&amp;quot;n&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;LR(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
axis(2, at=seq(0,1, 0.2), las=2)
title(main = &amp;quot;Binomial likelihood ratio&amp;quot;)
abline(h=1.0, lty=2)
segments(x0=0.4, y0=0, x1=0.4, y1=1, lty = 2)
plot(x, z, type = &amp;quot;l&amp;quot;, ylim = c(-10, 1), yaxt=&amp;quot;n&amp;quot;, frame.plot = FALSE,
     ylab = &amp;quot;llr(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot; )
axis(2, at=seq(-10, 0, 2), las=2)
title(main = &amp;quot;Binomial log-likelihood ratio&amp;quot;)
abline(h=0, lty=2)
segments(x0=0.4, y0=-10, x1=0.4, y1=0, lty = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;正態分佈數據的最大似然和對數似然比&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;正態分佈數據的最大似然和對數似然比&lt;/h4&gt;
&lt;p&gt;假設單個樣本 &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 是來自一組服從正態分佈數據的觀察值：&lt;span class=&#34;math inline&#34;&gt;\(Y\sim N(\mu, \tau^2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那麼有：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
f(y|\mu) &amp;amp;= \frac{1}{\sqrt{2\pi\tau^2}}e^{(-\frac{1}{2}(\frac{y-\mu}{\tau})^2)} \\
\Rightarrow L(\mu|y) &amp;amp;=\frac{1}{\sqrt{2\pi\tau^2}}e^{(-\frac{1}{2}(\frac{y-\mu}{\tau})^2)} \\
\Rightarrow \ell(\mu)&amp;amp;=log(\frac{1}{\sqrt{2\pi\tau^2}})-\frac{1}{2}(\frac{y-\mu}{\tau})^2\\
omitting&amp;amp;\;terms\;not\;in\;\mu \\
&amp;amp;= -\frac{1}{2}(\frac{y-\mu}{\tau})^2 \\
\Rightarrow \ell^\prime(\mu) &amp;amp;= 2\cdot[-\frac{1}{2}(\frac{y-\mu}{\tau})\cdot\frac{-1}{\tau}] \\
&amp;amp;=\frac{y-\mu}{\tau^2} \\
let \; \ell^\prime(\mu) &amp;amp;= 0 \\
\Rightarrow \frac{y-\mu}{\tau^2} &amp;amp;= 0 \Rightarrow \hat{\mu} = y\\
\because \ell^{\prime\prime}(\mu) &amp;amp;=  \frac{-1}{\tau^2} &amp;lt; 0 \\
\therefore \hat{\mu} &amp;amp;= y \Rightarrow \ell(\hat{\mu}=y)_{max}=0 \\
llr(\mu)&amp;amp;=\ell(\mu)-\ell(\hat{\mu})=\ell(\mu)\\
&amp;amp;=-\frac{1}{2}(\frac{y-\mu}{\tau})^2
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;n-個獨立正態分佈樣本的對數似然比&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立正態分佈樣本的對數似然比&lt;/h3&gt;
&lt;p&gt;假設一組觀察值來自正態分佈 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu,\sigma^2)\)&lt;/span&gt;，先假設 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 已知。將觀察數據 &lt;span class=&#34;math inline&#34;&gt;\(x_1,\cdots, x_n\)&lt;/span&gt; 標記爲 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt;。 那麼：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
L(\mu|\underline{x}) &amp;amp;=\prod_{i=1}^nf(x_i|\mu)\\
\Rightarrow \ell(\mu|\underline{x}) &amp;amp;=\sum_{i=1}^nlogf(x_i|\mu)\\
&amp;amp;=\sum_{i=1}^n[-\frac{1}{2}(\frac{x_i-\mu}{\sigma})^2]\\
&amp;amp;=-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\\
&amp;amp;=-\frac{1}{2\sigma^2}[\sum_{i=1}^n(x_i-\bar{x})^2+\sum_{i=1}^n(\bar{x}-\mu)^2]\\
omitting&amp;amp;\;terms\;not\;in\;\mu \\
&amp;amp;=-\frac{1}{2\sigma^2}\sum_{i=1}^n(\bar{x}-\mu)^2\\
&amp;amp;=-\frac{n}{2\sigma^2}(\bar{x}-\mu)^2 \\
&amp;amp;=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\\
\because \ell(\hat{\mu}) &amp;amp;= 0 \\
\therefore llr(\mu) &amp;amp;= \ell(\mu)-\ell(\hat{\mu}) = \ell(\mu)
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;n-個獨立正態分佈樣本的對數似然比的分佈&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立正態分佈樣本的對數似然比的分佈&lt;/h3&gt;
&lt;p&gt;假設我們用 &lt;span class=&#34;math inline&#34;&gt;\(\mu_0\)&lt;/span&gt; 表示總體均數這一參數的值。要注意的是，每當樣本被重新取樣，似然，對數似然方程，對數似然比都隨着觀察值而變 (即有自己的分佈)。&lt;/p&gt;
&lt;p&gt;考慮一個服從正態分佈的單樣本 &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(Y\sim N(\mu_0,\tau^2)\)&lt;/span&gt;。那麼它的對數似然比：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\mu_0|Y)=\ell(\mu_0)-\ell(\hat{\mu})=-\frac{1}{2}(\frac{Y-\mu_0}{\tau})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;根據&lt;a href=&#34;https://winterwang.github.io/post/chi-square-distribution/&#34;&gt;卡方分佈&lt;/a&gt;的定義：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\because \frac{Y-\mu_0}{\tau}\sim N(0,1)\\
\Rightarrow (\frac{Y-\mu_0}{\tau})^2 \sim \mathcal{X}_1^2\\
\therefore -2llr(\mu_0|Y) \sim \mathcal{X}_1^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，如果有一組服從正態分佈的觀察值：&lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu_0,\sigma^2)\)&lt;/span&gt;，且 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 已知的話：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2llr(\mu_0|\bar{X})\sim \mathcal{X}_1^2\]&lt;/span&gt;&lt;/p&gt;
根據&lt;a href=&#34;https://winterwang.github.io/post/central-limit-theory/&#34;&gt;中心極限定理&lt;/a&gt;，可以將上面的結論一般化：

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-2&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 1  &lt;/strong&gt;&lt;/span&gt;如果 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}f(x|\theta)\)&lt;/span&gt;。 那麼當重複多次從參數爲 &lt;span class=&#34;math inline&#34;&gt;\(\theta_0\)&lt;/span&gt; 的總體中取樣時，那麼統計量 &lt;span class=&#34;math inline&#34;&gt;\(-2llr(\theta_0)\)&lt;/span&gt; 會漸進於自由度爲 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; 的卡方分佈： &lt;span class=&#34;math display&#34;&gt;\[-2llr(\theta_0)=-2\{\ell(\theta_0)-\ell(\hat{\theta})\}\xrightarrow[n\rightarrow\infty]{}\;\sim \mathcal{X}_1^2\]&lt;/span&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div id=&#34;似然比信賴區間&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;似然比信賴區間&lt;/h3&gt;
&lt;p&gt;如果樣本量 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 足夠大 (通常應該大於 &lt;span class=&#34;math inline&#34;&gt;\(30\)&lt;/span&gt;)，根據上面的定理：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2llr(\theta_0)=-2\{\ell(\theta_0)-\ell(\hat{\theta})\}\sim \mathcal{X}_1^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(-2llr(\theta_0)\leqslant \mathcal{X}_{1,0.95}^2=3.84) = 0.95\\
\Rightarrow Prob(llr(\theta_0)\geqslant-3.84/2=-1.92) = 0.95\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;故似然比的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間就是能夠滿足 &lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)=-1.92\)&lt;/span&gt; 的兩個 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 值。&lt;/p&gt;
&lt;div id=&#34;以二項分佈數據爲例&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈數據爲例&lt;/h4&gt;
&lt;p&gt;繼續用本文開頭的例子：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\pi)=\ell(\pi)-\ell(\hat{\pi})=log\frac{\pi^4(1-\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果令 &lt;span class=&#34;math inline&#34;&gt;\(llr(\pi)=-1.92\)&lt;/span&gt; 在代數上可能較難獲得答案。然而從圖形上，如果我們在 &lt;span class=&#34;math inline&#34;&gt;\(y=-1.92\)&lt;/span&gt; 畫一條橫線，和該似然比方程曲線相交的兩個點就是我們想要求的信賴區間的上限和下限：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(0,1,by=0.001)
z &amp;lt;- log((x^4)*((1-x)^6))-log(0.4^4*0.6^6)
plot(x, z, type = &amp;quot;l&amp;quot;, ylim = c(-10, 1), yaxt=&amp;quot;n&amp;quot;, frame.plot = FALSE,
     ylab = &amp;quot;llr(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot; )
axis(2, at=seq(-10, 0, 2), las=2)
abline(h=0, lty=2)
abline(h=-1.92, lty=2)
segments(x0=0.15, y0=-12, x1=0.15, y1=-1.92, lty = 2)
segments(x0=0.7, y0=-12, x1=0.7, y1=-1.92, lty = 2)
axis(1, at=c(0.15,0.7))
text(0.9, -1, &amp;quot;-1.92&amp;quot;)
arrows(0.8, -1.92, 0.8, 0, lty = 1, length = 0.08)
arrows( 0.8, 0, 0.8, -1.92, lty = 1, length = 0.08)
title(main = &amp;quot;Log-likelihood ratio for binomial example, \n with 95% likelihood confidence interval shown&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;從上圖中可以讀出，&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 對數似然比信賴區間就是 &lt;span class=&#34;math inline&#34;&gt;\((0.15, 0.7)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;以正態分佈數據爲例&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以正態分佈數據爲例&lt;/h4&gt;
&lt;p&gt;本文前半部分證明過，
&lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu,\sigma^2)\)&lt;/span&gt;，先假設 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 已知。將觀察數據 &lt;span class=&#34;math inline&#34;&gt;\(x_1,\cdots, x_n\)&lt;/span&gt; 標記爲 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt;。 那麼：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\mu|\underline{x}) = \ell(\mu|\underline{x})-\ell(\hat{\mu}) = \ell(\mu|\underline{x}) \\
=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;很顯然，這是一個關於 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 的二次方程，且最大值在 MLE &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mu}=\bar{x}\)&lt;/span&gt; 時取值 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;。所以可以通過對數似然比法求出均值的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間公式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2\times[-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2]=3.84\\
\Rightarrow L=\bar{x}-\sqrt{3.84}\frac{\sigma}{\sqrt{n}} \\
U=\bar{x}+\sqrt{3.84}\frac{\sigma}{\sqrt{n}} \\
note: \;\sqrt{3.84}=1.96\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注意到這和我們&lt;a href=&#34;https://winterwang.github.io/post/frequentist-statistical-inference02/&#34;&gt;之前&lt;/a&gt;求的正態分佈均值的信賴區間公式完全一致。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exercise&lt;/h3&gt;
&lt;div id=&#34;q1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q1&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;假設十個對象中有三人死亡，用二項分佈模型來模擬這個例子，求這個例子中參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 的似然方程和圖形 (likelihood) ?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;解&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  L(\pi|3) &amp;amp;= \binom{10}{3}\pi^3(1-\pi)^{10-3} \\  omitting\;&amp;amp;terms\;not\;in\;\mu \\  \Rightarrow \ell(\pi|3) &amp;amp;= log[\pi^3(1-\pi)^7] \\  &amp;amp;= 3log\pi+7log(1-\pi)\\  \Rightarrow \ell^\prime(\pi|3)&amp;amp;= \frac{3}{\pi}-\frac{7}{1-\pi} \\  let \; \ell^\prime&amp;amp; =0\\  &amp;amp;\frac{3}{\pi}-\frac{7}{1-\pi} = 0 \\  &amp;amp;\frac{3-10\pi}{\pi(1-\pi)} = 0 \\  \Rightarrow MLE &amp;amp;= \hat\pi = 0.3 \end{aligned}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;計算似然比，並作圖，注意方程圖形未變，&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 軸的變化；取對數似然比，並作圖&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;LR &amp;lt;- L/max(L) ; head(LR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0000000000 0.0004191759 0.0031233631 0.0098110584 0.0216286076
## [6] 0.0392577320&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(pi, LR, type = &amp;quot;l&amp;quot;, ylim = c(0, 1),yaxt=&amp;quot;n&amp;quot;, col=&amp;quot;darkblue&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
grid(NA, 5, lwd = 1)
axis(2, at=seq(0,1,0.2), las=2)
title(main = &amp;quot;Binomial likelihood ratio function\n 3 out of 10 subjects&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;logLR &amp;lt;- log(L/max(L))
plot(pi, logLR, type = &amp;quot;l&amp;quot;, ylim = c(-4, 0),yaxt=&amp;quot;n&amp;quot;, col=&amp;quot;darkblue&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
grid(NA, 5, lwd = 1)
axis(2, at=seq(-4,0,1), las=2)
title(main = &amp;quot;Binomial log-likelihood ratio function\n 3 out of 10 subjects&amp;quot;)
abline(h=-1.92, lty=1, col=&amp;quot;red&amp;quot;)
axis(4, at=-1.92, las=0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q2&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;與上面用同樣的模型，但是觀察人數變爲 &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; 人 患病人數爲 &lt;span class=&#34;math inline&#34;&gt;\(30\)&lt;/span&gt; 人，試作對數似然比方程之圖形，與上圖對比：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;可以看出，兩組數據的 MLE 都是一致的， &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.3\)&lt;/span&gt;，但是對數似然比方程圖形在 樣本量爲 &lt;span class=&#34;math inline&#34;&gt;\(n=100\)&lt;/span&gt; 時比 &lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt; 時窄很多，由此產生的似然比信賴區間也就窄很多（精確很多）。所以對數似然比方程的曲率（二階導數），反映了觀察獲得數據提供的對總體參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 推斷過程中的信息量。而且當樣本量較大時，對數似然比方程也更加接近左右對稱的二次方程曲線。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q3&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q3&lt;/h4&gt;
&lt;p&gt;在一個實施了160人年的追蹤調查中，觀察到8個死亡案例。使用泊松分佈模型，繪製對數似然比方程圖形，從圖形上目視推測極大似然比的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;解-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  d = 8, \;p &amp;amp;= 160\; person\cdot year \\  \Rightarrow D\sim Poi(\mu &amp;amp;=\lambda p) \\  L(\lambda|data) &amp;amp;= Prob(D=d=8) \\  &amp;amp;= e^{-\mu}\frac{\mu^d}{d!} \\  &amp;amp;= e^{-\lambda p}\frac{\lambda^d p^d}{d!} \\  omitting&amp;amp;\;terms\;not\;in\;\lambda \\  &amp;amp;= e^{-\lambda p}\lambda^d \\ \Rightarrow \ell(\lambda|data)&amp;amp;= log(e^{-\lambda p}\lambda^d) \\  &amp;amp;= d\cdot log(\lambda)-\lambda p \\  &amp;amp; = 8\times log(\lambda) - 160\times\lambda \end{aligned}\)&lt;/span&gt;&lt;/p&gt;
&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;480&#34; /&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
lambda
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
LogLR
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.010
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-6.4755033
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.011
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-5.8730219
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.012
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-5.3369308
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.013
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.8565892
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.014
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.4237254
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.015
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.0317824
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.016
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.6754743
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.017
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.3504773
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.018
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.0532100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.019
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.7806722
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.020
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.5303259
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.021
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.3000045
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
0.022
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
-2.0878444
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
0.023
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
-1.8922303
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.024
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.7117534
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.025
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.5451774
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.026
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.3914117
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.027
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.2494891
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.028
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.1185480
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.029
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.9978174
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.030
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.8866050
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.031
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.7842864
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6902968
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.033
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6041236
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.034
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5252998
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.035
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.4533996
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.036
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3880325
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.037
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3288407
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.038
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2754948
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.039
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2276909
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.040
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1851484
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.041
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1476075
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.042
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1148271
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.043
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0865831
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.044
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0626670
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.045
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0428841
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.046
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0270529
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.047
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0150032
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.048
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0065760
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0016217
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.050
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.051
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0015790
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.052
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0062343
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.053
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0138487
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.054
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0243117
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.055
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0375186
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.056
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0533705
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.057
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0717739
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.058
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0926400
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.059
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1158845
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.060
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1414275
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.061
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1691931
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.062
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1991090
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.063
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2311062
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.064
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2651194
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.065
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3010859
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.066
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3389461
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.067
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3786431
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.068
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.4201224
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.069
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.4633320
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.070
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5082221
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.071
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5547450
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.072
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6028551
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.073
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6525085
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.074
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.7036633
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.075
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.7562791
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.076
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.8103173
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.077
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.8657407
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.078
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.9225134
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.079
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.9806012
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.080
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.0399710
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.081
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.1005908
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.082
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.1624301
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.083
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.2254592
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.084
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.2896497
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.085
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.3549740
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.086
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.4214057
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.087
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.4889191
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.088
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.5574895
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.089
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.6270931
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.090
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.6977067
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.091
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.7693080
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.092
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.8418754
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
0.093
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
-1.9153881
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
0.094
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
-1.9898258
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.095
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.0651689
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.096
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.1413985
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.097
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.2184962
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.098
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.2964442
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.099
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.3752252
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.100
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.4548226
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;所以從列表數據結合圖形， 可以找到信賴區間的下限在 0.022~0.023 之間， 上限在 0.093～0.094 之間。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>似然非然 Likelihood</title>
      <link>https://wangcc.me/post/likelihood/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/likelihood/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#概率-vs.推斷probability-vs.inference&#34;&gt;概率 vs. 推斷/Probability vs. Inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#似然和極大似然估計&#34;&gt;似然和極大似然估計&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#似然方程的一般化定義&#34;&gt;似然方程的一般化定義&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#對數似然方程-log-likelihood&#34;&gt;對數似然方程 log-likelihood&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#極大似然估計-maximum-likelihood-estimator-mle-的性質&#34;&gt;極大似然估計 (maximum likelihood estimator, MLE) 的性質：&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#率的似然估計-likelihood-for-a-rate&#34;&gt;率的似然估計 Likelihood for a rate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#有-n-個獨立觀察時的似然方程和對數似然方程&#34;&gt;有 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立觀察時的似然方程和對數似然方程&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;概率-vs.推斷probability-vs.inference&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;概率 vs. 推斷/Probability vs. Inference&lt;/h3&gt;
&lt;p&gt;在概率論的環境下，我們常常被告知的前提是：某某事件發生的概率是多少。例如： 一枚硬幣正面朝上的概率是 &lt;span class=&#34;math inline&#34;&gt;\(0.5\; Prob(coin\;landing\;heads)=0.5\)&lt;/span&gt;。然後在這個前提下，我們又繼續去計算複雜的事件發生的概率（例如，10次投擲硬幣以後4次正面朝上的概率是多少？）。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\binom{10}{4}\times(0.5^4)\times(0.5^{10-4}) = 0.205
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dbinom(4, 10, 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2050781&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# or you can calculate by hand:
factorial(10)*(0.5^10)/(factorial(4)*(factorial(6)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2050781&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在統計推斷的理論中，我們考慮實際的情況，這樣的實際情況就是，我們通過觀察獲得數據，然而我們並不知道某事件發生的概率到底是多少（神如果存在話，只有神知道）。故這個 &lt;span class=&#34;math inline&#34;&gt;\(Prob(coin\;landing\;heads)\)&lt;/span&gt; 的概率大小對於“人類”來說是未知的。我們可能觀察到投擲了10次硬幣，其中有4次是正面朝上的。那麼我們從這一次觀察實驗中，需要計算的是能夠符合觀察結果的“最佳”概率估計 (best estimate)。在這種情況下，&lt;strong&gt;似然法 (likelihood)&lt;/strong&gt; 就是我們進行參數估計的最佳手段。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;似然和極大似然估計&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;似然和極大似然估計&lt;/h3&gt;
&lt;p&gt;此處用二項分佈的例子來理解似然法的概念：假設我們觀察到10個對象中有4個患病，我們假定這個患病的概率爲 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;。於是我們就有了下面的模型：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型：&lt;/strong&gt; 我們假定患病與否是一個服從&lt;strong&gt;二項分佈的隨機變量&lt;/strong&gt;，&lt;span class=&#34;math inline&#34;&gt;\(X\sim Bin(10,\pi)\)&lt;/span&gt;。同時也默認每個人之間是否患病是相互獨立的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;數據：&lt;/strong&gt; 觀察到的數據是，10人中有4人患病。於是 &lt;span class=&#34;math inline&#34;&gt;\(x=4\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;現在按照觀察到的數據，參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 變成了未知數：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(X=4|\pi)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;此時我們會很自然的考慮，當 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 是未知數的時候，&lt;strong&gt;它取值爲多大的時候才能讓這個事件（即：10人中4人患病）發生的概率最大？&lt;/strong&gt; 所以我們可以將不同的數值代入 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 來計算該事件在不同概率的情況下發生的可能性到底是多少：&lt;/p&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Table 1: The probability of observing &lt;span class=&#34;math inline&#34;&gt;\(X=4\)&lt;/span&gt;
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
事件 &lt;span class=&#34;math inline&#34;&gt;\(X=4\)&lt;/span&gt; 發生的概率
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.088
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;0.4&lt;/strong&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;0.251&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.5
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.205
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.111
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.006
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;很顯然，如果 &lt;span class=&#34;math inline&#34;&gt;\(\pi=0.4\)&lt;/span&gt; 時，我們觀察到的事件發生的概率要比 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 取其它值時更大。於是小總結一下目前爲止的步驟如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;觀察到實驗數據（10人中4個患病）；&lt;/li&gt;
&lt;li&gt;假定這數據服從二項分佈的概率模型，計算不同（&lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 的取值不同的）情況下，該事件按照假定模型發生的概率；&lt;/li&gt;
&lt;li&gt;通過比較，我們選擇了能夠讓觀察事件發生概率最高的參數取值 (&lt;span class=&#34;math inline&#34;&gt;\(\pi=0.4\)&lt;/span&gt;)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;至此，我們可以知道，似然方程，是一個關於未知參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 的函數，我們目前位置做的就是找到這個函數的最大值 (maximised)，和使之成爲最大值時的 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; ：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\pi|X=4)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;我們可以畫出這個似然方程的形狀， &lt;span class=&#34;math inline&#34;&gt;\(\pi\in[0,1]\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(0,1,by=0.001)
y &amp;lt;- (factorial(10)/(factorial(4)*(factorial(6))))*(x^4)*((1-x)^6)
plot(x, y, type = &amp;quot;l&amp;quot;, ylim = c(0,0.3), ylab = &amp;quot;L(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
title(&amp;quot;Figure 1. Binomial Likelihood&amp;quot;)
abline(h=0.251, lty=2)
abline(v=0.4, lty=2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-02-likelihood_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;從圖形上我們也能確認，&lt;span class=&#34;math inline&#34;&gt;\(\pi=0.4\)&lt;/span&gt; 時能夠讓這個似然方程取得最大值。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;似然方程的一般化定義&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;似然方程的一般化定義&lt;/h3&gt;
&lt;p&gt;對於一個概率模型，如果其參數爲 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;，那麼在給定觀察數據 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 時，該參數的似然方程被定義爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(L(\theta|\underline{x})=P(\underline{x}|\theta)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(\underline{x}|\theta)\)&lt;/span&gt; 可以是概率（離散分佈）方程，也可以是概率密度（連續型變量）方程。對於此方程，&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 是給定的，然後再計算某些事件發生的概率。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(L(\theta|\underline{x})\)&lt;/span&gt; 是一個關於參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的方程，此時，&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 是固定不變的（觀察值）。我們希望通過這個方程求出能夠使觀察到的事件發生概率最大的參數值。&lt;/li&gt;
&lt;li&gt;似然方程&lt;strong&gt;不是&lt;/strong&gt;一個概率密度方程。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另一個例子：&lt;/p&gt;
&lt;p&gt;有一組觀察數據是離散型隨機變量 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;，它符合概率方程 &lt;span class=&#34;math inline&#34;&gt;\(f(x|\theta)\)&lt;/span&gt;。下表羅列了當 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 分別取值 &lt;span class=&#34;math inline&#34;&gt;\(1,2,3\)&lt;/span&gt; 時的概率方程的值，試求每個觀察值 &lt;span class=&#34;math inline&#34;&gt;\(X = 0,1,2,3,4\)&lt;/span&gt; 的最大似然參數估計：&lt;/p&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Exercise 1
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|1)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|2)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|3)\)&lt;/span&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Exercise 1 answer
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|1)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|2)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(f(x|3)\)&lt;/span&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;1&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;1&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;2&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;3&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1/3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;strong&gt;3&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;對數似然方程-log-likelihood&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;對數似然方程 log-likelihood&lt;/h3&gt;
&lt;p&gt;似然方程的最大值，可通過求 &lt;span class=&#34;math inline&#34;&gt;\(L(\theta|data)\)&lt;/span&gt; 的最大值獲得，也可以通過求該方程的對數方程 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt; 的最大值獲得。傳統上，我們估計最大方程的最大值的時候，會給參數戴一頂“帽子”（因爲這是觀察獲得的數據告訴我們的參數）： &lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}\)&lt;/span&gt;。並且我們發現對數似然方程比一般的似然方程更加容易微分，因此求似然方程的最大值就變成了求對數似然方程的最大值：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{d\ell}{d\theta}=\ell^\prime(\theta)=0\\
AND\\
\frac{d^2\ell}{d\theta^2}&amp;lt;0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;要注意的是，微分不一定總是能幫助我們求得似然方程的最大值。如果說參數本身的定義域是有界限的話，微分就行不通了：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(0,3,by=0.001)
y &amp;lt;- (x-1)^2-5
plot(x, y, type = &amp;quot;l&amp;quot;, ylim = c(-5,0-1), ylab = &amp;quot;L(\U03B8)&amp;quot;, xlab = &amp;quot;\U03B8&amp;quot;)
title(&amp;quot;Figure 2. Likelihood function with \n a limited domain&amp;quot;)
abline(v=3, lty=2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-02-likelihood_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;證明當-lthetadata-取最大值時該方程的對數方程-ellthetadata-也是最大值&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明：當 &lt;span class=&#34;math inline&#34;&gt;\(L(\theta|data)\)&lt;/span&gt; 取最大值時，該方程的對數方程 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt; 也是最大值：&lt;/h4&gt;
&lt;p&gt;如果似然方程是連續可導，只有一個最大值，且可以二次求導，假設 &lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}\)&lt;/span&gt; 使該方程取最大值，那麼：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{dL}{d\theta}=0, \frac{d^2L}{d\theta^2}&amp;lt;0 \Rightarrow \theta=\hat{\theta}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(\ell=logL\)&lt;/span&gt; 那麼 &lt;span class=&#34;math inline&#34;&gt;\(\frac{d\ell}{dL}=\ell^\prime=\frac{1}{L}\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{d\ell}{d\theta}=\frac{d\ell}{dL}\cdot\frac{dL}{d\theta}=\frac{1}{L}\cdot\frac{dL}{d\theta}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt; 取最大值時：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{d\ell}{d\theta}=0\Leftrightarrow\frac{1}{L}\cdot\frac{dL}{d\theta}=0\\
\because \frac{1}{L}\neq0 \\
\therefore \frac{dL}{d\theta}=0\\
\Leftrightarrow \theta=\hat{\theta}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\frac{d^2\ell}{d\theta^2} &amp;amp;= \frac{d}{d\theta}(\frac{d\ell}{dL}\cdot\frac{dL}{d\theta})\\
 &amp;amp;= \frac{d\ell}{dL}\cdot\frac{d^2L}{d\theta^2} + \frac{dL}{d\theta}\cdot\frac{d}{d\theta}(\frac{d\ell}{dL})
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(\theta=\hat{\theta}\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(\frac{dL}{d\theta}=0\)&lt;/span&gt; 且 &lt;span class=&#34;math inline&#34;&gt;\(\frac{d^2L}{d\theta^2}&amp;lt;0 \Rightarrow \frac{d^2\ell}{d\theta^2}&amp;lt;0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，求獲得 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta|data)\)&lt;/span&gt; 最大值的 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 即可令 &lt;span class=&#34;math inline&#34;&gt;\(L(\theta|data)\)&lt;/span&gt; 獲得最大值。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;極大似然估計-maximum-likelihood-estimator-mle-的性質&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;極大似然估計 (maximum likelihood estimator, MLE) 的性質：&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;漸進無偏 Asymptotically unbiased: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow \infty \Rightarrow E(\hat{\Theta}) \rightarrow \theta\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;漸進最高效能 Asymptotically efficient: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow \infty \Rightarrow Var(\hat{\Theta})\)&lt;/span&gt; 是所有參數中方差最小的估計&lt;/li&gt;
&lt;li&gt;漸進正態分佈 Asymptotically normal: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow \infty \Rightarrow \hat{\Theta} \sim N(\theta, Var(\hat{\Theta}))\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;變形後依然保持不變 Transformation invariant: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(\hat{\Theta}\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的MLE時 &lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow g(\hat{\Theta})\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt; 的 MLE&lt;/li&gt;
&lt;li&gt;信息足夠充分 Sufficient：&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(\hat{\Theta}\)&lt;/span&gt; 包含了觀察數據中所有的能夠用於估計參數的信息&lt;/li&gt;
&lt;li&gt;始終不變 consistent: &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow\infty\Rightarrow\hat{\Theta}\rightarrow\theta\)&lt;/span&gt; 或者可以寫成：&lt;span class=&#34;math inline&#34;&gt;\(\varepsilon&amp;gt;0, lim_{n\rightarrow\infty}P(|\hat{\Theta}-\theta|&amp;gt;\varepsilon)=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;率的似然估計-likelihood-for-a-rate&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;率的似然估計 Likelihood for a rate&lt;/h3&gt;
&lt;p&gt;如果在一項研究中，參與者有各自不同的追蹤隨訪時間（長度），那麼我們應該把事件（疾病）的發病率用率的形式（多少事件每單位人年, e.g. per person year of observation）。如果這個發病率的參數用 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 來表示，所有參與對象的隨訪時間之和爲 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 人年。那麼這段時間內的期望事件（疾病發病）次數爲：&lt;span class=&#34;math inline&#34;&gt;\(\mu=\lambda p\)&lt;/span&gt;。假設事件（疾病發病）發生是相互獨立的，可以使用泊松分佈來模擬期望事件（疾病發病）次數 &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[D\sim Poi(\mu)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;假設我們觀察到了 &lt;span class=&#34;math inline&#34;&gt;\(D=d\)&lt;/span&gt; 個事件，我們獲得這個觀察值的概率應該用以下的模型：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(D=d)=e^{-\mu}\frac{\mu^d}{d!}=e^{-\lambda p}\frac{\lambda^dp^d}{d!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;因此，&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的似然方程是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\lambda|observed \;data)=e^{-\lambda p}\frac{\lambda^dp^d}{d!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的對數似然方程是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\ell(\lambda|observed\;data) &amp;amp;= log(e^{-\lambda p}\frac{\lambda^dp^d}{d!}) \\
  &amp;amp;= -\lambda p+d\:log(\lambda)+d\:log(p)-log(d!) \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;解 &lt;span class=&#34;math inline&#34;&gt;\(\ell^\prime(\lambda|data)=0\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\ell^\prime(\lambda|data) &amp;amp;= -p+\frac{d}{\lambda}=0\\
\Rightarrow \hat{\lambda} &amp;amp;= \frac{d}{p} \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;
在對數似然方程中，不包含參數的部分，對與似然方程的形狀不產生任何影響，我們在微分對數似然方程的時候，這部分也都自動消失。所以不包含參數的部分，與我們如何獲得極大似然估計是無關的。因此，我們常常在寫對數似然方程的時候就把其中沒有參數的部分直接忽略了。例如上面泊松分佈的似然方程中，&lt;span class=&#34;math inline&#34;&gt;\(d\:log(p)-log(d!)\)&lt;/span&gt; 不包含參數 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 可以直接不寫出來。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;有-n-個獨立觀察時的似然方程和對數似然方程&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;有 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立觀察時的似然方程和對數似然方程&lt;/h3&gt;
&lt;p&gt;當有多個獨立觀察時，總體的似然方程等於各個觀察值的似然方程之&lt;strong&gt;乘積&lt;/strong&gt;。如果 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\stackrel{i.i.d}{\sim}f(\cdot|\theta)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\theta|x_1,\cdots,x_n)=f(x_1,\cdots,x_n|\theta)=\prod_{i=1}^nf(x_i|\theta)\\
\Rightarrow \ell(\theta|x_1,\cdots,x_n)=\sum_{i=1}^nlog(f(x_i|\theta))\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>臨牀實驗的樣本量計算問題 Sample Size in Clinical Trial</title>
      <link>https://wangcc.me/post/sample-size-in-clinical-trial/</link>
      <pubDate>Sun, 29 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/sample-size-in-clinical-trial/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;背景&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;背景&lt;/h3&gt;
&lt;p&gt;計劃臨牀實驗的時候，爲了避免偏倚和帶有偏見的結論，應當將注意力放在&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;如何將實驗對象隨機分配 (randomisation)&lt;/li&gt;
&lt;li&gt;設計對照組 (control group)&lt;/li&gt;
&lt;li&gt;合適（且必須）的貫徹盲法 (blinding)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另外一個同樣重要的問題是–&lt;strong&gt;“我到底需要多少樣本?”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一項臨牀實驗，應該提供足夠的證據來證明新藥物（新治療方法）是否有效，是否安全。影響一個實驗設計的樣本量的因素可能有如下幾種：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;統計學方案。&lt;/strong&gt;
&lt;br&gt; 從統計學上可以推算出，需要多少樣本來獲得一個堅實可信的證據來證明藥物的實際有效性。&lt;/li&gt;
&lt;li&gt;經濟上的因素。
&lt;br&gt; 然而實際上可能還有經濟上，時間上，人力物力資源上的現實因素，會制約到底一個實驗能夠收集到多少樣本量。&lt;/li&gt;
&lt;li&gt;倫理道德上的因素。
&lt;br&gt; 許多臨牀實驗還必須受制於醫學倫理因素。在倫理上一個實驗到底可以維持多久。或者說，要考慮當實驗中一些受試者的結果不理想，或者是有副作用的時候，我們何時該及時停止該實驗？&lt;/li&gt;
&lt;li&gt;實驗本身的可信度。
&lt;br&gt; 如果一個臨牀實驗的規模在設計上就很小，可能它本身的可信度就很低。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這裏我們只考慮沒有其他任何因素的影響下，&lt;strong&gt;1. 統計學方案&lt;/strong&gt;上該如何計算準確的所需樣本量的大小。&lt;/p&gt;
比較下列兩個同樣比較了溶栓酶和安慰劑在預防心肌梗塞患者死亡的臨牀實驗：
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-1&#34;&gt;Table 1: &lt;/span&gt;Results from the 1st Australian and ISIS-2 trials for reducing mortality from post-MI
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
治療組
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
溶栓酶
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
安慰劑
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1st Australian
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
n=264
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
n=253
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
死亡人數
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
26 (9.8%)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
32 (12.6%)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
p = 0.32
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
評價
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Risk ratio
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.78 (95% CI: 0.48 to 1.27)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ISIS-2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
n=8592
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
n=8595
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
死亡人數
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
791 (9.2%)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1029 (12.0%)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
p &amp;lt; 0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
評價
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Risk ratio
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.77 (95% CI: 0.70 to 0.84)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;這兩個臨牀實驗獲得的治療效果 (treatment effect)，在數字的百分比上幾乎十分接近。然而由於樣本兩巨大的差距，可以看到第一個實驗的信賴區間十分的大，使得實驗結果是無意義的。而第二個大樣本的實驗結果就告訴我們，溶栓酶的治療效果是有效降低了心肌梗死患者死亡概率（降低了23%）。第一個實驗收集了近500個病例，卻仍然不能提供確實有效的證據證明溶栓酶的治療效果（提供了強的關聯結果，卻是極弱的證據。strong correlation, but weak evidence) 。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;決定所需樣本量大小的統計學因素&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;決定所需樣本量大小的統計學因素&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;實驗主要結果的測量/比較方法是什麼？ What is the principal outcome measure of the trial?
&lt;br&gt; 一項臨牀實驗的主要結果，應該是切合該實驗的主要目的的。並且應當能夠客觀評價。(如死亡率的改善，治癒率的提高等等)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;實驗數據準備分析的方案是什麼？ How will the data be analysed to detect a treatment difference?
&lt;br&gt; 實驗結果獲得的數據是連續型的 (血壓，血糖值，BMI)？還是分類的離散變量 (死亡的發生與否，疾病的治癒與否)？統計學上認爲的，治療結果提示有意義的差別時的概率。通常定爲 5%。(p &amp;lt; 0.05)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;對照組的試驗期望結果是怎樣的？ What results are expected in the control group?
&lt;br&gt; 當然我們不可能事先預知實驗對照組可能出現的結果。此處只討論我們的預期結果。大多數情況下，我們可以從已經進行過的類似臨牀試驗報告中獲得，或者是從非臨牀干預型研究（觀察型研究）報告中獲得對照組的期望結果。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;如果實驗藥物在治療上確實有差異，當這個差異最小爲多少時希望能從設計的實驗中被檢測到？ How small a treatment difference, if it exists, is important to detect?
&lt;br&gt; 這一條恐怕是每個臨牀實驗在設計階段最重要，最敏感也是最難做出決定的。如果我們已知這個藥物療效和對照相比差別很大，那麼樣本量不用很大，就足以提供值得信賴的證據。不過臨牀上常常會認爲療效差距不必&lt;strong&gt;非常的&lt;/strong&gt;顯著，但是在臨牀意義上也是十分重要的。
&lt;br&gt; 常常在這個問題上會引起衆多討論，因爲醫生和患者可能認爲任何一點差異都是有臨牀意義的。但是如果我們想檢測出較小的差距，會需要非常巨大的樣本量，這將會是十分不切合實際的。&lt;strong&gt;What needs to be decided upon is the smallest clinically relevant difference that would be important to detect if it were true.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在上面第 4 條被決定了以後，還要確定的是我們需要多大的把握來相信這個被檢測出來的療效差別？ With what degree of certainty is needed to be able to detect the treatment difference in 4?
&lt;br&gt; 在實際臨牀實驗中，結論是從觀察數據中得來的，而不是從我們預想的那個“未知的實驗效果”。觀察獲得的療效差別，可能比預想的大（有效），也很可能比預想的小（無效）。設計較好的臨牀實驗應該有足夠機率觀察到有意義的療效差別，即使觀察得到的結果不如預期的大。當然要增加我們觀察到有意義的療效差別，最簡單的辦法是增加樣本量。這個條件的含義是，當療效真差別真實存在，我們要有足夠大的把握把它通過實驗觀察到。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;第一類和第二類錯誤-type-i-and-type-ii-errors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;第一類和第二類錯誤 Type I and type II errors&lt;/h3&gt;
&lt;p&gt;下面羅列一下我們在進行實驗設計時要用到的概念和相應的標記，注意雖然我們無法知道真正的人羣裏真實參數 (parameter) 的大小，但是我們需要用一些估計 (estimator) 來代替：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(p_1=\)&lt;/span&gt; the &lt;strong&gt;observed percentage&lt;/strong&gt; in those on standard treatment &lt;br&gt; 意爲施行標準治療法時觀察到的（治癒/有效）百分比&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(p_2=\)&lt;/span&gt; the &lt;strong&gt;observed percentage&lt;/strong&gt; in those on “new” treatment &lt;br&gt; 意爲施行“新療法”時觀察到的（治癒/有效）的百分比&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow p_1-p_2=\)&lt;/span&gt; &lt;strong&gt;observed treatment effect&lt;/strong&gt; &lt;br&gt; 意爲可以觀察到的治療效果。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\pi_1=\)&lt;/span&gt; the &lt;strong&gt;anticipated percentage&lt;/strong&gt; in those on standard treatment &lt;br&gt; 意爲施行標準治療法時，我們預期的（治癒/有效）百分比&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\pi_2=\)&lt;/span&gt; the &lt;strong&gt;anticipated percentage&lt;/strong&gt; in those on “new” treatment &lt;br&gt; 意爲施行“新療法”時，我們預期的（治療/有效）百分比&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow \pi_1-\pi_2=\)&lt;/span&gt; is the true difference which has been decided it is important to detect &lt;br&gt; 意爲上面第 4 條中我們設定好的希望通過實驗證實的真實的療效差別。&lt;/p&gt;
&lt;p&gt;其餘的數學標記包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha=\)&lt;/span&gt; 有意義的療效差異，在統計學上的水平 (概率水平，通常設定爲 0.05 or 5%)&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(1-\beta=\)&lt;/span&gt; Degree of certainty that a true difference of &lt;span class=&#34;math inline&#34;&gt;\(\pi_1 - \pi_2\)&lt;/span&gt; would be detected. &lt;br&gt; 效能, power。意爲有多大的把握能通過實驗檢測出療效差別。（通常將目標值設定爲 &lt;span class=&#34;math inline&#34;&gt;\(1-\beta=90\%\)&lt;/span&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Table 2: Observed trial results compared to the &lt;code&gt;truth&lt;/code&gt; of 1) no difference; 2) a true &lt;span class=&#34;math inline&#34;&gt;\(\pi_1-\pi_2\)&lt;/span&gt; diffrence
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;border-bottom:hidden&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;&#34; colspan=&#34;2&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px;&#34;&gt;
真實情況 &lt;br&gt; Truth
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
無差別
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
真實差別存在 &lt;span class=&#34;math inline&#34;&gt;\(\pi_1-\pi_2\)&lt;/span&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
觀察到不存在有意義差別
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(1−\alpha\)&lt;/span&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; &lt;br&gt; Type II error
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
觀察到存在有意義差別
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; &lt;br&gt; Type I error
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(1-\beta\)&lt;/span&gt; &lt;br&gt; Power
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;考慮上面這個表格，可以很容易想到，一個理想的實驗設計，我們希望這個臨牀實驗獲得的結果儘可能地落在上表中的&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;左上角：即如果真實情況是無差別的，實驗結果也應該觀察到不存在有意義的差別。&lt;/li&gt;
&lt;li&gt;右下角：即如果真實情況是是存在真實差別 &lt;span class=&#34;math inline&#34;&gt;\(\pi_1-\pi_2\)&lt;/span&gt; 的，試驗結果也應該觀察到有意義的差別。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;然而，我們在獲得臨牀實驗結果之後常常犯的兩類錯誤，同樣在上面的表格中顯示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Type I error:&lt;/strong&gt; A type I error is when a treatment difference is claimed based on a statistically significant observed result when in truth no such difference exists, i.e. a false positive result. &lt;br&gt; 左下角爲&lt;strong&gt;一類錯誤&lt;/strong&gt;，即實驗結果觀察到有顯著的療效差異，然而，真實情況是並沒有差異的話，被認爲是假陽性判斷。&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; 表示一類錯誤發生的概率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type II error:&lt;/strong&gt; A type II error is when in truth there exists a difference of &lt;span class=&#34;math inline&#34;&gt;\(\pi_1-\pi_2\)&lt;/span&gt; but the observed results fail to reach statistical significance, i.e. a false negative result. &lt;br&gt; 右上角爲&lt;strong&gt;二類錯誤&lt;/strong&gt;，即實驗結果觀察到沒有顯著的療效差異，然而，真實情況是有差異的話，被認爲是假陰性判斷。&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; 表示二類錯誤發生的概率。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Alternative ways of describing &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the risk of a Type I error; &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; 也被叫做檢驗的顯著水平, significant level。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the risk of a Type II error. &lt;span class=&#34;math inline&#34;&gt;\(1-\beta\)&lt;/span&gt; is termed statistical power. 其中 &lt;span class=&#34;math inline&#34;&gt;\(1-\beta\)&lt;/span&gt; 被叫做檢驗效能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha, 1-\beta\)&lt;/span&gt; 的水平需要事先被確定，否則無法進行進一步的樣本量的計算。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;比較兩組之間的百分比-percentages-or-proportions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;比較兩組之間的百分比 (percentages or proportions)&lt;/h3&gt;
&lt;div id=&#34;樣本量計算公式-使用顯著水平-5-和檢驗效能-90&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n=10.5\times\frac{[\pi_1\times(100-\pi_1)+\pi_2\times(100-\pi_2)]}{(\pi_1-\pi_2)^2}\times2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上面的公式後面有 &lt;span class=&#34;math inline&#34;&gt;\(\times2\)&lt;/span&gt; 是因爲前一半公式計算的只是一組（治療或對照組）所需的樣本量。&lt;/li&gt;
&lt;li&gt;這裏使用的是百分比。所以當使用比例的時候，要把 &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; 改成 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;使用公式計算的所需樣本量，並不是說我們需要的病例數就是計算出來的結果。上面的公式獲得的結果只是對所需樣本量的估算。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;樣本量計算公式的一般化-不同的顯著水平和檢驗效能條件下&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n=f(\alpha, \beta)\times\frac{[\pi_1\times(100-\pi_1)+\pi_2\times(100-\pi_2)]}{(\pi_1-\pi_2)^2}\times2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中， &lt;span class=&#34;math inline&#34;&gt;\(f(\alpha, \beta)\)&lt;/span&gt; 指的是關於檢驗顯著水平 &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; 和檢驗效能 &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; 的函數。 可以參考下面的表格：&lt;/p&gt;
&lt;table class=&#34;table table-striped table-bordered&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
Table 3: Values of &lt;span class=&#34;math inline&#34;&gt;\(f(\alpha, \beta)\)&lt;/span&gt; for different levels of &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;&#34; colspan=&#34;1&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;
&lt;/div&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;&#34; colspan=&#34;4&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px;&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0.1
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0.2
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0.5
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; power)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(&lt;span class=&#34;math inline&#34;&gt;\(90\%\)&lt;/span&gt; power)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(&lt;span class=&#34;math inline&#34;&gt;\(80\%\)&lt;/span&gt; power)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(&lt;span class=&#34;math inline&#34;&gt;\(50\%\)&lt;/span&gt; power)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
13.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
10.5
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7.85
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.84
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
17.8
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
14.9
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
11.7
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6.63
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;要注意的是，除了上面表格中提供的 &lt;span class=&#34;math inline&#34;&gt;\(f(\alpha, \beta)\)&lt;/span&gt; 數值，可以通過以下公式計算得出：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(\alpha, \beta)=(Z_{1-\frac{\alpha}{2}}+Z_{1-\beta})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05, \beta=0.1\)&lt;/span&gt; 時：&lt;span class=&#34;math inline&#34;&gt;\(f(\alpha, \beta)=(1.96+1.282)^2=10.5\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05, \beta=0.2\)&lt;/span&gt; 時：&lt;span class=&#34;math inline&#34;&gt;\(f(\alpha, \beta)=(1.96+0.84)^2=7.85\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;比較兩組之間的均值&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;比較兩組之間的均值&lt;/h3&gt;
&lt;p&gt;許多臨牀實驗不光關心患者是否被治癒或者死亡，另外還有許多實驗的主要結果是連續變量：例如，腎功能（腎小球濾過率），或收縮期血壓。然而背後的原理其實還是一樣的。&lt;/p&gt;
&lt;div id=&#34;樣本量計算公式&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;樣本量計算公式&lt;/h4&gt;
&lt;p&gt;然而，另外一個必須考慮的因素：治療組對照組測量結果的標準差 (standard deviation, &lt;span class=&#34;math inline&#34;&gt;\(sd, \sigma\)&lt;/span&gt;)。這裏先考慮兩者標準差相同的情況。標準差的數據通常來自與先行研究的科學文獻，有些（土豪）實驗會先進行預實驗獲得想要的實驗數據–標準差。通常，建議像比較百分比那樣，調整改變一下不同的檢驗顯著水品和檢驗效能，計算多個所需樣本量來互相比較參考。&lt;/p&gt;
&lt;p&gt;比較兩組均值時需要用到的數學標記：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_1=\)&lt;/span&gt; 標準治療法（對照組）的期待平均值；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_2=\)&lt;/span&gt; 新治療法（治療組）的期待平均值；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma=\)&lt;/span&gt; 兩組的標準差（假設兩組標準差相同）；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha=\)&lt;/span&gt; 一類錯誤發生的概率，檢驗顯著水平；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta=\)&lt;/span&gt; 二類錯誤發生的概率，&lt;span class=&#34;math inline&#34;&gt;\(1-\beta\)&lt;/span&gt; 是檢驗效能。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;用上面標記表示的公式如下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n=f(\alpha, \beta)\times\frac{2\sigma^2}{(\mu_1-\mu_2)^2}\times2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;可以認爲，上面的公式中 &lt;span class=&#34;math inline&#34;&gt;\(\mu_1-\mu_2\)&lt;/span&gt; ，各組的平均值本身並不重要，兩組之間均值的差是我們關心的。如果用 &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; 表示兩組之間均值差的期待值，那麼公式可以改寫爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n=f(\alpha, \beta)\times\frac{2\sigma^2}{\delta^2}\times2\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;樣本量計算的調整&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;樣本量計算的調整&lt;/h3&gt;
&lt;p&gt;如果我們無法成功隨訪部分患者，那麼這部分人的數據就無法獲得，實驗數據的說服力就會下降。如果我們預估計有 &lt;span class=&#34;math inline&#34;&gt;\(Q\%\)&lt;/span&gt; 的人會失去隨訪，那麼我們可以將之前步驟中計算獲得的數字乘以 &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{1-Q\%}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;如果實驗設計是我們會在某個時間點允許治療組或對照組中的部分人變更自己的實驗方案（即治療組的參與者改進入對照組，反之亦然）。那麼所需樣本量的計算調整的方法爲：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(Q_1=\)&lt;/span&gt; 第一組中改成第二組治療方案的人數比例；&lt;/li&gt;
&lt;li&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(Q_2=\)&lt;/span&gt; 第二組中改成第一組治療方案的人數比例；&lt;/li&gt;
&lt;li&gt;將之前步驟中計算獲得的樣本量數字乘以 &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{(1-Q_1-Q_2)^2}\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果預期參與實驗治療組（而不是對照組）的人中有部分人（比例爲 &lt;span class=&#34;math inline&#34;&gt;\(Q\)&lt;/span&gt;）會中斷實驗進程，那麼調整公式爲：&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{(1-Q)^2}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;還有的實驗會使用大於 &lt;span class=&#34;math inline&#34;&gt;\(1:1\)&lt;/span&gt; 的比例設計對照組和實驗組的人數。假設這一比例爲 &lt;span class=&#34;math inline&#34;&gt;\(r:1\)&lt;/span&gt; 那麼調整的樣本量數字還要乘以：&lt;span class=&#34;math inline&#34;&gt;\(\frac{(r+1)^2}{4r}\)&lt;/span&gt;。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>卡方分佈 chi square distribution</title>
      <link>https://wangcc.me/post/chi-square-distribution/</link>
      <pubDate>Thu, 26 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/chi-square-distribution/</guid>
      <description>


&lt;div id=&#34;卡方分佈的期望和方差的證明&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;卡方分佈的期望和方差的證明：&lt;/h3&gt;
&lt;p&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(X\sim N(0,1)\)&lt;/span&gt; 時， &lt;span class=&#34;math inline&#34;&gt;\(X^2\sim \mathcal{X}_1^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果 &lt;span class=&#34;math inline&#34;&gt;\(X_1, \dots, X_n\stackrel{i.i.d}{\sim} N(0,1)\)&lt;/span&gt;，
那麼 &lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^nX_i^2\sim\mathcal{X}_n^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中： &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{X}_n^2\)&lt;/span&gt; 表示自由度爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 的卡方分佈。&lt;/p&gt;
&lt;p&gt;且 &lt;span class=&#34;math inline&#34;&gt;\(X_m^2+X_n^2=\mathcal{X}_{m+n}^2\)&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;卡方分佈的期望&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;卡方分佈的期望：&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(X_1^2)=Var(X)+[E(X)]^2=1+0=1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Rightarrow E(X_n^2)=n\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;卡方分佈的方差&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;卡方分佈的方差：&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
Var(X_1^2) &amp;amp;= E(X_1^{2^2}) - E(X_1^2)^2 \\
           &amp;amp;= E(X_1^4)-1
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;下面來求-ex_14&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;下面來求 &lt;span class=&#34;math inline&#34;&gt;\(E(X_1^4)\)&lt;/span&gt;&lt;/h5&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\because E(X_1) &amp;amp;= \int_{-\infty}^{+\infty} xf(x)dx \\
\therefore E(X_1^4) &amp;amp;= \int_{-\infty}^{+\infty} x^4f(x)dx
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;已知： &lt;span class=&#34;math inline&#34;&gt;\(f(x)=\frac{1}{\sqrt{2\pi}}e^{(-\frac{x^2}{2})}\)&lt;/span&gt; 代入上式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E(X_1^4) &amp;amp;= \int_{-\infty}^{+\infty} x^4f(x)dx \\
         &amp;amp;= \int_{-\infty}^{+\infty} x^4\frac{1}{\sqrt{2\pi}}e^{(-\frac{x^2}{2})}dx\\
         &amp;amp;=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^4e^{(-\frac{x^2}{2})}dx\\
         &amp;amp;=\frac{-1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^3(-x)e^{(-\frac{x^2}{2})}dx
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(u=x^3, v=e^{(-\frac{x^2}{2})},t=-\frac{x^2}{2}\)&lt;/span&gt;
可以推導：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\frac{dv}{dx} &amp;amp;= \frac{dv}{dt}\frac{dt}{dx} \\
              &amp;amp;= e^t(-\frac{1}{2}\times2x) \\
              &amp;amp;= (-x)e^{(-\frac{x^2}{2})} \\
\Rightarrow dv &amp;amp;= (-x)e^{(-\frac{x^2}{2})}dx
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;再代入上面的式子：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E(X_1^4) &amp;amp;= \frac{-1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}u\:dv \\
integrate\; &amp;amp;by\; parts:\\
E(X_1^4) &amp;amp;= \frac{-1}{\sqrt{2\pi}}\{[u\:v] \rvert_{-\infty}^{+\infty}-\int_{-\infty}^{+\infty}v\:du\} \\
&amp;amp;= \frac{-1}{\sqrt{2\pi}}\{[x^3e^{(-\frac{x^2}{2})}]\rvert_{-\infty}^{+\infty} -\int_{-\infty}^{+\infty}v\:du\} \\
&amp;amp;=\frac{-1}{\sqrt{2\pi}}\{0-0-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx^3\} \\
&amp;amp;=\frac{-1}{\sqrt{2\pi}}[-3\int_{-\infty}^{+\infty}x^2e^{(-\frac{x^2}{2})}dx] \\
&amp;amp;=\frac{-3}{\sqrt{2\pi}}[\int_{-\infty}^{+\infty}x(-x)e^{(-\frac{x^2}{2})}dx] \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;再來一次分部積分：&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(a=x,b=e^{(-\frac{x^2}{2})},d\:b = (-x)e^{(-\frac{x^2}{2})}dx\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E(X_1^4) &amp;amp;= \frac{-3}{\sqrt{2\pi}}\{[a\:b] \rvert_{-\infty}^{+\infty} - \int_{-\infty}^{+\infty}b\:da\} \\
&amp;amp;=\frac{-3}{\sqrt{2\pi}}\{[xe^{(-\frac{x^2}{2})}]\rvert_{-\infty}^{+\infty} -\int_{-\infty}^{+\infty}b\:da\} \\
&amp;amp;=\frac{-3}{\sqrt{2\pi}}\{0-0-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx\} \\
&amp;amp;=\frac{-3}{\sqrt{2\pi}}[-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx] \\
&amp;amp;=\frac{3}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;下面令 &lt;span class=&#34;math inline&#34;&gt;\(I=\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx\\ \Rightarrow I^2=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{(-\frac{x^2+y^2}{2})}dxdy\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;接下來需要用到 &lt;a href=&#34;https://www.youtube.com/watch?v=r0fv9V9GHdo&#34;&gt;座標轉換&lt;/a&gt;的知識，將 &lt;span class=&#34;math inline&#34;&gt;\(x,y\)&lt;/span&gt; 表示的笛卡爾座標，轉換爲用角度 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 和半徑 &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; 表示的形式。之後的證明可以在&lt;a href=&#34;https://www.youtube.com/watch?v=fWOGfzC3IeY&#34;&gt;油管&lt;/a&gt;上看到，但是我還是繼續證明下去。&lt;/p&gt;
&lt;p&gt;直角座標系 (cartesian coordinators) 和
極座標系 (polar coordinators) 之間轉換的關係如下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
x&amp;amp;=r\:cos\theta\\
y&amp;amp;=r\:sin\theta\\
r^2&amp;amp;=x^2+y^2\\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;座標轉換以後可以繼續求 &lt;span class=&#34;math inline&#34;&gt;\(E(X_1^4)\)&lt;/span&gt;。 在那之前我們先求 &lt;span class=&#34;math inline&#34;&gt;\(I^2\)&lt;/span&gt;。
注意轉換座標系統以後，&lt;span class=&#34;math inline&#34;&gt;\(\theta\in[0,2\pi], r\in[0,+\infty]\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
I^2 &amp;amp;= \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{(-\frac{x^2+y^2}{2})}dxdy \\
&amp;amp;= \int_{0}^{+\infty}\int_{0}^{2\pi}e^{(-\frac{r^2}{2})}rd\theta dr \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由於先從中間的 &lt;span class=&#34;math inline&#34;&gt;\(\int_{0}^{2\pi}e^{(-\frac{r^2}{2})}rd\theta\)&lt;/span&gt; 開始積分，&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 以外都可以視爲常數，那麼這個 &lt;span class=&#34;math inline&#34;&gt;\([0,2\pi]\)&lt;/span&gt; 上的積分就的等於 &lt;span class=&#34;math inline&#34;&gt;\(2\pi e^{(-\frac{r^2}{2})}r\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;因此上面的式子又變爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
I^2 &amp;amp;=  2\pi\int_{0}^{+\infty}e^{(-\frac{r^2}{2})}r\:dr \\
\because \frac{d(e^{\frac{-r^2}{2}})}{dr} &amp;amp;= -e^{(-\frac{r^2}{2})}r \\
\therefore I^2 &amp;amp;= 2\pi(-e^{\frac{-r^2}{2}})\rvert_0^{+\infty} \\
               &amp;amp;= 0-(2\pi\times(-1)) \\
               &amp;amp;= 2\pi\\
\Rightarrow I  &amp;amp;= \sqrt{2\pi}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E(X_1^4) &amp;amp;= \frac{3}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx \\
&amp;amp;= \frac{3}{\sqrt{2\pi}}\times I \\
&amp;amp;= 3 \\
\Rightarrow Var(X_1^2) &amp;amp;= E(X_1^4) - 1 \\
                       &amp;amp;= 3-1 =2 \\
\Rightarrow Var(X_n^2) &amp;amp;= 2n
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;結論：&lt;span class=&#34;math inline&#34;&gt;\(X_1, \dots, X_n\stackrel{i.i.d}{\sim} N(0,1)\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^nX_i^2\sim\mathcal{X}_n^2\)&lt;/span&gt; 服從卡方分佈，其期望 &lt;span class=&#34;math inline&#34;&gt;\(E(X_n^2)=n\)&lt;/span&gt;，方差 &lt;span class=&#34;math inline&#34;&gt;\(Var(X_n^2)=2n\)&lt;/span&gt;。
根據&lt;a href=&#34;https://winterwang.github.io/post/central-limit-theory/&#34;&gt;中心極限定理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n\rightarrow \infty, X_n^2\sim N(n, 2n)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>估計和精確度的概念</title>
      <link>https://wangcc.me/post/frequentist-statistical-inference02/</link>
      <pubDate>Tue, 24 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/frequentist-statistical-inference02/</guid>
      <description>


&lt;div id=&#34;估計量和他們的樣本分佈&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;估計量和他們的樣本分佈&lt;/h3&gt;
&lt;p&gt;例子： 最大呼氣量 (Forced Expoiratory Volume in one second, FEV1) 用於測量一個人的肺功能，它的測量值是連續的。我們從前來門診的人中隨機抽取 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 人作爲樣本，用這個樣本的 FEV1 平均值來估計這個診所的患者的平均肺功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型假設：&lt;/strong&gt; 在這個例子中，我們的假設有如下：每個隨機抽取的 FEV1 測量值都是從同一個總體（人羣）中抽取，每一個觀察值 &lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt; 都互相獨立互不影響。我們用縮寫 iid 表示這些隨機抽取的樣本是服從獨立同分佈 (independent and identically distributed)。另外，總體的分佈也假定爲正態分佈，且總體均值爲 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;，總體方差爲 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;。那麼這個模型可以簡單的被寫成：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_i \stackrel{i.i.d}{\sim} N(\mu, \sigma^2), i=1,2,\dots,n\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;總體均值 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 的估計量：&lt;/strong&gt; 顯然算術平均值: &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}=\frac{1}{n}\sum_{i=1}^ny_i\)&lt;/span&gt; 是我們用於估計總體均值的估計量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;估計量的樣本分佈：&lt;/strong&gt;
&lt;span class=&#34;math display&#34;&gt;\[\bar{Y}\stackrel{i.i.d}{\sim}N(\mu, \frac{\sigma^2}{n})\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;證明&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E(\bar{Y}) &amp;amp;= E(\frac{1}{n}\sum Y_i) \\
           &amp;amp;= \frac{1}{n}E(\sum Y_i) \\
           &amp;amp;= \frac{1}{n}\sum E(Y_i) \\
           &amp;amp;= \frac{1}{n}n\mu = \mu \\
Var(\bar{Y}) &amp;amp;= Var(\frac{1}{n}\sum Y_i) \\
\because Y_i \;are &amp;amp;\; independent   \\
            &amp;amp;= \frac{1}{n^2}\sum Var(Y_i) \\
            &amp;amp;= \frac{1}{n^2} n Var(Y_i) \\
            &amp;amp;= \frac{\sigma^2}{n}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;證明當-zfracbary-musqrtvarbary-時-zsim-n01&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明當 &lt;span class=&#34;math inline&#34;&gt;\(Z=\frac{\bar{Y}-\mu}{\sqrt{Var(\bar{Y})}}\)&lt;/span&gt; 時， &lt;span class=&#34;math inline&#34;&gt;\(Z\sim N(0,1)\)&lt;/span&gt;:&lt;/h4&gt;
&lt;p&gt;由式子可知， &lt;span class=&#34;math inline&#34;&gt;\(Z\)&lt;/span&gt; 只是由一組服從正態分佈的數據 &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}\)&lt;/span&gt; 線性轉換 (linear transformation) 而來，所以 &lt;span class=&#34;math inline&#34;&gt;\(Z\)&lt;/span&gt; 本身也服從正態分佈
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E(Z) &amp;amp;= \frac{1}{\sqrt{Var(\bar{Y})}}E[\bar{Y}-\mu] \\
     &amp;amp;= \frac{1}{\sqrt{Var(\bar{Y})}}[\mu-\mu] = 0 \\
Var(Z) &amp;amp;= \frac{1}{Var(\bar{Y})}Var[\bar{Y}-\mu] \\
       &amp;amp;= \frac{1}{Var(\bar{Y})}Var(\bar{Y}) =1 \\
\therefore Z \;&amp;amp;\sim N(0,1)
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;均值 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 的信賴區間：&lt;/strong&gt; 上節說道，&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;信賴區間通常是成對成對的出現的，即有上限和下限。這樣的一對從樣本數據中計算得來的統計量，同樣也是有樣本分佈的。&lt;strong&gt;每次我們重新從總體或人羣中抽樣，計算獲得的信賴區間都不同，這些信賴區間就組成了信賴區間的樣本分佈。總體和人羣的參數落在這些信賴區間範圍內的概率，就是我們常說的信賴區間的水平（&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt;）。&lt;/strong&gt; 常用的這個概率值就是 &lt;span class=&#34;math inline&#34;&gt;\(95\%, 90\%, 99\%\)&lt;/span&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;假定我們用 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 作爲信賴區間的水平。那麼下面我們嘗試推導一下信賴區間的計算公式。從長遠來說（也就是假設我們從總體中抽樣無數次，每次都進行信賴區間的計算，也獲得無數個信賴區間），這些信賴區間中有 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 是包含了總體的真實均值（但是卻是未知）的，而且這些信賴區間由於是從一個服從正態分佈的數據而來，它們也服從正態分佈（對真實均值左右對稱）。所以我們有理由相信，可以找到一個數值 &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(\bar{Y} &amp;gt; \mu+c) = 0.025 \\
  Prob(\bar{Y} &amp;lt; \mu-c) = 0.025\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;因此，我們可以定義 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間的上限和下限分別是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L=\bar{Y}-c \Rightarrow Prob(L&amp;gt;\mu)=0.025 \\
  U=\bar{Y}+c \Rightarrow Prob(U&amp;lt;\mu)=0.025\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Selection_082.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;接下來就是推倒（故意的）&lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; 的過程啦：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
Prob(\bar{Y}&amp;gt;\mu+c)=Prob(\bar{Y}-\mu&amp;gt;c) \;&amp;amp;= 0.025 \\
\Rightarrow Prob(\frac{\bar{Y}-\mu}{\sqrt{Var(\bar{Y})}} &amp;gt; \frac{c}{\sqrt{Var(\bar{Y})}}) \;&amp;amp;= 0.025 \\
\Rightarrow Prob(Z&amp;gt;\frac{c}{\sqrt{Var(\bar{Y})}}) \;&amp;amp;= 0.025 \\
上面已經證明了 Z\sim N(0,1) \\
而且我們也已知 Prob(Z&amp;gt;1.96) \;&amp;amp;= 0.025 \\
所以只要令 \frac{c}{\sqrt{Var(\bar{Y})}} =1.96 \\
\Rightarrow c=1.96\sqrt{Var(\bar{Y})} \\
所以總體均值\mu 的 95\% 信賴區間就是: \\
\mu = \bar{Y}\pm1.96\sqrt{Var(\bar{Y})}=\bar{Y}\pm &amp;amp; 1.96\frac{\sigma}{\sqrt{n}}\\
其中，\sqrt{Var(\bar{Y})} 就是我們熟知的估計量 \bar{Y} &amp;amp;的標準誤。
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;估計量的特質&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;估計量的特質&lt;/h3&gt;
&lt;p&gt;考慮以下的問題：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;什麼因素決定了一個估計量 (estimator) 的好壞，是否實用？&lt;/li&gt;
&lt;li&gt;如果有其他的可選擇估計量，該如何取捨呢？&lt;/li&gt;
&lt;li&gt;當情況複雜的時候，我們該如何尋找合適的估計量？&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;偏倚&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;偏倚&lt;/h4&gt;
&lt;p&gt;假設 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 是我們估計總體參數 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 的一個估計量。一般來說我們希望估計量的樣本分佈可以在 &lt;code&gt;“正確的位置”&lt;/code&gt; 左右均勻分佈。換句話說我們希望：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(T)=\theta\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果實現了這個條件，我們說這樣的估計量是無偏的 (&lt;code&gt;unbiased&lt;/code&gt;)。然而，天下哪有這等好事，我們叫真實值和估計量之間的差距爲偏倚：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[bias(T) = E(T)-\theta\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其實偏倚完全等於零並不是最重要，許多常見的估計量都是有偏倚的。重要的是，這個偏倚會隨着樣本量的增加而逐漸趨近於零。所以我們就可以認爲這樣的估計量是漸進無偏的 (asymptotically unbiased)：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[T\;is\;an\;\textbf{unbiased}\;estimator\;for\;\theta\;if\;\\E(T)=\theta\\
T\;is\;an\;\textbf{asymptotically unbiased}\;estimator\;for\;\theta\;if\;\\lim_{n\rightarrow\infty}E(T)=\theta\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;估計量的效能-efficiency&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;估計量的效能 Efficiency&lt;/h4&gt;
&lt;p&gt;通常，我們希望一個估計量 (estimator) 的偏倚要小，同時，它的樣本分佈也希望能儘可能的不要波動太大。換句話說，我們還希望估計量的方差越小越好。&lt;/p&gt;
&lt;p&gt;如果說，兩個估計量有相同的偏倚，均可以選擇來推斷總體，我們說，其中樣本分佈的方差小的那個（波動幅度小）的那個估計量是相對更好的。因爲樣本分佈方差越小，說明可以&lt;strong&gt;更加精確的&lt;/strong&gt;估計總體參數。這兩個估計量的方差之比：&lt;span class=&#34;math inline&#34;&gt;\(Var(S)/Var(T)\)&lt;/span&gt; 被叫做這兩個估計量的&lt;strong&gt;相對效能 (relative efficiency)&lt;/strong&gt;。所以我們用估計量去推斷總體時，需要選用效能最高，精確度最好的估計量 &lt;strong&gt;(the minimum variance unbiased estimator/an efficient estimator)&lt;/strong&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;均值和中位數的相對效能&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;均值和中位數的相對效能&lt;/h4&gt;
&lt;p&gt;在一個服從 &lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2)\)&lt;/span&gt; 正態分佈的數據中，中位數和均值是一樣的，也都同時等於總體均值參數 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;。而且，樣本均數 &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}\)&lt;/span&gt; 和樣本中位數 &lt;span class=&#34;math inline&#34;&gt;\(\dot{Y}\)&lt;/span&gt; 都是對總體均值的無偏估計量。那麼應該選用中位數還是平均值呢？&lt;/p&gt;
&lt;p&gt;之前證明過當 &lt;span class=&#34;math inline&#34;&gt;\(Y_i \sim N(\mu,\sigma^2)\)&lt;/span&gt; 時， &lt;span class=&#34;math inline&#34;&gt;\(Var(\bar{Y}=\sigma^2/n)\)&lt;/span&gt;。然而，當 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 較大的時候，可以證明的是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var(\dot{Y})=\frac{\pi}{2}\frac{\sigma^2}{n}\approx1.571\frac{\sigma^2}{n}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;因此，這兩個估計量的相對效能就是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{Var(\dot{Y})}{Var(\bar{Y})}\approx1.571\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以總體是正態分佈時，平均值就是較中位數更適合用來估計總體的估計量。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;均方差-mean-square-error-mse&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;均方差 mean square error (MSE)&lt;/h3&gt;
&lt;p&gt;兩個估計量的偏倚不同時，可以比較他們和總體參數之間的差距，這被叫做均方差, Mean Square Error (MSE)。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[MSE(T)=E[(T-\theta)^2]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這裏用一個數學技巧，將式子中的估計量和總體參數之間的差，分成兩個部分：一是估計量本身的方差 (&lt;span class=&#34;math inline&#34;&gt;\(T-E(T)\)&lt;/span&gt;)，一是估計量的偏倚 (&lt;span class=&#34;math inline&#34;&gt;\(E(T)-\theta\)&lt;/span&gt;)。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
MSE(T) &amp;amp;= E[(T-\theta)^2] \\
       &amp;amp;= E\{[T-E(T)+E(T)-\theta]^2\} \\
       &amp;amp;= E\{[T-E(T)]^2+[E(T)-\theta]^2 \\
       &amp;amp; \;\;\;\;\; \;\;+2[T-E(T)][E(T)-\theta]\} \\
       &amp;amp;= E\{[T-E(T)]^2\}+E\{[E(T)-\theta]^2\} + 0\\
       &amp;amp;= Var(T) + [bias(T)^2]
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;總體方差的估計自由度&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;總體方差的估計，自由度&lt;/h3&gt;
&lt;p&gt;如果 &lt;span class=&#34;math inline&#34;&gt;\(Y_i \sim (\mu, \sigma^2)\)&lt;/span&gt;，並不需要默認或者假定它服從正態分佈或者任何分佈。那麼它的方差我們會用：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[V_{\mu}=\frac{1}{n}\sum_{i=1}^n(Y_i-\mu)\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;證明-v_mu-是-sigma2-的無偏估計&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明 &lt;span class=&#34;math inline&#34;&gt;\(V_{\mu}\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 的無偏估計：&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
V_{\mu} &amp;amp;= \frac{1}{n}\sum_{i=1}^n(Y_i-\mu) \\
需要證明 &amp;amp;E(V_{\mu}) = \sigma^2 \\
\Rightarrow E(V_{\mu}) &amp;amp;= \frac{1}{n}\sum_{i=1}^nE(Y_i-\mu)^2 \\
        &amp;amp;= \frac{1}{n}\sum_{i=1}^nVar(Y_i) \\
        &amp;amp;= \frac{1}{n}\sum_{i=1}^n\sigma^2 \\
        &amp;amp;= \sigma^2
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然而通常情況下，我們並不知道總體的均值 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;。因此，只好用樣本的均值 &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}\)&lt;/span&gt; 來估計 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;。所以上面的方程就變成了：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[V_{\mu}=\frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;你如果仔細觀察認真思考，就會發現，上面這個式子是&lt;code&gt;有問題的&lt;/code&gt;。這個大問題就在於，&lt;span class=&#34;math inline&#34;&gt;\(Y_i-\bar{Y}\)&lt;/span&gt; 中我們忽略掉了樣本均值 &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}\)&lt;/span&gt; 和總體均值 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 之間的差 (&lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}-\mu\)&lt;/span&gt;)。因此上面的計算式來估計總體方差時，很顯然是會低估平均平方差，從而低估了總體方差。&lt;/p&gt;
&lt;p&gt;這裏需要引入&lt;strong&gt;自由度 (degree of freedom)&lt;/strong&gt; 在參數估計中的概念。&lt;/p&gt;
&lt;p&gt;字面上可以理解爲：自由度是估計過程中使用了多少互相獨立的信息。所以在上面第一個公式中：&lt;span class=&#34;math inline&#34;&gt;\(V_{\mu}=\frac{1}{n}\sum_{i=1}^n(Y_i-\mu)\)&lt;/span&gt;。所有的 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個觀察值互相獨立，不僅如此，他們還對總體均值獨立。然而在第二個我們用 &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}\)&lt;/span&gt; 取代了 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 的公式中，樣本均數則與觀察值不互相獨立。因爲&lt;strong&gt;樣本均數必然總是落在觀察值的中間&lt;/strong&gt;。然而總體均數並不一定就會落在觀察值中間。總體均數，和觀察值之間是自由，獨立的。因此，當我們觀察到 &lt;span class=&#34;math inline&#34;&gt;\(n-1\)&lt;/span&gt; 個觀察值時，剩下的最後一個觀察值，決定了樣本均值的大小。所以說，樣本均值的自由度，是 &lt;span class=&#34;math inline&#34;&gt;\(n-1\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;所以，加入了自由度的討論，我們可以相信，用樣本估計總體的方差時，使用下面的公式將會是總體方差的無偏估計：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[V_{n-1}=\frac{1}{n-1}\sum_{i=1}^n(Y_i-\bar{Y})=\frac{n}{n-1}V_n\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;證明-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明&lt;/h4&gt;
&lt;p&gt;利用上面也用到過的證明方法 – 把樣本和總體均值之間的差分成兩部分：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
V_{\mu} &amp;amp;= \frac{1}{n}\sum_{i=1}^n(Y_i-\mu)^2 \\
        &amp;amp;= \frac{1}{n}\sum_{i=1}^n[(Y_i-\bar{Y})+(\bar{Y}-\mu)]^2 \\
        &amp;amp;= \frac{1}{n}\sum_{i=1}^n[(Y_i-\bar{Y})^2+(\bar{Y}-\mu)^2\\
        &amp;amp;\;\;\;\;\;\;\;\;\;\;\;\;+2(Y_i-\bar{Y})(\bar{Y}-\mu)]\\
        &amp;amp;=\frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y})^2+\frac{1}{n}\sum_{i=1}^n(\bar{Y}-\mu)^2\\
        &amp;amp;\;\;\;\;\;\;\;\;\;\;\;\;+\frac{2}{n}(\bar{Y}-\mu)\sum_{i=1}^n(Y_i-\bar{Y}) \\
        &amp;amp;= V_n+(\bar{Y}-\mu)^2 \\ &amp;amp;\;\;\;\;\;\;\;\;\;\;\;\;(note\;that\;\sum_{i=1}^n(Y_i-\bar{Y})=0) \\
\Rightarrow  V_n &amp;amp;= V_{\mu}-(\bar{Y}-\mu)^2  \\
\therefore E(V_n)&amp;amp;= E(V_{\mu}) - E[(\bar{Y}-\mu)^2] \\
                 &amp;amp;= Var(Y)-Var(\bar{Y}) \\
                 &amp;amp;= \sigma^2-\frac{\sigma^2}{n} \\
                 &amp;amp;= \sigma^2(\frac{n-1}{n})
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;因此，我們看見 &lt;span class=&#34;math inline&#34;&gt;\(V_n\)&lt;/span&gt; 正如上面討論的那樣，是低估了總體方差的。雖然當 &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow\infty\)&lt;/span&gt; 時無限接近 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 但是依然是低估了的。所以，我們可以對之進行修正：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E[\frac{n}{n-1}V_n]     &amp;amp;= \frac{n}{n-1}E[V_n] =\sigma^2 \\
\Rightarrow E[V_{n-1}]  &amp;amp;= \sigma^2
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;樣本方差的樣本分佈&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;樣本方差的樣本分佈&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt; 常用來標記樣本方差，取代上面我們用到的 &lt;span class=&#34;math inline&#34;&gt;\(V_{n-1}\)&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[S^2=\frac{1}{n-1}\sum_{i=1}^n(Y_i-\bar{Y})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;而且上面也證明了，&lt;span class=&#34;math inline&#34;&gt;\(E(S^2)=\sigma^2\)&lt;/span&gt; 是總體方差的無偏估計。然而，要注意的是，樣本標準差 &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{S^2}\)&lt;/span&gt; 卻不是總體標準差 &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; 的無偏估計（因爲並不是線性變換，而是開了根號）。&lt;/p&gt;
&lt;div id=&#34;證明樣本標準差-s-不是總體標準差-sigma-的無偏估計&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明樣本標準差 &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; 不是總體標準差 &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; 的無偏估計&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
Var(S)               &amp;amp;=E(S^2)-[E(S)]^2 \\
\Rightarrow [E(S)]^2 &amp;amp;=E(S^2)-Var(S) \\
\because E(S^2)      &amp;amp;=\sigma^2 \\
\therefore   [E(S)]^2 &amp;amp;=\sigma^2-Var(S) \\
             E(S)     &amp;amp;=\sqrt{\sigma^2-Var(S)} \\
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可見樣本標準差是低估了總體標準差的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;另外可以被證明的是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{n-1}{\sigma^2}S^2\sim \mathcal{X}_{n-1}^2\\
Var(S^2)=\frac{2\sigma^4}{n-1}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{X}^2_m\)&lt;/span&gt;： 自由度爲 &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; 的&lt;a href=&#34;https://winterwang.github.io/post/chi-square-distribution/&#34;&gt;卡方分佈&lt;/a&gt;。是在圖形上向右歪曲的分佈。當自由度增加時，會越來越接近正態分佈。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>概率論者統計推斷入門之-被門夾住</title>
      <link>https://wangcc.me/post/frequentist-statistical-inference01/</link>
      <pubDate>Tue, 24 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/frequentist-statistical-inference01/</guid>
      <description>


&lt;div id=&#34;人羣與樣本-population-and-sample&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;人羣與樣本 (population and sample)&lt;/h3&gt;
&lt;p&gt;討論樣本時，需考慮下面幾個問題：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;樣本是否具有代表性？&lt;/li&gt;
&lt;li&gt;人羣被準確定義了嗎？&lt;/li&gt;
&lt;li&gt;我們感興趣的“人羣”是否可以是無限大（多）的？&lt;/li&gt;
&lt;li&gt;我們研究的樣本，是僅僅用來觀察，亦或是計劃對之進行某種干預呢？&lt;/li&gt;
&lt;li&gt;我們從所有可能的人羣中抽樣了嗎？&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;樣本和統計量-sample-and-statistic&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;樣本和統計量 (sample and statistic)&lt;/h3&gt;
&lt;p&gt;通常我們在進行實驗或觀察時只是獲得了樣本的數據。而希望從樣本數據去推斷 (inference) 總體（或人羣）的一些特徵。我們也許只是想用樣本的平均值來估計整體人羣的某個特徵的平均值。不管是何種估計和推斷，都是基於對樣本數據的計算，從樣本中獲得想要推斷總體的&lt;strong&gt;統計量 (statistics)&lt;/strong&gt;。我們用已知樣本去推斷未知總體的過程就叫做&lt;strong&gt;估計 (estimate)&lt;/strong&gt;。這個想要被推斷的總體或人羣的值，被叫做&lt;strong&gt;參數 (parameter)&lt;/strong&gt;，常常使用希臘字母來標記。用來估計總體或人羣的，從樣本數據計算得來的統計量，叫做&lt;strong&gt;估計量 (estimator)&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;所有的統計量，都有&lt;strong&gt;樣本分佈 (sampling distributions，意爲重複無限次取樣後獲得的無限次統計量的分佈)&lt;/strong&gt;。推斷的過程歸納如下：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;從總體或人羣中抽樣 (樣本量 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;)&lt;/li&gt;
&lt;li&gt;計算這個樣本的合適統計量，從而用於估計它在整體或人羣中的值。&lt;/li&gt;
&lt;li&gt;我們還需要決定計算獲得的統計量的樣本分佈（假定會抽樣無數次）。&lt;/li&gt;
&lt;li&gt;一旦可以精確地確認樣本分佈，我們就可以定量地計算出使用步驟2中獲得的統計量估計總體或人羣的參數時的準確度。&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;估計-estimation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;估計 Estimation&lt;/h3&gt;
&lt;p&gt;從樣本的均值，推斷總體或人羣的均值是一種估計。我們的目的是，從已知樣本中計算一個儘可能接近那個未知的總體或人羣參數的值。一個估計量有兩個與生俱來的性質 (properties)：1) 偏倚 (bias); 2) 精確度 (precision)。這兩個性質都可以從樣本分佈和估計量獲得。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;偏倚： 偏倚簡單說就是樣本分佈的均值，也就是我們從樣本中計算獲得的估計量，和我們想要拿它來估計的總體或人羣的參數之間的差距。(The bias is the difference between the mean of the sampling distribution – the expected or average value of the estimator – and the population parameter being estimated.) 一個小的偏倚，確保了我們從樣本中計算獲得的估計值（假設我們抽樣無數次，計算無數個樣本估計值）&lt;strong&gt;均勻地&lt;/strong&gt;分佈在總體或人羣參數的左右兩邊。偏倚本身並不是太大的問題，但是假如樣本量增加，偏倚依然存在（估計量不一致, inconsistent），那常常意味着是抽樣過程出現了問題。例如：&lt;br&gt;用簡單隨機抽樣法獲得的樣本均值，就是總體或人羣均值的無偏估計 (unbiased estimator)。如果抽樣時由於某些主觀客觀的原因導致較小的樣本很少被抽樣（抽樣過程出了問題，脫離了簡單隨機抽樣原則），那麼此時得到的樣本均值就會是一個過高的估計值 (upward biased estimator)。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;精確度：估計值的精確度可以通過樣本分佈的方差或標準差來評價（簡單說是樣本分佈的方差越低，波動越小，精確度越高）。樣本分佈的標準差被定義爲估計值的標準誤。假如估計量是樣本均值，那麼樣本分佈的標準差（估計量的標準誤）和樣本數據之間有如下的關係：
&lt;span class=&#34;math display&#34;&gt;\[均值的標準誤 = \frac{樣本數據的標準差}{\sqrt{樣本量大小}}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在一些簡單的情況下，通常估計值的選用不言自明（例如均值，或者百分比）。但是在複雜的情況下，我們可能可以有多個不同類型的估計量可以選擇，他們也常常各有利弊，需要我們做出取捨。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;信賴區間-confidence-intervals&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;信賴區間 confidence intervals&lt;/h3&gt;
&lt;p&gt;從樣本中計算估計量獲得的一個估計值，只是一個&lt;strong&gt;點估計 (point estimate)&lt;/strong&gt;。對比之下，信賴區間就是一個對這個點估計的精確度的體現。信賴區間越窄，說明我們對於總體或人羣的參數的可能取值的範圍估計越精確。&lt;/p&gt;
&lt;p&gt;信賴區間通常是成對成對的出現的，即有上限和下限。這樣的一對從樣本數據中計算得來的統計量，同樣也是有樣本分佈的。&lt;strong&gt;每次我們重新從總體或人羣中抽樣，計算獲得的信賴區間都不同，這些信賴區間就組成了信賴區間的樣本分佈。總體和人羣的參數落在這些信賴區間範圍內的概率，就是我們常說的信賴區間的水平（&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt;）。&lt;/strong&gt; 常用的這個概率值就是 &lt;span class=&#34;math inline&#34;&gt;\(95\%, 90\%, 99\%\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;當從樣本數據計算獲得的估計量的信賴區間很寬，說明了這個收集來的數據提供了很少的參數信息，導致估計變得很不精確。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;看到這裏的都是好漢一條啊！ 我不知道你暈了麼有，反正我是已經暈了。。。。&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>中心極限定理的應用</title>
      <link>https://wangcc.me/post/central-limit-theorem-application/</link>
      <pubDate>Sat, 21 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/central-limit-theorem-application/</guid>
      <description>


&lt;div id=&#34;二項分佈的正態分佈近似&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;二項分佈的正態分佈近似&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;假設我們有大量(&lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow\infty\)&lt;/span&gt;)的二項分佈實驗 &lt;span class=&#34;math inline&#34;&gt;\(X\sim Bin(n, \pi)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;根據&lt;a href=&#34;https://winterwang.github.io/post/probability3/&#34;&gt;二項分佈的概率公式&lt;/a&gt;，計算將會變得很繁瑣複雜。&lt;/li&gt;
&lt;li&gt;解決辦法：應用中心極限定理。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/post/probability3/&#34;&gt;中心極限定理&lt;/a&gt;告訴我們，當樣本量足夠大時:
&lt;span class=&#34;math display&#34;&gt;\[X\sim N（n\pi, n\pi(1-\pi))\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;問題在於，多大的 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 才能算大樣本呢？
&lt;ul&gt;
&lt;li&gt;當且僅當 (only and if only) &lt;span class=&#34;math inline&#34;&gt;\(n&amp;gt;20\)&lt;/span&gt; AND &lt;span class=&#34;math inline&#34;&gt;\(n\pi&amp;gt;5\)&lt;/span&gt; AND &lt;span class=&#34;math inline&#34;&gt;\(n(1-\pi)&amp;gt;5\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;泊松分佈的正態分佈近似&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;泊松分佈的正態分佈近似&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;假設時間 &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; 內某事件的發生次數服從泊松分佈 &lt;span class=&#34;math inline&#34;&gt;\(X\sim Po(\mu)\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;考慮將這段時間 &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; 等分成 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個時間段。那麼第 &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; 時間段內事件發生次數依舊服從泊松分佈 &lt;span class=&#34;math inline&#34;&gt;\(X_i\sim Po(\frac{\mu}{n})\)&lt;/span&gt;。且 &lt;span class=&#34;math inline&#34;&gt;\(E(X_i)=\mu/n, Var(X_i)=\mu/n\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;那麼原先的 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 可以被視爲是將這無數的小時間段的 &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt; 相加。應用中心極限定理：
&lt;span class=&#34;math display&#34;&gt;\[X=\sum_{i=1}^nX_i\sim N(\frac{n\mu}{n}, \frac{n\mu}{n})\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;需要注意的是，這段時間 (&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;) 內發生的事件次數 (&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;) : &lt;span class=&#34;math inline&#34;&gt;\(\lambda t =\mu&amp;gt;10\)&lt;/span&gt; ，這樣的正態分佈模擬才能成立。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;正態分佈模擬的校正continuity-corrections&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;正態分佈模擬的校正：continuity corrections&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;如果我們使用正態分佈來模擬離散變量的分佈，常常需要用到正態分佈模擬的矯正。&lt;/li&gt;
&lt;li&gt;例如：我們如果用正態分佈模擬來計算 &lt;span class=&#34;math inline&#34;&gt;\(P(X=15)\)&lt;/span&gt;，那麼實際上我們應該計算的是 &lt;span class=&#34;math inline&#34;&gt;\(P(14.5&amp;lt;X&amp;lt;15.5)\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;例題&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;例題&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;已知 &lt;span class=&#34;math inline&#34;&gt;\(X\sim Bin(100,0.5)\)&lt;/span&gt;，求 &lt;span class=&#34;math inline&#34;&gt;\(P(X&amp;gt;60)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;解&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\because X&amp;amp;\sim Bin(100, 0.5) \\ \therefore E(X) &amp;amp;=n\pi=50 \\
Var(X) &amp;amp;= n\pi(1-\pi) =25=5^2\\
P(X&amp;gt;60)  &amp;amp;= 1-P(X\leqslant60) \\
         &amp;amp;= 1-P(Z\leqslant\frac{60.5-50}{\sqrt{25}}) \\
         &amp;amp;= 1-P(Z\leqslant2.1) \\
         &amp;amp;= 1-\Phi(2.1) \\
         &amp;amp;= 1-0.982 = 0.018
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 快來看實際用傻瓜算法計算獲得的概率：
1-pbinom(60, size=100, prob=0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0176001&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 快來看用中心極限定理模擬正態分佈獲得的概率：
1-pnorm((60.5-50)/sqrt(25))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.01786442&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-10-21-central-limit-theorem-application_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;已知 &lt;span class=&#34;math inline&#34;&gt;\(X\sim Bin(48, 0.75)\)&lt;/span&gt;, 求 &lt;span class=&#34;math inline&#34;&gt;\(P(30&amp;lt;X&amp;lt;39)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;解-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\because B &amp;amp;\; \sim Bin(48, 0.75) \\
\therefore E(X) &amp;amp;\; =n\pi=36 \\
           Var(X) &amp;amp;\; =n\pi(1-\pi)=9=3^2 \\
P(30&amp;lt;X&amp;lt;39) &amp;amp;\; = P(31\leqslant X\leqslant 38)\\
     &amp;amp;\; = P(30.5\leqslant Y \leqslant 38.5) \\
     Y\;is\;the&amp;amp;\;normal\;approximation \\
     &amp;amp;\;= P(Y&amp;lt;38.5) - P(Y&amp;lt;30.5) \\
     &amp;amp;\;= P(Z\leqslant\frac{38.5-36}{3})-
          P(Z\leqslant\frac{30.5-36}{3}) \\
     &amp;amp;\;= P(Z\leqslant0.833) - P(Z\leqslant-1.833) \\
     &amp;amp;\;= \Phi(0.833)-\Phi(-1.833) \\
     &amp;amp;\;= 0.798-0.033 = 0.764
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 快來看實際用傻瓜算法計算獲得的概率：
pbinom(38, size=48, prob=0.75)-pbinom(30, size=48, prob=0.75)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7578159&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 快來看用中心極限定理模擬正態分佈獲得的概率：
pnorm((38.5-36)/sqrt(9)) - pnorm((30.5-36)/sqrt(9))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7642951&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-10-21-central-limit-theorem-application_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;從上面兩個例題也能看出，&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 越小，正態分佈模擬的誤差就越大。&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;已知 &lt;span class=&#34;math inline&#34;&gt;\(X \sim Poisson(30)\)&lt;/span&gt; 求 &lt;span class=&#34;math inline&#34;&gt;\(P(X\leqslant20)\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;解-2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\because E(X)=\mu=30, \;Var(X)=\mu=30=(\sqrt{30})^2 \\
 \begin{aligned}
 Pr(X\leqslant20) &amp;amp;= P(Z\leqslant\frac{20.5-30}{\sqrt{30}}) \\
                  &amp;amp;= P(Z\leqslant-1.734) \\
                  &amp;amp;= \Phi(-1.734) \\
                  &amp;amp;= 0.0414
 \end{aligned}
 \]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 快來看實際用傻瓜算法計算獲得的概率：
ppois(20, lambda=30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.03528462&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 快來看用中心極限定理模擬正態分佈獲得的概率：
pnorm((20.5-30)/sqrt(30))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.04141871&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;這兩個其實有些小差距。不過看下圖，其模擬還是很到位的。只是正態分佈的面積明顯確實比泊松分佈的小柱子面積要大一些。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-10-21-central-limit-theorem-application_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;已知 &lt;span class=&#34;math inline&#34;&gt;\(X_1, X_2 \stackrel{i.i.d}{\sim} Poi(30)\)&lt;/span&gt; 求 &lt;span class=&#34;math inline&#34;&gt;\(P(X_1+X_2\leqslant40)\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;解-3&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E(X_1+X_2) &amp;amp;\;= E(X_1)+E(X_2) = 30+30 = 60\\
Var(X_1+X_2) &amp;amp;\;= Var(X_1)+Var(X_2) = 30+30 \\
             &amp;amp;\;= (\sqrt{60})^2 \\
P(X_1+X_2\leqslant 40) &amp;amp;\;= P(Z \leqslant \frac{40.5-60}{\sqrt{60}}) \\
           &amp;amp;\;= P(Z\leqslant-2.517) \\
           &amp;amp;\;= \Phi(-2.517) \\
           &amp;amp;\;= 0.006
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 快來看實際用傻瓜算法計算獲得的概率：
ppois(40, lambda=60)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.00398281&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 快來看用中心極限定理模擬正態分佈獲得的概率：
pnorm((40.5-60)/sqrt(60))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.005910569&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-10-21-central-limit-theorem-application_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;
又一次，正態分佈的面積比泊松分佈的小柱子面積要大一些。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;兩個連續隨機變量&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;兩個連續隨機變量&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;假定 &lt;span class=&#34;math inline&#34;&gt;\(X_1, X_2\)&lt;/span&gt; 是兩個連續隨機變量：
&lt;span class=&#34;math display&#34;&gt;\[E(X_1)=\mu_1, Var(X_1)=\sigma_1^2 \\
E(X_2)=\mu_2, Var(X_2)=\sigma_2^2 \\
Corr(X_1, X_2)=\rho \Rightarrow Cov(X_1, X_2)=\rho\sigma_1\sigma_2=\sigma_{12}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;利用矩陣的標記法，可以將 &lt;span class=&#34;math inline&#34;&gt;\(X_1, X_2\)&lt;/span&gt; 標記爲 &lt;span class=&#34;math inline&#34;&gt;\(\textbf{X}=(X_1, X_2)^T\)&lt;/span&gt;, 即：
&lt;span class=&#34;math display&#34;&gt;\[\textbf{X}=\left(
\begin{array}{c}
X_1\\
X_2\\
\end{array}
\right)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;上面的所有內容都可以標記爲：
&lt;span class=&#34;math display&#34;&gt;\[E(\textbf{X})=\mathbf{\mu}=\left(
\begin{array}{c}
\mu_1\\
\mu_2\\
\end{array}
\right)\\
Covariance \;matrix: \\
Var(\textbf{X})=\mathbf{\Sigma}=\left(
\begin{array}{c}
\sigma_1^2 &amp;amp; \sigma_{12}\\
\sigma_{12} &amp;amp; \sigma_1^2\\
\end{array}
\right)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;兩個連續隨機變量-例子&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;兩個連續隨機變量 例子：&lt;/h2&gt;
&lt;p&gt;假如要看收縮期血壓 (&lt;span class=&#34;math inline&#34;&gt;\(SBP\)&lt;/span&gt;) 和舒張期血壓 (&lt;span class=&#34;math inline&#34;&gt;\(DBP\)&lt;/span&gt;) 之間的關係：&lt;/p&gt;
&lt;p&gt;下列爲已知條件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(SBP\)&lt;/span&gt; 的均值爲 &lt;span class=&#34;math inline&#34;&gt;\(130\)&lt;/span&gt;， 標準差爲 &lt;span class=&#34;math inline&#34;&gt;\(15\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(DBP\)&lt;/span&gt; 的均值爲 &lt;span class=&#34;math inline&#34;&gt;\(90\)&lt;/span&gt;, 標準差爲 &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(SBP\)&lt;/span&gt; 和 &lt;span class=&#34;math inline&#34;&gt;\(DBP\)&lt;/span&gt; 之間的相關係數爲 &lt;span class=&#34;math inline&#34;&gt;\(0.75\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那麼， 我們可以把這些信息用下面的方法來標記：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(\textbf{X})=\mathbf{\mu}=\left(
\begin{array}{c}
130\\
90\\
\end{array}
\right)\\
Var(\textbf{X})=\mathbf{\Sigma}=\left(
\begin{array}{c}
225 &amp;amp; 112.5\\
112.5 &amp;amp; 225\\
\end{array}
\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;條件分佈和邊緣分佈的概念&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;條件分佈和邊緣分佈的概念&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;如果 &lt;span class=&#34;math inline&#34;&gt;\(\textbf{X}=(X_1, X_2)^T\)&lt;/span&gt; 的兩個變量都服從正態分佈；&lt;/li&gt;
&lt;li&gt;&lt;p&gt;那麼這兩個變量的邊緣分佈 (marginal distribution) 也服從正態分佈:
&lt;span class=&#34;math display&#34;&gt;\[X_1\sim N(\mu_1,\sigma_1^2), X_2\sim N(\mu, \sigma_2^2)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;同樣的，&lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt; 的給出 &lt;span class=&#34;math inline&#34;&gt;\(X_2\)&lt;/span&gt; 的條件分佈 (condition distribution) 也服從正態分佈：
&lt;span class=&#34;math display&#34;&gt;\[E(X_1|X_2)=\mu_1+\frac{\rho\sigma_1}{\sigma_2}(X_2-\mu_2) \\
 Var(X_1|X_2)=\sigma_1^2(1-\rho^2)\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;反之亦然。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;條件分佈和邊緣分佈的例子&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;條件分佈和邊緣分佈的例子&lt;/h2&gt;
&lt;p&gt;上面的概念過於抽象，用血壓的例子：&lt;/p&gt;
&lt;p&gt;收縮期血壓和舒張期血壓各自服從正態分佈。那麼可以用上面的概念來寫出已知舒張期血壓時，收縮期血壓的分佈。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;條件期望:
&lt;span class=&#34;math display&#34;&gt;\[E(SBP|DBP)=130+\frac{0.75\times15}{10}(DBP-90)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;實際如果來了一個病人，他說他只記得自己測的舒張期血壓是95：&lt;br&gt;
他的收縮期血壓的期望值就可以用上面的式子計算：
&lt;span class=&#34;math display&#34;&gt;\[E(SBP|DBP=95)=136\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;條件方差爲：
&lt;span class=&#34;math display&#34;&gt;\[Var(SBP|DBP)=15^2(1-0.75^2)=98.4\approx9.92^2&amp;lt;15^2\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;所以當我們知道了這個人的一部分信息以後，推測他的另一個相關連的變量變得更加準確(&lt;strong&gt;方差變小&lt;/strong&gt;)了。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;例題-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;例題&lt;/h3&gt;
&lt;p&gt;有 (閒) 人記錄了 &lt;span class=&#34;math inline&#34;&gt;\(1494\)&lt;/span&gt; 名兒童在 &lt;span class=&#34;math inline&#34;&gt;\(2, 4, 6\)&lt;/span&gt; 歲時的腿長度。已知在記錄的這三個年齡時的平均腿長度分別爲 &lt;span class=&#34;math inline&#34;&gt;\(85 cm, 103cm, 114cm\)&lt;/span&gt;。協方差矩陣如下:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left(
\begin{array}{c}
22.2 &amp;amp; 11.8 &amp;amp; 13.7\\
11.8 &amp;amp; 26.3 &amp;amp; 21.5\\
13.7 &amp;amp; 21.5 &amp;amp; 29.0
\end{array}
\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;假定，這三個年齡記錄的這些兒童的腿長度數據（聯合分佈, joint distribution）服從三個變量正態分佈。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;求 &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; 歲時這些兒童的腿長度的邊緣分佈 (marginal distribution)&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;解-4&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X_{age=2} \sim N(85, \sigma_{age=2}^2=22.2)\]&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;求他們 &lt;span class=&#34;math inline&#34;&gt;\(6\)&lt;/span&gt; 歲時腿長度的 &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; 歲時的條件分佈。(Find the distribution of leg length age 6 conditional on leg length at age 2.)&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;解-5&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(6\)&lt;/span&gt; 歲時和 &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; 歲時腿長的相關係數 (correlation, &lt;span class=&#34;math inline&#34;&gt;\(\rho_{6,2}\)&lt;/span&gt;) 爲：
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\rho_{6,2} &amp;amp;= \frac{Cov_{6,2}}{\sqrt{Var(length_6)}\sqrt{Var(length_2)}}\\
&amp;amp;= \frac{13.7}{\sqrt{22.2}\sqrt{29}}=0.54
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;條件分佈套用上面提到的公式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
E(length_6 | length_2) &amp;amp;= \mu_6+\frac{\rho_{6,2}\sigma_6}{\sigma_2}(length_2-\mu_2) \\
&amp;amp;= 114+\frac{0.54\times\sqrt{29.0}}{\sqrt{22.2}}(length_2-85)\\
Var(length_6 | length_2) &amp;amp;= \sigma_6^2(1-\rho_{6,2}^2) \\
                         &amp;amp;= 29.0\times(1-0.54^2) =20.5
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>偉大的中心極限定理</title>
      <link>https://wangcc.me/post/central-limit-theory/</link>
      <pubDate>Thu, 19 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/central-limit-theory/</guid>
      <description>


&lt;p&gt;最近明顯可以感覺到課程的步驟開始加速。看我的課表：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0522.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;手機畫面太小了。早上都是9點半開始，下午基本都是到5點。週一更慘，到7點。週二-週五中午都被統計中心的講座佔據。簡直是非人的生活。&lt;/p&gt;
&lt;p&gt;這周概率論基礎結束。中心極限定理講完以後我們正式進入了 Inference 統計推斷的課程。我們花了一天時間講什麼是樣本估計 (Estimation)，什麼是參數精確度 (Precision)，什麼是自由度 (degree of freedom)，怎樣進行不偏的估計 (unbiased inference)。然後還有似然方程 (likelihood function)。&lt;/p&gt;
&lt;p&gt;今天的更新還是簡單的把概率論掃尾一下。感受一下中心極限定理的偉大。&lt;/p&gt;
&lt;div id=&#34;協方差-covariance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;協方差 Covariance&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/post/probability2-4/&#34;&gt;之前我們定義過&lt;/a&gt;，兩個獨立連續隨機變量 &lt;span class=&#34;math inline&#34;&gt;\(X,Y\)&lt;/span&gt; 之和的方差 Variance ：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var(X+Y)=Var(X)+Var(Y)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然而如果他們並不相互獨立的話：&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
Var(X+Y) &amp;amp;= E[((X+Y)-E(X+Y))^2] \\
         &amp;amp;= E[(X+Y)-(E(X)+E(Y))^2] \\
         &amp;amp;= E[(X-E(X)) - (Y-E(Y))^2] \\
         &amp;amp;= E[(X-E(X))^2+(Y-E(Y))^2 \\
         &amp;amp; \;\;\; +2(X-E(X))(Y-E(Y))] \\
         &amp;amp;= Var(X)+Var(Y)+2E[(X-E(X))(Y-E(Y))]
\end{aligned}\]&lt;/span&gt;
&lt;p&gt;可以發現在兩者和的方差公式展開之後多了一部分 &lt;span class=&#34;math inline&#34;&gt;\(E[(X-E(X))(Y-E(Y))]\)&lt;/span&gt;。 這個多出來的一部分就說明了二者 &lt;span class=&#34;math inline&#34;&gt;\((X, Y)\)&lt;/span&gt; 之間的關係。它被定義爲協方差 (Covariance):
&lt;span class=&#34;math display&#34;&gt;\[Cov(X,Y) = E[(X-E(X))(Y-E(Y))]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    要記住，協方差只能用於評價&lt;span class=&#34;math inline&#34;&gt;(X,Y)&lt;/span&gt;之間的線性關係 (Linear Association)。
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;以下是協方差 (Covariance) 的一些特殊性質：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(X,X)=Var(X)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(X,Y)=Cov(Y,X)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(aX,bY)=ab\:Cov(X,Y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(aR+bS,cX+dY)=ac\:Cov(R,X)+ad\:Cov(R,Y)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+bc\:Cov(S,X)+bd\:Cov(S,Y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(aX+bY,cX+dY)=ac\:Var(X)+ad\:Var(Y)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+(ad+bc)Cov(X,Y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(X+Y,X-Y)=Var(X)-Var(Y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;If &lt;span class=&#34;math inline&#34;&gt;\(X, Y\)&lt;/span&gt; are independent. &lt;span class=&#34;math inline&#34;&gt;\(Cov(X,Y)=0\)&lt;/span&gt; &lt;span class=&#34;diff_alert&#34;&gt;But not vise-versa !&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;相關-correlation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;相關 Correlation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;協方差雖然&lt;span class=&#34;math inline&#34;&gt;\(Cov(X,Y)\)&lt;/span&gt; 的大小很大程度上會被他們各自的單位和波動大小左右。&lt;/li&gt;
&lt;li&gt;我們將協方差標準化(除以各自的標準差 s.d.) (standardization) 之後，就可以得到相關係數 Corr (&lt;span class=&#34;math inline&#34;&gt;\(-1\sim1\)&lt;/span&gt;):
&lt;span class=&#34;math display&#34;&gt;\[Corr(X,Y)=\frac{Cov(X,Y)}{SD(X)SD(Y)}=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;中心極限定理-the-central-limit-theory&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;中心極限定理 the Central Limit Theory&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;diff_add&#34;&gt;&lt;strong&gt;如果從人羣中多次選出樣本量爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 的樣本，並計算樣本均值, &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}_n\)&lt;/span&gt;。那麼這個樣本均值 &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}_n\)&lt;/span&gt; 的分佈，會隨着樣本量增加 &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow\infty\)&lt;/span&gt;，而接近正態分佈。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;偉大的中心極限定理告訴我們：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;diff_alert&#34;&gt;&lt;strong&gt;當樣本量足夠大時，樣本均值 &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}_n\)&lt;/span&gt; 的分佈爲正態分佈，這個特性與樣本來自的人羣的分佈 &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt; 無關。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;再說一遍：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果對象是獨立同分佈 i.i.d (identically and independently distributed)。那麼它的總體期望和方差分別是: &lt;span class=&#34;math inline&#34;&gt;\(E(X)=\mu;\;Var(X)=\sigma^2\)&lt;/span&gt;。
根據中心極限定理，可以得到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;當樣本量增加，樣本均值的分佈服從正態分佈：
&lt;span class=&#34;math display&#34;&gt;\[\bar{X}_n\sim N(\mu, \frac{\sigma^2}{n})\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;也可以寫作，當樣本量增加：
&lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^nX_i \sim N(n\mu,n\sigma^2)\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;有了這個定理，我們可以拋開樣本空間(&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;)的分佈，也不用假定它服從正態分佈。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;diff_alert&#34;&gt;但是樣本的均值，卻總是服從正態分佈的。&lt;/span&gt;簡直是太完美了！！！！！！&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>你買的彩票中獎概率到底有多少？</title>
      <link>https://wangcc.me/post/probability3/</link>
      <pubDate>Wed, 11 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/probability3/</guid>
      <description>


&lt;div id=&#34;二項分佈的概念-binomial-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;二項分佈的概念 Binomial distribution&lt;/h3&gt;
&lt;p&gt;二項分佈在醫學研究中至關重要，一組二項分佈的數據，指的通常是 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 次相互獨立的&lt;a href=&#34;https://winterwang.github.io/post/probability2-4/&#34;&gt;成功率爲 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 的伯努利實驗&lt;/a&gt; (&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; independent Bernoulli trials) 中成功的次數。&lt;/p&gt;
&lt;p&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 服從二項分佈，記爲 &lt;span class=&#34;math inline&#34;&gt;\(X \sim binomial(n, \pi)\)&lt;/span&gt; 或&lt;span class=&#34;math inline&#34;&gt;\(X \sim bin(n, \pi)\)&lt;/span&gt;。它的(第 &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; 次實驗的)概率被定義爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
P(X=x) &amp;amp;= ^nC_x\pi^x(1-\pi)^{n-x} \\
       &amp;amp;= \binom{n}{x}\pi^x(1-\pi)^{n-x} \\
       &amp;amp; for\;\; x = 0,1,2,\dots,n
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;二項分佈的期望和方差&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;二項分佈的期望和方差&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;期望 &lt;span class=&#34;math inline&#34;&gt;\(E(X)\)&lt;/span&gt;
&lt;ul&gt;
&lt;li&gt;若 &lt;span class=&#34;math inline&#34;&gt;\(X \sim bin(n,\pi)\)&lt;/span&gt;，那麼 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 就是這一系列獨立伯努利實驗中成功的次數。&lt;/li&gt;
&lt;li&gt;用 &lt;span class=&#34;math inline&#34;&gt;\(X_i, i =1,\dots, n\)&lt;/span&gt; 標記每個相互獨立的伯努利實驗。&lt;/li&gt;
&lt;li&gt;那麼我們可以知道 &lt;span class=&#34;math inline&#34;&gt;\(X=\sum_{i=1}^nX_i\)&lt;/span&gt;。
&lt;span class=&#34;math display&#34;&gt;\[\begin{align} E(X) &amp;amp;= E(\sum_{i=1}^nX_i)\\
                   &amp;amp;= E(X_1+X_2+\cdots+X_n) \\
                   &amp;amp;= E(X_1)+E(X_2)+\cdots+E(X_n)\\
                   &amp;amp;= \sum_{i=1}^nE(X_i)\\
                   &amp;amp;= \sum_{i=1}^n\pi \\
                   &amp;amp;= n\pi
\end{align}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;方差 &lt;span class=&#34;math inline&#34;&gt;\(Var(X)\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
Var(X) &amp;amp;= Var(\sum_{i=1}^nX_i) \\
      &amp;amp;= Var(X_i+X_2+\cdots+X_n) \\
      &amp;amp;= Var(X_i)+Var(X_2)+\cdots+Var(X_n) \\
      &amp;amp;= \sum_{i=1}^nVar(X_i) \\
      &amp;amp;= n\pi(1-\pi) \\
\end{align}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;超幾何分佈-hypergeometric-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;超幾何分佈 hypergeometric distribution&lt;/h3&gt;
&lt;p&gt;假設我們從總人數爲 &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; 的人羣中，採集一個樣本 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;。假如已知在總體人羣中(&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;)有 &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 人患有某種疾病。請問採集的樣本 &lt;span class=&#34;math inline&#34;&gt;\(X=n\)&lt;/span&gt; 中患有這種疾病的人，服從怎樣的分佈？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;從人羣(&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;)中取出樣本(&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;)，有 &lt;span class=&#34;math inline&#34;&gt;\(^NC_n\)&lt;/span&gt; 種方法。&lt;/li&gt;
&lt;li&gt;從患病人羣(&lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;)中取出患有該病的人(&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;)有 &lt;span class=&#34;math inline&#34;&gt;\(^MC_x\)&lt;/span&gt; 種方法。&lt;/li&gt;
&lt;li&gt;樣本中不患病的人(&lt;span class=&#34;math inline&#34;&gt;\(n-x\)&lt;/span&gt;)被採樣的方法有 &lt;span class=&#34;math inline&#34;&gt;\(^{N-M}C_{n-x}\)&lt;/span&gt; 種。&lt;/li&gt;
&lt;li&gt;採集一次 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 人作爲樣本的概率都一樣。因此：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(X=x)=\frac{\binom{M}{x}\binom{N-M}{n-x}}{\binom{N}{n}}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;樂透中獎概率問題&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;樂透中獎概率問題：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;從數字 &lt;span class=&#34;math inline&#34;&gt;\(1\sim59\)&lt;/span&gt; 中選取 &lt;span class=&#34;math inline&#34;&gt;\(6\)&lt;/span&gt; 個任意號碼&lt;/li&gt;
&lt;li&gt;開獎時從 &lt;span class=&#34;math inline&#34;&gt;\(59\)&lt;/span&gt; 個號碼球中隨機抽取 &lt;span class=&#34;math inline&#34;&gt;\(6\)&lt;/span&gt; 個&lt;/li&gt;
&lt;li&gt;如果六個號碼全部猜中(不分順序)，你可以成爲百萬富翁。請問一次猜中全部 &lt;span class=&#34;math inline&#34;&gt;\(6\)&lt;/span&gt; 個號碼的概率是多少？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;從 &lt;span class=&#34;math inline&#34;&gt;\(59\)&lt;/span&gt; 個號碼中隨機取出任意 &lt;span class=&#34;math inline&#34;&gt;\(6\)&lt;/span&gt; 個號碼的方法有 &lt;span class=&#34;math inline&#34;&gt;\(^{59}C_6\)&lt;/span&gt; 種。
&lt;span class=&#34;math display&#34;&gt;\[^{59}C_6=\frac{59!}{6!(59-6)!}=45,057,474\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;每次選取六個號碼做爲一組的可能性相同，所以，你買了一組樂透號碼，能中獎的概率就是 &lt;span class=&#34;math inline&#34;&gt;\(1/45,057,474 = 0.00000002219\)&lt;/span&gt;。你還會再去買彩票麼？&lt;/p&gt;
&lt;div id=&#34;如果我只想中其中的-3-個號碼概率有多大&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;如果我只想中其中的 &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; 個號碼，概率有多大？&lt;/h4&gt;
&lt;p&gt;用超幾何分佈的概率公式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
P(X=3) &amp;amp;= \frac{^6C_3\times ^{53}C_3}{^{59}C_6} \\
       &amp;amp;= 0.010
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;你有 &lt;span class=&#34;math inline&#34;&gt;\(1\%\)&lt;/span&gt; 的可能中獎。換句話說，如果中三個以上的數字算中獎的話，你買的彩票中獎的概率低於 &lt;span class=&#34;math inline&#34;&gt;\(1\%\)&lt;/span&gt;。是不是覺得下次送錢給博彩公司的時候還不如跟我一起喝一杯咖啡划算？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;泊松分佈-poisson-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;泊松分佈 Poisson Distribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;當一個事件，在一段時間 (&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;) 中可能發生的次數是 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 。那麼我們可以認爲，經過時間 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;，該時間發生的期望次數是 &lt;span class=&#34;math inline&#34;&gt;\(E(X)=\lambda T\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;利用微分思想，將這段時間 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 等分成 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個時間段，當 &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow\infty\)&lt;/span&gt; 直到每個微小的時間段內最多發生一次該事件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那麼&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每個微小的時間段，可以視爲是一個伯努利實驗（有事件發生或者沒有）&lt;/li&gt;
&lt;li&gt;那麼這整段時間 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 內發生的事件可以視爲是一個二項分佈實驗。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(X=\)&lt;/span&gt; 一次事件發生時所經過的所有時間段。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(X \sim Bin(n, \pi)\)&lt;/span&gt;，其中 &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow\infty\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 爲時間段。&lt;/li&gt;
&lt;li&gt;在每個分割好的時間段內，事件發生的概率都是：&lt;span class=&#34;math inline&#34;&gt;\(\pi=\frac{\lambda T}{n}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;期望 &lt;span class=&#34;math inline&#34;&gt;\(\mu=\lambda T \Rightarrow \pi=\mu/n\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;所以 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 的概率方程就是：
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
P(X=x) &amp;amp;= \binom{n}{x}\pi^x(1-\pi)^{n-x} \\
     &amp;amp;= \binom{n}{x}(\frac{\mu}{n})^x(1-\frac{\mu}{n})^{n-x} \\
     &amp;amp;= \frac{n!}{x!(n-x)!}(\frac{\mu}{n})^x(1-\frac{\mu}{n})^{n-x} \\
     &amp;amp;=\frac{n!}{n^x(n-x)!}\frac{\mu^x}{x!}(1-\frac{\mu}{n})^{n-x}\\
當 n\rightarrow\infty   &amp;amp;\; x \ll n (x遠小於n) 時\\
\frac{n!}{n^x(n-x)!} &amp;amp;=\frac{n(n-1)\dots(n-x+1)}{n^x} \rightarrow 1\\
(1-\frac{\mu}{n})^{n-x} &amp;amp;\approx  (1-\frac{\mu}{n})^n \rightarrow e^{-\mu}\\
所以 我們可&amp;amp;以得到泊松分佈的概率公式：   \\
P(X=x) &amp;amp;\rightarrow \frac{\mu^x}{x!}e^{-\mu}
\end{align}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當數據服從泊松分佈時，記爲 &lt;span class=&#34;math inline&#34;&gt;\(X\sim Poisson(\mu=\lambda T)\;\; or\;\; X\sim Poi(\mu)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;證明泊松分佈的參數特徵&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;證明泊松分佈的參數特徵：&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(E(X)=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
E(X)  &amp;amp;=  \sum_{x=0}^\infty xP(X=x) \\
      &amp;amp;=  \sum_{x=0}^\infty x\frac{\mu^x}{x!}e^{-\mu} \\
      &amp;amp;= 0+ \sum_{x=1}^\infty x\frac{\mu^x}{x!}e^{-\mu} \\
      &amp;amp;=  \sum_{x=1}^\infty \frac{\mu^x}{(x-1)!}e^{-\mu} \\
      &amp;amp;=  \mu\sum_{x=1}^\infty \frac{\mu^{x-1}}{(x-1)!}e^{-\mu} \\
這個時候我們用i&amp;amp;=x-1 替換掉所有的 x \\
      &amp;amp;=  \mu\sum_{i=0}^\infty \frac{\mu^{i}}{i!}e^{-\mu} \\
注意到右半部分 &amp;amp;\sum_{i=0}^\infty \frac{\mu^{i}}{i!}e^{-\mu}=1 是一個\\泊松分佈的所有&amp;amp;概率和 \\
      &amp;amp;= \mu
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Var(x)=\mu\)&lt;/span&gt;
爲了找到 &lt;span class=&#34;math inline&#34;&gt;\(Var(X)\)&lt;/span&gt;，我們用公式 &lt;span class=&#34;math inline&#34;&gt;\(Var(X)=E(X^2)-E(X)^2\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我們需要找到 &lt;span class=&#34;math inline&#34;&gt;\(E(X^2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
E(X^2) &amp;amp;= \sum_{x=0}^\infty x^2\frac{\mu^x}{x!}e^{-\mu} \\
       &amp;amp;= \mu \sum_{x=1}^\infty x\frac{\mu^{x-1}}{(x-1)!}e^{-\mu} \\
這個時候我們用i&amp;amp;=x-1 替換掉所有的 x \\
       &amp;amp;= \mu \sum_{i=0}^\infty (i+1)\frac{\mu^{i}}{i!}e^{-\mu} \\
       &amp;amp;= \mu(\sum_{i=0}^\infty i\frac{\mu^i}{i!}e^{-\mu} + \sum_{i=0}^\infty \frac{\mu^i}{i!}e^{-\mu}) \\
       &amp;amp;= \mu(E(X)+1) \\
       &amp;amp;= \mu^2+\mu \\
因此，代入上面&amp;amp;提到的方差公式： \\
Var(X) &amp;amp;= E(X^2) - E(X)^2 \\
       &amp;amp;= \mu^2 + \mu -\mu^2 \\
       &amp;amp;= \mu
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>正態分佈</title>
      <link>https://wangcc.me/post/normal-distribution/</link>
      <pubDate>Wed, 11 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/normal-distribution/</guid>
      <description>


&lt;div id=&#34;概率密度曲線-probability-density-function-pdf&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;概率密度曲線 probability density function， PDF&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;一個隨機連續型變量 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 它的性質由一個對應的&lt;strong&gt;概率密度方程 (probability density function, PDF)&lt;/strong&gt; 決定。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在給定的範圍區間內，如 &lt;span class=&#34;math inline&#34;&gt;\(a\sim b, (a &amp;lt; b)\)&lt;/span&gt;，它的概率滿足:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(a\leqslant X \leqslant b) = \int_a^bf(x)dx\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;這個相關的方程，在 &lt;span class=&#34;math inline&#34;&gt;\(a\sim b\)&lt;/span&gt; 區間內的積分，就是這個連續變量在這個區間內取值的概率。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# R codes for drawing a standard normal distribution by using ggplot2
library(ggplot2)
p &amp;lt;- ggplot(data.frame(x=c(-3,3)), aes(x=x)) +
  stat_function(fun = dnorm)
p + annotate(&amp;quot;text&amp;quot;, x=2, y=0.3, parse=TRUE, label=&amp;quot;frac(1, sqrt(2*pi)) * e ^(-z^2/2)&amp;quot;) +
  theme(plot.subtitle = element_text(vjust = 1),
        plot.caption = element_text(vjust = 1),
        axis.text.x = element_text(size = 12),
        axis.text.y = element_text(size = 12),
        plot.title = element_text(size = 10, face = &amp;quot;bold&amp;quot;, hjust = 0.5),
        panel.background = element_rect(fill = &amp;quot;ivory&amp;quot;)) +
  labs(title = &amp;quot;Probability density functions \n for standard normal distribution&amp;quot;,
       x = NULL, y = NULL) +
  stat_function(fun = dnorm,
                xlim = c(-1.3,0.4),
                geom = &amp;quot;area&amp;quot;,fill=&amp;quot;#00688B&amp;quot;, alpha= 0.2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-10-11-normal-distribution_files/figure-html/normal%20distribution%20graph-1.png&#34; width=&#34;528&#34; /&gt;&lt;/p&gt;
&lt;p&gt;注意：整個方程的曲線下面積等於 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;：
&lt;span class=&#34;math display&#34;&gt;\[\int_{-\infty}^\infty f(x)dx=1\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;期望 &lt;span class=&#34;math inline&#34;&gt;\(E(X)=\int_{-\infty}^\infty xf(x)dx\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;方差 &lt;span class=&#34;math inline&#34;&gt;\(Var(X)=\int_{-\infty}^\infty (x-\mu)^2f(x)dx\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;正態分佈&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;正態分佈&lt;/h3&gt;
&lt;p&gt;如果一組數據服從正態分佈，我們通常用它的期望（或者叫平均值）&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;，和它的方差 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;，來描述這組數據。記爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X \sim N(\mu, \sigma^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;它的概率密度方程可以表述爲：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}exp(-\frac{(x-\mu)^2}{2\sigma^2})\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(E(x) =\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Var(x)=\sigma^2\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;標準正態分佈&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;標準正態分佈&lt;/h3&gt;
&lt;p&gt;標準正態分佈的期望（或者均值）爲 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;，方差爲 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;記爲：&lt;span class=&#34;math inline&#34;&gt;\(Z \sim N(0,1)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;它的概率密度方程表述爲：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{1}{\sqrt{2\pi}}exp(-\frac{z^2}{2})\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;它的累積分佈方程 (cumulative distribution function， CDF)，是將概率密度方程 (PDF) 積分以後獲得的方程。通常我們記爲 &lt;span class=&#34;math inline&#34;&gt;\(\Phi(z)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;再看一下標準正態分佈的概率密度方程曲線：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-10-11-normal-distribution_files/figure-html/normal%20distribution%20graph2-1.png&#34; width=&#34;528&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;95% 的曲線下面積在標準差 standard deviation &lt;span class=&#34;math inline&#34;&gt;\(-1.96\sim1.96\)&lt;/span&gt; 之間的區域。&lt;/li&gt;
&lt;li&gt;而且，&lt;span class=&#34;math inline&#34;&gt;\(\phi(-x)=1-\phi(x)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;任何一個正態分佈都可以通過下面的公式，標準化成爲標準正態分佈：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Z=\frac{X-\mu}{\sigma}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>概率論2</title>
      <link>https://wangcc.me/post/probability2-4/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/probability2-4/</guid>
      <description>


&lt;div id=&#34;bayes-理論的概念&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bayes 理論的概念&lt;/h3&gt;
&lt;p&gt;許多時候，我們需要將概率中的條件相互對調。
例如：
在已知該人羣中有20%的人有吸菸習慣(&lt;span class=&#34;math inline&#34;&gt;\(P(S)\)&lt;/span&gt;)，吸菸的人有9%的概率有哮喘(&lt;span class=&#34;math inline&#34;&gt;\(P(A|S)\)&lt;/span&gt;)，不吸菸的人有7%的概率有哮喘(&lt;span class=&#34;math inline&#34;&gt;\(P(A|\bar{S})\)&lt;/span&gt;)的前提下，有個人前來門診，發現是哮喘患者，那麼這個人有多大的概率是一個菸民？也就是要求 &lt;span class=&#34;math inline&#34;&gt;\(P(S|A)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這裏先引入貝葉斯的概念：&lt;/p&gt;
&lt;p&gt;我們可以將 &lt;span class=&#34;math inline&#34;&gt;\(P(A\cap S)\)&lt;/span&gt; 寫成：
&lt;span class=&#34;math display&#34;&gt;\[P(A\cap S)=P(A|S)P(S)\\or\\
P(A\cap S)=P(S|A)P(A)\]&lt;/span&gt;
這兩個等式是完全等價的。我們將他們連起來：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(S|A)P(A)=P(A|S)P(S)\\
\Rightarrow P(S|A)=\frac{P(A|S)P(S)}{P(A)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;是不是看起來又像是寫了一堆&lt;strong&gt;廢話&lt;/strong&gt;？
沒錯，你看出來是一堆廢話的時候，證明你也同意這背後的簡單邏輯。&lt;/p&gt;
&lt;p&gt;再繼續，我們可以利用另外一個&lt;strong&gt;廢話&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(\because S+\bar{S}=1\\ \therefore P(A)=P(A\cap S)+P(A\cap\bar{S})\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;用上面的公式替換掉 &lt;span class=&#34;math inline&#34;&gt;\(P(A\cap S)+P(A\cap\bar{S}） \\ \therefore P(A)=P(A|S)P(S)+P(A|\bar{S})P(\bar{S})\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;可以得到&lt;strong&gt;貝葉斯理論公式&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(S|A)=\frac{P(A|S)P(S)}{P(A|S)P(S)+P(A|\bar{S})P(\bar{S})}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;回到上面說到的哮喘人中有多少比例吸菸的問題。可以繼續使用概率樹來方便的計算：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Selection_073.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
P(S|A) &amp;amp;= \frac{P(A|S)P(S)}{P(A|S)P(S)+P(A|\bar{S})P(\bar{S})} \\
        &amp;amp;= \frac{0.09\times0.2}{0.09\times0.2+0.07\times0.8} \\
        &amp;amp;= 0.24
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以我們的結論就是，在已知該人羣中有20%的人有吸菸習慣(&lt;span class=&#34;math inline&#34;&gt;\(P(S)\)&lt;/span&gt;)，吸菸的人有9%的概率有哮喘(&lt;span class=&#34;math inline&#34;&gt;\(P(A|S)\)&lt;/span&gt;)，不吸菸的人有7%的概率有哮喘(&lt;span class=&#34;math inline&#34;&gt;\(P(A|\bar{S})\)&lt;/span&gt;)的前提下，有個人前來門診，發現是哮喘患者，那麼這個人有24% 的概率是一個菸民(&lt;span class=&#34;math inline&#34;&gt;\(P(S|A)\)&lt;/span&gt;)。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;期望-expectation-或均值-or-mean-和-方差-variance&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;期望 Expectation (或均值 or mean) 和 方差 Variance&lt;/h3&gt;
&lt;p&gt;期望（或均值）是用來描述一組數據中心位置的指標（另一個是中位數 Median）。
對於離散型隨機變量 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; (discrete random variables)，它的期望被定義爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(X)=\sum_x xP(X=x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以就是將所有 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 可能取到的值乘以相應的概率後求和。這個期望（或均值）常常用希臘字母 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 來標記。&lt;/p&gt;
&lt;p&gt;方差 Variance 是衡量一組數據變化幅度(dispersion/variability)的指標之一。 方差的定義是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var(X)=E((X-\mu)^2)\\其中，\mu=E(x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;實際上我們更加常用的是它的另外一個公式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var(X)=E(X^2)-E(X)^2\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;證明-上面兩個方差公式相等&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明 上面兩個方差公式相等&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
Var(x)  &amp;amp;= E((X-\mu)^2) \\
        &amp;amp;= E(X^2-2X\mu+\mu^2)\\
        &amp;amp;= E(X^2) - 2\mu E(X) + \mu^2\\
        &amp;amp;= E(X^2) - 2\mu^2 + \mu^2 \\
        &amp;amp;= E(X^2) - \mu^2 \\
        &amp;amp;= E(X^2) - E(X)^2
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;方差的性質&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;方差的性質：&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Var(X+b)=Var(X)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Var(aX)=a^2Var(X)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Var(aX+b)=a^2Var(X)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;伯努利分佈-bernoulli-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;伯努利分佈 Bernoulli distribution&lt;/h3&gt;
&lt;p&gt;伯努利分佈，說的就是一個簡單的二分變量 (1, 0)，它取1時的概率如果是 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;。那麼我們可以計算這個分佈的期望值:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
E(X) &amp;amp;=\sum_x xP(X=x) \\
     &amp;amp;=1\times\pi + 0\times(1-\pi)\\
     &amp;amp;=\pi
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由於 &lt;span class=&#34;math inline&#34;&gt;\(x=x^2\)&lt;/span&gt;，因爲 &lt;span class=&#34;math inline&#34;&gt;\(x=0,1\)&lt;/span&gt;, 所以 &lt;span class=&#34;math inline&#34;&gt;\(E[X^2]=E[X]\)&lt;/span&gt;，那麼方差爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
Var(X) &amp;amp;=E[X^2]-E[X]^2 \\
       &amp;amp;=E[X]-E[X]^2 \\
       &amp;amp;=\pi - \pi^2 \\
       &amp;amp;=\pi(1-\pi)
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;證明xy-爲互爲獨立的隨機離散變量時-a-exyexey-b-varxyvarxvary&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;證明，&lt;span class=&#34;math inline&#34;&gt;\(X,Y\)&lt;/span&gt; 爲互爲獨立的隨機離散變量時，&lt;br&gt;a) &lt;span class=&#34;math inline&#34;&gt;\(E(XY)=E(X)E(Y)\)&lt;/span&gt; ; &lt;br&gt;b) &lt;span class=&#34;math inline&#34;&gt;\(Var(X+Y)=Var(X)+Var(Y)\)&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;strong&gt;證明&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
E(XY) &amp;amp;= \sum_x\sum_y xyP(X=x, Y=y) \\
\because &amp;amp;\; X,Y are\;independent\;to\;each\;other \\
\therefore &amp;amp;= \sum_x\sum_y xyP(X=x)P(Y=y)\\
      &amp;amp;=\sum_x xP(X=x)\sum_y yP(Y=y)\\
      &amp;amp;=E(X)E(Y)
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;ol start=&#34;2&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;strong&gt;證明&lt;/strong&gt;
根據方差的定義：
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
Var(X+Y) &amp;amp;= E((X+Y)^2)-E(X+Y)^2 \\
    &amp;amp; \; Expand \\
    &amp;amp;=E(X^2+2XY+Y^2)-(E(X)+E(Y))^2\\
    &amp;amp;=E(X^2)+E(Y^2)+2E(XY)\\
    &amp;amp;\;\;\; - E(X)^2-E(Y)^2-2E(X)E(Y)\\
    &amp;amp;\; We\;just\;showed\; E(XY)=E(X)E(Y)\\
    &amp;amp;=E(X^2)-E(X)^2+E(Y^2)-E(Y)^2 \\
    &amp;amp;=Var(X)+Var(Y)
\end{align}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>“你會用概率論來賭博嗎？”之解答</title>
      <link>https://wangcc.me/post/probability-gambling-answers/</link>
      <pubDate>Mon, 09 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/probability-gambling-answers/</guid>
      <description>


&lt;p&gt;前情提要：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Selection_071.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;假設你在一個電視遊戲節目。有上圖一樣的三扇門。其中一扇門後面有一輛保時捷，另兩扇門後面則是&lt;a href=&#34;https://winterwang.github.io/post/black-meal/&#34;&gt;(味道奇特的)山羊&lt;/a&gt;。遊戲規則是主持人會讓你先選擇其中一扇門（先不打開你選的這扇門）。主持人隨後打開另外兩扇門中的一扇沒有保時捷的門。主持人問你，你要堅持選擇之前選中的那扇門，還是要改變主意換一扇門去猜是否可以猜中保時捷。
請問，堅持選擇之前選中的門猜中保時捷的概率高，還是主持人打開一扇門以後改變主意猜中保時捷的概率更高呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;答案是：必須改變主意才能提高中獎概率。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上述情況下，最簡單的是用概率樹 (probability tree) 來做決定：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Selection_072.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;解說一下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;假定保時捷在1號門後，你第一次選擇了1號門，那麼此時主持人可以任意打開2號或者三號門（因爲他們後面都沒有保時捷）。&lt;/li&gt;
&lt;li&gt;假定保時捷在1號門後，你第一次選了2號門，那麼此時主持人只能打開3號門（因爲一號門後是保時捷，按照遊戲規則主持人不能打開）。&lt;/li&gt;
&lt;li&gt;假定保時捷在1號門後，你第一次選了3號門，那麼此時主持人只能打開2號門（因爲一號門後是保時捷，按照遊戲規則主持人不能打開）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以按照圖中給出的計算概率樹的過程可以得到:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P[改變主意以後贏得保時捷的概率]\\=\frac{1}{3}+\frac{1}{3}=\frac{2}{3}\\
P[不改主意，贏得保時捷的概率]\\=\frac{1}{6}+\frac{1}{6}=\frac{1}{3}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;你是否選擇了改變主意了呢？&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>你會用概率論來賭博嗎？</title>
      <link>https://wangcc.me/post/probability-gambling/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/probability-gambling/</guid>
      <description>


&lt;p&gt;轉眼我已經進入課程的第二週了，總體來說，我們一半的時間都在電腦房練習 Stata 的數據清理和簡單的描述統計 (descriptive statistics)。從我個人的經驗來說，數據分析的過程，其實一大半的時間是消耗在 data cleaning 上的，即使手頭拿到了所謂的乾淨的數據，到真正要分析的時候就會發現一大堆的問題在裏面，需要重新整理，重新添加標記以使之變得更加讓人類可以讀懂。電腦是機器，他是不管你的數據是否乾淨的。只要你放了數據進去，邏輯還可以，沒有編程上的語法錯誤，它總歸會出來一些報告和結果的。如果就這麼直接用的話，大部分的人就會掉進陷阱。畢竟數據不光會說出事實真相，&lt;strong&gt;更多的情況下還會把真相給掩蓋住了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我的其餘大部分時間都用在了複習高等數學的微積分上了。感覺好似回到了高中時代。其實大學的時候線性代數得分還是接近滿分的。後來多年不用，生疏了。剛打開複習的書的時候，許多微分積分的規則都已經忘記。通過這一週的辛苦練習，終於是找回了一點狀態。如果你也想有空的時候複習以下高中數學知識，這本書可以推薦給你：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.uk/gp/product/0471827223/ref=oh_aui_detailpage_o04_s00?ie=UTF8&amp;amp;psc=1&#34;&gt;Quick Calculus: Short Manual of Self-instruction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Selection_070.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;上面這本書的內容可以一邊閱讀，一邊練習。實在是複習的一本好書。我花了一週的課餘時間，從頭到尾把裏面的習題和解答全部完成。收穫很大。感覺年輕時的數學思維又開始在大腦裏復甦了。一身輕鬆。&lt;/p&gt;
&lt;p&gt;下面想介紹一下上週學習的概率的基礎問題。&lt;/p&gt;
&lt;div id=&#34;首先是最基礎的三個概率的公理&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;首先是最基礎的&lt;strong&gt;三個概率的公理&lt;/strong&gt;：&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;對於任意事件 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;，它發生的概率 &lt;span class=&#34;math inline&#34;&gt;\(P(A)\)&lt;/span&gt; 滿足這樣的不等式： &lt;span class=&#34;math inline&#34;&gt;\(0 \leqslant P(A) \leqslant 1\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(\Omega)=1\)&lt;/span&gt; , &lt;span class=&#34;math inline&#34;&gt;\(\Omega\)&lt;/span&gt; 是全樣本空間 (total sample space)&lt;/li&gt;
&lt;li&gt;對於互斥（相互獨立）的事件 &lt;span class=&#34;math inline&#34;&gt;\(A_1, A_2, \dots, A_n\)&lt;/span&gt; 有如下的等式關係： &lt;span class=&#34;math inline&#34;&gt;\(P(A_1\cup A_2 \cup \cdots \cup A_n)=P(A_1)+P(A_2)+\cdots+P(A_n)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;你是不是覺得上面三條公理都是&lt;strong&gt;廢話&lt;/strong&gt;。
不用擔心，我也是這麼覺得的。因爲所有人都認同的道理，才能成爲公理 (axiom)，因爲它們是不需要證明的自然而然形成的人人都接受的觀念。&lt;code&gt;(axiom: a saying that is widely accepted on its own merits; its truth is assumed to be self-evident)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;然而，正是這樣顯而易見的道理，確是拿來建築理論的基石，千萬不能小看了他們。例如，我們看下面這個看似也應該成爲公理的公式，你能證明嗎：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A_1\cup A_2) = P(A_1) + P(A_2) - P(A_1 \cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/venngram.png&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;證明&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明：&lt;/h4&gt;
&lt;p&gt;先考慮 &lt;span class=&#34;math inline&#34;&gt;\(A_1 \cup A_2\)&lt;/span&gt; 是什麼（拆分成三個互斥事件）&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A_1 \cup A_2 = (A_1\cap \bar{A_2})\cup(\bar{A_1}\cap A_2)\cup(A_1\cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;運用上面的公理&lt;del&gt;2&lt;/del&gt; 3&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\therefore P(A_1 \cup A_2) = P(A_1\cap \bar{A_2}) + P(\bar{A_1}\cap A_2) + P(A_1\cap A_2) \;\;\;\;\;\;(1)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;再考慮 &lt;span class=&#34;math inline&#34;&gt;\(A_1=(A_1\cap A_2)\cup(A_1\cap\bar{A_2})\)&lt;/span&gt; 繼續拆分成兩個互斥事件&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\therefore P(A_1)=P(A_1\cap A_2)+P(A_1\cap\bar{A_2})\)&lt;/span&gt; 整理一下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A_1\cap\bar{A_2})=P(A_1)-P(A_1\cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同理可得: &lt;span class=&#34;math inline&#34;&gt;\(P(\bar{A_1}\cap A_2)=P(A_2)-P(A_1\cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;代入上面第(1)式可得：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A_1 \cup A_2) =P(A_1)-P(A_1\cap A_2)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+P(A_2)-P(A_1\cap A_2)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+P(A_1\cap A_2)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;=P(A_1) + P(A_2) - P(A_1 \cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;條件概率-conditional-probability&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;條件概率 Conditional probability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A|S)=\frac{P(A\cap S)}{P(S)}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A\cap S) = P(A|S)P(S)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;獨立-independence-的定義&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;獨立 (independence) 的定義&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;兩個事件定義爲互爲獨立時 (&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; are said to be independent &lt;strong&gt;if and only if&lt;/strong&gt;)
&lt;span class=&#34;math display&#34;&gt;\[P(A\cap B)=P(A)P(B)\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;因爲從條件概率的概念我們已知&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(P(A\cap B) = P(A|B)P(B)\)&lt;/span&gt; &lt;br&gt;所以&lt;span class=&#34;math inline&#34;&gt;\(P(A|B)=P(A)\)&lt;/span&gt; 即：事件 &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; 無法提供事件 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的任何有效訊息 (&lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(A, B\)&lt;/span&gt; 互相獨立&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;賭博問題&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;賭博問題&lt;/h2&gt;
&lt;p&gt;終於來到本次話題的重點了。我要扣題了哦。語文老師快在此加分。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Selection_071.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;假設你在一個電視遊戲節目。有上圖一樣的三扇門。其中一扇門後面有一輛保時捷，另兩扇門後面則是&lt;a href=&#34;https://winterwang.github.io/post/black-meal/&#34;&gt;(味道奇特的)山羊&lt;/a&gt;。遊戲規則是主持人會讓你先選擇其中一扇門（先不打開你選的這扇門）。主持人隨後打開另外兩扇門中的一扇沒有保時捷的門。主持人問你，你要堅持選擇之前選中的那扇門，還是要改變主意換一扇門去猜是否可以猜中保時捷。
請問，堅持選擇之前選中的門猜中保時捷的概率高，還是主持人打開一扇門以後改變主意猜中保時捷的概率更高呢？&lt;/p&gt;
&lt;p&gt;答案明天揭曉。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>倫敦城漫步 (2)</title>
      <link>https://wangcc.me/post/first-impression-of-london2/</link>
      <pubDate>Wed, 27 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/first-impression-of-london2/</guid>
      <description>

&lt;p&gt;我們學科 (Medical Statistics) 是爲數不多的在 Orientation 周就有一半以上的時間在上課的學科。別的學科像 Epidemiology 這周還集體去劍橋大學見學啥的。幾乎都是第二周，也就是10月2日週一開始的時候才有大量的必修和選修課。所以不見得再有太多時間寫見聞和體驗。（也沒有時間出去玩了&amp;hellip;..）不過學習的內容還是會來更新一下，給各位有個印象，也讓大家都來判斷以下，這裏的碩士課程的內容和質量到底如何。&lt;/p&gt;

&lt;h4 id=&#34;9月22日-isw-ucl-福爾摩斯博物館-的紀念品商店&#34;&gt;9月22日 ISW &amp;amp; UCL &amp;amp; 福爾摩斯博物館（的紀念品商店）&lt;/h4&gt;

&lt;p&gt;忘了交代，9月21日和22日都是 Internatioanal Student Welcome (留學生歡迎會, ISW) 的日子。充滿對這一年的期待，和但是是否自己能最終倖存下來的不安，坐在這樣壓力巨大的梯形教室裏，我和這麼多來自世界各地的年輕人成爲了同學：
&lt;img src=&#34;https://wangcc.me/img/1015171443.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;這個教室就是大名鼎鼎的 &lt;a href=&#34;http://johnsnowbicentenary.lshtm.ac.uk/about-john-snow/&#34; target=&#34;_blank&#34;&gt;John Snow&lt;/a&gt; Lecture Theatre。我就知道你以爲是這個人：
&lt;img src=&#34;https://wangcc.me/img/Jonsnow.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;其實歷史上的 Snow 同學可是奠定了近代流行病學基礎的巨人。比這個 bastard 強$^{9999999}$ 多了好麼，快去維基百科自學去。&lt;/p&gt;

&lt;p&gt;這個大名鼎鼎的水泵就是他拆的！
&lt;img src=&#34;https://wangcc.me/img/1759791785.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;閒話少敘，註冊參加時，排隊的樣子：
&lt;img src=&#34;https://wangcc.me/img/1738788923.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;領到自己的卡，寫上自己的名，和課程名稱 (原諒我的粗鄙的筆跡)：
&lt;img src=&#34;https://wangcc.me/img/39418260.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;看這梯形教室有多陡峭：（據說梯形教室陡峭的程度和學習壓力成正比）&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/876198141.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;學校還請來了倫敦警察（可愛壞）薯熟來跟大家講我以前感覺只有在中國才會有的防盜防火防學長的故事：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/697554235.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;22日中午結束以後我就步行在大學附近閒逛，UCL就在我們大學 Keppel Street 往北一點點。連3分鐘都不到。看這&lt;strong&gt;大學&lt;/strong&gt;，真有&lt;strong&gt;大學&lt;/strong&gt;的感覺：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/761318563.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;爲數不多的晴天在這一週已經碰到兩天了。是不是應該買張彩票試試看？（笑）
UCL是以前高中同班同學待過（一個已經回廈門），和正在待的地方（一個正在博士後/Research Assistant?）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/16618557.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;大學對面是UCL的醫學院：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/979802270.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;有那麼一點點霍格沃茨的感覺。我在校內略逛了以下，起身前去貝克街。如果你聽說過貝克街，那你一定聽說過221號B。因爲這是小說裏福爾摩斯和華生的住址。來之前我就查過了，距離倫敦大學步行半個小時左右，中途還會經過杜莎夫人蠟像館（聽起來就令人覺得索然無味的地方）。&lt;/p&gt;

&lt;p&gt;當我來到貝克街的時候，路邊有個福爾摩斯的雕像，許多人駐足和心目中世界上最聰明的男人合影留念：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/801300689.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;旁邊還有一個貝克街的公共汽車站證明了這可是真實存在的地址哦：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1411584999.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;但是其實這裏只是貝克街的起點。走到 Baker Street 221 B 之後我被門口排的長隊驚呆了：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1790216276.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;於是我趕緊跟在隊的最後面排隊，大概五分鐘過後有個老頭過來問說，你買了門票了嗎？ 我說我還以爲這裏就是排隊買門票呢。他說這些人都是排隊進福爾摩斯紀念館的。旁邊的小房間現在是紀念品商店，可以在那裏買到門票。所以我就轉身進入了紀念品商店。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1556464625.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;商店裏還真是應有盡有。你能想到的關於福爾摩斯的任何東西。而且大多數價格都不便宜：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/2032661472.jpg&#34; alt=&#34;&#34; /&gt;
這個杯子賣八鎊，低下寫着英國製造。&lt;/p&gt;

&lt;p&gt;這頂帽子，全羊毛手工製作，也寫着英國製造，49鎊一頂：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_20170922_165434.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;這兩個東西正好也是我現在需要的。所以我就買了下來。但是進入紀念館的門票竟然要16英鎊。我想還是等我有學生優惠了以後再來問問看吧。說不定可以便宜一些。打道回府的路上又經過UCL，在這棟標誌性的建築物門口的長椅上坐了許久，休息，沉思。側面的角度還是很有感覺的呢。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1277846351.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>漫步倫敦城 (1)</title>
      <link>https://wangcc.me/post/first-impression-of-london/</link>
      <pubDate>Tue, 26 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/first-impression-of-london/</guid>
      <description>

&lt;p&gt;在倫敦生活過完了第一周，似乎快要步入正軌了。因為許許多多的前輩告誡說，第一周是唯一可以輕鬆度過的時間，一定要珍惜好好利用。多看看倫敦，多四處走走。&lt;/p&gt;

&lt;p&gt;於是我很聽話的每天都四處走走。接下來打算把這幾天去過的地方盡量根據回憶都列舉一下：&lt;/p&gt;

&lt;h4 id=&#34;9月19日-大英博物館初體驗&#34;&gt;9月19日 大英博物館初體驗&lt;/h4&gt;

&lt;p&gt;國王十字車站附近的郵局 → 大英博物館&lt;/p&gt;

&lt;p&gt;從宿舍往北步行十五分鐘左右，就是大英圖書館，圖書館的旁邊就能看到國王十字車站 (King&amp;rsquo;s Cross Station)。所有剛到英國的留學生（簽證在6個月以上的吧？），都要去自己申請簽證時登記的郵局領取BRP卡。BRP卡就相當於日本的在留卡，也就是登記一下外國人的個人信息，住址和在留期限。我當時登記的是這個最近的郵局，叫做國王十字車站郵局 (Kings Cross Post Office)。&lt;/p&gt;

&lt;p&gt;去郵局的路上看到了兩個騎著高頭大馬的帥氣警察。不敢從正面拍，所以走到了後面才趕緊拍了一張：
&lt;img src=&#34;https://wangcc.me/img/188242805.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然後你也會看到一個非常有巴洛克風的建築物：
&lt;img src=&#34;https://wangcc.me/img/1279177784.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;這個叫做 &lt;a href=&#34;http://www.marriott.com/hotels/travel/lonpr-st-pancras-renaissance-hotel-london/?scid=bb1a189a-fec3-4d19-a255-54ba596febe2&#34; target=&#34;_blank&#34;&gt;St. Pancras Renaissance Hotel London&lt;/a&gt;，中文名應該是聖潘克拉斯萬麗酒店。如果你玩過&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%88%BA%E5%AE%A2%E6%95%99%E6%A2%9D%EF%BC%9A%E6%A2%9F%E9%9B%84&#34; target=&#34;_blank&#34;&gt;刺客信條梟雄&lt;/a&gt;。一定會對這樣的建築印象深刻。&lt;/p&gt;

&lt;p&gt;郵局內部真的是破爛不堪，連中國三線城市的郵政儲蓄營業廳都不如，櫃檯工作的好多是黑人和印度人，口音很重，態度蠻橫。要做好心理準備。而且標識十分不明，你必須問周圍的人我現在排的隊是幹什麼的。&lt;/p&gt;

&lt;p&gt;領完我的BRP卡之後，又往回走，到宿舍以南步行也是10分鐘左右，進入大英博物館。從正門走時，因為每個進入大英博物館的人如果有帶包都要打開給警備員查看。所以入口處隊伍非常的長。後來聽說從後門走的話人就少很多。不過這天不是週末，所以我得以很快的通過安檢進入博物館。&lt;/p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;strong&gt;最重要的是，大英博物館是免費的！&lt;/strong&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;大英博物館外觀：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0123.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;進入大英博物館的玄關以後，視野一下子就開闊起來:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0129.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;果然從世界各地搶來的東西展覽起來就是有底氣！ 呵呵！&lt;/p&gt;

&lt;p&gt;當然英國人對世界人類瑰寶的保存還是花了不少力氣。我花了一個小時左右看了古埃及部分，一點點古希臘，還有一個專門展覽人類各種貨幣的展廳。&lt;strong&gt;牆裂推薦！&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0125.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0124.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;9月20日-暴走倫敦城&#34;&gt;9月20日 暴走倫敦城&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1865771317.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;谷歌事無鉅細記錄了我一天的行程。早晨我起床吃了早飯就離開宿舍前往&lt;a href=&#34;https://skygarden.london/&#34; target=&#34;_blank&#34;&gt;天空花園 (Sky Garden)&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;出發來倫敦之前，通過閱讀學校給的關於倫敦的簡單介紹，知道了這個地方。應該是類似新加坡 &lt;a href=&#34;http://www.marinabaysands.com/sands-skypark/observation-deck.html&#34; target=&#34;_blank&#34;&gt;Sky Park&lt;/a&gt;。的空中花園。天氣晴朗的時候可以俯瞰全城的地標性建築物。
不同的是倫敦的天空花園是免費，且要預約的。如果你打開上面天空花園的網頁鏈接，就能看見預約的方法。我提前預約了週三早晨10點半進入參觀的門票。如果我沒有記錯的話，新加坡的空中花園不用預約，但是需要在門口乘電梯的地方購買門票，一個人應該是15新幣的樣子。&lt;/p&gt;

&lt;p&gt;Sky Garden 的外觀：
&lt;img src=&#34;https://wangcc.me/img/508099424.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;週三天氣很不好，看不清楚太遠的地方。不過畢竟登高望遠，泰晤士河兩岸，倫敦塔橋等建築物還是能看得見：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0130.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/453454807.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;霧濛濛的是不是感覺比北京天氣還糟糕？！ 這麼說有點不公平，因為我沒在北京生活過。客觀點說倫敦空氣質量還不錯，天氣很不好。據說到了冬天抑鬱症的人就會增加。&lt;/p&gt;

&lt;p&gt;雖然預約的是10點半到11點半一個小時，不過整個花園不大，天氣不好所以也沒什麼看頭，十五分鐘我就下來了。看著地圖又繼續往泰晤士河邊走。中途路過&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%80%AB%E6%95%A6%E5%A4%A7%E7%81%AB&#34; target=&#34;_blank&#34;&gt;倫敦大火&lt;/a&gt;紀念碑：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0136.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;經過倫敦橋(你以為倫敦橋有多壯觀？看了你會失望)以後你會發現這種橋在黃浦江上可能還根本算不上是一座橋。也就跟我們村里小河邊看櫻花的那個橋差不太多。。。&lt;/p&gt;

&lt;p&gt;可能倫敦“城裡人”會不同意我的話哈哈，請多見諒，您是城里人嘛。&lt;/p&gt;

&lt;p&gt;到了泰晤士河南岸，往西走，去塔橋 (Tower Bridge) 的路上會看見一艘軍艦停靠在港口：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0137.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;估計和停靠在珍珠港的軍艦一樣曾經在戰爭中服役。只不過從外觀規模上來看這艘軍艦顯然小很多。門票有點小貴，所以我也沒有花錢進去。經過軍艦以後是個不大不小的廣場。讓我想起了廈門輪渡碼頭。不過，再往前就是壯觀的塔橋了 (Tower Bridge)：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0144-EFFECTS.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;塔橋在大船要進入泰晤士河的時候是可以從中間舉起，讓船通過然後再放下的。之前都只在風景明信片裡面看過的建築物，我終於有幸在上面留下我的足跡。走上塔橋意味著就離開南岸，又回到北岸了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1101681166.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/584841134.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;回宿舍的路上，我注意觀察了路邊的ATM機器。絕大部分都是只在牆壁上挖了一個洞，放個機器。讓人超級沒有安全感的。密碼被周圍的人看了咋辦？ 取了多少錢都被周圍的人看見了，有人見財起意咋辦？ 英國人都不在乎這些嗎？ 好像銀行的建築物裡面的ATM機器可能可以多少讓人有點安全感吧。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/860210008.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;機器上方的字的意思是取錢不收手續費。這非常的好。於是我在一個車站的較為隱蔽的角落裡的 ATM 嘗試著用 manepartners 的卡著取了些現金。後來手機一查，還是扣了我 1.5 鎊的手續費。估計多半是 manepartners 扣去了的。&lt;/p&gt;

&lt;p&gt;回到宿舍，我暴走了近 10 公里的腳都已不聽使喚，我還盤算著這樣白天足夠累了的話，夜裡就能多睡睡，把時差快點調整過來。誒，調整時差也應該有個人區別，也許我就是屬於不太容易調整時差的那類吧。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>London Baby !</title>
      <link>https://wangcc.me/post/london-life-started/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/london-life-started/</guid>
      <description>

&lt;h4 id=&#34;離開&#34;&gt;離開&lt;/h4&gt;

&lt;p&gt;飛機翱翔在俄羅斯上空。我在機艙內拿出手機，再一次看老友記第四季的最後一集。講的是 Ross 和 Emily 在倫敦的婚禮。
熟悉的歡樂劇情，不熟悉的城市。如果你對老友記像我一樣熟悉，快來跟我做朋友吧！&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/friends.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;十三個小時的飛行，我一直無法休息。我在憧憬這一年如痴如醉的傲遊知識海洋嗎？我離開家，離開愛妻，離開親愛的孩子們，是多麼的捨不得。我才剛踏上旅程，思念就如同潮水在心中湧起。在中部機場和妻告別時，她拿出一個小小的粉紅色信封。依依不捨的告訴我說上了飛機再看。想來和妻在一起這幾年，這是她第一次這樣細膩又柔軟的感情表達。可是我卻把整個家留在了身後，全部交給了她。這一年，要辛苦你了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/taifeng.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;就在離開日本的前一日，名古屋還在18號颱風的正面襲擊之下。夜晚狂風驟雨，摧枯拉朽地吹散整個城市的思念。早晨醒來，天空還是陰沉沉的，颱風仍然沒有完全過去。全家人擔心著飛機的起飛是否被影響。我們還是毅然決然地開著心愛的小西沖向了機場。在日航的櫃檯等待行李寄存時，抬頭看見大屏幕上的航班信息，名古屋-沖繩 取消， 名古屋-札幌 取消，名古屋-成田（東京） 取消。。。。 一整個屏幕都是航班取消的紅色信號。可是最後，名古屋-羽田（東京）的航班竟然顯示的是 &amp;lsquo;計劃&amp;rsquo;。拿到機票進入候機大樓以後才看見，這時天空的烏雲已經開始逐漸散去。原來，我的航班真的可以按時離開了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/ontheflight.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;抵達&#34;&gt;抵達&lt;/h4&gt;

&lt;p&gt;同行的本田是一個日本人小兒科醫生。她跟我很早就通過 Facebook 聯絡，並且發現我們恰好訂了同一天的航班，宿舍距離也不遠。於是順理成章地，我們到了希思羅機場以後準備一起乘 Uber 去我們各自的宿舍。希思羅機場乘 Uber 時要先去出發的航站樓的停車場，才能順利上車。推著行李過去停車場的一路上我們是真切的感受到了9月倫敦的氣溫是多麼的冷。我趕快拿出放在包裏的羽絨服披上才算沒有被凍到。&lt;/p&gt;

&lt;p&gt;不過奇怪的是我的 uber 賬號本來在美國西雅圖，新加坡等地方都用的好好的，在倫敦卻一直提示我支付用的信用卡信息有誤。就算我立刻更新了信用卡信息，或者是從 mastercard 換成 visa 均不能成功。真是尷尬死了。正在此時，旁邊另一個留學生模樣的女生湊過來說，“我可以借一下你的 wifi 熱點嗎？”。原來此人來自香港，在 LSE （倫敦政經學院）做交換留學生一年。真是巧了。宿舍也離我們的不太遠。所以果斷把我租的小米全球上網分享給她：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/xiaomiwifi.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;三個剛剛踏上留學生活的陌生人，就這樣乘了同一輛車進入這個陌生的大城市。倫敦，I am coming。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/internationalhall.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;順利抵達我的&lt;a href=&#34;https://www.internationalhall.com/&#34; target=&#34;_blank&#34;&gt;宿舍 International Hall&lt;/a&gt;，領了房間卡之後，住進了我此生租過的最貴的每週200鎊的單身無廁所無浴室學習房間 (Study Room) :&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/studyroom.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;大學附贈了一套被褥床單和浴巾。房間的暖氣片暫時還不能使用。夜裡的溫度已經降到10度以下了呢！！！衣櫃裡的鏡子已經碎了，不過我很喜歡這個特別長的書桌，上面的書櫃，還有牆壁上的這塊掛墊：(我的兩個小寶貝的照片被我第一時間貼了上去。)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/room2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;宿舍附近就有 Tesco，是個24小時開門的小超市。類似在日本的7/11。也是應有盡有，甚至還能買到新鮮果蔬：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/avocadotesco.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我的宿舍之所以這麼貴，是有原因的！因為住在這裡，旁邊就是大英博物館：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Britshmuseum.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;進去走馬觀花看了一個半小時，又在附近逛了逛，和一個正在 LSHTM 讀博士學位的日本人見面送了東西，然後又和闊別多年的高中同學吃了午餐。&lt;/p&gt;

&lt;p&gt;壽司果然在這裡價格不菲：
&lt;img src=&#34;https://wangcc.me/img/sushilondon.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;當然更不能錯過美好的天氣，還有我將要奉獻一年時間的夢想中的大學： 倫敦衛生學與熱帶醫學學院 (London School of Hygiene and Tropical Medicine)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/LSHTMdoor.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;初來乍到的幾天，時差還根本轉不過來，晚上8點多就困的不省人事，現在半夜三點又精神抖擻。希望能快點適應這裡的生活。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>UK visa succeed</title>
      <link>https://wangcc.me/post/uk-visa-succeed/</link>
      <pubDate>Tue, 29 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/uk-visa-succeed/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/post/visa-application/&#34; target=&#34;_blank&#34;&gt;我在近一個月前去了大阪的英國簽證中心申請了去英國的簽證。&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;當時大英帝國的簽證申請就給我留下極差的印象。結果後來我的等待才是最漫長的。&lt;/p&gt;

&lt;p&gt;理一下時間線：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;7月31日 提交簽證材料&lt;/li&gt;
&lt;li&gt;8月16日 收到郵件提示，護照抵達馬尼拉&lt;/li&gt;
&lt;li&gt;8月23日 打電話給大英帝國高貴的&lt;a href=&#34;https://www.gov.uk/contact-ukvi-inside-outside-uk/y/outside-the-uk/english&#34; target=&#34;_blank&#34;&gt;移民局(UK Visas and Immigration)&lt;/a&gt; (下面詳述)&lt;/li&gt;
&lt;li&gt;8月23日 收到郵件提示，護照抵達日本大阪簽證申請中心&lt;/li&gt;
&lt;li&gt;8月24日 下午查詢郵局訂單號發現已經到了我所在的城市，晚上，配送完畢，簽證到手:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/UKvisa.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;當時提交簽證材料時，告訴我的是，提交之日起15個工作日，所以我的預計是8月中旬能入手簽證。結果，實際上8月中旬才剛剛寄到馬尼拉。也許是因爲這個時期有許多學生簽證申請，比較擁擠。我又不樂意去花錢買他們所謂的加急服務。因爲付錢等於我承認了這樣的做法是合理的。反而會助長這種依靠金錢來獲取方便的惡習。（當然我相信他們也不缺我一個人）
申請的順序，爲什麼不是按照申請的時間順序來呢？有人晚來了，付了錢加急就可以排到我前面去，這哪裏公平了？這在日本根本無法想象。最可恨的是，23日那天我實在是等不及了，早晨給移民局打電話去詢問簽證狀態，電話接通以後是機器聲音，提示先輸入有效的信用卡或者借記卡號碼，方便他們收取諮詢費用(1.37 £/min)。&lt;/p&gt;

&lt;p&gt;這一趟簽證申請體驗下來，只能令人感嘆大英帝國真的是沒落了。做事情效率之低下，每一個環節透露出來的全部都是赤裸裸的金錢至上主義。&lt;/p&gt;

&lt;p&gt;回想起當日在大阪簽證中心提交材料時，電視屏幕上循環播放着大英帝國的宣傳片。介紹着英國的方方面面，從工業革命，到互聯網的發明，以及優越先進的醫療和社會制度，無處沒有英國在其中起到的關鍵或者領導式的作用。這不是讓人覺得極爲諷刺嗎？過去的強盛，給他們留下的只有傲慢嗎？&lt;/p&gt;

&lt;p&gt;可能上面的體驗只是我還沒出發之前，體會到的十分侷限的部份，但願接下來一年英國風調雨順。&lt;/p&gt;

&lt;p&gt;大概我除了讀書一無是處，所以畢業應該（希望）是沒有問題！&lt;/p&gt;

&lt;p&gt;還有一個月不到就要出發了，倫敦，我來也！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>大英帝國簽證申請</title>
      <link>https://wangcc.me/post/visa-application/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/visa-application/</guid>
      <description>&lt;p&gt;來說說7月31日去大阪交簽證材料的事情。&lt;/p&gt;

&lt;p&gt;那叫一個鬱悶。
總之，我在日本還是第一次遇見如此糟糕的接待。另外，大阪的簽證辦理中心，非常不好找，建議第一次去的人挑一個不那麼熱的日子去。這樣也不會像我一樣在馬路上被曬成狗。&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;div class=&#34;google-maps&#34;&gt;
&lt;iframe src=&#34;https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d6562.23754229744!2d135.49993028993563!3d34.67695175141651!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x0%3A0x58d2656af250486b!2zVkZTIEdMT0JBTCDjg5PjgrbnlLPoq4vjgrvjg7Pjgr_jg7w!5e0!3m2!1sen!2sjp!4v1501653424481&#34; width=&#34;350&#34; height=&#34;300&#34; frameborder=&#34;0&#34; style=&#34;border:0&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;當然我才不會告訴你我早上起晚了差點趕不上我訂的火車票（9：00）。而且近鐵列車的城市快線 &lt;a href=&#34;http://www.kintetsu.co.jp/gyoumu/meihan/culture/timetable/timetable_weekday.html&#34; target=&#34;_blank&#34;&gt;(urban liner)&lt;/a&gt; 開得不是很平穩，我半路感覺暈車不適還跑去洗手間把早飯吐了以後才能舒服一點得繼續坐到大阪難波車站。從難波車站再換乘御堂筋線到心斎橋，之後就出車站步行差不多10個被暴曬的街區到VFS簽證代理處。不過並非領事館或者大使館，所以我想應該不會像美國領事館那樣戒備森嚴。結果上到10樓VFS辦公室的地方，有提示語告訴我先按門鈴讓保安檢查攜帶行李。按了門鈴，出來一個身材矮小的保安問我預約的時間和簽證申請種類。我把我的預約郵件在手機上打開給他看確認以後才肯帶我進門。&lt;/p&gt;

&lt;p&gt;進去之後就能看到一個還沒有我辦公室大的房間被隔板隔開成幾個部分。保安同學說不能用手機拍照，攜帶的筆記本拿出來給他確認關機。然後材料拿出來先交給保安。他又煞有介事地讓我把揹包每一層都打開給他看確認我沒帶炸彈。這些都搞定了以後又像機場安檢一樣全身掃描一遍確認我身上沒有綁着炸彈。。。&lt;/p&gt;

&lt;p&gt;此時已經比我預約的時間晚了10分鐘。當然我不怪他。他只是認真完成任務。之後讓我在等待區域等待。不久之後來了一個接待員用機器人一樣的語調和口吻告訴我說：“把所有的材料按照不同類別分好類，一定要使用牆壁上掛着的那些分類用的不同顏色的紙張。” 我擡頭一看牆壁上掛着的文件架子上有紅色藍色黃色等不同顏色的A4紙。她又接着機械地說：“如果你發現自己不知道怎麼歸類整理這些文檔的話，我也可以幫你，但是要收取1920日元的服務費。” 我艹，連看文件整理都要收費，我心想。接待員小姐估計聽見我的心裏話了，漫不經心地又說，“你當然可以自己整理，不過責任自負喲。”&lt;/p&gt;

&lt;p&gt;你這是在威脅我嗎？我心裏又想。後來才在他們的&lt;a href=&#34;http://www.vfsglobal.co.uk/japan/user_pay_services.html#15&#34; target=&#34;_blank&#34;&gt;網站&lt;/a&gt;上看到這樣的收費提示：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Application and Document Checks&lt;br&gt;
The Application and Document Checks service is for applicants who have already applied and have printed out their application form to check that an application is complete before sending it to the UK Visas and Immigration in Manila.&lt;br&gt;
The service will be charged an additional fee of JPY 1,920 per applicant. The fee can only be paid at Visa Application Centre in person by cash.&lt;br&gt;
VFS staff will check mandatory required documents have been submitted, but not the actual content of the documents.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我想省這點錢來着，看着他們的分類文件，毫無提示，簡直就像在嘲諷我“你真的是個PhD嗎？”。隨便分類了以後我想就試試看算了去交材料時，她才說，你這個沒有清單表格不行，你這裏有一張是絕對不能使用的。我心裏十萬頭草泥馬奔騰而過，這些事你們爲啥不能寫在通知預約的郵件裏面呢？爲啥不能算在網上交的簽證費用裏面呢？&lt;/p&gt;

&lt;p&gt;然後那小妞又告訴我說，“反正你要用郵寄服務收護照的話，你可以付錢我幫你整理阿，這兩個服務可以合算起來給你打九折！”。她是不是還期待我感激一下有折扣這件事呢？ “W！T！F！”三個字明確的寫在我的臉上，我想在日本這麼多年了，我TM還是第一次感覺回到了中國大陸。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/gif/wtf.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;強忍不爽的我無奈極了，說，那好吧你幫我整理材料吧。&lt;/p&gt;

&lt;p&gt;總之，什麼都是我自己負責，什麼都要從我身上掏錢，出錯了什麼都該自認倒楣的這種噁心頭頂的感覺從一開始進門一直到錄完指紋，拍好照片準備要離開的時刻。下午1點多，十幾張材料才遞交完。&lt;/p&gt;

&lt;p&gt;不知道是不是因爲接觸太多日本的無微不至的服務突然覺得有心理落差。但願以後去了英國不是這樣的服務。&lt;/p&gt;

&lt;p&gt;兩週以後能否安全收到簽證呢？ 拭目以待。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>無條件 offer, CAS, 和宿舍抽籤結果</title>
      <link>https://wangcc.me/post/unconditional/</link>
      <pubDate>Sat, 29 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/unconditional/</guid>
      <description>&lt;p&gt;言而總之，總而言之，我的4月5月6月7月在無盡的等待中度過。期間投稿了一篇論文。和西山一起進行了磕磕絆絆的GWAS數據分析。&lt;/p&gt;

&lt;p&gt;本來以爲我的 offer 條件僅僅衹是把我原先名古屋大學的博士學位證書，中英文的原本郵寄給 LSHTM 負責確認就可以了。&lt;/p&gt;

&lt;p&gt;結果6月8日那天收到郵件催促我快點滿足 offer 條件：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/fig/meetingcondition.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到資金證明是我必須提供的條件。所以，我立刻開始著手資金的準備，存款全部移到一個賬戶中去，然後開了一個存款證明。結果就是這個新開的存款證明，後來拖了我一個多月的腿。差點害我以爲可能這次留學計劃就要泡湯了。我原本告訴 LSHTM 的簽證詢問小組（visa-enquiries）說，我的生活費由我的大學支付的工資來做擔保，然後大學還有資助我的一部分旅費和住宿費。因此我還要求我工作的大學給我速速給我開具了上述證明。結果後來被證明這些都不如一張自己賬戶上有錢的證明來得簡單。&lt;/p&gt;

&lt;p&gt;因爲英國留學簽證(Tier 4 student)對 sponsor (資金贊助者)極爲嚴格：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For visa purposes, an Official Financial Sponsor is only one of the following: Her Majesty’s Government, your home government, the British Council or any international organisation, international company, university or an Independent School&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我原以爲我開的三個證明完全足夠了吧。結果過了一個月告訴我說：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Your documents didn’t meet the requirements because: &lt;br&gt;
 1.  The salary expectancy is not admissible &lt;br&gt;
 2. The statement you have provided only shows the balance on a single day and we therefore recommend a bank letter to show funds held for 28 days. Please find attached an example bank letter. &lt;br&gt;
 3.  The bank statements did not include the bank name and logo.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;不知道爲什麽，未來的工資單證明不被接受，然後資金證明必須證明說我擁有足夠的資金并且保持了4周時間。而且還要求資金證明上面有銀行的logo。WTF!&lt;/p&gt;

&lt;p&gt;這些都好說。可是日本的銀行，&lt;strong&gt;沒有&lt;/strong&gt;這種類型的證明書（我也是第一次知道日本銀行不給開這樣子的證明）。所以許多人的解決辦法是讓銀行開一個月的流水賬單，要命的是這個證明不能開英文的，然後再去找翻譯公司翻譯流水。當然我也可以這麽辦。衹是，當我知道我的三個證明書都不能作爲有效的資金證明的時候，我離7月31日祗剩下不到2周時間了。在此奉勸后來者，一定要先準備好自己的資金證明書。最好能按照下面的樣本，讓銀行開具類似的證明書：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/fig/bankstatement.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我在接到證明書不滿足條件的郵件的第二天，立刻去了銀行，接待我的銀行經理先是打報告給總部請示。毫無意外被擋回來。說如果是客人自己要求的樣式的證明書，無法給加銀行logo，也不能蓋章，衹能簽字。在我一個多小時的軟磨硬泡以後，經理鬆動了。竟然主動想辦法，她提議說，可以辦理bank statement，不過我看了他們給的bank statement樣本也是一個時間點的賬戶存款而已，無法滿足28天的資金維持證明。看我面有難色，日本人經理還是挺善解人意的，說，我可以把日期改成，從xx月xx日-xx月xx日（28天）的最低資金證明。這樣就能解決問題了。而且bank statement本身自帶銀行logo。謝天謝地，一項死板不能變通的日本人讓我從此刮目相看。解決了我的燃眉之急。也不必再去找翻譯公司翻譯賬戶流水了。有驚無險。第二天我拿到開好的證明，立刻掃描PDF郵件發給LSHTM，期待他們能馬上給開來 CAS (Confirmation of Acceptance of Studies)。等了一周，還是左等不來右等不來，距離7月31日還剩下不到10天了。終於無法忍耐等待的我，打電話去倫敦詢問我的情況。對方接電話的是個年輕女聲，優雅的倫敦音告訴我，不要着急，先無視學校的提醒滿足條件的郵件吧。我們會儘快看你的檔案。無奈我衹好作罷，挂了電話繼續等待。&lt;/p&gt;

&lt;p&gt;結果第二天晚上就收到了確認函，說你的CAS很快就能發給你了。oh yeah！半夜裏我就收到了發來的新鮮剛出爐的CAS號碼以及新的無條件錄取證明：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/fig/InkedCAS_LI.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/fig/uncon.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我很早以前就在&lt;a href=&#34;https://www.visa4uk.fco.gov.uk/home/welcome&#34; target=&#34;_blank&#34;&gt;visa4uk&lt;/a&gt;上註冊好了全部的信息，就等着學校發來 CAS 的文件了。於是我再花了半個小時把 CAS 上的內容填寫到簽證申請的網站上去。在申請的網站上，會中途跳出來讓你支付一年醫療保險的頁面（£150），付完保險費以後會收到自己的保險號碼。估計以後在英國如果需要看病的話報自己的保險號碼就OK了。於是乎我以迅雷不及掩耳之勢立刻預約了7月31日去大阪的簽證申請中心遞交簽證材料。&lt;/p&gt;

&lt;p&gt;等待去辦簽證的過程中，又收到好消息，宿舍抽籤中了。於是我就成了倫敦準市民之一拉。哈哈哈哈。今兒真高興阿，今兒真高興。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/gif/shuang.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我抽中的是&lt;a href=&#34;http://halls.london.ac.uk/international-hall&#34; target=&#34;_blank&#34;&gt;International Hall&lt;/a&gt;的單人間。仔細閱讀了條款後發現，每週2百鎊的房租確實有點小貴，但是呢，確是包了早餐晚餐和週末的四餐的。我想這將會大大減輕時間和金錢的成本。畢竟只有一年的留學時間。將就將就吧，每天都是炸魚和薯條估計吃一週就會讓人瘋了誒。。。先做好心理準備。對伙食不應有太高期待。&lt;/p&gt;

&lt;p&gt;萬事具備，&lt;del&gt;只差簽證了。&lt;/del&gt; 於是就到了預約機票的時候，查了半天各種中介的網站，結果都是什麼中轉三四次的，要不就是繞地球一大圈的，才能有價格比較便宜的。索性打電話去日本航空詢問有沒有給留學生準備的往返一年，時間靈活的機票。果然不問不知道，一問嚇一跳阿，電話接線員小哥樂呵呵:-)說，哎呀你這電話打的太是時候了，我們日本航空正好最近上線了歐洲航線的特價機票，而且專門針對你這樣要待三個月以上的客戶。一問價格，我的媽呀，出發行程已定，歸程未定的叫做半靈活機票 (semi-flexi)，日本航空的這個折扣價爲12萬日元。比全日空便宜了一半，比其他的可疑航空減少了飛行時間，還有什麼好說的，果斷就訂了。結果呢，準備付錢了小哥告訴我說，您現在先別付定金，我這裏已經幫你把機票預留好了，您等8月1日以後再上網站上打開訂單支付，因爲8月1日後的燃油稅機場時用費等雜費由於匯率等變化會再便宜一萬日元左右。&lt;strong&gt;W!T!F!&lt;/strong&gt; 感動得熱淚盈眶有沒有，簡直就想穿過電話線去擁抱這位小哥了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/jal.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;這一週簡直了，從前幾個月的無盡等待到讓人懷疑人生，懷疑自己還能不能去英國，瞬間轉到材料全備齊，訂了飛機票，而且還額外中了一個獎學金（日本的財團）。快要樂不攏嘴了。。。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>留學筆記</title>
      <link>https://wangcc.me/post/2017-03-16/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-03-16/</guid>
      <description>

&lt;h2 id=&#34;尋找並確定合適自己的大學-合適的課程&#34;&gt;尋找並確定合適自己的大學，合適的課程&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;英國，還是美國？ 這是一個問題

&lt;ul&gt;
&lt;li&gt;我能獲得現在工作的大學的經費（其實就是保留職位，工資照發）支持的條件是，最長的出差/留學不能超過一年。&lt;/li&gt;
&lt;li&gt;上面這個條件是最硬的了，沒有銀子，啥都辦不成是吧。美國的碩士基本都是兩年，而且每年的學費都是英國的兩倍左右。真是羨慕嫉妒自費去英美讀書的大陸籍學生們，你們都是行走的美金符號 $。&lt;/li&gt;
&lt;li&gt;加上美國目前爲止去了3-4次了，對北美大陸除了加拿大(溫哥華)印象非常好以外，美帝給人的感覺就是一個自由化了的中國大陸。沒有任何親切感，或者吸引我個人再去長久居住的地方。當然去美國的機會以後可能還有。故覺得去正在經歷激盪變幻莫測歷史的英國也是不錯的選擇。脫歐愈演愈烈，不知道英國會不會有什麼波瀾壯闊的變化，如果能碰巧做個見證人，也是不錯的。將來可以跟我兒子說，看當年大英帝國被踢出歐萌的時候，爸爸在那親眼看着呢。&lt;/li&gt;
&lt;li&gt;另外就是大學的選擇了。當然可選擇的大學有很多，奈何我之前跟大學申請這個例外項目的時候說的是倫敦大學。因此什麼劍橋牛津都是浮雲了。還好我沒明確說，其實倫敦大學底下一大堆大學，UCL和LSHTM是我的申請重點。因爲論醫學統計學課程，大家可以參考這篇&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/7754267&#34; target=&#34;_blank&#34;&gt;文章&lt;/a&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:Pocock-S-J-Life&#34;&gt;&lt;a href=&#34;#fn:Pocock-S-J-Life&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; 。儘管時間有點久遠，但是英國國內大學有開設醫學統計課程的大概就那麼幾個，估計沒什麼太大變化，摘錄Pro. Pocock總結的各家特色如下：&lt;br&gt;我們可以看到，從最上面的劍橋大學，到最下面的LSHTM(有人翻譯成倫敦衛校😅)按照教學內容偏重理論還是實際進行了排序。所以，LSHTM最偏重實際應用的名氣，是由來已久的。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Theory&lt;br&gt; (偏重理論)&lt;/td&gt;
&lt;td&gt;Cambridge&lt;/td&gt;
&lt;td&gt;Mathematical Statistics&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;Sheffield&lt;/td&gt;
&lt;td&gt;Statistics&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;University College London&lt;/td&gt;
&lt;td&gt;Applied Stochastic Systems&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;Oxford&lt;/td&gt;
&lt;td&gt;Applied Statistics&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;Kent&lt;/td&gt;
&lt;td&gt;Statistics&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;Reading&lt;/td&gt;
&lt;td&gt;Biometry&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;Southampton&lt;/td&gt;
&lt;td&gt;Statistics with Application in Medicine&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;Leicester&lt;/td&gt;
&lt;td&gt;Medical Statistics &amp;amp; Information Technology&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Applications (偏重實踐)&lt;/td&gt;
&lt;td&gt;London School of Hygiene &amp;amp; Tropical Medicine&lt;/td&gt;
&lt;td&gt;Medical Statitics&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;確認申請時間-申請要點-雅思成績要求-是否有面試-推薦信&#34;&gt;確認申請時間，申請要點（雅思成績要求，是否有面試，推薦信）&lt;/h2&gt;

&lt;p&gt;決定了申請 LSHTM 以後，便要開始準備材料，確定截止時間，以及雅思成績的要求等。&lt;/p&gt;

&lt;p&gt;我之前並無申請歐美大學的經驗，許多都是這次申請過程中自己摸索的。總結一下就是，留學申請這種事，自己來就可以搞定了。經過仔細鑽研LSHTM的醫學統計碩士課程&lt;a href=&#34;http://www.lshtm.ac.uk/study/masters/msms.html&#34; target=&#34;_blank&#34;&gt;網站&lt;/a&gt;，確認雅思成績要求總分不低於7，聽說讀單項最低不低於5.5，寫作不低於6.5以後，便着手開始集中複習英語的計劃。&lt;/p&gt;

&lt;p&gt;至於申請截止時間，&lt;a href=&#34;http://www.lshtm.ac.uk/study/applications/index.html&#34; target=&#34;_blank&#34;&gt;網站&lt;/a&gt;說的8月1日，沃天。。。9月底開學8月還能申請。不過，6月1日以後的申請要交£100的過遲申請費用。不管怎麼說，越早越好。我是2016年10月開始計劃申請的，那時候自己給自己定下目標，1月7日雅思成績如果達標，1月份之內就完成所有申請步驟。&lt;/p&gt;

&lt;p&gt;面試的情況後面會再多說一些，其他課程不太瞭解，醫學統計學的碩士課程是對有可能成爲學生的人進行面試的 (potential students will be invited to join an interview)。所以估計材料交了以後很久都沒有面試的通知的話，那就可以安心在家當作自己沒有申請過，該幹嘛幹嘛了。儘量保持低調嘛。我還跟他們負責招生的人發郵件確認了，材料遞交6周左右會給面試通知。估計不錄取也是在這個時間點給通知的。&lt;/p&gt;

&lt;p&gt;最後一個就是最重要的推薦人的選擇了。我邀請之前博士階段的導師，以及現在的同事。聽說美國大學要三個推薦人。英國是只要兩人的。關於如何選擇推薦人，LSHTM的網站上說的是，如果申請人正在就學，那就需要兩個都是對你的學業/學術十分瞭解的人。如果申請人已經就業，那就填最高學歷時期的導師一名，及現在的同事一名或者老闆/上司。當然，在把自己要寫的推薦人姓名信息等填入申請表格之前，要跟他們打個招呼才是。&lt;/p&gt;

&lt;p&gt;至於推薦信的內容。我的博士導師收到我的邀請郵件以後欣然同意，然而那之後我並沒有收到他給我的個人評價或者推薦信內容/稿件。我想，大概(有些)認真的日本人認爲這個推薦信對申請人本人來說也應該保密的。不過我對我的導師有充分的信任，不至於在推薦信裏寫我不愛讀書行爲不端之類害我的話。他一直都是實事求是認真做事的人。另外一封推薦信來自我的同事，他對自己英文不太有自信，而且他每天就坐在我隔壁，寫了稿子就讓我看，我又請native speaker幫忙校對了以後提交的。所以我對這個第二封推薦信的內容是掌握的。&lt;/p&gt;

&lt;h2 id=&#34;3個月突擊-雅思8分&#34;&gt;3個月突擊，雅思8分&lt;/h2&gt;

&lt;p&gt;我以前考過兩次託福。都是裸考。一次是大學期間跟風考的，大夥兒都忙忙碌碌，準備考研啦，準備託福GRE出國拉，所以我也想說考一個，看看這些英語考試都考什麼內容。如果您來我這裏想瞭解託福雅思考試的祕籍，抱歉出門左轉去&lt;a href=&#34;https://www.hujiang.com/&#34; target=&#34;_blank&#34;&gt;滬江外語&lt;/a&gt;吧。我每日也都是用的他家的APP和資源（主要是聽寫BBC新聞）。另外推薦一個背單詞的軟件：&lt;a href=&#34;https://www.baicizhan.com/&#34; target=&#34;_blank&#34;&gt;百詞斬&lt;/a&gt;。&lt;a href=&#34;https://www.shanbay.com/&#34; target=&#34;_blank&#34;&gt;扇貝單詞&lt;/a&gt;也不錯。不過個人還是對百詞斬比較偏愛。也許是先入爲主吧。第一次打開時，設置自己的背誦單詞表（雅思詞彙）然後設定好時間，和背詞計劃。我是設定了每日100個單詞。每天堅持一百個，直到考試前一天。百詞斬的app會再每天第一次打開app的時候提醒，並且複習昨天或者最近背誦過的生詞。感覺他們應該是用了一些算法的，大約是根據個人背誦單詞的記錄（傳說中的記憶曲線？），以及錯誤次數來選出每天複習的詞彙的，這一點百詞斬很厲害。&lt;/p&gt;

&lt;p&gt;除了背單詞，就是尋找合適的老師練習寫作和口語了。在此我就不去給某寶作廣告了。我找了兩個雅思作文老師練習，每天都有寫作的作業，一天 task 1 第二天 task 2 這樣。有的老師只提供作文修改和點評，有的還會給你上課，當然費用就比前一種稍微貴一些。能提供授課服務的老師基本上就是具有新東方，環球雅思等授課經驗的作文老師。作文老師推薦的教材可以在此介紹一下:
&lt;a href=&#34;https://book.douban.com/subject/11596223/&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://wangcc.me/img/ieltswriting.jpg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;至於口語，某寶上的口語外教中介等類似商品就更多了。基本上應該都是菲律賓的口語老師。一開始我也抱着忐忑的心情預約試聽了以下，擔心菲律賓的口語老師可能會有類似印度人的難懂口音。後來的事實證明自己完全是多慮了。至少在我聽課的那幾位菲律賓的外教的口音都較爲純正。況且每個人的口音（應該）都是天生的/後天跟父母學的，不必擔心自己上了幾天口語可就變成怪怪的阿三口音。另外記得以前看過文章說英語母語者能辨別很多不同的口音，所以關鍵不是口音影響一個人的表達，而是你到底真的會不會表達。而且如果你的有點異國口音的英語常常還會被認爲很有趣，很性感，或者很有特點。個人認爲典型的中國人的口音其實多數情況下不太性感，但是你也可以變得像下面這個人一樣風趣幽默（點擊圖片可以看到他講的中式腔調的英語笑話，老外一樣被逗得一樂一樂的）:
&lt;a href=&#34;https://www.youtube.com/watch?v=JTE0-UY9_T0&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://wangcc.me/img/joewong.jpg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;
於是我的口語課就固定爲每天早晨9點鐘開始一個小時，和老師練習過去口語考過的題目。各種常見/不常見話題的切磋和準備。許多話題是根本想不到的。比如，“請描述一次你參加過的婚禮”，或者“請用英語講一個中國歷史上的有趣的故事”這樣的題目，讓我用中文來講述我還要愣上個1分鐘，更不要說在分秒必爭的口語考試中被問道這樣的題目，基本就等於告訴你回去準備再交錢考試了。&lt;/p&gt;

&lt;p&gt;備考雅思是一段辛苦的過程。堅持每日練習才能保持良好的考試/競技狀態，口語和作文是中國人的短板。聽力和寫作常常有不少人（包括我）可以拿到接近滿分。我一開始備考時也是覺得要把過去劍橋雅思的4-11套&lt;a href=&#34;https://book.douban.com/subject/1479127/&#34; target=&#34;_blank&#34;&gt;全真練習題&lt;/a&gt;全部過一邊，題海戰術嘛。後來被寫作的老師敲了警鐘。他說：「聽力和閱讀如果每天都花過多的時間去做的話，對於你來說提高很有限，因爲你都只有錯很少的題目，只是自己刷高分滿足自己的虛榮心而已。到頭來短板的作文和口語都沒有時間練習的話，總分還是上不去。」於是我聽從了寫作老師的話，改爲三四天做一套聽力和閱讀。當然每次都是用考試時的標準來。所以其實一直到了考前，我也沒有把4-11的所有過去試題都練習完。只是挑着做了一些。關於考場的真實感受和我的考分。可以看我之前的&lt;a href=&#34;https://winterwang.github.io/post/2017-01-07-ielts-test/&#34; target=&#34;_blank&#34;&gt;文章&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;1個月集中-文件準備&#34;&gt;1個月集中，文件準備&lt;/h2&gt;

&lt;p&gt;考完雅思考試以後等待考試成績公佈的這段時間，我便開始着手準備申請所需要的各種文件。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;最近的大學院（就是我的博士課程）成績單，英文版。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;博士學位證書，和名古屋大學的畢業證書的英文版。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1和2由於是要開英文版的，聯繫名古屋大學的留學生辦公室，申請郵寄辦理（無手續費），然後附上回信的信封和郵票就可以了。&lt;/li&gt;
&lt;li&gt;另外，爲了以防萬一，我又拜託之前本科階段上海交大的指導老師幫忙開具了本科階段的學位證書，畢業證書的英文版，以及當年的成績單。（看了當時的成績單，不禁回想當年在上海求學的日子。曾經有段時間，在中國訪問facebook是不需要任何技巧的。那個時候，我們還有google reader，還有google.cn。。。）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;個人簡歷&lt;a href=&#34;https://github.com/winterwang/markdown_cv/raw/master/Rmarkdown/rap-2pg-cv.pdf&#34; target=&#34;_blank&#34;&gt;cv&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;查找了許多模板，后来选择了(&lt;a href=&#34;http://svmiller.com/blog/2016/03/svm-r-markdown-cv/&#34; target=&#34;_blank&#34;&gt;这一款&lt;/a&gt;)。&lt;code&gt;Fork&lt;/code&gt;过来以后打开&lt;code&gt;Rmd&lt;/code&gt;文件，写上自己的内容，&lt;code&gt;knit&lt;/code&gt;，pdf就生成了。生活从未如此简单与快乐。告别Micro$oft，你会更轻松。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;個人陳述(Personal Statement)寫作，修改，寫作，修改。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;格式依然是用&lt;a href=&#34;https://github.com/rohanarora/SoP&#34; target=&#34;_blank&#34;&gt;模板&lt;/a&gt;，然后内容的写作和修改，确实费了一番脑筋和功夫。先是寫了初稿，然後給了曾經上过LSHTM醫學統計課程的日本人前輩看，然後修改，又給寫推薦信的兩位導師看，然後再修改，之後再給曾經在UCL留學的高中同學，以及他認識的 native speaker 看，之後再修改。此後又给目前在UCL任教的曾經的高中同學看。最后又花錢送去潤色和校對一遍，才決定最後作爲申請文書遞交給LSHTM。六個不同的人給的意見自然會有不同，最終還是要自己作決斷和取捨的。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;跟以前的導師，現在的上司請求推薦信&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;上面提到個人陳述的時候也說到把稿子給了兩位寫推薦信的導師看。我覺得這一點十分重要。畢竟寫推薦信的導師，他要知道你自己在個人陳述中自我推薦了什麼，才能再在推薦信裏加以強調。深以爲然。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;備齊材料-終於可以申請了&#34;&gt;備齊材料，終於可以申請了！&lt;/h2&gt;

&lt;p&gt;上面的各種文件備齊了以後，就是直接在線填寫申請表格了。表格中仍有部分內容需要自己填寫的。在此不再贅述。 按下申請按鈕之後，LSHTM發來確認信。估計是系統自動發送的。之後便是等待兩位推薦人在線遞交推薦信了。兩位推薦人交齊了推薦信，已經是我申請提交之後一個月左右的事了。之後該是進入和文書審查階段。&lt;/p&gt;

&lt;h2 id=&#34;面試來了-面試真的來了&#34;&gt;面試來了！面試真的來了！&lt;/h2&gt;

&lt;p&gt;過了兩到三週。課程的聯絡人(Admissions Administrator)發來郵件說安排一下Skype面試的時間。&lt;/p&gt;

&lt;h2 id=&#34;我被錄取了&#34;&gt;我被錄取了！&lt;/h2&gt;

&lt;h2 id=&#34;補交畢業證書的原件&#34;&gt;補交畢業證書的原件&lt;/h2&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:Pocock-S-J-Life&#34;&gt;Pocock, S. J. Life as an academic medical statistician and how to survive it. Statist. Med. 14, 209–222 (1995). &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:Pocock-S-J-Life&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
