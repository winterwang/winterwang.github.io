<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Inference on Be ambitious</title>
    <link>https://winterwang.github.io/tags/inference/</link>
    <description>Recent content in Inference on Be ambitious</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Chaochen Wang | 王超辰</copyright>
    <lastBuildDate>Thu, 19 Oct 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/inference/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>偉大的中心極限定理</title>
      <link>https://winterwang.github.io/post/central-limit-theory/</link>
      <pubDate>Thu, 19 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/central-limit-theory/</guid>
      <description>&lt;p&gt;最近明顯可以感覺到課程的步驟開始加速。看我的課表：&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://winterwang.github.io/img/IMG_0522.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;手機畫面太小了。早上都是9點半開始，下午基本都是到5點。週一更慘，到7點。週二-週五中午都被統計中心的講座佔據。簡直是非人的生活。&lt;/p&gt;
&lt;p&gt;這周概率論基礎結束。中心極限定理講完以後我們正式進入了 Inference 統計推斷的課程。我們花了一天時間講什麼是樣本估計 (Estimation)，什麼是參數精確度 (Precision)，什麼是自由度 (degree of freedom)，怎樣進行不偏的估計 (unbiased inference)。然後還有似然方程 (likelihood function)。&lt;/p&gt;
&lt;p&gt;今天的更新還是簡單的把概率論掃尾一下。感受一下中心極限定理的偉大。&lt;/p&gt;
&lt;div id=&#34;-covariance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;協方差 Covariance&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/post/probability2-4/&#34;&gt;之前我們定義過&lt;/a&gt;，兩個獨立連續隨機變量 &lt;span class=&#34;math inline&#34;&gt;\(X,Y\)&lt;/span&gt; 之和的方差 Variance ：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var(X+Y)=Var(X)+Var(Y)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然而如果他們並不相互獨立的話：&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
Var(X+Y) &amp;amp;= E[((X+Y)-E(X+Y))^2] \\
         &amp;amp;= E[(X+Y)-(E(X)+E(Y))^2] \\
         &amp;amp;= E[(X-E(X)) - (Y-E(Y))^2] \\
         &amp;amp;= E[(X-E(X))^2+(Y-E(Y))^2 \\
         &amp;amp; \;\;\; +2(X-E(X))(Y-E(Y))] \\
         &amp;amp;= Var(X)+Var(Y)+2E[(X-E(X))(Y-E(Y))]
\end{aligned}\]&lt;/span&gt;
&lt;p&gt;可以發現在兩者和的方差公式展開之後多了一部分 &lt;span class=&#34;math inline&#34;&gt;\(E[(X-E(X))(Y-E(Y))]\)&lt;/span&gt;。 這個多出來的一部分就說明了二者 &lt;span class=&#34;math inline&#34;&gt;\((X, Y)\)&lt;/span&gt; 之間的關係。它被定義爲協方差 (Covariance): &lt;span class=&#34;math display&#34;&gt;\[Cov(X,Y) = E[(X-E(X))(Y-E(Y))]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)\]&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;要記住，協方差只能用於評價&lt;span class=&#34;math inline&#34;&gt;(X,Y)&lt;/span&gt;之間的線性關係 (Linear Association)。&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;以下是協方差 (Covariance) 的一些特殊性質：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(X,X)=Var(X)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(X,Y)=Cov(Y,X)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(aX,bY)=ab\:Cov(X,Y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(aR+bS,cX+dY)=ac\:Cov(R,X)+ad\:Cov(R,Y)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+bc\:Cov(S,X)+bd\:Cov(S,Y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(aX+bY,cX+dY)=ac\:Var(X)+ad\:Var(Y)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+(ad+bc)Cov(X,Y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(X+Y,X-Y)=Var(X)-Var(Y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;If &lt;span class=&#34;math inline&#34;&gt;\(X, Y\)&lt;/span&gt; are independent. &lt;span class=&#34;math inline&#34;&gt;\(Cov(X,Y)=0\)&lt;/span&gt; &lt;span class=&#34;diff_alert&#34;&gt;But not vise-versa !&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;-correlation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;相關 Correlation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;協方差雖然&lt;span class=&#34;math inline&#34;&gt;\(Cov(X,Y)\)&lt;/span&gt; 的大小很大程度上會被他們各自的單位和波動大小左右。&lt;/li&gt;
&lt;li&gt;我們將協方差標準化(除以各自的標準差 s.d.) (standardization) 之後，就可以得到相關係數 Corr (&lt;span class=&#34;math inline&#34;&gt;\(-1\sim1\)&lt;/span&gt;): &lt;span class=&#34;math display&#34;&gt;\[Corr(X,Y)=\frac{Cov(X,Y)}{SD(X)SD(Y)}=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;-the-central-limit-theory&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;中心極限定理 the Central Limit Theory&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;diff_add&#34;&gt;&lt;strong&gt;如果從人羣中多次選出樣本量爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 的樣本，並計算樣本均值, &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}_n\)&lt;/span&gt;。那麼這個樣本均值 &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}_n\)&lt;/span&gt; 的分佈，會隨着樣本量增加 &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow\infty\)&lt;/span&gt;，而接近正態分佈。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;偉大的中心極限定理告訴我們：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;diff_alert&#34;&gt;&lt;strong&gt;當樣本量足夠大時，樣本均值 &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}_n\)&lt;/span&gt; 的分佈爲正態分佈，這個特性與樣本來自的人羣的分佈 &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt; 無關。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;再說一遍：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果對象是獨立同分佈 i.i.d (identically and independently distributed)。那麼它的總體期望和方差分別是: &lt;span class=&#34;math inline&#34;&gt;\(E(X)=\mu;\;Var(X)=\sigma^s\)&lt;/span&gt;。 根據中心極限定理，可以得到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;當樣本量增加，樣本均值的分佈服從正態分佈： &lt;span class=&#34;math display&#34;&gt;\[\bar{X}_n\sim N(\mu, \frac{\sigma^2}{n})\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;也可以寫作，當樣本量增加： &lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^nX_i \sim N(n\mu,n\sigma^2)\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;有了這個定理，我們可以拋開樣本空間(&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;)的分佈，也不用假定它服從正態分佈。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;diff_alert&#34;&gt;但是樣本的均值，卻總是服從正態分佈的。&lt;/span&gt;簡直是太完美了！！！！！！&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>你會用概率論來賭博嗎？</title>
      <link>https://winterwang.github.io/post/probability-gambling/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://winterwang.github.io/post/probability-gambling/</guid>
      <description>&lt;p&gt;轉眼我已經進入課程的第二週了，總體來說，我們一半的時間都在電腦房練習 Stata 的數據清理和簡單的描述統計 (descriptive statistics)。從我個人的經驗來說，數據分析的過程，其實一大半的時間是消耗在 data cleaning 上的，即使手頭拿到了所謂的乾淨的數據，到真正要分析的時候就會發現一大堆的問題在裏面，需要重新整理，重新添加標記以使之變得更加讓人類可以讀懂。電腦是機器，他是不管你的數據是否乾淨的。只要你放了數據進去，邏輯還可以，沒有編程上的語法錯誤，它總歸會出來一些報告和結果的。如果就這麼直接用的話，大部分的人就會掉進陷阱。畢竟數據不光會說出事實真相，&lt;strong&gt;更多的情況下還會把真相給掩蓋住了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我的其餘大部分時間都用在了複習高等數學的微積分上了。感覺好似回到了高中時代。其實大學的時候線性代數得分還是接近滿分的。後來多年不用，生疏了。剛打開複習的書的時候，許多微分積分的規則都已經忘記。通過這一週的辛苦練習，終於是找回了一點狀態。如果你也想有空的時候複習以下高中數學知識，這本書可以推薦給你：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.uk/gp/product/0471827223/ref=oh_aui_detailpage_o04_s00?ie=UTF8&amp;amp;psc=1&#34;&gt;Quick Calculus: Short Manual of Self-instruction&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://winterwang.github.io/img/Selection_070.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;上面這本書的內容可以一邊閱讀，一邊練習。實在是複習的一本好書。我花了一週的課餘時間，從頭到尾把裏面的習題和解答全部完成。收穫很大。感覺年輕時的數學思維又開始在大腦裏復甦了。一身輕鬆。&lt;/p&gt;
&lt;p&gt;下面想介紹一下上週學習的概率的基礎問題。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;首先是最基礎的&lt;strong&gt;三個概率的公理&lt;/strong&gt;：&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;對於任意事件 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;，它發生的概率 &lt;span class=&#34;math inline&#34;&gt;\(P(A)\)&lt;/span&gt; 滿足這樣的不等式： &lt;span class=&#34;math inline&#34;&gt;\(0 \leqslant P(A) \leqslant 1\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(\Omega)=1\)&lt;/span&gt; , &lt;span class=&#34;math inline&#34;&gt;\(\Omega\)&lt;/span&gt; 是全樣本空間 (total sample space)&lt;/li&gt;
&lt;li&gt;對於互斥（相互獨立）的事件 &lt;span class=&#34;math inline&#34;&gt;\(A_1, A_2, \dots, A_n\)&lt;/span&gt; 有如下的等式關係： &lt;span class=&#34;math inline&#34;&gt;\(P(A_1\cup A_2 \cup \cdots \cup A_n)=P(A_1)+P(A_2)+\cdots+P(A_n)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;你是不是覺得上面三條公理都是&lt;strong&gt;廢話&lt;/strong&gt;。 不用擔心，我也是這麼覺得的。因爲所有人都認同的道理，才能成爲公理 (axiom)，因爲它們是不需要證明的自然而然形成的人人都接受的觀念。&lt;code&gt;(axiom: a saying that is widely accepted on its own merits; its truth is assumed to be self-evident)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;然而，正是這樣顯而易見的道理，確是拿來建築理論的基石，千萬不能小看了他們。例如，我們看下面這個看似也應該成爲公理的公式，你能證明嗎：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A_1\cup A_2) = P(A_1) + P(A_2) - P(A_1 \cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://winterwang.github.io/img/venngram.png&#34; /&gt;

&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明：&lt;/h4&gt;
&lt;p&gt;先考慮 &lt;span class=&#34;math inline&#34;&gt;\(A_1 \cup A_2\)&lt;/span&gt; 是什麼（拆分成三個互斥事件）&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A_1 \cup A_2 = (A_1\cap \bar{A_2})\cup(\bar{A_1}\cap A_2)\cup(A_1\cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;運用上面的公理&lt;del&gt;2&lt;/del&gt; 3&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\therefore P(A_1 \cup A_2) = P(A_1\cap \bar{A_2}) + P(\bar{A_1}\cap A_2) + P(A_1\cap A_2) \;\;\;\;\;\;(1)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;再考慮 &lt;span class=&#34;math inline&#34;&gt;\(A_1=(A_1\cap A_2)\cup(A_1\cap\bar{A_2})\)&lt;/span&gt; 繼續拆分成兩個互斥事件&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\therefore P(A_1)=P(A_1\cap A_2)+P(A_1\cap\bar{A_2})\)&lt;/span&gt; 整理一下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A_1\cap\bar{A_2})=P(A_1)-P(A_1\cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同理可得: &lt;span class=&#34;math inline&#34;&gt;\(P(\bar{A_1}\cap A_2)=P(A_2)-P(A_1\cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;代入上面第(1)式可得：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A_1 \cup A_2) =P(A_1)-P(A_1\cap A_2)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+P(A_2)-P(A_1\cap A_2)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+P(A_1\cap A_2)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;=P(A_1) + P(A_2) - P(A_1 \cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-conditional-probability&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;條件概率 Conditional probability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A|S)=\frac{P(A\cap S)}{P(S)}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A\cap S) = P(A|S)P(S)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;-independence-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;獨立 (independence) 的定義&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;兩個事件定義爲互爲獨立時 (&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; are said to be independent &lt;strong&gt;if and only if&lt;/strong&gt;) &lt;span class=&#34;math display&#34;&gt;\[P(A\cap B)=P(A)P(B)\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;因爲從條件概率的概念我們已知&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(P(A\cap B) = P(A|B)P(B)\)&lt;/span&gt; &lt;br&gt;所以&lt;span class=&#34;math inline&#34;&gt;\(P(A|B)=P(A)\)&lt;/span&gt; 即：事件 &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; 無法提供事件 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的任何有效訊息 (&lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(A, B\)&lt;/span&gt; 互相獨立&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;賭博問題&lt;/h2&gt;
&lt;p&gt;終於來到本次話題的重點了。我要扣題了哦。語文老師快在此加分。&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://winterwang.github.io/img/Selection_071.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;假設你在一個電視遊戲節目。有上圖一樣的三扇門。其中一扇門後面有一輛保時捷，另兩扇門後面則是&lt;a href=&#34;https://winterwang.github.io/post/black-meal/&#34;&gt;(味道奇特的)山羊&lt;/a&gt;。遊戲規則是主持人會讓你先選擇其中一扇門（先不打開你選的這扇門）。主持人隨後打開另外兩扇門中的一扇沒有保時捷的門。主持人問你，你要堅持選擇之前選中的那扇門，還是要改變主意換一扇門去猜是否可以猜中保時捷。 請問，堅持選擇之前選中的門猜中保時捷的概率高，還是主持人打開一扇門以後改變主意猜中保時捷的概率更高呢？&lt;/p&gt;
&lt;p&gt;答案明天揭曉。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
