<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Be Ambitious</title>
    <link>https://wangcc.me/post/</link>
      <atom:link href="https://wangcc.me/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2017-2020 Chaochen Wang | 王超辰</copyright><lastBuildDate>Mon, 24 Feb 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://wangcc.me/img/icon-192.png</url>
      <title>Posts</title>
      <link>https://wangcc.me/post/</link>
    </image>
    
    <item>
      <title>道聽途說的奇幻錄--20200224</title>
      <link>https://wangcc.me/post/qihuanrizhi/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/qihuanrizhi/</guid>
      <description>&lt;p&gt;![封還是不封](/post/2020-02-24-qihuanrizhi_files/2020-02-24 17.52.29.jpg)&lt;/p&gt;
&lt;p&gt;其實我也不知道到底誰在造謠。政令之混亂，只能反映出這個政權是多麼地無能。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-24-qihuanrizhi_files/IMG_3871.JPG&#34; alt=&#34;防控的是誰&#34;&gt;&lt;/p&gt;
&lt;p&gt;日本的話，估計病毒是防控不住了額，好在，安倍是會被控制住的，他事後被問責是逃不掉的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-24-qihuanrizhi_files/IMG_3870.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-24-qihuanrizhi_files/IMG_3875.JPG&#34; alt=&#34;lock&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-24-qihuanrizhi_files/IMG_3881.JPG&#34; alt=&#34;&#34;&gt;
其實輸血漿的治療方法並不是很理想。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-24-qihuanrizhi_files/IMG_3882.JPG&#34; alt=&#34;a month ago&#34;&gt;
一個月前。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-24-qihuanrizhi_files/IMG_3884.JPG&#34; alt=&#34;&#34;&gt;
病毒傳遍天涯。比瘟疫更可怕的是謊言，是毫無羞恥的謊言。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-24-qihuanrizhi_files/IMG_3886.JPG&#34; alt=&#34;crazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-24-qihuanrizhi_files/IMG_3887.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;他也喊過蔣委員長萬歲，然後又逼着4億人喊他萬歲。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-24-qihuanrizhi_files/IMG_3888.JPG&#34; alt=&#34;&#34;&gt;
金將軍還可以用石子擊落敵機呢。&lt;/p&gt;
&lt;p&gt;![](/post/2020-02-24-qihuanrizhi_files/2020-02-23 12.07.14.jpg)
這不是住在奇幻世界的人的體溫嗎？&lt;/p&gt;
&lt;p&gt;![](/post/2020-02-24-qihuanrizhi_files/2020-02-23 16.00.47.jpg)
恐怕真的不在少數。&lt;/p&gt;
&lt;p&gt;![老婆呢](/post/2020-02-24-qihuanrizhi_files/Screen Shot 2020-02-23 at 11.45.31.png)&lt;/p&gt;
&lt;p&gt;下列視頻可能引起不適，如果你想看喜訊請自覺調到CCTV進行自我調理。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;無情抓捕。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;他們是最可憐的。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;只是不知道萬一發生火災，樓上隔離的人有沒有辦法逃生呢？&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;秦暉老師說的好，救災是最基本的職責，沒有哪個國家的&lt;strong&gt;公民&lt;/strong&gt;會讚美政府的救災，只有批評救災不及時，只有問責災害發生的責任，但是在奇葩魔幻世界的神奇國度裏，你會看見無數讚美之詞，而且有些百姓還會起身咒罵那些拒絕舔菊，甚至是讚美得不夠起勁的人，把他們遊街示衆。這不是奇幻世界是什麼。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-24-qihuanrizhi_files/IMG_3883.JPG&#34; alt=&#34;記憶&#34;&gt;
你還記得多少？&lt;/p&gt;
&lt;p&gt;推薦閱讀：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://matters.news/@zfeaglesky/%E5%AE%98%E5%83%9A%E4%BD%93%E7%B3%BB%E4%B8%8E%E5%85%AC%E6%B0%91%E7%A4%BE%E4%BC%9A-%E8%B0%81%E6%98%AF%E8%82%BA%E7%82%8E%E5%8D%B1%E6%9C%BA%E7%9A%84%E7%AD%94%E6%A1%88-%E7%AC%94%E8%AE%B0-and-%E5%95%86%E6%A6%B7-bafyreiae7fs6zh2zcpbv3ta3bsdda6jviii7plyn6f3hg2vrez4nrpttc4&#34;&gt;《官僚体系与公民社会：谁是肺炎危机的答案》笔记&amp;amp;商榷&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://matters.news/@hannah0905/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E5%8E%8C%E6%81%B6%E7%96%AB%E6%83%85%E9%98%B2%E6%8E%A7%E4%B8%AD%E7%9A%84-%E6%8A%84%E4%BD%9C%E4%B8%9A-%E6%AF%94%E5%96%BB-bafyreihzmimjx47lrsewshljn6uivcsj75kqqgemgxs6zubou63tiut6fm&#34;&gt;为什么我厌恶疫情防控中的“抄作业”比喻？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://matters.news/@sy457/%E8%AF%91%E6%96%87-%E6%9F%B3%E5%8F%B6%E5%88%80%E4%B8%BB%E7%BC%96%E8%AF%84%E8%AE%BA%E6%96%87-%E4%B8%8D%E6%AD%A2%E4%BA%8E%E7%9C%9F%E7%9B%B8-bafyreihb67g77sgkgjqftuuex4n363i2u4ezqf7grgm6oxqmsnfyqz5hyq&#34;&gt;译文 | 柳叶刀主编评论文《不止于真相》&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://matters.news/@Sama/%E7%96%AB%E6%83%85%E6%97%A5%E8%AE%B02020-02-23-%E7%97%85%E5%9C%A8%E7%98%9F%E7%96%AB%E8%94%93%E5%BB%B6%E6%97%B6-%E4%B8%A7%E4%BA%8B%E5%8B%BF%E5%BD%93%E6%88%90%E5%96%9C%E4%BA%8B%E5%81%9A-bafyreifjev2hgg6zrsxrhdsjzecqirirbxa52ipfvym5mhienmzql5zjjm&#34;&gt;疫情日记2020.02.23. 病在瘟疫蔓延时，丧事勿当成喜事做&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>道聽途說的奇幻錄--20200222</title>
      <link>https://wangcc.me/post/rizhi20200222/</link>
      <pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/rizhi20200222/</guid>
      <description>&lt;p&gt;![](/post/2020-02-22-rizhi_files/2020-02-22 15.18.31.jpg)&lt;/p&gt;
&lt;p&gt;韓國一夜之間變成了疫區。武漢那邊正在高奏凱歌噢。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-22-rizhi_files/EQ7Z043XYAAXvdZ.jpeg&#34; alt=&#34;fangfang&#34;&gt;&lt;/p&gt;
&lt;p&gt;感謝方方&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-22-rizhi_files/EQ7Z048XUAcTeXS.jpeg&#34; alt=&#34;紀念&#34;&gt;&lt;/p&gt;
&lt;p&gt;如果你也明白這首詩紀念的是誰，請留言和我做朋友。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-22-rizhi_files/EQ7Z04vXkAEySYj.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;永別了。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;湖南這天报的新增病例只有1例。&lt;/p&gt;
&lt;p&gt;![](/post/2020-02-22-rizhi_files/2020-02-22 15.13.06.jpg)&lt;/p&gt;
&lt;p&gt;指鹿爲馬，秦人不暇自哀。崇禎最後亡國的時候，全部的臣子都在等待他的最高指示。&lt;/p&gt;
&lt;p&gt;![](/post/2020-02-22-rizhi_files/2020-02-22 15.13.51.jpg)&lt;/p&gt;
&lt;p&gt;圍觀各種奇葩標語。這些算不算是對漢字的侮辱。&lt;/p&gt;
&lt;p&gt;![](/post/2020-02-22-rizhi_files/2020-02-22 15.15.59.jpg)&lt;/p&gt;
&lt;p&gt;![](/post/2020-02-22-rizhi_files/2020-02-22 15.16.06.jpg)&lt;/p&gt;
&lt;p&gt;![](/post/2020-02-22-rizhi_files/2020-02-22 15.16.10.jpg)&lt;/p&gt;
&lt;p&gt;![](/post/2020-02-22-rizhi_files/2020-02-22 15.16.16.jpg)&lt;/p&gt;
&lt;p&gt;![](/post/2020-02-22-rizhi_files/2020-02-22 15.16.25.jpg)&lt;/p&gt;
&lt;p&gt;![](/post/2020-02-22-rizhi_files/2020-02-22 15.16.30.jpg)&lt;/p&gt;
&lt;p&gt;![](/post/2020-02-22-rizhi_files/2020-02-22 15.16.35.jpg)&lt;/p&gt;
&lt;p&gt;![](/post/2020-02-22-rizhi_files/2020-02-22 16.24.29.jpg)&lt;/p&gt;
&lt;p&gt;連刪除它的網絡警察也都明白衆望所歸之事指的是什麼。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-22-rizhi_files/IMG_3776.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-22-rizhi_files/IMG_3833.jpg&#34; alt=&#34;iwata&#34;&gt;&lt;/p&gt;
&lt;p&gt;岩田教授說，他認爲他的視頻已經起到了驚醒大家的作用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-22-rizhi_files/IMG_3840.jpg&#34; alt=&#34;tignhua&#34;&gt;&lt;/p&gt;
&lt;p&gt;一定打贏防疫站，的病毒，黨性覺悟大概緊跟一尊其後。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-22-rizhi_files/IMG_3846.JPG&#34; alt=&#34;404&#34;&gt;&lt;/p&gt;
&lt;p&gt;404 的頁面，他們已經遠離這羣無法被醫治的行屍走肉。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-22-rizhi_files/IMG_3855.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;其實我也不知道誰才是負面輿論，誰才是這個世界邪惡的化身。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-22-rizhi_files/IMG_3853.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;領導開會可以延遲，屁民趕工上班死活算什麼。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-22-rizhi_files/IMG_3848.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;2月30日，這是在說疫情結束遙遙無期麼。如果你說的是社會主義官狀瘟疫，那可能真的是遙遙無期。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-22-rizhi_files/IMG_3842.jpg&#34; alt=&#34;kyoto&#34;&gt;&lt;/p&gt;
&lt;p&gt;這天，我還自己驅車155公里從名古屋來到京都參加日本流行病學會的口頭發表。結束回家的第二天，就爆出名古屋高速上收費站的職員有人被確診了。。確診了。。。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-22-rizhi_files/IMG_3838.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;所謂治癒患者，可能只是病毒選擇潛伏一段時間，暫時陰性而已。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;上面是許志永給BBC的採訪視頻。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;網絡上流傳的歌曲。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;白色恐怖，隨時都會降臨在你我頭上。我們都是臨時工。&lt;/p&gt;
&lt;p&gt;推薦閱讀：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Terminus2049/Terminus2049.github.io/blob/master/_posts/2020-02-21-nursing-home.md&#34;&gt;防疫死角：武汉养老院多名老人感染后死亡，有人去世前感叹“死了算啦”&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Terminus2049/Terminus2049.github.io/blob/master/_posts/2020-02-21-Philosophia.md&#34;&gt;疫情之下，诸众联合的新可能性：在市场–国家的对立之外，我们还应看到什么?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Terminus2049/Terminus2049.github.io/blob/master/_posts/2020-02-21-homeless.md&#34;&gt;受歧视遭退租被辞工，湖北籍农民工流落深圳烂尾楼&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.duping.net/XHC/show.php?bbs=10&amp;amp;post=466358&#34;&gt;回国杂记完整版&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>道聽途說的奇幻錄--20200220</title>
      <link>https://wangcc.me/post/rizhi20200220/</link>
      <pubDate>Thu, 20 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/rizhi20200220/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/photo_2020-02-19_21-56-56.jpg&#34; alt=&#34;不能不明白&#34;&gt;&lt;/p&gt;
&lt;p&gt;不能不明白，你明白了嗎？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/photo_2020-02-19_14-20-33.jpg&#34; alt=&#34;17年&#34;&gt;
披上17年前的戰袍，致敬愛的醫護工作者。一定要安全歸來。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/photo_2020-02-19_14-22-35.jpg&#34; alt=&#34;&#34;&gt;
院長犧牲。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/photo_2020-02-19_18-05-43.jpg&#34; alt=&#34;&#34;&gt;
微信什麼時候才會自掛東南枝？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/photo_2020-02-19_11-05-36.jpg&#34; alt=&#34;&#34;&gt;
俄國終於找到理由驅逐黃禍了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/photo_2020-02-19_14-19-54.jpg&#34; alt=&#34;&#34;&gt;
WHO他們已經絞盡腦汁了唉。。。太拆臺了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/photo_2020-02-19_19-49-09.jpg&#34; alt=&#34;&#34;&gt;
王朔說的話，不能再同感。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/photo_2020-02-19_18-59-58.jpg&#34; alt=&#34;&#34;&gt;
啪&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/photo_2020-02-20_10-14-00.jpg&#34; alt=&#34;&#34;&gt;
歌舞昇平，白骨如山&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3703.PNG&#34; alt=&#34;&#34;&gt;
日本媒體終於醒悟，現在日本也已經處在傳染病爆發前期階段。日本人是否會開始後悔把口罩毫無保留地都捐助給了西邊的鄰居？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3726.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Terminus2049/Terminus2049.github.io/blob/master/_posts/2020-02-19-you-you-lu-ming.md&#34;&gt;二十天的婴儿开口说话后，卧床多年的植物人也笑了&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3731.JPG&#34; alt=&#34;&#34;&gt;
其實我也不知道是誰在造謠，他們中有人領訓誡書了嗎？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3738.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3739.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3740.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3737.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3733.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3735.JPG&#34; alt=&#34;&#34;&gt;
有些人說了些實話，然後他們就失蹤了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3816.JPG&#34; alt=&#34;&#34;&gt;
政治正確是最令人作嘔的遮羞布，殺人不眨眼的制度。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3810.PNG&#34; alt=&#34;&#34;&gt;
在鑽石公主號新診斷了79人感染者的今天，總理大臣撒完了謊，也沒有出現在國會，而是去品嚐了美味的河豚魚，現在NHK正在介紹他吃的山口縣的河豚魚。這就是美麗的日本。&amp;mdash;清水潔&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3798.JPG&#34; alt=&#34;&#34;&gt;
安倍晉三的內閣這次出醜出大了，弱智政府總是那麼相似。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3786.JPG&#34; alt=&#34;&#34;&gt;
你知道該寫什麼嗎？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3778.jpg&#34; alt=&#34;&#34;&gt;
卑鄙是卑鄙者的通行證。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3777.jpg&#34; alt=&#34;&#34;&gt;
不要臉的最高境界。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3770.JPG&#34; alt=&#34;&#34;&gt;
演員演技不行。警察叔叔快點來寫訓誡書。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3769.JPG&#34; alt=&#34;&#34;&gt;
中國好故事，怎麼看起來似曾相識。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3765.jpg&#34; alt=&#34;&#34;&gt;
日本厚生省提出的4個自查用的就診條件：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;感冒症狀，或者37.5以上發燒持續4天以上&lt;/li&gt;
&lt;li&gt;感到呼吸困難或者重度倦怠感&lt;/li&gt;
&lt;li&gt;有以上兩條者，請聯絡歸國者/接觸者聯繫中心，如果是高齡患者，或者同時具有糖尿病，心衰竭等基礎疾病，或者是需要接受腎臟透析的患者，患者正在服用免疫抑制劑/抗癌藥物的人，那麼上述1，2兩條症狀持續2天以上就需要聯繫求助電話。&lt;/li&gt;
&lt;li&gt;孕婦也請聯繫求助電話
電話聯繫之前，請避免外出，上班或者上學。每天請測量體溫，並做好記錄。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-20-rizhi_files/IMG_3751.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这条幽暗无光的隧道，我们还要走多久才能到头？&lt;/p&gt;
&lt;p&gt;思念曲，紀念李文亮，希望他不會白白逝去：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;推薦閱讀：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Terminus2049/Terminus2049.github.io/blob/master/_posts/2020-02-20-da-jia.md&#34;&gt;大家｜比病毒可怕：被谣言操纵的人类暴力史&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://matters.news/@2020Era/%E6%AD%A6%E6%B1%89%E8%82%BA%E7%82%8E50%E5%A4%A9-%E5%85%A8%E4%BD%93%E4%B8%AD%E5%9B%BD%E4%BA%BA%E9%83%BD%E5%9C%A8%E6%89%BF%E5%8F%97%E5%AA%92%E4%BD%93%E6%AD%BB%E4%BA%A1%E7%9A%84%E4%BB%A3%E4%BB%B7-zdpuB35z4kGhHnfq9qupMsVh41RP9UDhbB6x9x3XTsfmURDNL&#34;&gt;武汉肺炎50天，全体中国人都在承受媒体死亡的代价&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>比電影更加奇幻的是現實--道聽途說的記錄20200216</title>
      <link>https://wangcc.me/post/rizhi/</link>
      <pubDate>Thu, 13 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/rizhi/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-13-rizhi_files/IMG_3702.JPG&#34; alt=&#34;kelianyisheng&#34;&gt;&lt;/p&gt;
&lt;p&gt;可憐的醫務工作者們，光致敬太廉價了，她們的付出，是那麼地不值得。原本他們可以不用這樣“視死如歸，殊死搏鬥”的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-13-rizhi_files/IMG_3706.jpg&#34; alt=&#34;snow&#34;&gt;&lt;/p&gt;
&lt;p&gt;我對這張照片和上面的評論類似，感到極爲不齒。這個所謂的全責政府，就是這樣對待一線工作的“戰士”的嗎？下大雪之前爲什麼不準備好帳篷和取暖設備，這哪裏是裝給上級看的，以中國大陸給人的信任度來說，有理由相信說這可能和雷鋒叔叔一樣都是擺拍的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-13-rizhi_files/IMG_3699.jpg&#34; alt=&#34;leak&#34;&gt;
曾經SARS病毒也有過泄漏的前科，你說武漢的實驗室萬無一失？呵呵。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-13-rizhi_files/IMG_3688.JPG&#34; alt=&#34;linyutang&#34;&gt;
林語堂此話，我深以爲然。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-13-rizhi_files/EQy9iSiUUAEVvkk.jpeg&#34; alt=&#34;linyutang&#34;&gt;
去世了的“學生”如果能本人提出申請，估計受理申請的人會被嚇死。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-13-rizhi_files/IMG_3658.PNG&#34; alt=&#34;Japan lost&#34;&gt;
日本可能要失守，我對安倍政府這次反應遲鈍和對中國大陸的過度信任表示遺憾，如果會影響到奧運會的舉辦，估計日本人腸子都要悔青了。大家都要好好保護自己和家人。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;希望秋實這樣正直勇敢的人，可以多一點，祝願他被強制隔離期間平安。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;歡迎轉載上面打臉視頻。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;真正的病毒，是產生紅衛兵的萬惡的制度，至今無反思，無認罪，永遠都不可能進步，無正義可以在這篇土地上得到申張。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;鼓勵大家對全責政府無限追責，幹不好，請自己走人。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;中國速度，中國質量。&lt;/p&gt;
&lt;p&gt;推薦下列值得一讀的文章：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Terminus2049/Terminus2049.github.io/blob/master/_posts/2020-02-16-sars.md&#34;&gt;非典幸存医护者现状：不是说不会忘了我们吗？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Terminus2049/Terminus2049.github.io/blob/master/_posts/2020-02-16-qin-hui-2.md&#34;&gt;秦晖：不能真把「防疫」当作「战争」&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Terminus2049/Terminus2049.github.io/blob/master/_posts/2020-02-13-%E6%84%A4%E6%80%92%E7%9A%84%E4%BA%BA%E6%B0%91%E5%B7%B2%E4%B8%8D%E5%86%8D%E6%81%90%E6%83%A7.md&#34;&gt;愤怒的人民已不再恐惧&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Terminus2049/Terminus2049.github.io/blob/master/_posts/2020-02-14-wuhan-hosiptal.md&#34;&gt;武汉广发肿瘤医院被临时征用，家属口述癌症患者被强制出院后的遭遇&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Terminus2049/Terminus2049.github.io/blob/master/_posts/2020-02-15-ni-shou-ye.md&#34;&gt;永不消逝的哨音&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>日誌</title>
      <link>https://wangcc.me/post/daily-thinking0212/</link>
      <pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/daily-thinking0212/</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;日本援助時送的物品上寫的那些詩詞，讀起來真是暖暖的感動。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-12-rizhi_files/IMG_3611.jpg&#34; alt=&#34;origami&#34;&gt;&lt;/p&gt;
&lt;p&gt;兒子剛學會的紙飛機，一下子折了這麼多。&lt;/p&gt;
&lt;p&gt;看見有人傳現在在中國大陸各個居民小區門禁時使用口令，有這樣小清新的也算是有點文化了：
&lt;img src=&#34;https://wangcc.me/post/2020-02-12-rizhi_files/IMG_3631.JPG&#34; alt=&#34;zhuziqing&#34;&gt;&lt;/p&gt;
&lt;p&gt;鍾南山其實也是這個制度的受害者：
&lt;img src=&#34;https://wangcc.me/post/2020-02-12-rizhi_files/IMG_3630.JPG&#34; alt=&#34;zhong&#34;&gt;&lt;/p&gt;
&lt;p&gt;又嘗試了一下 Plague 遊戲，果然成功消滅人類只需要一個病毒：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-12-rizhi_files/IMG_3636.PNG&#34; alt=&#34;plague&#34;&gt;&lt;/p&gt;
&lt;p&gt;看看我可愛的女兒壓壓驚：
&lt;img src=&#34;https://wangcc.me/post/2020-02-12-rizhi_files/IMG_3592.jpg&#34; alt=&#34;chicken&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>誰在救度，誰在欺騙</title>
      <link>https://wangcc.me/post/daily-thinking/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/daily-thinking/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-10-daily-thinking_files/IMG_3567.JPG&#34; alt=&#34;freedomofspeech&#34;&gt;&lt;/p&gt;
&lt;p&gt;其實這些日子，太多人都是以淚洗面地度過的吧。&lt;/p&gt;
&lt;p&gt;多年前，我參觀廣島和平紀念館的時候，內心感到極爲震撼的是看到整面整面的牆壁刻下的受難者的名字。如果你去看廣島市政府網站上關於&lt;a href=&#34;http://www.city.hiroshima.lg.jp/www/contents/1283234256399/index.html&#34;&gt;受難者名錄的解說&lt;/a&gt;，你會發現，至今受難者名字都沒有錄全。但是這並不妨礙她們每日每月每年努力的尋找可能沒有被記錄的受難者。整面牆下每個人經過的時候都會產生敬畏之情。因爲這個民族學會了尊重每個受難者，因爲他們深深的明白，建造這座紀念館，是爲了記住這一人類造成的災難，爲了警醒世人莫要再重蹈戰爭覆轍，而不是爲了培養無端的仇恨。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-10-daily-thinking_files/tsuitou002-thumb-1060xauto-5845.jpg&#34; alt=&#34;name of victims&#34;&gt;&lt;/p&gt;
&lt;p&gt;這就是廣島和平紀念館內刻有受難者名字的禱告牆。&lt;/p&gt;
&lt;p&gt;即使是純粹的自然災害，&lt;a href=&#34;https://w.atwiki.jp/earthquakematome/pages/161.html&#34;&gt;311地震後死者名錄&lt;/a&gt;，也是可以公開查閱得到的，失蹤者，固然是無法知曉（但是也不能放棄尋找線索），那麼已知的死難者，就更應該留下她們曾經來過的痕跡，名字，性別，居住的城市，年齡。這是對死者最起碼的尊重。如果要成爲一個有人性的值得尊重的文明，而不是只有（可能還是編造的）外表光鮮亮麗，內心只有空洞甚至是（讓人覺得無比）邪惡的野蠻國家的話，我呼籲，認真反省並追尋發生疫情災害的真實原因，爲犯下的錯誤道歉，謝罪，爲將來不再犯同樣的錯誤作準備，也爲每一名死難者留下在這個世界來過的痕跡，刻一面受難者名字的碑文。即使這樣，可能也難以撫慰逝去的人的遺憾，和破碎的那些家庭的悲傷。那些苦難的人們，永遠也回不來了，他們永遠也無法再對你我訴說也無法再哭泣。請不要再在他們受難的軀體上表演不可能存在的醫學奇跡。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;請記住下面這份訓誡書。這是一份野蠻世界給爲我們敲響警鐘的醫生的墓誌銘。一個連“出生年月”都能寫錯別字的黨衛警察，竟然可以這樣以居高臨下的口氣質問一名醫生，“你能做的到嗎？你明白了嗎？”。我無法想象，不知道李醫生的靈魂離開他的軀體的時候，是否看見這一出比哈姆雷特還慘的悲劇，是否後悔當初寫下了“能，明白”。也許那時他才真正地明白魯迅說的那句，學醫，是救不了這些人的，他最終連自己都沒辦法拯救。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-10-daily-thinking_files/IMG_3508.JPG&#34; alt=&#34;xunjie&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-10-daily-thinking_files/IMG_3524.JPG&#34; alt=&#34;rumor&#34;&gt;&lt;/p&gt;
&lt;p&gt;在野蠻世界的局域網，有個叫做weibo的東西上，掀起了一番小小的波瀾。彷彿死水裏被丟入一塊石子，其實不可能有期待有什麼驚濤駭浪。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;就像我贊同的下面的說法：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-10-daily-thinking_files/IMG_3571.JPG&#34; alt=&#34;beiju&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-10-daily-thinking_files/IMG_3519.JPG&#34; alt=&#34;changye&#34;&gt;&lt;/p&gt;
&lt;p&gt;嗚呼哀哉。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-10-daily-thinking_files/IMG_3509.JPG&#34; alt=&#34;buzhide&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>在新家住了3個月</title>
      <link>https://wangcc.me/post/newhome3month/</link>
      <pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/newhome3month/</guid>
      <description>&lt;p&gt;更新一些我們住進新家以後的照片。還有我們做院子進度(監工)的照片。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2499.JPG&#34; alt=&#34;no garden&#34;&gt;&lt;/p&gt;
&lt;p&gt;這是剛住進來的時候，可以看到門口玄關地磚上的保護用紙還沒有撕掉，因爲前面做停車場和院子的地方還都是泥土。。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2523.JPG&#34; alt=&#34;christmas&#34;&gt;&lt;/p&gt;
&lt;p&gt;去送別響子，我們在名古屋站吃了一次晚餐，小朋友們興奮地在名站門口巨大的聖誕樹前跳起來。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2531.JPG&#34; alt=&#34;shovel car&#34;&gt;&lt;/p&gt;
&lt;p&gt;院子開工了，一個白髮老爺爺開着小卡車載着一臺挖掘機駕到。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;用攝像頭拍到的挖掘機作業，老爺爺很認真。（請忽略背景音😂）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2565.JPG&#34; alt=&#34;tubebroken&#34;&gt;&lt;/p&gt;
&lt;p&gt;上班開會時接到奶奶從家裏撥來緊急聯絡電話，說，停車場的下水管被老爺爺用挖掘機挖斷了。。。看，這都還是一個新管子。奶奶一整個下午都沒辦法使用洗手間。還好負責院子施工的人及時聯繫了水道公司，很快緊急修復好了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2562.jpg&#34; alt=&#34;brickshere&#34;&gt;
門口一大堆廢土被挖掉之後的樣子，接下來就要開始往上鋪水泥，砌磚塊啦。你可以看到這個時候（2019年12月初），南邊那塊土地上還什麼都沒有，只是堆積了一堆建築材料而已。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2566.jpg&#34; alt=&#34;xuexiezi&#34;&gt;&lt;/p&gt;
&lt;p&gt;房間寬敞，小朋友們歡樂地學習寫字。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;用鋼筋作出了停車場和院子的輪廓之後，專業搬磚工人開始認真地固定這些水泥磚塊。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;家附近有一條磁懸浮的電車，大家叫他Linimo，很親切的稱呼，在車站候車時拍到的夕陽時Linimo進站的鏡頭。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;繼續鋪磚塊。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2684.jpg&#34; alt=&#34;parking00&#34;&gt;&lt;/p&gt;
&lt;p&gt;停車場的雛形出來了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2692.jpg&#34; alt=&#34;parking01&#34;&gt;&lt;/p&gt;
&lt;p&gt;停車場的水泥需要保養。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;小朋友喜歡的冬至湯圓在鍋裏滾。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2724.jpg&#34; alt=&#34;sweet puddings&#34;&gt;&lt;/p&gt;
&lt;p&gt;紅色白色的湯圓好看，還是女兒的笑臉好看呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2835.jpg&#34; alt=&#34;AMUH&#34;&gt;&lt;/p&gt;
&lt;p&gt;在工作單位前的池塘拍到藍天與白雲。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2844.jpg&#34; alt=&#34;lobster&#34;&gt;&lt;/p&gt;
&lt;p&gt;我們居然買到了大龍蝦。奶奶也好興奮。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_E2849.JPG&#34; alt=&#34;lobster done&#34;&gt;&lt;/p&gt;
&lt;p&gt;這隻大龍蝦非常飽滿，奶奶的手藝真是沒得挑剔。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;點播放這個監視器視頻的時候請關閉音量，原諒這拍攝時角度麼有調試好，是倒置的。不過可以看見院子的柵欄正在一點點被固定好。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2855.jpg&#34; alt=&#34;fence done&#34;&gt;&lt;/p&gt;
&lt;p&gt;噹噹噹噹。院子完工，停車場水泥也養護完畢可以停上我家的小西了。好興奮。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2896.JPG&#34; alt=&#34;potnothot&#34;&gt;&lt;/p&gt;
&lt;p&gt;兒子打開待煮的火鍋，開心溢於言表。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2909.JPG&#34; alt=&#34;grilled chicken&#34;&gt;&lt;/p&gt;
&lt;p&gt;第一次試用電磁爐的烤箱烤了一隻雞，味道淡了一些，不過還是很有成就感。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;家附近的永旺（AEON）有十分有趣的電子黑板，小朋友們（還有童心未泯的大哥）在玩耍。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2914.JPG&#34; alt=&#34;meandbro&#34;&gt;&lt;/p&gt;
&lt;p&gt;第一次嘗試日本回転寿司的大表哥。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_2927.jpg&#34; alt=&#34;redsweet&#34;&gt;&lt;/p&gt;
&lt;p&gt;調皮搗蛋的小朋友捏雪人一樣的紅色湯圓。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_3032.jpg&#34; alt=&#34;JR&#34;&gt;&lt;/p&gt;
&lt;p&gt;女兒呆萌的表情真有愛，話筒的方向都拿反了。哈哈。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_3037.jpg&#34; alt=&#34;tyrant00&#34;&gt;&lt;/p&gt;
&lt;p&gt;帶小朋友們去圖書館借繪本的時候，竟然發現了講獨裁統治的小人書。感慨萬千。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_3038.jpg&#34; alt=&#34;tyrant01&#34;&gt;&lt;/p&gt;
&lt;p&gt;看看這些榜上有名的萬歲爺們是否有你認識的，也許這個名單還會再更新。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_3039.jpg&#34; alt=&#34;tyrant02&#34;&gt;&lt;/p&gt;
&lt;p&gt;這天（1月21日），我被派去大阪負責大學入學考試的一部分監考工作。酒店的頂樓居酒屋裏沒有什麼客人，窗口看見的是大阪繁華的燈光與樓房。那天，我和幾個同行的監考老師一起晚餐，談到了可能會爆發（事後證明，我是錯的，因爲那個時候是已經爆發）的SARS。本來，一切都可能繼續着平靜祥和，或者叫歲月靜好？那天那個酒店裏，其實我看到了不少來自中國大陸的遊客，現在想起來，還是有點令人憂心的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_3043.jpg&#34; alt=&#34;exam&#34;&gt;&lt;/p&gt;
&lt;p&gt;收拾疲憊回到家以後，看到這隻蜘蛛俠這麼風騷的姿勢，不禁啞然失笑，家裏還是最溫馨的地方。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_3051.jpg&#34; alt=&#34;spider&#34;&gt;&lt;/p&gt;
&lt;p&gt;農曆春節奶奶辛苦地準備一大桌美食，其實我的內心還牽掛着萬里之外那些還被蒙在鼓裏的朋友和她們的親人們。自己和家人的平安之外，今年我並沒有其他更多的願望了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_3123.JPG&#34; alt=&#34;dinnernewyear&#34;&gt;&lt;/p&gt;
&lt;p&gt;最後，請我們家的新成員日產Dayz來和大家拜個年，希望你們都還好，你們都還平安。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2020-02-04-newhome3month_files/IMG_3551.jpg&#34; alt=&#34;duang&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>搬家</title>
      <link>https://wangcc.me/post/move-to-new-home/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/move-to-new-home/</guid>
      <description>&lt;p&gt;11月28日，左盼右盼，終於盼到了搬家的日子，我提前一天打開了新家的地暖。&lt;/p&gt;
&lt;p&gt;搬家當天，還有光纖網絡的施工：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_2436.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;施工的人說因爲附近的NTT的網絡線路距離家門口有點遠，結果這個網絡施工竟然持續了2個多小時。&lt;/p&gt;
&lt;p&gt;裝完網絡之後，搬家公司的車就來了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_2437.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;一輛中型卡車竟然就把全家5口人的箱子都裝走了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_2443.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;搬入新家的作業時，可以看出這家0123的搬家公司還是很細緻的：
&lt;img src=&#34;https://wangcc.me/img/IMG_2440.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;去年購買的大冰箱竟然剛剛好經過玄關的過道，&lt;strong&gt;玄關感覺壓力山大&lt;/strong&gt;：
&lt;img src=&#34;https://wangcc.me/img/IMG_2444.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;清空後的舊房子，想不到在這裏住了4年多，快5年。大寶寶的0-5歲，小寶寶的0-2歲都是在這裏度過的。雖然有不捨，但是這裏的冬天實在是太冷，夏天實在是太熱了。再見拉，希望你在不久的將來繼續成爲別的幸福家庭過渡時期的溫馨小屋。
&lt;img src=&#34;https://wangcc.me/img/IMG_2446.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>馬上搬家，腳手架拆除之後</title>
      <link>https://wangcc.me/post/home-almost-complete/</link>
      <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/home-almost-complete/</guid>
      <description>&lt;p&gt;10月12日，拆完腳手架之後，開始貼牆紙的工作：
&lt;img src=&#34;https://wangcc.me/img/IMG_1672.jpg&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;https://wangcc.me/img/IMG_1673.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;10月18日，牆紙貼好了以後第一次去看，發現房子內部的設備也撕掉了他們神祕的面紗，廚房的台和壁櫥簡直不能再寬敞：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1996.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;地板的顏色也很有格調：
&lt;img src=&#34;https://wangcc.me/img/IMG_1999.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;洗手間也做好了：
&lt;img src=&#34;https://wangcc.me/img/IMG_1951.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_2004.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;藍色的網也拆除了之後，從南側看整個建築還是挺大的：
&lt;img src=&#34;https://wangcc.me/img/IMG_2022.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;小朋友們在玄關門口看見天上飛過直升飛機，興奮地打招呼：
&lt;img src=&#34;https://wangcc.me/img/IMG_2045.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;太陽能發電試運行，一切看起來都準備妥當：
&lt;img src=&#34;https://wangcc.me/img/IMG_2162.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;一條還贈送了放在室內外的溫度溼度計看，可以隨時監測房間內外的溫度溼度：
&lt;img src=&#34;https://wangcc.me/img/IMG_2434.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;另外還有專門爲電動車充電使用的開關，酷酷的：
&lt;img src=&#34;https://wangcc.me/img/IMG_1958.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;再上一張穿堂透光部分的照片：
&lt;img src=&#34;https://wangcc.me/img/IMG_1957.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;11月12日，領鑰匙的日子，好激動：
&lt;img src=&#34;https://wangcc.me/img/IMG_2163.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;新買的沙發，牀鋪也搬進來了，好讚：
&lt;img src=&#34;https://wangcc.me/img/IMG_2287.JPG&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;https://wangcc.me/img/IMG_2285.JPG&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;https://wangcc.me/img/IMG_2286.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;接下來就剩下搬家啦&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>馬上竣工，腳手架拆除之前</title>
      <link>https://wangcc.me/post/home-before-completion/</link>
      <pubDate>Sat, 12 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/home-before-completion/</guid>
      <description>&lt;h2 id=&#34;before-2019-12-03&#34;&gt;Before 2019-12-03&lt;/h2&gt;
&lt;p&gt;日本蓋房子的速度還是很快的。&lt;/p&gt;
&lt;p&gt;我這一轉眼馬上就要搬新家了，結果發現自己太多都還沒有準備。&lt;/p&gt;
&lt;p&gt;這篇日誌本來上個月12日就想更新上傳的，結果遇到去愛爾蘭發表，參加日本疫学会若手の会，等等都被我用來當作自己懶惰拖延更新的藉口。&lt;/p&gt;
&lt;p&gt;其實最大的障礙是，&lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;Blogdown&lt;/a&gt; 上最流行的學術主題 &lt;a href=&#34;https://github.com/gcushen/hugo-academic&#34;&gt;Academic&lt;/a&gt; 經歷了數次重大更新之後，增加了夜間和日間模式的主題樣式，讓人十分心動，所以更新主題搬家花去了太多時間（因爲我對一些CSS文件和進行了修改然而我自己又不完全記得具體改了哪些，所以需要一個個再在更新後的主題中加上去）。最想吐嘈的是新的學術主題 &lt;a href=&#34;https://github.com/gcushen/hugo-academic&#34;&gt;Academic&lt;/a&gt;和之前的版本在整體結構，和許多設計上雖然做了很多改進，但是某些語言也進行了本質的修改，例如在個人主頁中介紹自己研究項目 &lt;code&gt;project&lt;/code&gt; 的部分的開頭，原先都是用下面的加號的形式包括進來各種選項。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;+++

+++
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但是現在最新的主題中不再支持過去的格式轉而要求全部以標準 Rmarkdown 的開頭部分一樣的形式用三個減號 &lt;code&gt;---&lt;/code&gt; 來包含全部的選項。類似這樣的巨大修改，但是又需要對每個文檔進行調整的部分實在是多的數不勝數。將來更新的學術主題可能只會愈來越複雜繁瑣，年紀大了實在是經不起這麼大的折騰。但是欣慰的是如今默認增加了一個 &lt;code&gt;update_academic.sh&lt;/code&gt; 文件，下次更新或許能用上 (T_T)。&lt;/p&gt;
&lt;h2 id=&#34;updated-2019-12-3&#34;&gt;UPdated 2019-12-3&lt;/h2&gt;
&lt;p&gt;其實到這裏我才開始打算放重點圖片哈哈。
過去了三個多月了，從夏天一直忙活到冬天。我家的房子終於平安建成。&lt;/p&gt;
&lt;p&gt;8月份地基好了以後，一樓的地板下面的空間開始鋪設：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_20190817_143007.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_20190817_143424.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;這是工人們鋪設時的錄像，可以看到地板下面有較大的隔空空間，還有厚厚的防熱層。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;之後就到了上棟的日子（8月22日）了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_20190822_091324.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;高高的腳手架前，用大吊車把工廠運來的房屋部件大大小小的送進工地。看這會飛的牆壁：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/mmexport1566442416961.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;一樓：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0699.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;8月24日，二樓搭起來了，還沒有房頂，很擔心下雨(T_T)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_20190824_103057.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;站在二樓西側時的樣子：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/mmexport1566614302031.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;二樓堆滿了建築資材：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/mmexport1566614351032.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;一樓也堆滿了接下來需要的各種材料和工具：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/mmexport1566614327505.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;南側可以看到東邊吐出來一塊是陽臺：
&lt;img src=&#34;https://wangcc.me/img/IMG_20190824_164155.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;9月7日，房間內地板下開始鋪設地暖的水管：
&lt;img src=&#34;https://wangcc.me/img/IMG_0847.jpg&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;https://wangcc.me/img/IMG_20190907_152212.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;樓頂上的太陽能板也已鋪設完畢：
&lt;img src=&#34;https://wangcc.me/img/IMG_20190907_153641.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;屋檐下還沒貼磚頭的牆壁長這樣：
&lt;img src=&#34;https://wangcc.me/img/IMG_20190907_153757.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;這天還在機場的好市多買了這臺65寸的電視，有機LED屏，支持4K，好期待，暫時存放在辦公室：
&lt;img src=&#34;https://wangcc.me/img/IMG_20190907_104803.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;從西側看這三七開的房頂，有點小尷尬：
&lt;img src=&#34;https://wangcc.me/img/IMG_20190907_154353.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;9月14日，廚房的台架起來：
&lt;img src=&#34;https://wangcc.me/img/IMG_20190914_115129.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;站在廚房，客廳裏的地暖也鋪起來：
&lt;img src=&#34;https://wangcc.me/img/IMG_20190914_115145.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;屋檐下白色的隔板裝上了：
&lt;img src=&#34;https://wangcc.me/img/IMG_0852.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;粉紅色的東側陽臺有點羞澀：
&lt;img src=&#34;https://wangcc.me/img/IMG_20190914_115859.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;加上房頂以後，一條在腳手架外面掛上了他們自家的廣告和彩旗：
&lt;img src=&#34;https://wangcc.me/img/IMG_20190904_093820.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;二樓陽臺內側，可以看到地板已經鋪設成功，地暖的水管看不見了：
&lt;img src=&#34;https://wangcc.me/img/IMG_0027.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;二樓的穿堂透光部分（吹き抜け）也差不多完成了，窗戶很明亮：
&lt;img src=&#34;https://wangcc.me/img/IMG_0028.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;10月1日，穿堂部分後來竟然架起了腳手架，應該是爲了貼牆紙用的，這裏可以看見我們選的白色滑動門，用於隔開玄關和客廳：
&lt;img src=&#34;https://wangcc.me/img/IMG_1590.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;浴室前的洗臉檯：
&lt;img src=&#34;https://wangcc.me/img/IMG_1583.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;至此，房子外圍的腳手架可以拆除了，看拆掉了腳手架之後的家：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1618.jpg&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;https://wangcc.me/img/IMG_1619.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>等級線性回歸模型的 Rstan 貝葉斯實現</title>
      <link>https://wangcc.me/post/multilevel-model-rstan/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/multilevel-model-rstan/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#多層等級線性回歸模型混合效應模型-multilevelmixed-effect-regression-model&#34;&gt;多層(等級)線性回歸模型/混合效應模型 multilevel/mixed effect regression model&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#適用於等級線性回歸模型的數據&#34;&gt;適用於等級線性回歸模型的數據&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#確認數據分佈&#34;&gt;確認數據分佈&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#如果不考慮組間公司間差異&#34;&gt;如果不考慮組間(公司間)差異&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#如果要考慮組間差異&#34;&gt;如果要考慮組間差異&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#等級線性回歸的貝葉斯實現&#34;&gt;等級線性回歸的貝葉斯實現&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#模型機制-mechanism&#34;&gt;模型機制 mechanism&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;多層等級線性回歸模型混合效應模型-multilevelmixed-effect-regression-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;多層(等級)線性回歸模型/混合效應模型 multilevel/mixed effect regression model&lt;/h2&gt;
&lt;p&gt;關於等級線性回歸的基本知識和概念，請參考&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/Hierarchical.html&#34;&gt;讀書筆記58-60章節&lt;/a&gt;。簡單來說，等級線性回歸通過給數據內部可能存在或者已知存在的結構或者層級增加隨機截距或者隨機斜率的方式來輔助解釋組間差異和組內的差異。&lt;/p&gt;
&lt;div id=&#34;適用於等級線性回歸模型的數據&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;適用於等級線性回歸模型的數據&lt;/h3&gt;
&lt;p&gt;本章節使用的數據是四家大公司40名社員的年齡和年收入數據：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;- read.csv(file=&amp;#39;../../static/files/data-salary-2.txt&amp;#39;)
d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     X   Y KID
## 1   7 457   1
## 2  10 482   1
## 3  16 518   1
## 4  25 535   1
## 5   5 427   1
## 6  25 603   1
## 7  26 610   1
## 8  18 484   1
## 9  17 508   1
## 10  1 380   1
## 11  5 453   1
## 12  4 391   1
## 13 19 559   1
## 14 10 453   1
## 15 21 517   1
## 16 12 553   2
## 17 17 653   2
## 18 22 763   2
## 19  9 538   2
## 20 18 708   2
## 21 21 740   2
## 22  6 437   2
## 23 15 646   2
## 24  4 422   2
## 25  7 444   2
## 26 10 504   2
## 27  2 376   2
## 28 15 522   3
## 29 27 623   3
## 30 14 515   3
## 31 18 542   3
## 32 20 529   3
## 33 18 540   3
## 34 11 411   3
## 35 26 666   3
## 36 22 641   3
## 37 25 592   3
## 38 28 722   4
## 39 24 726   4
## 40 22 728   4&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;X&lt;/code&gt;: 社員年齡減去23獲得的數據（23歲是大部分人大學畢業入職時的年齡）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Y&lt;/code&gt;: 年收入（萬日元）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;KID&lt;/code&gt;: 公司編號&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們認爲，年收入 &lt;code&gt;Y&lt;/code&gt;，是基本平均年收入和隨機誤差（服從均值爲零，方差是 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 的正態分佈）之和。且基本平均年收入和年齡成正比（年功序列型企業）。但是呢，因爲不同的公司入職時的基本收入可能不同，且可能隨着年齡增加而增長薪水的速度可能也不一樣。那麼由於不同公司所造成的差異，可以被認爲是組間差異。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;確認數據分佈&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;確認數據分佈&lt;/h3&gt;
&lt;p&gt;這次分析的目的是要瞭解「每個公司&lt;code&gt;KID&lt;/code&gt;內隨着年齡的增加而增長的薪水幅度是多少」，那麼我們要在結果報告中體現的就是每家公司的基本年收入，新入職時的年收入，以及隨着年齡增長而上升的薪水的事後分佈。&lt;/p&gt;
&lt;p&gt;我們先來看把四家公司職員放在一起時的整體圖形：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

d$KID &amp;lt;- as.factor(d$KID)
res_lm &amp;lt;- lm(Y ~ X, data=d)
coef &amp;lt;- as.numeric(res_lm$coefficients)

p &amp;lt;- ggplot(d, aes(X, Y, shape=KID))
p &amp;lt;- p + theme_bw(base_size=18)
p &amp;lt;- p + geom_abline(intercept=coef[1], slope=coef[2], size=2, alpha=0.3)
p &amp;lt;- p + geom_point(size=2)
p &amp;lt;- p + scale_shape_manual(values=c(16, 2, 4, 9))
p &amp;lt;- p + labs(x=&amp;#39;X (age-23)&amp;#39;, y=&amp;#39;Y (10,000 Yen/year)&amp;#39;)
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:fig8-1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-08-16-multilevel-model-rstan_files/figure-html/fig8-1-1.png&#34; alt=&#34;年齡和年收入的散點圖，不同點的形狀代表不同的公司編號。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: 年齡和年收入的散點圖，不同點的形狀代表不同的公司編號。
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;從總體的散點圖 &lt;a href=&#34;#fig:fig8-1&#34;&gt;1&lt;/a&gt; 來看，似乎年收入確實是隨着年齡增長而呈現直線增加的趨勢。但是公司編號 &lt;code&gt;KID = 4&lt;/code&gt; 的三名社員薪水似乎是在同一水平的並無明顯變化。這一點可以把四家公司社員的數據分開來看更加清晰:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(d, aes(X, Y, shape=KID))
p &amp;lt;- p + theme_bw(base_size=20)
p &amp;lt;- p + geom_abline(intercept=coef[1], slope=coef[2], size=2, alpha=0.3)
p &amp;lt;- p + facet_wrap(~KID)
p &amp;lt;- p + geom_line(stat=&amp;#39;smooth&amp;#39;, method=&amp;#39;lm&amp;#39;, se=FALSE, size=1, color=&amp;#39;black&amp;#39;, linetype=&amp;#39;31&amp;#39;, alpha=0.8)
p &amp;lt;- p + geom_point(size=3)
p &amp;lt;- p + scale_shape_manual(values=c(16, 2, 4, 9))
p &amp;lt;- p + labs(x=&amp;#39;X (age-23)&amp;#39;, y=&amp;#39;Y (10,000 Yen/year)&amp;#39;)
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:fig8-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-08-16-multilevel-model-rstan_files/figure-html/fig8-2-1.png&#34; alt=&#34;年齡和年收入的散點圖，不同的公司在四個平面中展示,黑色點線是每家公司數據單獨使用線性回歸時獲得的直線。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: 年齡和年收入的散點圖，不同的公司在四個平面中展示,黑色點線是每家公司數據單獨使用線性回歸時獲得的直線。
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;如果不考慮組間公司間差異&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;如果不考慮組間(公司間)差異&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;模型的數學描述&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
              Y[n] &amp;amp; = y_{\text{base}}[n] + \varepsilon[n] &amp;amp; n = 1, \dots, N \\
y_{\text{base}}[n] &amp;amp; = a + bX[n]                           &amp;amp; n = 1, \dots, N \\
    \varepsilon[n] &amp;amp; \sim \text{Normal}(0, \sigma_Y^2)     &amp;amp; n = 1, \dots, N \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;當然，如果你想，模型可以直接簡化成：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Y[n] \sim \text{Normal}(a + bX[n], \sigma^2_Y) \;\;\;\;\;\; n = 1, \dots, N \\
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;上述簡化版的模型，翻譯成Stan語言如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data {
  int N;
  real X[N];
  real Y[N];
}

parameters{
  real a;
  real b;
  real&amp;lt;lower = 0&amp;gt; s_Y;
}

model {
  for (n in 1 : N)
  Y[n] = normal(a + b * X[n], s_Y);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面的 R 代碼用來實現對上面 Stan 模型的擬合:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstan)
d &amp;lt;- read.csv(file=&amp;#39;../../static/files/data-salary-2.txt&amp;#39;)
d$KID &amp;lt;- as.factor(d$KID)

data &amp;lt;- list(N=nrow(d), X=d$X, Y=d$Y)
fit &amp;lt;- stan(file=&amp;#39;stanfiles/model8-1.stan&amp;#39;, data=data, seed=1234)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;model8-1&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 9e-06 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.051415 seconds (Warm-up)
## Chain 1:                0.036278 seconds (Sampling)
## Chain 1:                0.087693 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;model8-1&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 4e-06 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.054178 seconds (Warm-up)
## Chain 2:                0.03123 seconds (Sampling)
## Chain 2:                0.085408 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;model8-1&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 4e-06 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.055162 seconds (Warm-up)
## Chain 3:                0.033103 seconds (Sampling)
## Chain 3:                0.088265 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;model8-1&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 4e-06 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.056718 seconds (Warm-up)
## Chain 4:                0.03356 seconds (Sampling)
## Chain 4:                0.090278 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: model8-1.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##         mean se_mean    sd    2.5%     25%     50%     75%   97.5% n_eff Rhat
## a     376.97    0.58 24.54  329.21  360.86  377.27  393.00  425.66  1811    1
## b      10.99    0.03  1.41    8.25   10.07   10.98   11.94   13.78  1865    1
## s_Y    68.85    0.19  8.21   54.92   63.07   68.08   73.79   86.74  1938    1
## lp__ -184.12    0.03  1.29 -187.39 -184.69 -183.79 -183.17 -182.66  1450    1
## 
## Samples were drawn using NUTS(diag_e) at Tue Jan  7 14:55:40 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;現在有更加方便的 &lt;code&gt;rstanarm&lt;/code&gt; 包可以幫助我們省去寫 Stan 模型的過程：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstanarm)

rstanarm_results = stan_glm(Y ~ X, data=d, iter=2000, warmup=1000, cores=4)
summary(rstanarm_results, probs=c(.025, .975), digits=3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model Info:
##  function:     stan_glm
##  family:       gaussian [identity]
##  formula:      Y ~ X
##  algorithm:    sampling
##  sample:       4000 (posterior sample size)
##  priors:       see help(&amp;#39;prior_summary&amp;#39;)
##  observations: 40
##  predictors:   2
## 
## Estimates:
##               mean    sd      2.5%    97.5%
## (Intercept) 376.287  23.966 329.948 423.392
## X            11.028   1.413   8.243  13.842
## sigma        67.884   8.214  54.036  86.018
## 
## Fit Diagnostics:
##            mean    sd      2.5%    97.5%
## mean_PPD 547.732  14.914 517.835 576.914
## 
## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&amp;#39;summary.stanreg&amp;#39;)).
## 
## MCMC diagnostics
##               mcse  Rhat  n_eff
## (Intercept)   0.416 0.999 3319 
## X             0.024 1.000 3490 
## sigma         0.145 1.000 3217 
## mean_PPD      0.234 1.000 4047 
## log-posterior 0.029 1.000 1758 
## 
## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到強制不同公司社員的年收入來自同一個正態分佈時，方差顯得非常的大。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;如果要考慮組間差異&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;如果要考慮組間差異&lt;/h3&gt;
&lt;p&gt;我們認爲每家公司社員新入職時的起點薪水不同(截距不同-隨機截距)，進入公司之後隨年齡增加的薪水幅度也不同(斜率不同-隨機斜率)。因此，用 &lt;span class=&#34;math inline&#34;&gt;\(a[1]\sim a[K], K = 1, 2, 3, 4\)&lt;/span&gt; 表示每家公司的截距，用 &lt;span class=&#34;math inline&#34;&gt;\(b[1] \sim b[K], K = 1, 2, 3, 4\)&lt;/span&gt; 表示每家公司薪水上升的斜率。那麼每家公司的薪水年齡線性回歸模型可以寫作是 &lt;span class=&#34;math inline&#34;&gt;\(a[K] + b[K] X, K = 1, 2, 3, 4\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型數學描述&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Y[n] \sim \text{Normal}(a[\text{KID[n]}] + b[\text{KID}[n]] X[n], \sigma^2_Y) \\ n = 1, \dots, N
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;上述模型的 Stan 譯文如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data {
  int N;
  int K;
  real X[N];
  real Y[N];
  int&amp;lt;lower = 1, upper = K&amp;gt; KID[N];
}

parameters {
  real a[K];
  real b[K];
  real&amp;lt;lower = 0&amp;gt; s_Y; 
}

model {
  for (n in 1:N)
  Y[n] ~ normal(a[KID[n]] + b[KID[n]] * X[n], s_Y);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面的 R 代碼用來實現上面貝葉斯多組不同截距不同斜率線性回歸模型的擬合:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstan)
d &amp;lt;- read.csv(file=&amp;#39;../../static/files/data-salary-2.txt&amp;#39;)

data &amp;lt;- list(N=nrow(d), X=d$X, Y=d$Y, KID = d$KID, K = 4)
fit &amp;lt;- stan(file=&amp;#39;stanfiles/model8-2.stan&amp;#39;, data=data, seed=1234)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;model8-2&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 1.2e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.291379 seconds (Warm-up)
## Chain 1:                0.247714 seconds (Sampling)
## Chain 1:                0.539093 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;model8-2&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 4e-06 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.307839 seconds (Warm-up)
## Chain 2:                0.19135 seconds (Sampling)
## Chain 2:                0.499189 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;model8-2&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 5e-06 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.345166 seconds (Warm-up)
## Chain 3:                0.177124 seconds (Sampling)
## Chain 3:                0.52229 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;model8-2&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 4e-06 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.325194 seconds (Warm-up)
## Chain 4:                0.206306 seconds (Sampling)
## Chain 4:                0.5315 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: model8-2.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##         mean se_mean     sd    2.5%     25%     50%     75%   97.5% n_eff Rhat
## a[1]  387.11    0.27  14.17  359.31  377.78  387.20  396.47  415.13  2828    1
## a[2]  329.03    0.33  16.43  296.89  317.97  328.89  340.33  360.46  2517    1
## a[3]  314.11    0.75  34.43  246.03  291.69  313.70  335.87  382.48  2129    1
## a[4]  748.39    2.88 153.50  446.07  643.82  746.53  853.26 1054.33  2834    1
## b[1]    7.52    0.02   0.87    5.82    6.92    7.52    8.10    9.26  2604    1
## b[2]   19.82    0.02   1.21   17.47   19.01   19.82   20.63   22.20  2438    1
## b[3]   12.44    0.03   1.70    9.08   11.34   12.44   13.57   15.82  2595    1
## b[4]   -0.93    0.12   6.20  -13.37   -5.14   -0.91    3.22   11.19  2827    1
## s_Y    27.17    0.07   3.58   21.23   24.68   26.82   29.30   35.16  2695    1
## lp__ -148.01    0.06   2.40 -153.78 -149.35 -147.61 -146.26 -144.55  1414    1
## 
## Samples were drawn using NUTS(diag_e) at Tue Jan  7 14:56:32 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;等級線性回歸的貝葉斯實現&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;等級線性回歸的貝葉斯實現&lt;/h2&gt;
&lt;div id=&#34;模型機制-mechanism&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;模型機制 mechanism&lt;/h3&gt;
&lt;p&gt;如果我們認爲每家公司的起點薪水 &lt;span class=&#34;math inline&#34;&gt;\(a[k]\)&lt;/span&gt; 服從正態分佈，且該正態分佈的平均值是全體公司的起點薪水的均值 &lt;span class=&#34;math inline&#34;&gt;\(a_\mu\)&lt;/span&gt;，方差是 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_a\)&lt;/span&gt;。類似地，假設每家公司內隨着年齡增長而增加薪水的幅度 &lt;span class=&#34;math inline&#34;&gt;\(b[k]\)&lt;/span&gt; 也服從某個正態分佈，均值和方差分別是 &lt;span class=&#34;math inline&#34;&gt;\(b_\mu, \sigma^2_b\)&lt;/span&gt;。這樣我們就不僅僅是允許了各家公司的薪水年齡回歸直線擁有不同的斜率和截距，還對這些隨機斜率和截距的前概率分佈進行了設定。&lt;/p&gt;
&lt;p&gt;此時，隨機效應模型的數學表達式就可以寫成下面這樣:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
Y[n] &amp;amp;\sim \text{Normal}(a[\text{KID[n]}] + b[\text{KID}[n]] X[n], \sigma^2_Y) &amp;amp; n = 1, \dots, N \\
a[k] &amp;amp;= a_\mu + a_\varepsilon[k]   &amp;amp; k = 1, \dots, K \\
a_\varepsilon[k] &amp;amp; \sim \text{Normal}(0, \sigma^2_a) &amp;amp; k = 1, \dots, K \\
b[k] &amp;amp; = b_\mu + b_\varepsilon[k]  &amp;amp; k = 1, \dots, K \\
b_\varepsilon[k] &amp;amp;\sim \text{Normal}(0, \sigma^2_b) &amp;amp; k = 1, \dots, K
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;使用 &lt;code&gt;rstanarm&lt;/code&gt; 包可以使用下面的代碼實現&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstanarm)
M1_stanlmer &amp;lt;- stan_lmer(formula = Y ~ X  + (X | KID), 
                            data = d,
                            seed = 1234)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;continuous&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 8.1e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.81 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 5.02763 seconds (Warm-up)
## Chain 1:                1.63677 seconds (Sampling)
## Chain 1:                6.6644 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;continuous&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 1.6e-05 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 6.86217 seconds (Warm-up)
## Chain 2:                2.63666 seconds (Sampling)
## Chain 2:                9.49883 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;continuous&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 1.7e-05 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 4.64937 seconds (Warm-up)
## Chain 3:                2.72015 seconds (Sampling)
## Chain 3:                7.36952 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;continuous&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 2e-05 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 5.35582 seconds (Warm-up)
## Chain 4:                2.13219 seconds (Sampling)
## Chain 4:                7.488 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(M1_stanlmer, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## stan_lmer
##  family:       gaussian [identity]
##  formula:      Y ~ X + (X | KID)
##  observations: 40
## ------
##             Median MAD_SD
## (Intercept) 359.02  15.02
## X            12.80   2.98
## 
## Auxiliary parameter(s):
##       Median MAD_SD
## sigma 30.00   3.58 
## 
## Error terms:
##  Groups   Name        Std.Dev. Corr 
##  KID      (Intercept) 23.94         
##           X            8.76    -0.26
##  Residual             30.28         
## Num. levels: KID 4 
## 
## ------
## * For help interpreting the printed output see ?print.stanreg
## * For info on the priors used see ?prior_summary.stanreg&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(M1_stanlmer, 
        pars = c(&amp;quot;(Intercept)&amp;quot;, &amp;quot;X&amp;quot;,&amp;quot;sigma&amp;quot;, 
                 &amp;quot;Sigma[KID:(Intercept),(Intercept)]&amp;quot;,
                 &amp;quot;Sigma[KID:X,(Intercept)]&amp;quot;, &amp;quot;Sigma[KID:X,X]&amp;quot;),
        probs = c(0.025, 0.975),
        digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model Info:
##  function:     stan_lmer
##  family:       gaussian [identity]
##  formula:      Y ~ X + (X | KID)
##  algorithm:    sampling
##  sample:       4000 (posterior sample size)
##  priors:       see help(&amp;#39;prior_summary&amp;#39;)
##  observations: 40
##  groups:       KID (4)
## 
## Estimates:
##                                      mean    sd      2.5%    97.5%
## (Intercept)                         358.72   18.63  322.31  394.35
## X                                    12.59    3.97    3.57   20.91
## sigma                                30.28    3.82   23.76   38.95
## Sigma[KID:(Intercept),(Intercept)]  572.98 1381.86    1.70 3803.32
## Sigma[KID:X,(Intercept)]            -54.05  190.09 -444.45  144.95
## Sigma[KID:X,X]                       76.74  130.06    6.91  412.48
## 
## MCMC diagnostics
##                                    mcse  Rhat  n_eff
## (Intercept)                         0.38  1.00 2464 
## X                                   0.14  1.00  771 
## sigma                               0.08  1.00 2032 
## Sigma[KID:(Intercept),(Intercept)] 33.93  1.01 1659 
## Sigma[KID:X,(Intercept)]            4.80  1.00 1569 
## Sigma[KID:X,X]                      4.34  1.01  898 
## 
## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;和非貝葉斯版本的概率論隨機效應線性回歸模型的結果相對比一下：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)
M1 &amp;lt;- lmer(formula = Y ~ X  + (X | KID), 
           data = d, 
           REML = TRUE)
summary(M1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed model fit by REML [&amp;#39;lmerMod&amp;#39;]
## Formula: Y ~ X + (X | KID)
##    Data: d
## 
## REML criterion at convergence: 387.2
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.36969 -0.51837 -0.03545  0.76358  1.87881 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  KID      (Intercept) 503.78   22.445        
##           X            28.53    5.341   -1.00
##  Residual             833.95   28.878        
## Number of obs: 40, groups:  KID, 4
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  358.207     15.383  23.286
## X             13.067      2.741   4.767
## 
## Correlation of Fixed Effects:
##   (Intr)
## X -0.848
## convergence code: 0
## boundary (singular) fit: see ?isSingular&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>房子還是只有地基</title>
      <link>https://wangcc.me/post/entrance-done/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/entrance-done/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-30-entrance-done_files/IMG_20190810_130312.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-30-entrance-done_files/IMG_20190810_130330.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-30-entrance-done_files/IMG_20190810_130252.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-30-entrance-done_files/IMG_20190810_130259.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-30-entrance-done_files/IMG_20190728_123038.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-30-entrance-done_files/IMG_20190728_122945.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-30-entrance-done_files/IMG_20190728_123026.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>沖繩旅行小記</title>
      <link>https://wangcc.me/post/okinawa-trip/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/okinawa-trip/</guid>
      <description>&lt;p&gt;來日本第8個年頭，一次也未去過沖繩實在是有些說不過去。&lt;/p&gt;
&lt;p&gt;一家人自上次冬天去了北海道感受零下極寒的風雪之後，疲於處理找土地蓋房子的事情，終於得空再出門度假休息，這次我們登上飛機飛往離日本本土較遠的沖繩本島。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/animalflight.jpg&#34; alt=&#34;&#34;&gt;
(有趣的日本航空在機翼兩側頑皮地繪製了可愛的小動物)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/wifionflight.jpg&#34; alt=&#34;&#34;&gt;
(日本航空飛行時可以連接機艙內無線網路，非常貼心，好評)&lt;/p&gt;
&lt;p&gt;從名古屋離開時天氣預報顯示颱風的尾部可能還在對沖繩造成風雨的影響，有點擔心短短的三天時間不要全部都是下雨天。兩小時之後抵達那霸機場，剛出艙門，一陣悶熱的空氣迎面而來，讓我想起多年不曾再感受過的南國海濱城市的酷暑。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/stationnahaairport.jpg&#34; alt=&#34;&#34;&gt;
(日本最西端的車站&amp;ndash;那霸空港站)&lt;/p&gt;
&lt;p&gt;那霸機場往市區有一條單軌電車，我們上電車去國際通附近預訂的酒店住下。夜裏小朋友睡着了以後。我們還去拉麵館犯了罪(T_T)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/ramen.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;第二天想起早去吃個早點，結果幾家有早餐的沖繩餐廳已經人滿爲患，最後我們在買完早餐去取車時站在國際通的十字路口碰見大晴天：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/naha.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/hat.jpg&#34; alt=&#34;&#34;&gt;
(我還買了一頂草帽臭美)&lt;/p&gt;
&lt;h2 id=&#34;去浮潛&#34;&gt;去浮潛&lt;/h2&gt;
&lt;p&gt;然後我們開着日產的紅色Serena開始一路向北去體驗第一站&amp;mdash;-&lt;a href=&#34;http://www.natural-blue.net/tw/cp/&#34;&gt;青の洞窟浮潛&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/carnissan.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我們預約的浮潛店裏有懂國語的潛水員，你可能還能看見我的中文評論：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;下水之前穿上潛水服是一件有些困難且需要技巧的事情：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/kayodivingsuit.jpg&#34; alt=&#34;&#34;&gt;
(還留着鼻涕的KY，興奮地牽着潛水員姐姐的手往海邊走)&lt;/p&gt;
&lt;p&gt;我帶着像素很差，勉強可以在水中成像的小米小蟻運動相機。水下拍照也挺有趣的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/diving06.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/fish01.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/fish02.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;還能拍到背着氧氣瓶在深處潛水的朋友：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/scubadiving.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;但是和潛水員背着的水下相機相比，小蟻相機真的僅僅只是能拍出東西而已：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/diving01.jpg&#34; alt=&#34;&#34;&gt;
(專業水下拍攝裝備的照片頓時給出高大上的圖)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/diving02.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/diving03.jpg&#34; alt=&#34;&#34;&gt;
(我在拍魚，有人在拍我)
&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/diving04.jpg&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/diving05.jpg&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/bluecave.jpg&#34; alt=&#34;&#34;&gt;
(藍色洞窟的得名原因&lt;!-- raw HTML omitted --&gt;&amp;mdash;洞窟裏水下透出的陽光讓這海水顯得無比蔚藍)&lt;/p&gt;
&lt;p&gt;後來奶奶對潛水體驗也念念不忘，這是我的小蟻相機在水裏拍到的魚和奶奶：
&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/grammaswiming.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;(上岸之後，陽光明媚笑容燦爛的奶奶)
&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/grammaswim.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;去水族館&#34;&gt;去水族館&lt;/h2&gt;
&lt;p&gt;第二天我們來到沖繩旅行必去的景點之一&amp;ndash;&lt;a href=&#34;https://churaumi.okinawa/&#34;&gt;美ら海水族館&lt;/a&gt;。天氣又不遺餘力地晴空萬里。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/takephoto.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;海豚在興奮地跳躍，天空和大海比賽誰更藍：
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/cutebackbig.jpg&#34; alt=&#34;&#34;&gt;
沖繩水族館展示巨大鯊魚的玻璃牆聽說是吉尼斯世界紀錄上水族館裏最大的玻璃牆。
&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/sharkaquarium.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;這個大水缸裏著名的兩頭大鯊魚分別有5噸重和4.5噸重。真是兩個龐然大物了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/turtle.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;大海龜游泳都顯得那麼自得其樂。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/taketakephoto.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;第一次體驗海邊游泳，看到這麼大的魚，我家的兩個KY小寶寶都開心得不得了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/cuteswimsuit.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/kaicutie.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/children.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/mangoice.jpg&#34; alt=&#34;&#34;&gt;
(南國不可少的芒果冰)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/sobacool.jpg&#34; alt=&#34;&#34;&gt;
(沖繩特色紫薯蕎麥麵)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/sushiokinawa.jpg&#34; alt=&#34;&#34;&gt;
(在離開&lt;a href=&#34;https://www.google.co.jp/maps/place/%E5%8F%A4%E5%AE%87%E5%88%A9%E3%82%AA%E3%83%BC%E3%82%B7%E3%83%A3%E3%83%B3%E3%82%BF%E3%83%AF%E3%83%BC/@26.700156,128.024059,3a,75y/data=!3m8!1e2!3m6!1sAF1QipM8QZLq5lMn5M0E1REpv5VziBPa_zEtAsilhR4q!2e10!3e12!6shttps:%2F%2Flh5.googleusercontent.com%2Fp%2FAF1QipM8QZLq5lMn5M0E1REpv5VziBPa_zEtAsilhR4q%3Dw152-h86-k-no!7i3840!8i2160!4m5!3m4!1s0x34e458323adc1d13:0xe85316ec7281cf24!8m2!3d26.7001491!4d128.0240679?hl=ja&amp;amp;authuser=0&#34;&gt;古宇利島&lt;/a&gt;不遠處經過一家不顯眼的壽司店，價格實惠又意外地美味的壽司。)&lt;/p&gt;
&lt;h2 id=&#34;依依不捨地離開&#34;&gt;依依不捨地離開&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/cuteback.jpg&#34; alt=&#34;&#34;&gt;
(和藍天碧海說再見)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/gohome.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;(海邊撿到的寄居蟹)
&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/crabinshell.jpg&#34; alt=&#34;&#34;&gt;
(疲倦地睡到大天亮)
&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/sleepkai.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;中午趕到那霸機場，帶着小朋友們登上塗着藍色鯨魚的圖案的日航飛機。沖繩真是適合帶小朋友來旅行的好地方。想起三天前下飛機時還擔心颱風擾亂旅行計劃的我們，這次運氣真的好。希望下次還能再來體驗其他的離島。再見啦，沖繩。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-24-okinawa-trip_files/okinawaflight.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>受難者列傳筆記</title>
      <link>https://wangcc.me/post/notes/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/notes/</guid>
      <description>&lt;p&gt;如果你想看這本書，可以在&lt;a href=&#34;http://ywang.uchicago.edu/history/&#34;&gt;王友琴教授&lt;/a&gt;的網站上&lt;a href=&#34;https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=26&amp;amp;cad=rja&amp;amp;uact=8&amp;amp;ved=2ahUKEwjL1piUo7jjAhWCad4KHY3CAIc4FBAWMAV6BAgCEAI&amp;amp;url=http%3A%2F%2Fywang.uchicago.edu%2Fhistory%2Fvictim_ebook_070505.pdf&amp;amp;usg=AOvVaw1IdtbLLjoZIBJdxY5qsiO4&#34;&gt;下載&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;P18:
所謂“無法顯示”，完全是謊言。這個網站一直存在並且運作良好。當然，說謊的並不是電腦。&lt;/p&gt;
&lt;p&gt;盡管不是出乎意料，我仍然感到震驚。受難者們已經死亡三十多年。當年他們死亡的時候，大多數人的骨灰都沒有保留，更談不上安葬。三十年後，在電腦網絡的虛擬空間裏，都不容許有他們的安息之地，是爲了什麼？是誰，做了決定禁止受難者的名字在網上？&lt;/p&gt;
&lt;p&gt;P21:
流落人間者，泰山一毫芒&lt;/p&gt;
&lt;p&gt;P23:
中國是一個最講尊師重道的古老文明古國，而且尊師的傳統從未斷絕過。&lt;/p&gt;
&lt;p&gt;P26:
對於一個患了嚴重失憶症的民族，王友琴博士這部文革受難者真是一劑及時良藥。&lt;/p&gt;
&lt;p&gt;P28:
毛首先罷黜了那些試圖約束青年的同僚，以此掃清了道路，致使很多地方陷入霍布斯式的自然狀態（即相互爭鬥，人人自危的野蠻狀態），中學生和大學生實施暴力和恐怖整整兩年，最先鬥老師，然後鬥黨內幹部，最後自己互相鬥。。。。　但是真正的研究可能形成對整個一代人的指控－－那些參與者和觀看者。他們正在掌握國家的領導權。&lt;/p&gt;
&lt;p&gt;P29:
她是受難者的一個活資料庫。她一個人抗拒着數億人的遺忘。&lt;/p&gt;
&lt;p&gt;P40:
其實，看看事實，就知道這不但不是什麼向權勢者“造反”，而且從開始就是極權勢力的一次直接擴張。&lt;/p&gt;
&lt;p&gt;P46:
作爲一個中學校長，她從來沒有也幾乎不可能在上級指示之外做什麼標新立異之事，也沒有違抗過他們的命令。高層領導人的孩子，都在她主管的學校上學。然而，當革命需要打擊目標的時候，上級們就可以翻臉不認人，把一個個活人當做靶子拋出來，批判鬥爭，處分懲罰。他們根本不把他們的下級當人來看待，而只是一些數字和百分比，一些可以服務於革命目標的工具甚至靶子。冷酷是文革的一個重要特徵。文革不但嚴厲打擊反對革命的人，而且嚴厲打擊未曾反對革命的人。&lt;/p&gt;
&lt;p&gt;P48:
我們永遠無法知道，在卞仲耘死前的幾個小時裡，當她遭到這樣殘酷的毆打和折磨的時候，她想了些什麼。雖然她一直被人群包圍，&lt;strong&gt;她死在絕對的孤獨之中&lt;/strong&gt;。當她被打的時候，沒有一個人出來制止暴行。當她快要死去的時候，沒有一個人在身邊表示同情。&lt;strong&gt;她從來沒有與這些打死她的人為敵，但是這些人不但打死了她，而且，在打她的時候毫不猶豫，在她被打死後也沒有覺得任何後悔或者羞愧&lt;/strong&gt;。她孤立無援地死在紅衛兵學生的亂棒之下，甚至沒有可能作一點但反抗來保護自己。從一個活人的世界上，她被無情無義地背叛了，被拋棄了被犧牲了。&lt;/p&gt;
&lt;p&gt;P51:
1966年的夏天，全中國的學校變成了刑訊室，監獄，甚至殺人場。大批老師被迫害致死。&lt;/p&gt;
&lt;p&gt;P52:
1966年10月召開的“中共中央工作會議”發放了一個題為《把舊世界打個落花流水》的文章，其中被列為紅衛兵功績之一的，是1968年8月20日到9月底北京有1772人被打死。有理由認為實際死亡數據大於此數。但是，此數已經是極其巨大的數字。卞仲耘的死尚不在此數之中。1966年8月5日發生的卞仲耘之死，是8月殺戮的開端，經過三個星期的發展，在8月底前後達到每日被害人數的最高峰。由最高權力者號召鼓動，用中學生紅衛兵為打手，打死手無寸鐵的教育工作者如卞仲耘，以及大批沒有防衛能力的和平居民，還視為偉大功績，這實在是二十世紀統治者所作的最為殘忍和無恥的行為之一。&lt;/p&gt;
&lt;p&gt;P62:
卞仲耘，一個教育工作者的死，標誌了這個血腥時代的開始。讓我們記住這個名字和這個日期，記住在文明的進程中可能發生什麼樣的逆轉和災難。&lt;/p&gt;
&lt;p&gt;P63:
1993年，筆者到校中攝下一張宿舍樓的照片。卞仲耘被打死在這座宿舍樓門口的台階上。四個住在樓裡的高中三年級的學生問我：“20多年前有人在這兒被打死，這是真的嗎？我們什麼都沒聽說過。”&lt;/p&gt;
&lt;p&gt;P101:
文革前，清華大學有108名教授，曾經被人開玩笑說好像《水滸傳》裏有“108將”。陳祖東就是這“108將”之一。陳祖東的家人聽說，到1978年，這108人只死剩下40多人了。&lt;/p&gt;
&lt;p&gt;P104:
我在文革後考進北京大學中文系讀書，從來沒有聽到人提起程賢策的名字和他在文革中自殺的事情。雖然這個大學剛剛發生過文革這樣的重大歷史事件，文革歷史還未得到記錄和分析，但是，有着著名文科科系的北京大學，卻不教學生去認識和分析這些發生在自己學校的重要歷史事實，這顯然不恰當也相當具有諷刺性。不過，這也是普遍現象。其中主要的原因，是最高權力當局的嚴格禁止。&lt;/p&gt;
&lt;p&gt;P110:
1968年，北京大學建立了一所校園監獄，命名爲&amp;quot;黑幫監改大院&amp;rdquo;，把二百多名教職員工關在裏面。那年6月18日，關在&amp;quot;監改大院&amp;quot;裏的人被拉出來&amp;quot;鬥爭&amp;rdquo;，當他們排隊穿過校園的時候，甬道兩側站滿了學生，手持棍棒皮鞭，爭相痛打他們。然後，他們被拉到各系，施以種種酷刑。&lt;strong&gt;那一天，北大校園裏充滿了狂熱的殘忍於惡毒。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;P110:
北京大學建立於1898年的維新運動中。大學本該是中國現代化，科學和文明的代表。但是在文革中，北京大學卻變成最野蠻殘酷的行爲發生的地方。暴力性的&amp;quot;鬥爭會&amp;rdquo;，包括毆打侮辱掛黑牌戴高帽子等等，校園&amp;quot;勞改隊&amp;rdquo;，校園監獄，都在北京大學領先開始，更不要說道德方面的墮落如誣陷，謊言，讒佞等等普遍發生。北京大學發生的這種巨大變化，是文革真正劇烈改變社會傳統以及行爲規範最&amp;quot;成功&amp;quot;的例子。這種成功，令人震驚，也令人思考。&lt;/p&gt;
&lt;p&gt;P112:
一批一批的人成爲&amp;quot;敵人&amp;rdquo;，一旦被指控，就被無情地清洗出去，既不能自我辯護，也逃脫不了殘酷的處罰。革命的巨爪不但在農村，也在這所中國最早建立的現代大學裏面，把人一把一把抓起來，糟蹋丟棄。&lt;/p&gt;
&lt;p&gt;P112:
在1966年，程賢策從&amp;quot;革命者&amp;quot;變成爲&amp;quot;革命&amp;quot;打擊的對象。看起來，文革好像是非邏輯的。但是實際上這一切有其內在的邏輯。檢視往事，現在可以看出，一批人在參與迫害的同時，也鋪就了迫害他們自己的道路。因爲他們參與的迫害，不只是對一些個人的否定，而且是對法治，對程序正義，對一個公民應該具有的公民權利的根本否定。&lt;/p&gt;
&lt;p&gt;P139:
在1991年範長江的名字被用來命名“新聞獎”，但是，他本人爲什麼從1952年就不能再做新聞工作，爲什麼他在1970年悲慘地死於井中，這些卻沒有報道和分析。&lt;/p&gt;
&lt;p&gt;P139:
樊西曼，女，1915年生，鐵道部中共黨校黨委副書記，1966年8月25日被兒子的同學，北京師範大學附屬第二中學紅衛兵綁架到學校，在學校內一個磚砌的乒乓球臺子上被打死。兒子曹濱海從此精神失常。同一天在校中被打死的，還有這個中學的語文老師斳正宇和學校負責人姜培良。&lt;/p&gt;
&lt;p&gt;P142:
從此，鬥打，亂殺事件日益嚴重，由開始打鬥個別“表現不好”的“四類分子”（地主，富農，反革命分子，壞分子），發展到打鬥一般的四類分子；由一個大隊消滅一兩個，兩三個四類分子，發展到亂殺家屬子女和有一般問題的人，最後發展到全家被滅絕。子8月27日至9月1日，該縣的13個公社，48個大隊，先後殺害“四類分子”及其家屬供325人。最大的80歲，最小的僅38天，有22戶被殺絕。&lt;/p&gt;
&lt;p&gt;P147:
傅雷，男，1908年生，上海居民，翻譯家，翻譯大量法語作品，在1957年被劃成“右派分子”，1966年8月下旬被抄家和“鬥爭”，9月3日在寓所中和妻子朱梅馥一起留下遺書自殺身亡。傅雷時年53歲。文革後傅雷得到“平反”。《傅雷家書》出版後，成爲受歡迎的暢銷書。“家書”是他和兒子的通信。他有兩個兒子，一名“聰”，一名“敏”，都出生與1930年代。1966年時，傅敏是北京第一女子中學的英文教員。1966年8月北京的中學教員和校長們遭到紅衛兵學生的野蠻攻擊，傅敏在學校附近投水自殺，幸而未死。他的哥哥是鋼琴家傅聰，1958年在公派波蘭學習畢業的時候，不回中國，去了英國，當時被稱作“叛國分子”。&lt;/p&gt;
&lt;p&gt;P150:
乒乓球和政治和思想觀念沒有直接的關聯。然而，文革不但整死作家，教員和演員，還把這些乒乓球運動員整死，這是怎樣的殘酷和瘋狂？在毛澤東之前和之後，還沒有一個暴君做過這樣的事情。&lt;/p&gt;
&lt;p&gt;P151:
高斌，男，湖北人，1940年代留學英國，曾任北京外國語學院俄國文學教授，調陝西師範大學後，在“反右運動”中被定位“右派分子”，送農場“勞動改造”，“摘帽”後恢復授課，但降薪降級。1966年遭到“批鬥”後自縊身亡。&lt;/p&gt;
&lt;p&gt;P158:
夜裏，龔維泰就躺在“一教”的地板上，靜悄悄地殺死了自己。很難想象，什麼樣的絕望會讓人這樣結束自己的生命！他自殺，沒有抗議，沒有抱怨，甚至在流血中漸漸死去的過程中沒有呻吟，沒有響動，以至躺在他身邊的人們都不知道發生了什麼。
。。。
龔維泰的事情聽起來確實很“奇怪”。龔維泰參加共產黨組織的“民青”反對國民黨政府，他被逮捕以後並沒有治他的罪。沒有證據說明他被捕後爲國民黨政府做過任何傷害共產黨的事情，他卻在20年後的“清理階級隊伍運動”中，爲此被捕事件遭到嚴酷的審查，最後這樣可怕的死去。&lt;strong&gt;實際上，從法律的角度看，除非是殺了人，不管龔維泰在那時候做了什麼，都已經過了法律的追溯期限，不能再作追究。但是“革命”壓倒一切的時候，法律是紙上空文。非常諷刺的是，文革後有人控告文革中的殺人兇手，北京的檢察院卻以“法律追溯時限已過”拒絕。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;P169:
“中華人民共和國憲法”上冠冕堂皇地寫着中國公民享有“言論自由”，甚至在文革中修改過的新憲法中，雖然去掉了“遷徙自由”，卻依然留有“言論自由”。然而，在實際上，言論竟被當作判處死刑的根據。
&amp;hellip;
顧文選的第二條罪狀是逃離中國，在材料上被稱爲“叛國投敵”。在共產黨宣傳中，人民是“國家的主人”，但是在1950，1960，1970年代，普通人民根本不被允許得到護照出國。如果他們想要離開中國，只有祕密離開。祕密離開中國是十分危險的事情。他們可能在中途被打死。如果被抓住，竟然可以成爲判處死刑的根據。&lt;/p&gt;
&lt;p&gt;在歷史上，從來沒有過這樣殘酷的執法。在德國有過“柏林牆”。在1989年柏林牆被推倒以前，試圖偷越“柏林牆”的人，有一百多人被哨兵打死，這是非常兇殘的事情，因此在柏林牆被推倒之後，下令開槍射擊的東德領導人被法庭起訴。&lt;/p&gt;
&lt;p&gt;P170:
在文革後很多年，仍然有很人認爲文革是一個“大民主”。這種看法的“根據”是，普通人可以對各級領導幹部“造反”。且不說當時的“鬥爭會”等形式是多麼野蠻和違法的手段，也不說可以“造反”的內容僅僅是那些人“反對毛澤東思想”，這樣的看法無視顧文選這樣的人被殘酷殺害的事實，無視聞佳這樣的人被判重型的事實，創造了一個遠離事實的文革神話。&lt;/p&gt;
&lt;p&gt;P172:
至今一些人還在肯定文革“反對官僚制度”的正面貢獻，因爲毛澤東說了要“精兵簡政”以及“打破重疊的行政機構”（1968年3月）。然而文革中實際上工作了的，是取消了公安局，檢察院，法院三家分開並且獨立這樣的社會組織形式，&lt;strong&gt;取消了定罪和審判的法律程序，在製造對人的迫害方面大大提高了效率&lt;/strong&gt;。這是一種多麼可怕的提高效率啊。
&amp;hellip;&lt;/p&gt;
&lt;p&gt;文革中掌管北京的“公檢法”長達十年的，是原爲南京軍區某部軍委副政委的劉傳新。1976年毛澤東死去以及“四人幫”隨之被逮捕。在文革中被劉傳新關押迫害過的一批老幹部重新回到權力位置上。1977年1月27日，劉傳新被免去北京市公安局長的職務。他被“隔離”在東交民巷他居住的院落裏受“審查”。1977年5月18日，他接到了北京市公安局第二天要開“聲討劉傳新大會”的通知。半夜，他在一棵樹上上吊自殺。&lt;/p&gt;
&lt;p&gt;劉傳新自殺，當然是因爲他的失勢，也可能是由於懼怕他用於別人身上的殘酷做法會被用到他自己身上。但是他懼怕的人中間，不會有顧文選。這不但因爲顧文選已經被殺死，也因爲顧文選本來也只是一個沒有權力的普通人。&lt;/p&gt;
&lt;p&gt;P186:
把社會中的一個很大的人羣，劃出來進行“審查”，隔離審訊，再從中劃出一部分作爲受到永久性處罰的“敵人”，這樣的做法幾十年來不斷實行，以致有的中國人已經把這樣的做法視爲像颳風下雨一樣的常態，從不從根本上去質疑和反對。&lt;/p&gt;
&lt;p&gt;P187:
也使人吃驚的是，被裝載籮筐裏遭到“鬥爭”的人，對於他自己被安的罪名不承認，但是對他自己曾經發動的對幾百萬人進行過的於此類似的“鬥爭”，至死也並未覺得不安。在1990年代出版的他的女兒寫的關於他的書裏（《紅色家族檔案：羅瑞卿的女兒的點點回憶》，羅點點，南海出版公司，海口1999年），細膩深情地寫到他在文革中的遭遇多麼不公平，&lt;strong&gt;卻一字也沒有提到他曾多麼殘酷地對待千千萬萬別的人。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;P187:
在歷史上，也還從來沒有一個時代和一個政權，可以把普通人民控制到這樣嚴密的程度。他們不告訴人民這些人的“反革命”活動到底是些什麼，卻要求每一個人都“表態”來支持殺死這些人。他們不但殺人，還要造成一個“衆口一詞”的形勢。他們用恐怖來塑造輿論，這輿論反過來又來支持恐怖。
。。。
一位被訪者說：你能想象那時候北京人有多壞嗎？他們根本不把別人的命當回事兒。他們喊過“槍斃槍斃”，就趕快回家吃飯去了。&lt;/p&gt;
&lt;p&gt;魯迅寫的阿Q，在他自己被殺之前，曾經很興奮地去看殺別人的頭。文革年代，普通人也活得像魯迅筆下的阿Q，會興高采烈地參加“公判大會”，把別人被槍斃當作好戲看。&lt;/p&gt;
&lt;p&gt;P189：
以意識形態的名義和革命的名義，把人類的一部分宣佈爲必須消滅的“敵人”，通過一系列預先設計的所謂“政治運動”，一個政權把社會中的一個羣體，不是一個人兩個人，也不是幾十個或幾百個人，而是一個及其巨大的人數&amp;ndash;人羣中的一個百分比，有計劃有組織有系統地予以打擊和消滅，這就是毛澤東對顧文選和億萬中國人所作的。&lt;/p&gt;
&lt;p&gt;P192:
筆者曾經問清華附中的受訪者，你們是怎麼知道紅衛兵不準醫院搶救郭蘭蕙的。兩位認識郭蘭蕙的學生說，紅衛兵曾經在學校當衆宣佈，由於郭蘭蕙是自殺的，**醫院打電話到清華附中詢問她是什麼人，是否有“問題”，清華附中紅衛兵接了電話告訴醫院，郭蘭蕙是“右派學生”，於是醫院不給搶救，讓郭蘭蕙在醫院的地板上死去。**紅衛兵不但對郭蘭蕙自殺毫無憐憫之心，而且用得意洋洋的口氣在學校裏告訴其他學生這些情況，顯示他們主宰生死的權力和威風。&lt;/p&gt;
&lt;p&gt;郭蘭蕙死時只有19歲。她曾經病休一年，所以1966年她上高二，而不是高三。&lt;/p&gt;
&lt;p&gt;P192：
在郭蘭蕙死亡兩個星期以前，該校高一（二）班學生楊愛倫也因相同的原因試圖自殺。楊愛倫的父親在1949年以前的政府海關做事，於是被認定爲“壞家庭出身”。她在1966年7月底就開始在班裏被紅衛兵“鬥爭”。清華附中紅衛兵的領導人之一曾經到她的班上詳細指示如何整她。她被緊閉在一間小屋裏，被強迫寫“檢查交代”。1966年8月8日，楊愛倫到“清華園”火車站附近臥軌自殺。火車頭把她鏟出了軌道。她沒有死，但是臉部和身體受到重傷，並且失去了三個手指，成爲永久性傷殘。&lt;/p&gt;
&lt;p&gt;P197-199:
韓光第，男，牙醫，家住四川省漢源縣富林鎮第二居民段。在1968年夏天因說毛澤東送給“首都工農毛澤東思想宣傳隊”的芒果“像一條紅薯沒什麼看頭”，被逮捕，長期關押之後，1970年被以“現行反革命”罪判處死刑，在富林鎮郊被槍斃。
。。。&lt;/p&gt;
&lt;p&gt;實際上，送到四川漢源鎮上的這個芒果，也根本不是真的芒果。真的芒果要保存那麼長的時間，早已經腐爛了。在漢源鎮上展示的，只可能是個蠟製的複製件。當時在全國各地作了無數這類的複製品或者芒果照片，強制八億人崇拜。1968年，是文革中害死人最多的“清理階級隊伍運動”進行的時候，也是對毛澤東的個人崇拜最嚴重的時候之一。
。。。&lt;/p&gt;
&lt;p&gt;漢源鎮上的人，包括很多小學生，看到了韓光第被槍殺的場面。這樣的場面，無疑對他們的一生都影響深遠。它們從此再不會敢對任何和毛澤東有關的東西，說任何自己想作的評論。它們變得非常謹慎小心。甚至在35年之後，它們還得顧慮是否要把這樣的事實說出來。
。。。&lt;/p&gt;
&lt;p&gt;文革時期曾經秩序相當混亂，當時的“專政機關”審批死刑的手續也被簡化（文革前死刑要經過最高法院批准，文革中這個權力被下放了），但是&lt;strong&gt;文革並不是一個失控的時期&lt;/strong&gt;，被判處死刑的人，都是當時上面下令開始的政治運動高潮的結果，有一套逮捕人和處分人的規定。&lt;/p&gt;
&lt;p&gt;P201: 南京第13中學位於南京市“西家大塘”，離開市中心不願。韓康是13中學的圖書館員。韓康的家就在學校附近。因1949年以前曾參加過國民黨，紅衛兵抄了他的家，把他家的東西雜碎毀壞。&lt;/p&gt;
&lt;p&gt;1966年9月5日早上韓康被十三中的紅衛兵揪到學校操場上“批鬥”。另有十三中體育老師夏忠謀，也因歷史上參加過三青團等“問題”，一起被揪到操場批鬥。批鬥中，紅衛兵對二人拳打腳踢，用皮帶抽，用磚頭砸。由於紅衛兵說韓康的態度不好，對他打得更是厲害。直至下午三四點中，韓康兩三次昏死過去，但都被紅衛兵用冷水潑醒後再接着批鬥，到傍晚，韓康終於被活活打死。&lt;/p&gt;
&lt;p&gt;夏忠謀因一直低頭任由紅衛兵批鬥，所以僥倖沒有被當場打死，晚上他被關押到學校實驗室，外面有紅衛兵看守。夏忠謀看到韓康被打死，自己被關押第二天要接着被批鬥，肯定是難逃一死，因此晚上用衣服撕成布繩上吊自殺身亡。兩人都死於1966年9月5日一天。&lt;/p&gt;
&lt;p&gt;P202:
韓志穎，西安市第五中學校長，男，中國民主同盟盟員。1966年8月，第五中學的紅衛兵把凳子壘成高臺，讓韓志穎站上去接受“批鬥”。他不吸菸，紅衛兵把數隻香菸點燃後分別插入韓的耳朵，鼻孔和嘴中，用煙熏韓。韓志穎在1966年被“批鬥”至死。&lt;/p&gt;
&lt;p&gt;P206:
這種“主席大手筆”的說法正是文革思維的產物。實際上，在文明設會裏，儘管人們之間有貧富之分，有地位高低的區別，但是，沒有一個人有權力在法庭之外剝奪另一個人的生命，是普遍的基本原則。文革以“革命”的名義，打破了這一條原則。而且，不但這樣做了，而且，樹立了這樣的“大手筆”觀念，即認爲是可以做的，特別是對“偉大”人物來說。&lt;/p&gt;
&lt;p&gt;在建設“紀念園”的時候，不止一人向筆者提過這樣的問題：寫這種普通人受難者的故事有什麼意義？這種質疑和這種“主席大手筆”說法有實質相連。如果說這種話的是有權勢的人，那是權勢使它們眼裏沒有普通人的位置。如果說這種話的是普通人，那麼是長期精神奴役的結果。&lt;/p&gt;
&lt;p&gt;P224:
文革後進入北京航空學院讀書的一位被訪者說，那時候學校裏依然流傳着文革時代留下的一句話：該校主樓的每一扇窗戶，差不多都曾經有人跳下來自殺。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>地基完成啦</title>
      <link>https://wangcc.me/post/base-of-the-house-done/</link>
      <pubDate>Mon, 15 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/base-of-the-house-done/</guid>
      <description>&lt;p&gt;過了一週時間，我又忍不住跑去我家的地裏去看看進展如何。發現上週的所謂&lt;a href=&#34;https://wangcc.me/post/construction/&#34;&gt;貌似已經完成地基&lt;/a&gt;完全是未經證實的假消息。
原來這周結束才算是真正完成了房屋的地基結構，不信你看：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_whole_kayo.jpg&#34; alt=&#34;basedone&#34;&gt;&lt;/p&gt;
&lt;p&gt;對比前一個週五同一個角度拍下的地基模樣，是不是相差很多？（不要告訴我只是多了一個熊孩子&amp;hellip;.）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-07-construction_files/IMG_20190706_113603.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;原來只有鋼筋的地方現在都灌上了水泥。還能看見這周下過雨留下的積水。。。所以，前一週僅僅只是按照圖紙把鋼筋骨骼的結構鋪設好了。這周加上了水泥，就像骨骼上長滿了肌肉一樣，一下子順眼很多。房間結構也更加清晰了。&lt;/p&gt;
&lt;p&gt;快來看將來的玄關：
&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_entrance.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;感覺進門之後的空間略有狹小，前進四五步之後左手邊會是一個類似壁櫥的位置可以放置進門帶着的隨手行李，手提包，還可以掛不想帶入房間內的外套。同一位置的右手邊則是一樓的洗手間。再進去就是客廳了。這張圖沒有照進去的是左手邊，也就是壁櫥後面的一個連着客廳的房間，我們暫時準備放置給小朋友練習的鋼琴，以及平時玩耍的玩具之類。大概格局是這樣子的，也可以用作臨時客房：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_pianoroom.jpg&#34; alt=&#34;pianoroom&#34;&gt;&lt;/p&gt;
&lt;p&gt;琴房的背後連着客廳：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_livingroom.jpg&#34; alt=&#34;living&#34;&gt;&lt;/p&gt;
&lt;p&gt;鏡頭中照進去的會是一樓通往二樓的樓梯的位置，樓梯上面會有一個透光採光用的大窗，樓梯前面則可以放置電視臺。拍這張照片時準備放置沙發的位置放了一堆不明鐵板（期待下星期再來時鐵板會被拼成什麼樣子）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_unknownsteel.jpg&#34; alt=&#34;steel&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看到鐵板被防雨的帆布包裹着，上面有一籃不明鐵器：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_unknownsteelagain.jpg&#34; alt=&#34;steelagain&#34;&gt;&lt;/p&gt;
&lt;p&gt;客廳連着廚房和餐廳的位置：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_anotherkitchen.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;這裏的右邊將來會是全家人洗漱的洗臉檯房間，感覺這裏會比玄關還要寬敞：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_washroom.jpg&#34; alt=&#34;washroom&#34;&gt;&lt;/p&gt;
&lt;p&gt;洗臉房間往裏走連着浴室，不清楚這裏途中右手邊黑色的一塊是什麼。
&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_bathroomwater.jpg&#34; alt=&#34;bathroom&#34;&gt;&lt;/p&gt;
&lt;p&gt;靠近拍了一張：
&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_bathroomwood.jpg&#34; alt=&#34;wood&#34;&gt;&lt;/p&gt;
&lt;p&gt;發現有一行字被印在左下角，放大了才看清楚寫的是&amp;quot;防蟻処理済&amp;rdquo;，原來這竟是一塊木頭放在洗臉房間和浴室連接的門框下面的地基位置。很好奇這是一種什麼處理方式。
&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_bathroomwood1.jpg&#34; alt=&#34;wood&#34;&gt;&lt;/p&gt;
&lt;p&gt;另外，浴室外面西北角的土地上現在被打入了三個小小的洞，也不太清楚目的是什麼：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_hole.jpg&#34; alt=&#34;hole&#34;&gt;&lt;/p&gt;
&lt;p&gt;另外三個小洞這張圖的右側水泥牆壁的部分，保留了一個和外面相同的洞，估計能通過水管之類的用於排水？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_hole_onthewall.jpg&#34; alt=&#34;hole on the wall&#34;&gt;&lt;/p&gt;
&lt;p&gt;從外側再給廚房來一張特寫：
&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/base_kitchen.jpg&#34; alt=&#34;kitchenagain&#34;&gt;&lt;/p&gt;
&lt;p&gt;另外讓人有點遺憾的是整個房子的南側，由於土地形狀的限制，其實是有個梯形的結構的。這使得餐廳連接客廳的位置被收窄。這裏垂直上方會是二樓的陽臺，因此這裏將來準備鋪木質的平臺，連着客廳的大落地窗。南部的採光會不會被這個陽臺應響了呢。這裏正好往北推進了大約20~30公分，所以，希望上面即使會有陽臺也不至於把南側進入客廳的陽光擋住了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/baseleft.jpg&#34; alt=&#34;left&#34;&gt;&lt;/p&gt;
&lt;p&gt;這天我們其實是先帶了小朋友們去參觀體操俱樂部，看他倆多開心：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/kids_taiso.jpg&#34; alt=&#34;taiso&#34;&gt;&lt;/p&gt;
&lt;p&gt;我們離開新家的時候，還在家旁邊的萬博紀念公園的樹上發現了褪了殼的知了，是不是安靜完整得像一隻真的蟲？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-15-base-of-the-house-done_files/locust01.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;炎熱夏日就要到來，希望工地的工人們不要中暑。這週末我們全家會啓程去沖繩度假。也但願天公作美，沖繩的海要藍藍地等我們來玩耍呀。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>泊松回歸模型的貝葉斯Stan實現</title>
      <link>https://wangcc.me/post/poisson-stan/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/poisson-stan/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#分析目的數據和選擇-poisson-回歸模型的原因&#34;&gt;分析目的，數據，和選擇 Poisson 回歸模型的原因&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#想象模型機制&#34;&gt;想象模型機制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#寫下數學模型表達式&#34;&gt;寫下數學模型表達式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#把數學模型翻譯成-stan-模型代碼&#34;&gt;把數學模型翻譯成 Stan 模型代碼&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#運行結果的解釋&#34;&gt;運行結果的解釋&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;分析目的數據和選擇-poisson-回歸模型的原因&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;分析目的，數據，和選擇 Poisson 回歸模型的原因&lt;/h1&gt;
&lt;p&gt;我們這裏使用&lt;a href=&#34;https://wangcc.me/post/logistic-rstan/&#34;&gt;之前擬合貝葉斯邏輯回歸模型&lt;/a&gt;時使用的相同的數據來展示如何跑貝葉斯泊松回歸模型。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;- read.table(&amp;quot;https://raw.githubusercontent.com/winterwang/RStanBook/master/chap05/input/data-attendance-2.txt&amp;quot;, sep = &amp;quot;,&amp;quot;, header = T)
head(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   PersonID A Score  M  Y
## 1        1 0    69 43 38
## 2        2 1   145 56 40
## 3        3 0   125 32 24
## 4        4 1    86 45 33
## 5        5 1   158 33 23
## 6        6 0   133 61 60&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;PersonID&lt;/code&gt;: 是學生的編號；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A&lt;/code&gt;, &lt;code&gt;Score&lt;/code&gt;: 用來預測出勤率的兩個預測變量，分別是表示是否喜歡打工的 &lt;code&gt;A&lt;/code&gt;，和表示對學習本身是否喜歡的評分 (滿分200)；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;M&lt;/code&gt;: 過去三個月內，該名學生一共需要上課的總課時數；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Y&lt;/code&gt;: 過去三個月內，該名學生實際上出勤的課時數。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這一次我們希望通過分析泊松回歸來回答「&lt;code&gt;A&lt;/code&gt; 和 &lt;code&gt;Score&lt;/code&gt; 對總課時數 &lt;code&gt;M&lt;/code&gt; 具體有多大的影響？」這個問題。&lt;a href=&#34;https://wangcc.me/post/logistic-rstan/&#34;&gt;之前擬合貝葉斯邏輯回歸模型&lt;/a&gt;時，使用的結果變量是 &lt;code&gt;Y&lt;/code&gt;，也就是實際出勤課時數。但是本小節我們用 &lt;code&gt;M&lt;/code&gt; 作爲結果變量。因爲總課時數是學生自己選課時的結果，也就是說學生本身的態度（是否喜歡打工，是否熱愛學習），可能本身左右了他/她到底會選多少課。背景知識假設是：喜歡多去打工的學生，選課可能態度消極，總課時數從開始可能就選的少。那麼像總選課時數這樣的非負（計數型）離散變量作爲結果變量的時候，&lt;strong&gt;泊松回歸模型是我們的第一選擇。&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;想象模型機制&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;想象模型機制&lt;/h2&gt;
&lt;p&gt;如果使用&lt;a href=&#34;https://wangcc.me/post/rstan-wonderful-r3/&#34;&gt;上上節介紹的多重線性回歸模型&lt;/a&gt;，那麼模型的預測變量的分佈便可能取到負數，這樣就不符合實際情況下“總選課時數”是非負（計數型）離散變量這一事實。這就需要把預測變量 &lt;code&gt;A&lt;/code&gt; 和 &lt;code&gt;Score&lt;/code&gt; 相加的線性模型 &lt;span class=&#34;math inline&#34;&gt;\((b_1 + b_2A + b_3Score)\)&lt;/span&gt;，通過數學轉換限制在非負數範圍。假設平均總課時數是 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;，我們認爲它服從均值是 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的泊松分佈。關於泊松分佈的詳細知識，期望值和方差的推導可以參考&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/poisson.html&#34;&gt;學習筆記&lt;/a&gt;。另外，非貝葉斯版本的一般性傳統泊松回歸模型可以參照學習筆記的&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/poisson-regression.html&#34;&gt;廣義線性回歸的泊松回歸模型章節&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;對泊松回歸模型略有瞭解的話應該很自然地想到，把結果變量限制在非負數範圍的標準鏈接方程是 &lt;span class=&#34;math inline&#34;&gt;\(\log(\lambda)\)&lt;/span&gt;，或者在 Stan 模型中，我們更自然地把線性模型部分寫在指數模型中: &lt;span class=&#34;math inline&#34;&gt;\(\exp(b_1 + b_2A + b_3Score)\)&lt;/span&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;寫下數學模型表達式&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;寫下數學模型表達式&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\lambda[n] &amp;amp; = \exp(b_1 + b_2A[n] + b_3Score[n]) &amp;amp; n = 1, \dots, N \\
M[n]       &amp;amp; \sim \text{Poisson}(\lambda[n])     &amp;amp; n = 1, \dots, N
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;，是該數據中學生的人數；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;，是每名學生的標籤/編號（下標）；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_1, b_2, b_3\)&lt;/span&gt; 是我們感興趣的參數。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;把數學模型翻譯成-stan-模型代碼&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;把數學模型翻譯成 Stan 模型代碼&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;data {
  int N; 
  int&amp;lt;lower=0, upper=1&amp;gt; A[N]; 
  real&amp;lt;lower=0, upper=1&amp;gt; Score[N]; 
  int&amp;lt;lower=0&amp;gt; M[N];
}

parameters {
  real b[3]; 
}

transformed parameters {
  real lambda[N];
  for (n in 1:N) {
    lambda[n] = exp(b[1] + b[2]*A[n] + b[3]*Score[n]);
  }
}

model {
  for (n in 1:N) {
    M[n] ~ poisson(lambda[n]); 
  }
}

generated quantities {
  int m_pred[N]; 
  for (n in 1:N) {
    m_pred[n] = poisson_rng(M[n], q[n]);
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;值得一提的是，在 Stan 中，提供了 &lt;code&gt;poisson_log(x)&lt;/code&gt; 分佈函數，其實它等價於使用 &lt;code&gt;poisson(exp(x))&lt;/code&gt;。除了更加接近我們熟悉的泊松回歸模型的數學表達式，避免了 &lt;code&gt;exp&lt;/code&gt; 指數運算，計算結果穩定。於是我們還可以把上面的模型修改成：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data {
  int N; 
  int&amp;lt;lower=0, upper=1&amp;gt; A[N]; 
  real&amp;lt;lower=0, upper=1&amp;gt; Score[N]; 
  int&amp;lt;lower=0&amp;gt; M[N];
}

parameters {
  real b[3]; 
}

transformed parameters {
  real lambda[N];
  for (n in 1:N) {
    lambda[n] = b[1] + b[2]*A[n] + b[3]*Score[n]；
  }
}

model {
  for (n in 1:N) {
    M[n] ~ poisson_log(lambda[n]); 
  }
}

generated quantities {
  int m_pred[N]; 
  for (n in 1:N) {
    m_pred[n] = poisson_log_rng(M[n], q[n]);
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;運行它的代碼如下：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: StanHeaders&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: ggplot2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## rstan (Version 2.19.2, GitRev: 2e1f913d3ca3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## For execution on a local, multicore CPU with excess RAM we recommend calling
## options(mc.cores = parallel::detectCores()).
## To avoid recompilation of unchanged Stan programs, we recommend calling
## rstan_options(auto_write = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- list(N=nrow(d), A=d$A, Score=d$Score/200, M=d$M)
# fit &amp;lt;- stan(file=&amp;#39;model/model5-6.stan&amp;#39;, data=data, seed=1234)
fit &amp;lt;- stan(file=&amp;#39;stanfiles/model5-6b.stan&amp;#39;, data=data, seed=1234, pars = c(&amp;quot;b&amp;quot;, &amp;quot;lambda&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;model5-6b&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 1.3e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.101417 seconds (Warm-up)
## Chain 1:                0.11273 seconds (Sampling)
## Chain 1:                0.214147 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;model5-6b&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 9e-06 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.103552 seconds (Warm-up)
## Chain 2:                0.113478 seconds (Sampling)
## Chain 2:                0.21703 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;model5-6b&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 6e-06 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.106149 seconds (Warm-up)
## Chain 3:                0.103742 seconds (Sampling)
## Chain 3:                0.209891 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;model5-6b&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 7e-06 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.10037 seconds (Warm-up)
## Chain 4:                0.11621 seconds (Sampling)
## Chain 4:                0.21658 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: model5-6b.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##               mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff
## b[1]          3.58    0.00 0.10    3.38    3.51    3.58    3.64    3.76  1187
## b[2]          0.26    0.00 0.04    0.18    0.24    0.26    0.29    0.35  1831
## b[3]          0.29    0.00 0.15    0.01    0.19    0.29    0.39    0.58  1227
## lambda[1]     3.68    0.00 0.05    3.58    3.65    3.68    3.71    3.77  1276
## lambda[2]     4.05    0.00 0.03    3.98    4.03    4.05    4.07    4.12  2189
## lambda[3]     3.76    0.00 0.03    3.70    3.74    3.76    3.78    3.81  2467
## lambda[4]     3.97    0.00 0.04    3.88    3.94    3.97    3.99    4.05  1735
## lambda[5]     4.07    0.00 0.04    3.99    4.04    4.07    4.10    4.15  1793
## lambda[6]     3.77    0.00 0.03    3.71    3.75    3.77    3.79    3.83  2509
## lambda[7]     3.74    0.00 0.03    3.68    3.72    3.74    3.76    3.79  1991
## lambda[8]     4.05    0.00 0.03    3.98    4.03    4.06    4.08    4.12  2102
## lambda[9]     3.79    0.00 0.03    3.72    3.77    3.79    3.81    3.85  2282
## lambda[10]    3.79    0.00 0.03    3.72    3.77    3.79    3.81    3.85  2305
## lambda[11]    4.05    0.00 0.03    3.98    4.02    4.05    4.07    4.11  2347
## lambda[12]    3.78    0.00 0.03    3.72    3.76    3.78    3.80    3.83  2465
## lambda[13]    4.01    0.00 0.03    3.95    3.99    4.01    4.03    4.07  2499
## lambda[14]    3.74    0.00 0.03    3.68    3.72    3.74    3.76    3.79  1991
## lambda[15]    3.73    0.00 0.03    3.68    3.72    3.74    3.76    3.79  1910
## lambda[16]    3.98    0.00 0.04    3.91    3.96    3.98    4.01    4.05  2088
## lambda[17]    3.74    0.00 0.03    3.68    3.72    3.74    3.76    3.80  2122
## lambda[18]    3.70    0.00 0.04    3.61    3.67    3.70    3.72    3.78  1360
## lambda[19]    3.85    0.00 0.05    3.74    3.81    3.85    3.88    3.95  1653
## lambda[20]    4.07    0.00 0.04    3.99    4.04    4.07    4.09    4.14  1835
## lambda[21]    3.97    0.00 0.04    3.88    3.94    3.97    3.99    4.05  1735
## lambda[22]    4.00    0.00 0.03    3.93    3.98    4.00    4.02    4.06  2298
## lambda[23]    3.99    0.00 0.03    3.93    3.97    3.99    4.02    4.06  2252
## lambda[24]    4.05    0.00 0.03    3.98    4.03    4.05    4.07    4.11  2283
## lambda[25]    4.01    0.00 0.03    3.95    3.99    4.01    4.03    4.07  2483
## lambda[26]    4.03    0.00 0.03    3.97    4.01    4.03    4.05    4.09  2548
## lambda[27]    3.75    0.00 0.03    3.69    3.73    3.75    3.77    3.80  2321
## lambda[28]    3.75    0.00 0.03    3.69    3.73    3.75    3.77    3.80  2321
## lambda[29]    3.81    0.00 0.04    3.73    3.78    3.81    3.84    3.89  1971
## lambda[30]    3.74    0.00 0.03    3.68    3.72    3.74    3.76    3.80  2077
## lambda[31]    4.08    0.00 0.04    4.00    4.05    4.08    4.11    4.17  1672
## lambda[32]    3.95    0.00 0.05    3.85    3.92    3.95    3.98    4.04  1571
## lambda[33]    4.04    0.00 0.03    3.98    4.02    4.04    4.06    4.10  2409
## lambda[34]    4.02    0.00 0.03    3.96    4.00    4.02    4.04    4.08  2554
## lambda[35]    3.76    0.00 0.03    3.70    3.74    3.76    3.78    3.81  2482
## lambda[36]    3.77    0.00 0.03    3.71    3.75    3.77    3.79    3.82  2516
## lambda[37]    3.99    0.00 0.03    3.93    3.97    3.99    4.02    4.06  2229
## lambda[38]    3.74    0.00 0.03    3.68    3.72    3.74    3.76    3.79  1950
## lambda[39]    3.71    0.00 0.04    3.63    3.68    3.71    3.73    3.78  1437
## lambda[40]    3.70    0.00 0.04    3.63    3.68    3.70    3.73    3.78  1424
## lambda[41]    3.76    0.00 0.03    3.71    3.75    3.76    3.78    3.82  2512
## lambda[42]    3.77    0.00 0.03    3.71    3.75    3.77    3.79    3.83  2509
## lambda[43]    3.75    0.00 0.03    3.70    3.74    3.75    3.77    3.81  2404
## lambda[44]    3.79    0.00 0.03    3.72    3.77    3.79    3.82    3.86  2236
## lambda[45]    3.84    0.00 0.05    3.74    3.81    3.84    3.88    3.95  1683
## lambda[46]    3.73    0.00 0.03    3.67    3.71    3.73    3.75    3.79  1772
## lambda[47]    3.65    0.00 0.06    3.53    3.61    3.65    3.69    3.77  1222
## lambda[48]    3.79    0.00 0.04    3.73    3.77    3.79    3.82    3.86  2191
## lambda[49]    3.72    0.00 0.03    3.65    3.70    3.72    3.74    3.79  1613
## lambda[50]    3.98    0.00 0.04    3.91    3.96    3.98    4.01    4.05  2088
## lp__       6896.53    0.03 1.28 6893.17 6895.97 6896.87 6897.45 6897.95  1452
##            Rhat
## b[1]          1
## b[2]          1
## b[3]          1
## lambda[1]     1
## lambda[2]     1
## lambda[3]     1
## lambda[4]     1
## lambda[5]     1
## lambda[6]     1
## lambda[7]     1
## lambda[8]     1
## lambda[9]     1
## lambda[10]    1
## lambda[11]    1
## lambda[12]    1
## lambda[13]    1
## lambda[14]    1
## lambda[15]    1
## lambda[16]    1
## lambda[17]    1
## lambda[18]    1
## lambda[19]    1
## lambda[20]    1
## lambda[21]    1
## lambda[22]    1
## lambda[23]    1
## lambda[24]    1
## lambda[25]    1
## lambda[26]    1
## lambda[27]    1
## lambda[28]    1
## lambda[29]    1
## lambda[30]    1
## lambda[31]    1
## lambda[32]    1
## lambda[33]    1
## lambda[34]    1
## lambda[35]    1
## lambda[36]    1
## lambda[37]    1
## lambda[38]    1
## lambda[39]    1
## lambda[40]    1
## lambda[41]    1
## lambda[42]    1
## lambda[43]    1
## lambda[44]    1
## lambda[45]    1
## lambda[46]    1
## lambda[47]    1
## lambda[48]    1
## lambda[49]    1
## lambda[50]    1
## lp__          1
## 
## Samples were drawn using NUTS(diag_e) at Tue Jan  7 14:46:49 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;運行結果的解釋&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;運行結果的解釋&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;...{省略}...
              mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat
b[1]          3.58    0.00 0.09    3.38    3.51    3.58    3.64    3.76  1373    1
b[2]          0.26    0.00 0.04    0.18    0.24    0.26    0.29    0.35  1797    1
b[3]          0.29    0.00 0.15    0.00    0.20    0.29    0.39    0.59  1422    1
lambda[1]     3.68    0.00 0.05    3.58    3.65    3.68    3.71    3.77  1510    1
...{省略}...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我們把計算獲得的事後概率分佈均值放入前面寫下的數學表達式:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\lambda[n] &amp;amp; = \exp(3.58 + 0.26A[n] + 0.29Score[n]/200) &amp;amp; n = 1, \dots, N \\
M[n]       &amp;amp; \sim \text{Poisson}(\lambda[n])     &amp;amp; n = 1, \dots, N
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;例如說，&lt;code&gt;Score = 150&lt;/code&gt; 和 &lt;code&gt;Score = 50&lt;/code&gt; 的兩名學生，如果對打工喜好態度相同的話，他們之間選課的總課時數之比爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\frac{M_\text{Score = 150}}{M_\text{Score = 50}} &amp;amp; = \frac{\exp(3.58 + 0.26A + 0.29\times\frac{150}{200})}{\exp(3.58 + 0.26A + 0.29\times\frac{50}{200})} \\ 
&amp;amp; = \exp(0.29\times\frac{150-50}{200}) \approx 1.16
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;也就是熱愛學習分數 &lt;code&gt;Score&lt;/code&gt; 達到150的人和只有50的人相比，選課總課時數平均多 16%。相似地，喜歡打工 &lt;code&gt;A = 1&lt;/code&gt; 的學生和不喜歡打工 &lt;code&gt;A = 0&lt;/code&gt; 的學生選課總課時數之比爲 &lt;span class=&#34;math inline&#34;&gt;\(\exp(0.26)\approx1.30\)&lt;/span&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>地基貌似已經完成</title>
      <link>https://wangcc.me/post/construction/</link>
      <pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/construction/</guid>
      <description>&lt;p&gt;上週6月29日結束開工的&lt;a href=&#34;https://wangcc.me/post/jichinsai/&#34;&gt;祈福儀式(地鎮祭)&lt;/a&gt;過後，又是一星期的陰雨天不斷。&lt;/p&gt;
&lt;p&gt;週五下午接到工地負責師傅打來電話報告進度說，這周的工事基本已經完成，地基的輪廓大致做好了。我很好奇這陰雨天中他們是怎麼見縫插針地找時間灌好水泥的。直到看到建築公司的銷售小哥發了下面的挖土作業的照片給我，心終於放了下來：&lt;/p&gt;
&lt;p&gt;![](/post/2019-07-07-construction_files/shovel car.jpg)&lt;/p&gt;
&lt;p&gt;看來他們還是能找到不下雨的空隙來作業的。顯然我的擔心有點多餘。但畢竟可能這輩子就蓋這一次房子。真是不想有任何不順利的事發生呢。&lt;/p&gt;
&lt;p&gt;週六白天去菜市場買菜回來的路上又拐過去工地看了一下，看見他們已經在門口立起來一塊牌子，牌子上有一条工務店給自己打的廣告，還有建築工地負責人，設計師的名字以及一条的公司老闆的名字：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-07-construction_files/IMG_20190706_113411.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看見預計的工事期間是到12月10日。也就是說，我們的元旦和新年就會在新房子裏度過啦！十分期待。&lt;/p&gt;
&lt;p&gt;擡腳跑到西邊空地上（稍高）給這個地基來了一張整體照（封面圖片）：
&lt;img src=&#34;https://wangcc.me/post/2019-07-07-construction_files/IMG_20190706_113603.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以清楚的看到離鏡頭最近的部分將會是浴室和洗手臺的房間。右邊很寬敞的則是廚房及餐廳。稍遠一點的地方將會是未來的大客廳。還有停在路邊的就是我自家開的豐田Sienta。估計這樣每週每週過來看看進度，會是一件很有意思，也很有盼頭的事呢。&lt;/p&gt;
&lt;p&gt;同一天，其實正好也是女兒的2歲生日。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-07-07-construction_files/mmexport1562415995625.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;去年女兒一歲的時候，我人還在倫敦苦逼地寫着畢業論文。今年我們就已經在一起期盼着年底住新房的喜悅了。希望在新的房子裏，孩子們能健康快樂地長大。等8月份上樑了以後，房子的輪廓就能看見了，到時候可能又會是新的不安新的期待，還有好多傢俱和生活所需的電器的要準備，要花銀子的地方實在是數不玩。。。。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>地鎮祭</title>
      <link>https://wangcc.me/post/jichinsai/</link>
      <pubDate>Sat, 29 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/jichinsai/</guid>
      <description>&lt;p&gt;今日在即將開工建房的土地上，建築公司請來神社的神職人，花了大約一個小時的時間，幫助我們完成了
地鎮祭的儀式。&lt;/p&gt;
&lt;p&gt;地鎮祭儀式主要是為了祈福接下來的建築過程以及主人家人居住之後的平安與幸福的祈禱儀式。聽說中國農村如果自己土地上蓋房子，也會有相似的儀式來祈求神靈守護。&lt;/p&gt;
&lt;p&gt;本來儀式本身我們並不擔心會有什麼意外的事情發生。是這一週的天氣預報總是雷雨和陰雨不斷。於是家人都很擔心週六的地鎮祭儀式時的天氣，從週一開始每天都在手機查閱天氣情況。還好到了地鎮祭舉行的週六這天，天公作美在早上11點儀式開始前雨停下。我們抵達土地時，神職人也為了以防萬一搭好了臨時擋風遮雨的帳篷。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-06-30-jichinsai_files/IMG_20190629_104451.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看到神職人已經為我們準備好了供奉的水果蔬菜，清酒，驅邪的食鹽和潔淨的大米：
&lt;img src=&#34;https://wangcc.me/post/2019-06-30-jichinsai_files/IMG_20190629_104416.jpg&#34; alt=&#34;準備就緒&#34;&gt;&lt;/p&gt;
&lt;p&gt;之後儀式順利舉行，神職人帶著我們在土地建房的東南西北各個方向上把祭拜後的食鹽和淨米，還有清酒灑在地面上。&lt;/p&gt;
&lt;p&gt;兒子也很聽話地參與了祭拜和祈禱的整個過程：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-06-30-jichinsai_files/mmexport1561797204704.jpg&#34; alt=&#34;兒子&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-06-30-jichinsai_files/mmexport1561797168564.jpg&#34; alt=&#34;還是兒子&#34;&gt;&lt;/p&gt;
&lt;p&gt;全家一起在未開工的新家地址上第一張合照產生啦：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-06-30-jichinsai_files/mmexport1561797153590.jpg&#34; alt=&#34;合照&#34;&gt;&lt;/p&gt;
&lt;p&gt;感謝上蒼，我們順利在無風無雨中結束儀式，建築現場負責的工人安排說明了接下來直至我們能夠搬新家之前的流程之後，天又一下子陰沈下來，轉眼又大雨傾盆。&lt;/p&gt;
&lt;p&gt;祝願我們的新家可以平安無事地建成，建成後，也保佑我們會幸福美滿地在這裏繼續我們的生活。封面是從神職人手裏領受的守護。聽說會被一直埋在地基下面，從今天起，保佑這片土地。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>菜鳥的Mac筆記本折騰之路</title>
      <link>https://wangcc.me/post/2019-06-28-macbook/</link>
      <pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2019-06-28-macbook/</guid>
      <description>&lt;p&gt;這些年習慣了折騰Ubuntu之後，突然切換回高大上的 Macbook Pro，真心不太適應。&lt;/p&gt;
&lt;p&gt;首先吐槽花了兩天時間才搞定家裏和學校的打印機聯接設定。真是不曉得昨天早上和晚上為啥死都連不上的佳能打印機驅動，今天重新打開電腦之後就突然能接上了。果然&amp;quot;重新啟動&amp;quot;永遠是最有有效的招數。其實完全不知道未重啟之前到底電腦的哪根筋沒有接好。&lt;/p&gt;
&lt;p&gt;接下來讓人不可思議的是 MacOS 沒有OpenBUGS。經過放狗搜索之後找到了&lt;a href=&#34;https://oliviergimenez.github.io/post/run_openbugs_on_mac/&#34;&gt;在蘋果電腦上安裝 OpenBUGS 的方法&lt;/a&gt;。簡單總結就是下載 Wine 之後用 wine 來跑OpenBUGES，介面風格像80年代的筆電一樣：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-06-28-testpost_files/wineOpenBUGS.png&#34; alt=&#34;wineOpenBUGS&#34;&gt;&lt;/p&gt;
&lt;p&gt;即使最終能夠使用OpenBUGS的介面進行運算之後，在Ubuntu和Windows都能自動識別並連結OpenBUGS引擎的 &lt;a href=&#34;https://cran.r-project.org/web/packages/BRugs/index.html&#34;&gt;Brugs&lt;/a&gt; 包竟然還是無法下載識別MCMC引擎。所以下載了勉強能夠使用 R2OpenBUGS 包計算，但是還需要用下面繁瑣的設定：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;WINE=&amp;quot;/usr/local/bin/wine&amp;quot;
WINEPATH=&amp;quot;/usr/local/bin/winepath&amp;quot;
OpenBUGS.pgm=&amp;quot;/Users/{user.name}/Wine\ Files/drive_c/Program\ Files/OpenBUGS/OpenBUGS323/OpenBUGS.exe&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;於是，我的學習筆記大概率估計是只能在Ubuntu上更新了。&lt;/p&gt;
&lt;p&gt;還有要吐槽的一個事情就是，StataIC 版本在Ubuntu下可以使用命令行直接在終端呼叫Stata引擎進行統計分析並且輸出結果，十分方便。而且設定了路徑之後可以直接在Rstudio裡面加入Stata引擎，使得Rmarkdown的代碼部分可以自由地在R和Stata之間切換。但是Mac版本的StataIC竟然沒有命令行的安裝方式。繼續放狗查詢才知道，必須是StataSE或者StataMP版本才可以。這是另一條讓我滾回Ubuntu的理由嗎？&lt;/p&gt;
&lt;p&gt;Mac電腦現在在我眼裡已經爛得只剩下顏值了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-06-28-testpost_files/IMG_20190627_102846.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;這兩天折騰安裝各種軟件之時，發現Texlive 2019的Mac版本安裝完畢之後佔據將近6個G的硬盤空間。於是狠狠心刪除了之後換上輕巧簡潔的 &lt;a href=&#34;https://yihui.name/tinytex/&#34;&gt;TinyTex&lt;/a&gt;，發現整個世界都純淨了。&lt;/p&gt;
&lt;p&gt;只需要在Rmd文檔的YAML部分加入下面這段代碼，一份日語（中文）英文混合的PDF文檔即可在Rstudio中編譯完成，從安裝到完成第一個日語文檔的編譯，基本上僅僅耗時十分鐘左右。好評！&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
title: &amp;quot;日本語&amp;quot;
header-includes:
  - \usepackage{xltxtra}
  - \usepackage{zxjatype}
  - \usepackage[ipaex]{zxjafont}
output: 
  pdf_document: 
    latex_engine: xelatex 
---
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-06-28-testpost_files/TinyTexJap.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>誰還未覺醒 | Do you hear people sing</title>
      <link>https://wangcc.me/post/do-you-hear-people-sing/</link>
      <pubDate>Wed, 12 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/do-you-hear-people-sing/</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
&lt;blockquote&gt;
&lt;p&gt;試問誰還未發聲&lt;br&gt;
都捨我其誰衛我城&lt;br&gt;
天生有權還有心可作主&lt;br&gt;
誰要認命噤聲&lt;br&gt;
試問誰能未覺醒&lt;br&gt;
聽真那自由在奏鳴&lt;br&gt;
激起再難違背的那份良知和應&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;為何美夢仍是個夢&lt;br&gt;
還想等恩賜泡影&lt;br&gt;
為這黑與白這非與是&lt;br&gt;
真與偽來做證&lt;br&gt;
為這世代有未來&lt;br&gt;
要及時擦亮眼睛&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;無人有權沉默&lt;br&gt;
看著萬家燈火變了色&lt;br&gt;
問我心再用我手&lt;br&gt;
去為選我命途力拼&lt;br&gt;
人既是人&lt;br&gt;
有責任有自由決定遠景&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;這是一個值得銘記的日子。這是一個需要我們所有人都認識到自己所處的世代，要面臨劇變的時刻。&lt;/p&gt;
&lt;p&gt;在那個廣場上，你要麼是王維林，要麼就是那臺坦克。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-06-12-do-you-hear-people-sing_files/IMG_20190609_180641.jpg&#34; alt=&#34;lie&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>君與長江|傍晚穿過廣場</title>
      <link>https://wangcc.me/post/2019-06-04/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2019-06-04/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://chinadigitaltimes.net/chinese/2019/06/%E5%90%9B%E4%B8%8E%E9%95%BF%E6%B1%9F-%E5%82%8D%E6%99%9A%E7%A9%BF%E8%BF%87%E5%B9%BF%E5%9C%BA/&#34;&gt;原文鏈接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-06-06_files/toprotest0.png&#34; alt=&#34;go to protest!&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我不知道一個過去年代的廣場&lt;br&gt;
從何而始，從何而終&lt;br&gt;
有的人用一小時穿過廣場&lt;br&gt;
有的人用一生 &amp;mdash;&amp;mdash;&lt;br&gt;
早晨是孩子，傍晚已是垂暮之人&lt;br&gt;
我不知道還要在陽光中走出多遠&lt;br&gt;
才能停住腳步？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;還要在陽光中眺望多久才能&lt;br&gt;
閉上眼睛？&lt;br&gt;
當高速行駛的汽車打開刺目的車燈&lt;br&gt;
哪些曾在一個明媚早晨穿過廣場的人&lt;br&gt;
我從汽車的後視鏡看見過他們一閃即逝&lt;br&gt;
的面孔&lt;br&gt;
傍晚他們乘車離去&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;一個無人離去的地方不是廣場&lt;br&gt;
一個無人倒下的地方也不是&lt;br&gt;
離去的重新歸來&lt;br&gt;
倒下的卻永遠倒下了&lt;br&gt;
一種叫做石頭的東西&lt;br&gt;
迅速地堆積，屹立&lt;br&gt;
不像骨頭的生長需要一百年的時間&lt;br&gt;
也不像骨頭那麼軟弱&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;每個廣場都有一個用石頭壘起來的&lt;br&gt;
腦袋，使兩手空空的人們感到生存的&lt;br&gt;
分量。以巨大的石頭腦袋去思考和仰望&lt;br&gt;
對任何人都不是一件輕鬆的事&lt;br&gt;
石頭的重量&lt;br&gt;
減輕了人們肩上的責任，愛情和犧牲&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;或許人們會在一個明媚的早晨穿過廣場&lt;br&gt;
張開手臂在四面來風中柔情地擁抱&lt;br&gt;
但當黑夜降臨&lt;br&gt;
雙手就變得沉重&lt;br&gt;
唯一的發光體是腦袋裏的石頭&lt;br&gt;
唯一刺向石頭的利劍悄然墜地&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;黑暗和寒冷在上升&lt;br&gt;
廣場周圍的高層建築穿上了瓷和玻璃的時裝&lt;br&gt;
一切變得矮小了。石頭的世界&lt;br&gt;
在玻璃反射出來的世界中輕輕浮起&lt;br&gt;
像是塗在孩子們作業本上的&lt;br&gt;
一個隨時會被撕下來揉成一團的陰沉念頭&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;汽車疾駛而過，把流水的速度&lt;br&gt;
傾瀉到有着鋼鐵筋骨的龐大混凝土制度中&lt;br&gt;
賦予寂靜以喇叭的形狀&lt;br&gt;
一個過去年代的廣場從後視鏡消失了&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;永遠消失了 &amp;mdash;&amp;mdash;&lt;br&gt;
一個青春期的，初戀的，佈滿粉刺的廣場&lt;br&gt;
一個從未在賬單和死亡通知書上出現的廣場&lt;br&gt;
一個路初胸膛，挽起衣袖，紮緊腰帶&lt;br&gt;
一個雙手使勁搓洗的帶補丁的廣場&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;一個通過年輕的血液流到身體之外&lt;br&gt;
用舌頭去舔，用前額去下磕，用旗幟去掩蓋&lt;br&gt;
的廣場&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;空想的，消失的，不復存在的廣場&lt;br&gt;
像下了一夜的大雪在早晨停住&lt;br&gt;
一種純潔而神祕的融化&lt;br&gt;
在良心和眼睛裏交替閃爍&lt;br&gt;
一部分成爲叫做淚水的東西&lt;br&gt;
零一部分在叫做石頭的東西裏變得堅硬起來&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;石頭的世界崩潰了&lt;br&gt;
一個軟組織的世界爬到高處&lt;br&gt;
整個過程就像泉水從吸管離開礦物&lt;br&gt;
進入密閉的，蒸餾過的，有着精美包裝的空間&lt;br&gt;
我乘坐高速電梯在雨天的傘柄裏上升&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;回到地面時，我看到雨傘一樣張開的&lt;br&gt;
一座圓形餐廳在城市上空旋轉&lt;br&gt;
像一頂從魔法變出來的帽子&lt;br&gt;
它的尺寸並不適合&lt;br&gt;
用石頭壘起來的巨人的腦袋&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;那些曾托起廣場的手臂放了下來&lt;br&gt;
如今巨人僅靠一柄短劍來支撐&lt;br&gt;
它會不會刺破什麼呢？比如，一場曾經有過的&lt;br&gt;
從紙上掀起，在牆上張貼的脆弱革命？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;從來沒有一種力量&lt;br&gt;
能把兩個不同世界長久地粘在一起&lt;br&gt;
一個反覆張貼的腦袋最終將被撕去&lt;br&gt;
反覆粉刷的牆壁&lt;br&gt;
被露出大腿的混血女郎佔據了一半&lt;br&gt;
另一半時頭髮再生，假肢安裝之類的誘人廣告&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;一輛嬰兒車靜靜地停在傍晚的廣場上&lt;br&gt;
靜靜地，和這個快要發瘋的世界沒有關係&lt;br&gt;
我猜嬰兒和落日之間的距離有一百年之遙&lt;br&gt;
這是近乎無限的尺度，足以測量&lt;br&gt;
穿過廣場所要經歷的一個幽閉時代有多麼漫長&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;對幽閉的普遍恐懼，使人們從各自的棲居&lt;br&gt;
雲集廣場，把一生中的孤獨時刻變成熱烈的節日&lt;br&gt;
但在棲居深處，在愛與死的默默的注目禮中&lt;br&gt;
一個空無人際的影子廣場被珍藏着&lt;br&gt;
像緊閉的懺悔室只屬於內心的祕密&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;是否穿越廣場之前必須穿越內心的黑暗&lt;br&gt;
現在黑暗中最黑的兩個世界合爲一體&lt;br&gt;
堅硬的石頭腦袋被劈開&lt;br&gt;
利劍在黑暗中閃閃發光&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;如果我能用被劈成兩半的神祕黑夜&lt;br&gt;
去解釋一個雙腳踏在大地上的明媚早晨 &amp;mdash;&amp;mdash;&lt;br&gt;
如果我能沿着灑滿晨曦的臺階&lt;br&gt;
去登上虛無之巔的巨人的肩膀&lt;br&gt;
不是爲了升起，而是爲了隕落 &amp;mdash;&amp;mdash;&lt;br&gt;
如果黃金鐫刻的銘文不是爲了被傳頌&lt;br&gt;
而是爲了被抹去，被遺忘，被踐踏 &amp;mdash;&amp;mdash;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;正如一個被踐踏的廣場遲早要落到踐踏者頭上&lt;br&gt;
哪些曾在一個明媚早晨穿過廣場的人&lt;br&gt;
他們的黑色皮鞋也遲早要落到利劍之上&lt;br&gt;
像必將落下的棺蓋落到棺材上那麼沉重&lt;br&gt;
躺在裏面的不是我，也不是&lt;br&gt;
行走在劍刃上的人&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;我沒想到這麼多人會在一個明媚的早晨&lt;br&gt;
穿過廣場，避開孤獨和永生&lt;br&gt;
他們時幽閉時代的倖存者&lt;br&gt;
我沒想到他們會在傍晚時離去或倒下&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;一個無人倒下的地方不是廣場&lt;br&gt;
一個無人站立的地方也不是&lt;br&gt;
我曾時站着的嗎？還要站立多久？&lt;br&gt;
畢竟我和哪些倒下去的人一樣&lt;br&gt;
從來不是一個永生者&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2019-06-06_files/toprotest1.png&#34; alt=&#34;go to tiananmen is my duty&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Berksonian Bias</title>
      <link>https://wangcc.me/post/berksonian-bias/</link>
      <pubDate>Sat, 09 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/berksonian-bias/</guid>
      <description>&lt;p&gt;在幫別人做論文質量評價的時候，也是個自我學習的過程。在下不才，目前無償爲幾個雜誌做審稿的工作。&lt;/p&gt;
&lt;p&gt;今天發來的稿件是某財大氣粗，曾經因爲篡改患者治療數據而臭名昭著的製藥公司員工寫的文章。那文章讀起來不長，卻實在是狗屎一堆。他們對歐洲高血壓患者中，直腸息肉的發生和直腸癌的發病率進行了數據庫分析。其中作者提到它們爲了避免&lt;a href=&#34;http://influentialpoints.com/Training/berksons_bias.htm&#34;&gt;伯克森偏倚(Berksonian Bias)&lt;/a&gt;，還對未執行直腸指檢篩查的高血壓患者的數據進行了分析。聽說高血壓患者中，直腸癌發病率也高（不知是真是假）。該文章在背景中大言不慚說別人的研究都搞不定到底是因爲治療高血壓的藥物導致了直腸癌，還是高血壓本身導致了直腸癌。我讀到這裏不禁已經覺得此文下半身應該已經涼涼。忍住不笑看完它們華麗麗地對每個risk factor單獨進行了一個回歸模型之後我的下巴已經掉了一半。心中暗想，他家就這水平還生產全世界最著名的高血壓藥物真的沒關係嗎？怪不得要去篡改患者的數據了。&lt;/p&gt;
&lt;p&gt;在鄙人的觀察下，該論文估計是沒戲了，但是這個偏倚的類型卻是我這個流行病學博士僧未曾聽說過的。算是這篇屎一樣的論文中唯一的發光點。&lt;/p&gt;
&lt;p&gt;原來這種偏倚最常見於樣本均採集自醫院樣本的病例對照研究。&lt;/p&gt;
&lt;p&gt;如果我們使用均來自於醫院的樣本作爲病例對照研究的對象，那麼我們需要假設，我們研究A疾病患者被收治到醫院內的概率，不會被該疾病可能的 risk factor 影響。但是，這種前提很多時候是無法被滿足的。特別是當A疾病的 risk factor 本身是另一種疾病的時候。理由很簡單，一名同時患有兩種疾病的患者去醫院報道的概率，顯然是要高於只有一種疾病的患者的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;When we take the sample we have to assume that the chance of admission to hospital for the disease is not affected by the presence or absence of the risk factor for that disease. This may not be the case, especially if the risk factor is another disease. This is because people are more likely to be hospitalized if they have two diseases, rather than only one.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如本文開頭使用的圖片中所提示的那樣，Sacket (1979)^[Sackett, D.L. (1979). Bias in analytic research. Journal of Chronic Diseases 32, 51-63.] 當年從一般社區人羣中採集了2784名樣本進行調查，看這些研究對象中呼吸道系統疾病，和身體機能嚴重下降(locomotor disease)之間是否存在相關性。然後，他又對同一樣本中，過去半年內住院過的患者進行了相同的分析。結果顯示，如果只看住院的患者數據，作者會作出&amp;quot;患有呼吸道疾病，有較高概率導致身體機能嚴重下降。&amp;ldquo;這樣的結論。也就是兩種疾病之間存在相關性。但是如果看右半側全體社區人羣數據的話，兩種疾病之間並無顯著的關係。顯然後者才是正確的結論。前者之所以會推導出錯誤的結論，純粹是因爲同時患有兩種疾病的人，比起只有呼吸系統疾病，或者只有身體機能下降的患者有更高的概率&lt;strong&gt;住院&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;回頭想起我們曾經做過那麼多院內病例對照研究，不禁感到細思極恐。。。。。。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rstan Wonderful R-(5)</title>
      <link>https://wangcc.me/post/logistic-rstan2/</link>
      <pubDate>Sun, 03 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/logistic-rstan2/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#另一種形式的貝葉斯邏輯回歸&#34;&gt;另一種形式的貝葉斯邏輯回歸&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#分析的目的&#34;&gt;分析的目的&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#確認數據分佈&#34;&gt;確認數據分佈&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#思考數據模型&#34;&gt;思考數據模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#寫下-stan-模型代碼&#34;&gt;寫下 Stan 模型代碼&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#檢查模型參數的收斂情況&#34;&gt;檢查模型參數的收斂情況&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#檢查模型的擬合情況&#34;&gt;檢查模型的擬合情況&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;另一種形式的貝葉斯邏輯回歸&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;另一種形式的貝葉斯邏輯回歸&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wangcc.me/post/logistic-rstan/&#34;&gt;前面一節&lt;/a&gt;使用的數據是以學生爲單位，將每名學生的實際課時數和實際出勤數進行了彙總之後的總結性數據，本章我們來看看相同數據的另一種形式。由於分析中有人建議說，天氣狀況對出勤率也是有較大的影響的，所以希望在&lt;a href=&#34;https://wangcc.me/post/logistic-rstan/&#34;&gt;前一節&lt;/a&gt;已有的邏輯回歸模型中增加對天氣狀況的調整。那麼這時候需要使用的就是彙總之前的數據，也就是要是用實際記錄了每名學生每一次課時的出勤與否的原始數據。值得注意的是，這時候&lt;a href=&#34;https://raw.githubusercontent.com/winterwang/RStanBook/master/chap05/input/data-attendance-3.txt&#34;&gt;原始數據&lt;/a&gt;中每名學生的記錄有許多行，因爲每行記錄的是該名學生每次上課時的天氣狀況和他/她是否出勤(0,1)的結果。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;- read.table(&amp;quot;https://raw.githubusercontent.com/winterwang/RStanBook/master/chap05/input/data-attendance-3.txt&amp;quot;, 
                     sep = &amp;quot;,&amp;quot;, header = T)
head(d, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    PersonID A Score Weather Y
## 1         1 0    69       B 1
## 2         1 0    69       A 1
## 3         1 0    69       C 1
## 4         1 0    69       A 1
## 5         1 0    69       B 1
## 6         1 0    69       B 1
## 7         1 0    69       C 0
## 8         1 0    69       B 1
## 9         1 0    69       A 1
## 10        1 0    69       A 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Weather\)&lt;/span&gt;，天氣數據 (&lt;code&gt;A&lt;/code&gt; = 晴天，&lt;code&gt;B&lt;/code&gt; = 多雲，&lt;code&gt;C&lt;/code&gt; = 下雨)；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;，該次課時學生是否出勤 (&lt;code&gt;0&lt;/code&gt; = 缺勤，&lt;code&gt;1&lt;/code&gt; = 出勤)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其他的數據和前一節中使用的數據相同。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;分析的目的&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;分析的目的&lt;/h1&gt;
&lt;p&gt;本次數據分析的目的依然是瞭解幾個預測變量，天氣，是否喜歡打工，是否熱愛學習，對學生出勤率的影響。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;確認數據分佈&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;確認數據分佈&lt;/h1&gt;
&lt;p&gt;你可以用先進的 &lt;code&gt;tidyverse&lt;/code&gt; 進行簡單的數據彙總，看看天氣狀況不同時實際出勤率是否有差別:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
d %&amp;gt;% 
  group_by(Weather, Y) %&amp;gt;% 
  summarise (n= n()) %&amp;gt;%
  mutate(rel.freq = paste0(round(100 * n/sum(n), 2), &amp;quot;%&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
## # Groups:   Weather [3]
##   Weather     Y     n rel.freq
##   &amp;lt;fct&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   
## 1 A           0   306 24.31%  
## 2 A           1   953 75.69%  
## 3 B           0   230 31.51%  
## 4 B           1   500 68.49%  
## 5 C           0   138 33.91%  
## 6 C           1   269 66.09%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果你不想學習 &lt;code&gt;tidyverse&lt;/code&gt;，也可以用下面的方法獲得類似的效果，&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;aggregate(Y ~ Weather, data = d, FUN = table)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Weather Y.0 Y.1
## 1       A 306 953
## 2       B 230 500
## 3       C 138 269&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;無論是哪種方法，我們都能大概猜出，天氣是晴天的時候 (&lt;code&gt;Weather = A&lt;/code&gt;)，出勤率相對較高。&lt;/p&gt;
&lt;p&gt;在作者的原著中，&lt;a href=&#34;https://raw.githubusercontent.com/winterwang/RStanBook/master/chap05/run-model5-5.R&#34;&gt;使用的是給分類型變量強制賦予連續值的方法&lt;/a&gt;，這點確實有點噁心，爲了正常的模型，我們需要把天氣轉換成爲更加常見的啞變量 (dummy variable) 如下:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;- fastDummies::dummy_cols(d, select_columns = &amp;quot;Weather&amp;quot;)
head(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   PersonID A Score Weather Y Weather_A Weather_B Weather_C
## 1        1 0    69       B 1         0         1         0
## 2        1 0    69       A 1         1         0         0
## 3        1 0    69       C 1         0         0         1
## 4        1 0    69       A 1         1         0         0
## 5        1 0    69       B 1         0         1         0
## 6        1 0    69       B 1         0         1         0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;思考數據模型&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;思考數據模型&lt;/h1&gt;
&lt;p&gt;我們設想的數學模型應該是這樣子的:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\text{logit}(q[i]) &amp;amp; = b_{1} + b_{2}A_{i} + b_{3}\text{Score}_{i} + b_{4}\text{WeatherB} + b_{5}\text{WeatherC} \\ 
\text{where} &amp;amp; \\ 
&amp;amp; \text{ WeatherB} = 0, \text{ WeatherC} = 0 \text{ indicates weather = A} \\ 
&amp;amp; \text{ WeatherB} = 1, \text{ WeatherC} = 0 \text{ indicates weather = B} \\ 
&amp;amp; \text{ WeatherB} = 0, \text{ WeatherC} = 1 \text{ indicates weather = C} \\
Y[i] &amp;amp;\sim \text{Bernulli}(q[i])
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;寫下-stan-模型代碼&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;寫下 Stan 模型代碼&lt;/h1&gt;
&lt;p&gt;下面是相應的 Stan 模型:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data {
  int I;
  int&amp;lt;lower=0, upper=1&amp;gt; A[I];
  real&amp;lt;lower=0, upper=1&amp;gt; Score[I];
  int&amp;lt;lower=0, upper=1&amp;gt; W_B[I];
  int&amp;lt;lower=0, upper=1&amp;gt; W_C[I];
  int&amp;lt;lower=0, upper=1&amp;gt; Y[I];
}

// The parameters accepted by the model. 
parameters {
  real b[5];
}

// The model to be estimated. 
model {
   for (i in 1:I)
    Y[i] ~ bernoulli_logit(b[1] + b[2]*A[i] + b[3]*Score[i] + b[4]*W_B[i] + b[5]*W_C[i]);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;和跑它們的 R 代碼&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: StanHeaders&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## rstan (Version 2.19.2, GitRev: 2e1f913d3ca3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## For execution on a local, multicore CPU with excess RAM we recommend calling
## options(mc.cores = parallel::detectCores()).
## To avoid recompilation of unchanged Stan programs, we recommend calling
## rstan_options(auto_write = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;rstan&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:tidyr&amp;#39;:
## 
##     extract&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- list(I=nrow(d), A=d$A, Score=d$Score/200, 
             W_A=d$Weather_A, W_B = d$Weather_B, W_C = d$Weather_C, 
             Y=d$Y)
fit1 &amp;lt;- stan(file=&amp;#39;stanfiles/myex4.stan&amp;#39;, data=data, pars=c(&amp;#39;b&amp;#39;, &amp;quot;OR1&amp;quot;, &amp;quot;OR2&amp;quot;, &amp;quot;OR3&amp;quot;, &amp;quot;OR4&amp;quot;, &amp;quot;q&amp;quot;), seed=1234)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;myex4&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0.000882 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 8.82 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 10.175 seconds (Warm-up)
## Chain 1:                9.91225 seconds (Sampling)
## Chain 1:                20.0872 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;myex4&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 0.000481 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 4.81 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 9.50031 seconds (Warm-up)
## Chain 2:                10.1304 seconds (Sampling)
## Chain 2:                19.6307 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;myex4&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 0.000467 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 4.67 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 9.76009 seconds (Warm-up)
## Chain 3:                10.4794 seconds (Sampling)
## Chain 3:                20.2395 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;myex4&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 0.000714 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 7.14 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 9.27456 seconds (Warm-up)
## Chain 4:                11.3889 seconds (Sampling)
## Chain 4:                20.6635 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: myex4.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##             mean se_mean   sd     2.5%      25%      50%      75%    97.5%
## b[1]        0.27    0.00 0.23    -0.18     0.12     0.28     0.43     0.72
## b[2]       -0.63    0.00 0.09    -0.81    -0.69    -0.63    -0.57    -0.44
## b[3]        1.95    0.01 0.37     1.22     1.71     1.96     2.20     2.69
## b[4]       -0.38    0.00 0.11    -0.59    -0.45    -0.38    -0.31    -0.18
## b[5]       -0.49    0.00 0.12    -0.74    -0.58    -0.49    -0.41    -0.25
## OR1         0.54    0.00 0.05     0.44     0.50     0.53     0.57     0.64
## OR2         7.56    0.06 2.92     3.40     5.52     7.08     9.05    14.79
## OR3         0.69    0.00 0.07     0.55     0.64     0.68     0.74     0.84
## OR4         0.61    0.00 0.08     0.48     0.56     0.61     0.66     0.78
## q[1]        0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[2]        0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[3]        0.61    0.00 0.04     0.54     0.59     0.61     0.64     0.68
## q[4]        0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[5]        0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[6]        0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[7]        0.61    0.00 0.04     0.54     0.59     0.61     0.64     0.68
## q[8]        0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[9]        0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[10]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[11]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[12]       0.61    0.00 0.04     0.54     0.59     0.61     0.64     0.68
## q[13]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[14]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[15]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[16]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[17]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[18]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[19]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[20]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[21]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[22]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[23]       0.61    0.00 0.04     0.54     0.59     0.61     0.64     0.68
## q[24]       0.61    0.00 0.04     0.54     0.59     0.61     0.64     0.68
## q[25]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[26]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[27]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[28]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[29]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[30]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[31]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[32]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[33]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[34]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[35]       0.61    0.00 0.04     0.54     0.59     0.61     0.64     0.68
## q[36]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[37]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[38]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[39]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[40]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[41]       0.72    0.00 0.02     0.67     0.70     0.72     0.74     0.77
## q[42]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[43]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[44]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[45]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[46]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[47]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.69
## q[48]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[49]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[50]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[51]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[52]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[53]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[54]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[55]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[56]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[57]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[58]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.69
## q[59]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[60]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.69
## q[61]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[62]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[63]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[64]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[65]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[66]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[67]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[68]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.69
## q[69]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[70]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.69
## q[71]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.69
## q[72]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[73]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[74]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[75]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[76]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.69
## q[77]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[78]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[79]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.69
## q[80]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[81]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[82]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.69
## q[83]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[84]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[85]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[86]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[87]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[88]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[89]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[90]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[91]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[92]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[93]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[94]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[95]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[96]       0.66    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[97]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[98]       0.74    0.00 0.02     0.71     0.73     0.74     0.75     0.78
## q[99]       0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.69
## q[100]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[101]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[102]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[103]      0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[104]      0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[105]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[106]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[107]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[108]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[109]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[110]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[111]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[112]      0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[113]      0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[114]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[115]      0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[116]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[117]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[118]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[119]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[120]      0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[121]      0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[122]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[123]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[124]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[125]      0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[126]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[127]      0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[128]      0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[129]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[130]      0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[131]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[132]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[133]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[134]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[135]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[136]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[137]      0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[138]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[139]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[140]      0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[141]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[142]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[143]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[144]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[145]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[146]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[147]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[148]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[149]      0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[150]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[151]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[152]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[153]      0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[154]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[155]      0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[156]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[157]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[158]      0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[159]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[160]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[161]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[162]      0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[163]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[164]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[165]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[166]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[167]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[168]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[169]      0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[170]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[171]      0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[172]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[173]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[174]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[175]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[176]      0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[177]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[178]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[179]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[180]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[181]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[182]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[183]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[184]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[185]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[186]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[187]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[188]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[189]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[190]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[191]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[192]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[193]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[194]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[195]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[196]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[197]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[198]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[199]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[200]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[201]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[202]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[203]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[204]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[205]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[206]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[207]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[208]      0.69    0.00 0.02     0.64     0.68     0.69     0.71     0.74
## q[209]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.80
## q[210]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[211]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[212]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[213]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[214]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[215]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[216]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[217]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[218]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[219]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[220]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[221]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[222]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[223]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[224]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[225]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[226]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[227]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[228]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[229]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[230]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[231]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[232]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[233]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[234]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[235]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[236]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[237]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[238]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[239]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[240]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[241]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[242]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[243]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[244]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[245]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[246]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[247]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[248]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[249]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[250]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[251]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[252]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[253]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[254]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[255]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[256]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[257]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[258]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[259]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[260]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[261]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[262]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[263]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[264]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[265]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[266]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[267]      0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[268]      0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[269]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[270]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[271]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[272]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[273]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[274]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[275]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[276]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[277]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[278]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[279]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[280]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[281]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[282]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[283]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[284]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[285]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[286]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[287]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[288]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[289]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[290]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[291]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[292]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[293]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[294]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[295]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[296]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[297]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[298]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[299]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[300]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[301]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[302]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[303]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[304]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[305]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[306]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[307]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[308]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[309]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[310]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[311]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[312]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[313]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[314]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[315]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[316]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[317]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[318]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[319]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[320]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[321]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[322]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[323]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[324]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[325]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[326]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[327]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[328]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[329]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[330]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[331]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[332]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[333]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[334]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[335]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[336]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[337]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[338]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[339]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[340]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[341]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[342]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[343]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[344]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[345]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[346]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[347]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[348]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[349]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[350]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[351]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[352]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[353]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[354]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[355]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[356]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[357]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[358]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[359]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[360]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[361]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[362]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[363]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[364]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[365]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[366]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[367]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[368]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[369]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[370]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[371]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[372]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[373]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[374]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[375]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[376]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[377]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[378]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[379]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[380]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[381]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[382]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[383]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[384]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[385]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[386]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[387]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[388]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[389]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[390]      0.67    0.00 0.02     0.62     0.65     0.67     0.68     0.71
## q[391]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[392]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[393]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[394]      0.64    0.00 0.03     0.59     0.62     0.64     0.66     0.70
## q[395]      0.75    0.00 0.02     0.71     0.73     0.75     0.76     0.78
## q[396]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[397]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[398]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[399]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.81
## q[400]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[401]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[402]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[403]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[404]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[405]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[406]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[407]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.81
## q[408]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[409]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.81
## q[410]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[411]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[412]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[413]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[414]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[415]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[416]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[417]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.81
## q[418]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[419]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[420]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[421]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[422]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[423]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[424]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[425]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[426]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[427]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[428]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[429]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[430]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[431]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[432]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[433]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[434]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[435]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.81
## q[436]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[437]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[438]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[439]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[440]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[441]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[442]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[443]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[444]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[445]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[446]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[447]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[448]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[449]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[450]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[451]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[452]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[453]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[454]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[455]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[456]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[457]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[458]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[459]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.81
## q[460]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[461]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.81
## q[462]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[463]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[464]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[465]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.81
## q[466]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[467]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[468]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[469]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[470]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[471]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[472]      0.77    0.00 0.02     0.73     0.75     0.77     0.78     0.81
## q[473]      0.85    0.00 0.01     0.82     0.84     0.85     0.85     0.87
## q[474]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[475]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[476]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[477]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[478]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[479]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[480]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[481]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[482]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[483]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[484]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[485]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[486]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[487]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[488]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[489]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[490]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[491]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[492]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[493]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[494]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[495]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[496]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[497]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[498]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[499]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[500]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[501]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[502]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[503]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[504]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[505]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[506]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[507]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[508]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[509]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[510]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[511]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[512]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[513]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[514]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[515]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[516]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[517]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[518]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[519]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[520]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[521]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[522]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[523]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[524]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[525]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[526]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[527]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[528]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[529]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[530]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[531]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[532]      0.79    0.00 0.02     0.75     0.78     0.79     0.80     0.82
## q[533]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[534]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[535]      0.84    0.00 0.01     0.82     0.84     0.84     0.85     0.87
## q[536]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[537]      0.77    0.00 0.02     0.72     0.75     0.77     0.78     0.81
## q[538]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[539]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[540]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[541]      0.66    0.00 0.02     0.61     0.64     0.66     0.67     0.70
## q[542]      0.66    0.00 0.02     0.61     0.64     0.66     0.67     0.70
## q[543]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[544]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[545]      0.63    0.00 0.03     0.57     0.61     0.63     0.65     0.68
## q[546]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[547]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[548]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[549]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[550]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[551]      0.66    0.00 0.02     0.61     0.64     0.66     0.67     0.70
## q[552]      0.63    0.00 0.03     0.57     0.61     0.63     0.65     0.68
## q[553]      0.66    0.00 0.02     0.61     0.64     0.66     0.67     0.70
## q[554]      0.66    0.00 0.02     0.61     0.64     0.66     0.67     0.70
## q[555]      0.63    0.00 0.03     0.57     0.61     0.63     0.65     0.68
## q[556]      0.63    0.00 0.03     0.57     0.61     0.63     0.65     0.68
## q[557]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[558]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[559]      0.63    0.00 0.03     0.57     0.61     0.63     0.65     0.68
## q[560]      0.66    0.00 0.02     0.61     0.64     0.66     0.67     0.70
## q[561]      0.63    0.00 0.03     0.57     0.61     0.63     0.65     0.68
## q[562]      0.66    0.00 0.02     0.61     0.64     0.66     0.67     0.70
## q[563]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[564]      0.66    0.00 0.02     0.61     0.64     0.66     0.67     0.70
## q[565]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[566]      0.63    0.00 0.03     0.57     0.61     0.63     0.65     0.68
## q[567]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[568]      0.66    0.00 0.02     0.61     0.64     0.66     0.67     0.70
## q[569]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[570]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[571]      0.74    0.00 0.02     0.70     0.72     0.74     0.75     0.77
## q[572]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[573]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[574]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[575]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[576]      0.75    0.00 0.02     0.71     0.74     0.75     0.77     0.80
## q[577]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[578]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[579]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[580]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[581]      0.75    0.00 0.02     0.71     0.74     0.75     0.77     0.80
## q[582]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[583]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[584]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[585]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[586]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[587]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[588]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[589]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[590]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[591]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[592]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[593]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[594]      0.75    0.00 0.02     0.71     0.74     0.75     0.77     0.80
## q[595]      0.75    0.00 0.02     0.71     0.74     0.75     0.77     0.80
## q[596]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[597]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[598]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[599]      0.75    0.00 0.02     0.71     0.74     0.75     0.77     0.80
## q[600]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[601]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[602]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[603]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[604]      0.75    0.00 0.02     0.71     0.74     0.75     0.77     0.80
## q[605]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[606]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[607]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[608]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[609]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[610]      0.75    0.00 0.02     0.71     0.74     0.75     0.77     0.80
## q[611]      0.77    0.00 0.02     0.74     0.76     0.77     0.79     0.81
## q[612]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[613]      0.83    0.00 0.01     0.81     0.83     0.83     0.84     0.86
## q[614]      0.75    0.00 0.02     0.71     0.74     0.75     0.77     0.80
## q[615]      0.75    0.00 0.02     0.71     0.74     0.75     0.77     0.80
## q[616]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[617]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[618]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[619]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[620]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[621]      0.58    0.00 0.03     0.52     0.56     0.58     0.59     0.63
## q[622]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[623]      0.58    0.00 0.03     0.52     0.56     0.58     0.59     0.63
## q[624]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[625]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[626]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[627]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[628]      0.58    0.00 0.03     0.52     0.56     0.58     0.59     0.63
## q[629]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[630]      0.58    0.00 0.03     0.52     0.56     0.58     0.59     0.63
## q[631]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[632]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[633]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[634]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[635]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[636]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[637]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[638]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[639]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[640]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[641]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[642]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[643]      0.58    0.00 0.03     0.52     0.56     0.58     0.59     0.63
## q[644]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[645]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[646]      0.58    0.00 0.03     0.52     0.56     0.58     0.59     0.63
## q[647]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[648]      0.58    0.00 0.03     0.52     0.56     0.58     0.59     0.63
## q[649]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[650]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[651]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[652]      0.58    0.00 0.03     0.52     0.56     0.58     0.59     0.63
## q[653]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[654]      0.58    0.00 0.03     0.52     0.56     0.58     0.59     0.63
## q[655]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[656]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[657]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[658]      0.58    0.00 0.03     0.52     0.56     0.58     0.59     0.63
## q[659]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[660]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[661]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[662]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[663]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[664]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[665]      0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.65
## q[666]      0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[667]      0.58    0.00 0.03     0.52     0.56     0.58     0.59     0.63
## q[668]      0.58    0.00 0.03     0.52     0.56     0.58     0.59     0.63
## q[669]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[670]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[671]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[672]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[673]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[674]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[675]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[676]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[677]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[678]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[679]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[680]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[681]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[682]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[683]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[684]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[685]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[686]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[687]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[688]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[689]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[690]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[691]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[692]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[693]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[694]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[695]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[696]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[697]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[698]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[699]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[700]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[701]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[702]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[703]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[704]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[705]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[706]      0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[707]      0.80    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[708]      0.70    0.00 0.02     0.65     0.69     0.70     0.72     0.75
## q[709]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[710]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[711]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[712]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[713]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[714]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[715]      0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[716]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[717]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[718]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[719]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[720]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[721]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[722]      0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[723]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[724]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[725]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[726]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[727]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[728]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[729]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[730]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[731]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[732]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[733]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[734]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[735]      0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[736]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[737]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[738]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[739]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[740]      0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[741]      0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[742]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[743]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[744]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[745]      0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[746]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[747]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[748]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[749]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[750]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[751]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[752]      0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[753]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[754]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[755]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[756]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[757]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[758]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[759]      0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[760]      0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.76
## q[761]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[762]      0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.82
## q[763]      0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[764]      0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[765]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[766]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[767]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[768]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[769]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[770]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[771]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[772]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[773]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[774]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[775]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[776]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[777]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[778]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[779]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[780]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[781]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[782]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[783]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[784]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[785]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[786]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[787]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[788]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[789]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[790]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[791]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[792]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[793]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[794]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[795]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[796]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[797]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[798]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[799]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[800]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[801]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[802]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[803]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[804]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[805]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[806]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[807]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[808]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[809]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[810]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[811]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[812]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[813]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[814]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[815]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[816]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[817]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[818]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[819]      0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[820]      0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[821]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[822]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[823]      0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[824]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[825]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[826]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[827]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[828]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[829]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[830]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[831]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[832]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[833]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[834]      0.71    0.00 0.02     0.66     0.69     0.71     0.73     0.75
## q[835]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[836]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[837]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[838]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[839]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[840]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[841]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[842]      0.71    0.00 0.02     0.66     0.69     0.71     0.73     0.75
## q[843]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[844]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[845]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[846]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[847]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[848]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[849]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[850]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[851]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[852]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[853]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[854]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[855]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[856]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[857]      0.71    0.00 0.02     0.66     0.69     0.71     0.73     0.75
## q[858]      0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.77
## q[859]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[860]      0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[861]      0.71    0.00 0.02     0.66     0.69     0.71     0.73     0.75
## q[862]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[863]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[864]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[865]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[866]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[867]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[868]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[869]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[870]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[871]      0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[872]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[873]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[874]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[875]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[876]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[877]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[878]      0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[879]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[880]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[881]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[882]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[883]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[884]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[885]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[886]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[887]      0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[888]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[889]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[890]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[891]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[892]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[893]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[894]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[895]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[896]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[897]      0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[898]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[899]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[900]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[901]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[902]      0.67    0.00 0.03     0.61     0.65     0.67     0.69     0.72
## q[903]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[904]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[905]      0.64    0.00 0.03     0.58     0.62     0.64     0.66     0.70
## q[906]      0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.78
## q[907]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[908]      0.83    0.00 0.02     0.78     0.81     0.83     0.85     0.87
## q[909]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[910]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[911]      0.83    0.00 0.02     0.78     0.81     0.83     0.85     0.87
## q[912]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[913]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[914]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[915]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[916]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[917]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[918]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[919]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[920]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[921]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[922]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[923]      0.83    0.00 0.02     0.78     0.81     0.83     0.85     0.87
## q[924]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[925]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[926]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[927]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[928]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[929]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[930]      0.83    0.00 0.02     0.78     0.81     0.83     0.85     0.87
## q[931]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[932]      0.83    0.00 0.02     0.78     0.81     0.83     0.85     0.87
## q[933]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[934]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[935]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[936]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[937]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[938]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[939]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[940]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[941]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[942]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[943]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[944]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[945]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[946]      0.83    0.00 0.02     0.78     0.81     0.83     0.85     0.87
## q[947]      0.83    0.00 0.02     0.78     0.81     0.83     0.85     0.87
## q[948]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[949]      0.84    0.00 0.02     0.80     0.83     0.85     0.86     0.88
## q[950]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[951]      0.89    0.00 0.02     0.86     0.88     0.89     0.90     0.92
## q[952]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[953]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[954]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[955]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[956]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[957]      0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[958]      0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[959]      0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[960]      0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[961]      0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[962]      0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[963]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[964]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[965]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[966]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[967]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[968]      0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[969]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[970]      0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[971]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[972]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[973]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[974]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[975]      0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[976]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[977]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[978]      0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[979]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[980]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[981]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[982]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[983]      0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[984]      0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[985]      0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[986]      0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[987]      0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[988]      0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[989]      0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[990]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[991]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[992]      0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[993]      0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[994]      0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[995]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[996]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[997]      0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[998]      0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[999]      0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1000]     0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[1001]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1002]     0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[1003]     0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[1004]     0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[1005]     0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[1006]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1007]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1008]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1009]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1010]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1011]     0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[1012]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1013]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1014]     0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[1015]     0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[1016]     0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[1017]     0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[1018]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1019]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1020]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1021]     0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[1022]     0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[1023]     0.69    0.00 0.02     0.64     0.67     0.69     0.70     0.73
## q[1024]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1025]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1026]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1027]     0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[1028]     0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.72
## q[1029]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1030]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1031]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1032]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1033]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1034]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1035]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1036]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1037]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1038]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1039]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1040]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1041]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1042]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1043]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1044]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1045]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1046]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1047]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1048]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1049]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1050]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1051]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1052]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1053]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1054]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1055]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1056]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1057]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1058]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1059]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1060]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1061]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1062]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1063]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1064]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1065]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1066]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1067]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1068]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1069]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1070]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1071]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1072]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1073]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1074]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1075]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1076]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1077]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1078]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1079]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1080]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1081]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1082]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1083]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1084]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1085]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1086]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1087]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1088]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1089]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1090]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1091]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1092]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.58
## q[1093]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1094]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1095]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1096]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1097]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1098]     0.62    0.00 0.02     0.57     0.60     0.62     0.64     0.66
## q[1099]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1100]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1101]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1102]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1103]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1104]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1105]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1106]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1107]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1108]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1109]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1110]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1111]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1112]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1113]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1114]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1115]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1116]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1117]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1118]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1119]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1120]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1121]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1122]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1123]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1124]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1125]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1126]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1127]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1128]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1129]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1130]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1131]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1132]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1133]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1134]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1135]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1136]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1137]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1138]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1139]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1140]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1141]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1142]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1143]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1144]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1145]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1146]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1147]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1148]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1149]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1150]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1151]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1152]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1153]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1154]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1155]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1156]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1157]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1158]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1159]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1160]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1161]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1162]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1163]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1164]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1165]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1166]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1167]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1168]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1169]     0.58    0.00 0.02     0.53     0.56     0.58     0.60     0.63
## q[1170]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1171]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1172]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1173]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1174]     0.67    0.00 0.02     0.63     0.66     0.67     0.68     0.70
## q[1175]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.61
## q[1176]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1177]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1178]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1179]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.60
## q[1180]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1181]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.60
## q[1182]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1183]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.60
## q[1184]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1185]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1186]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1187]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1188]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1189]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1190]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1191]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1192]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1193]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1194]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1195]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1196]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1197]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1198]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1199]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1200]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1201]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1202]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1203]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1204]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.60
## q[1205]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1206]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1207]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1208]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1209]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1210]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1211]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1212]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.60
## q[1213]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.60
## q[1214]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1215]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.60
## q[1216]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1217]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.60
## q[1218]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1219]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1220]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1221]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1222]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1223]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1224]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.60
## q[1225]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1226]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1227]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1228]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1229]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1230]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.60
## q[1231]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1232]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1233]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1234]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.60
## q[1235]     0.58    0.00 0.02     0.53     0.56     0.58     0.59     0.62
## q[1236]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1237]     0.66    0.00 0.02     0.63     0.65     0.66     0.68     0.70
## q[1238]     0.55    0.00 0.03     0.49     0.53     0.55     0.57     0.60
## q[1239]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1240]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1241]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1242]     0.63    0.00 0.03     0.58     0.61     0.63     0.65     0.69
## q[1243]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1244]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1245]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1246]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1247]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1248]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1249]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1250]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1251]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1252]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1253]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1254]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1255]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1256]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1257]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1258]     0.63    0.00 0.03     0.58     0.61     0.63     0.65     0.69
## q[1259]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1260]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1261]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1262]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1263]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1264]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1265]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1266]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1267]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1268]     0.63    0.00 0.03     0.58     0.61     0.63     0.65     0.69
## q[1269]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1270]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1271]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1272]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1273]     0.63    0.00 0.03     0.58     0.61     0.63     0.65     0.69
## q[1274]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1275]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1276]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1277]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1278]     0.63    0.00 0.03     0.58     0.61     0.63     0.65     0.69
## q[1279]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1280]     0.63    0.00 0.03     0.58     0.61     0.63     0.65     0.69
## q[1281]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1282]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1283]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1284]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1285]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1286]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1287]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1288]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1289]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1290]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1291]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1292]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1293]     0.63    0.00 0.03     0.58     0.61     0.63     0.65     0.69
## q[1294]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1295]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1296]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1297]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1298]     0.63    0.00 0.03     0.58     0.61     0.63     0.65     0.69
## q[1299]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1300]     0.66    0.00 0.02     0.61     0.64     0.66     0.68     0.70
## q[1301]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1302]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1303]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1304]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1305]     0.63    0.00 0.03     0.58     0.61     0.63     0.65     0.69
## q[1306]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.77
## q[1307]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1308]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1309]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1310]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1311]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1312]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1313]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1314]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1315]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1316]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1317]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1318]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1319]     0.57    0.00 0.03     0.52     0.55     0.57     0.59     0.63
## q[1320]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1321]     0.57    0.00 0.03     0.52     0.55     0.57     0.59     0.63
## q[1322]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1323]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1324]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1325]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1326]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1327]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1328]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1329]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1330]     0.57    0.00 0.03     0.52     0.55     0.57     0.59     0.63
## q[1331]     0.57    0.00 0.03     0.52     0.55     0.57     0.59     0.63
## q[1332]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1333]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1334]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1335]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1336]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1337]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1338]     0.57    0.00 0.03     0.52     0.55     0.57     0.59     0.63
## q[1339]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1340]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1341]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1342]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1343]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1344]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1345]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1346]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1347]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1348]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1349]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1350]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1351]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1352]     0.57    0.00 0.03     0.52     0.55     0.57     0.59     0.63
## q[1353]     0.60    0.00 0.02     0.56     0.59     0.60     0.62     0.64
## q[1354]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1355]     0.69    0.00 0.02     0.65     0.68     0.69     0.70     0.72
## q[1356]     0.57    0.00 0.03     0.52     0.55     0.57     0.59     0.63
## q[1357]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1358]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1359]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1360]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1361]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1362]     0.63    0.00 0.02     0.58     0.61     0.63     0.64     0.67
## q[1363]     0.60    0.00 0.03     0.55     0.58     0.60     0.62     0.65
## q[1364]     0.63    0.00 0.02     0.58     0.61     0.63     0.64     0.67
## q[1365]     0.63    0.00 0.02     0.58     0.61     0.63     0.64     0.67
## q[1366]     0.60    0.00 0.03     0.55     0.58     0.60     0.62     0.65
## q[1367]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1368]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1369]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1370]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1371]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1372]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1373]     0.63    0.00 0.02     0.58     0.61     0.63     0.64     0.67
## q[1374]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1375]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1376]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1377]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1378]     0.63    0.00 0.02     0.58     0.61     0.63     0.64     0.67
## q[1379]     0.60    0.00 0.03     0.55     0.58     0.60     0.62     0.65
## q[1380]     0.63    0.00 0.02     0.58     0.61     0.63     0.64     0.67
## q[1381]     0.63    0.00 0.02     0.58     0.61     0.63     0.64     0.67
## q[1382]     0.63    0.00 0.02     0.58     0.61     0.63     0.64     0.67
## q[1383]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1384]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1385]     0.63    0.00 0.02     0.58     0.61     0.63     0.64     0.67
## q[1386]     0.60    0.00 0.03     0.55     0.58     0.60     0.62     0.65
## q[1387]     0.60    0.00 0.03     0.55     0.58     0.60     0.62     0.65
## q[1388]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1389]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1390]     0.63    0.00 0.02     0.58     0.61     0.63     0.64     0.67
## q[1391]     0.60    0.00 0.03     0.55     0.58     0.60     0.62     0.65
## q[1392]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1393]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1394]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1395]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1396]     0.60    0.00 0.03     0.55     0.58     0.60     0.62     0.65
## q[1397]     0.60    0.00 0.03     0.55     0.58     0.60     0.62     0.65
## q[1398]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1399]     0.60    0.00 0.03     0.55     0.58     0.60     0.62     0.65
## q[1400]     0.63    0.00 0.02     0.58     0.61     0.63     0.64     0.67
## q[1401]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1402]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1403]     0.63    0.00 0.02     0.58     0.61     0.63     0.64     0.67
## q[1404]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1405]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1406]     0.71    0.00 0.02     0.68     0.70     0.71     0.72     0.74
## q[1407]     0.60    0.00 0.03     0.55     0.58     0.60     0.62     0.65
## q[1408]     0.72    0.00 0.02     0.67     0.70     0.72     0.73     0.76
## q[1409]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1410]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1411]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1412]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1413]     0.72    0.00 0.02     0.67     0.70     0.72     0.73     0.76
## q[1414]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1415]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1416]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1417]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1418]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1419]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1420]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1421]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1422]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1423]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1424]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1425]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1426]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1427]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1428]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1429]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1430]     0.72    0.00 0.02     0.67     0.70     0.72     0.73     0.76
## q[1431]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1432]     0.72    0.00 0.02     0.67     0.70     0.72     0.73     0.76
## q[1433]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1434]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1435]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1436]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1437]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1438]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1439]     0.72    0.00 0.02     0.67     0.70     0.72     0.73     0.76
## q[1440]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1441]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1442]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1443]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1444]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1445]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1446]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1447]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1448]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1449]     0.72    0.00 0.02     0.67     0.70     0.72     0.73     0.76
## q[1450]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1451]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1452]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1453]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1454]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1455]     0.72    0.00 0.02     0.67     0.70     0.72     0.73     0.76
## q[1456]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1457]     0.72    0.00 0.02     0.67     0.70     0.72     0.73     0.76
## q[1458]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1459]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1460]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1461]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1462]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1463]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1464]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1465]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1466]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1467]     0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[1468]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1469]     0.72    0.00 0.02     0.67     0.70     0.72     0.73     0.76
## q[1470]     0.72    0.00 0.02     0.67     0.70     0.72     0.73     0.76
## q[1471]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1472]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1473]     0.81    0.00 0.01     0.78     0.80     0.81     0.82     0.83
## q[1474]     0.86    0.00 0.01     0.84     0.85     0.86     0.87     0.89
## q[1475]     0.81    0.00 0.02     0.78     0.80     0.81     0.83     0.85
## q[1476]     0.79    0.00 0.02     0.75     0.78     0.79     0.81     0.84
## q[1477]     0.86    0.00 0.01     0.84     0.85     0.86     0.87     0.89
## q[1478]     0.86    0.00 0.01     0.84     0.85     0.86     0.87     0.89
## q[1479]     0.81    0.00 0.02     0.78     0.80     0.81     0.83     0.85
## q[1480]     0.86    0.00 0.01     0.84     0.85     0.86     0.87     0.89
## q[1481]     0.86    0.00 0.01     0.84     0.85     0.86     0.87     0.89
## q[1482]     0.86    0.00 0.01     0.84     0.85     0.86     0.87     0.89
## q[1483]     0.79    0.00 0.02     0.75     0.78     0.79     0.81     0.84
## q[1484]     0.79    0.00 0.02     0.75     0.78     0.79     0.81     0.84
## q[1485]     0.81    0.00 0.02     0.78     0.80     0.81     0.83     0.85
## q[1486]     0.79    0.00 0.02     0.75     0.78     0.79     0.81     0.84
## q[1487]     0.79    0.00 0.02     0.75     0.78     0.79     0.81     0.84
## q[1488]     0.81    0.00 0.02     0.78     0.80     0.81     0.83     0.85
## q[1489]     0.86    0.00 0.01     0.84     0.85     0.86     0.87     0.89
## q[1490]     0.81    0.00 0.02     0.78     0.80     0.81     0.83     0.85
## q[1491]     0.79    0.00 0.02     0.75     0.78     0.79     0.81     0.84
## q[1492]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1493]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1494]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1495]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1496]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1497]     0.71    0.00 0.02     0.66     0.69     0.71     0.72     0.75
## q[1498]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1499]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1500]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1501]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1502]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1503]     0.71    0.00 0.02     0.66     0.69     0.71     0.72     0.75
## q[1504]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1505]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1506]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1507]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1508]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1509]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1510]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1511]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1512]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1513]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1514]     0.71    0.00 0.02     0.66     0.69     0.71     0.72     0.75
## q[1515]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1516]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1517]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1518]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1519]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1520]     0.71    0.00 0.02     0.66     0.69     0.71     0.72     0.75
## q[1521]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1522]     0.71    0.00 0.02     0.66     0.69     0.71     0.72     0.75
## q[1523]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1524]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1525]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1526]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1527]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1528]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1529]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1530]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1531]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1532]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1533]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1534]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1535]     0.71    0.00 0.02     0.66     0.69     0.71     0.72     0.75
## q[1536]     0.73    0.00 0.02     0.69     0.72     0.73     0.74     0.77
## q[1537]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1538]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1539]     0.80    0.00 0.01     0.77     0.79     0.80     0.81     0.83
## q[1540]     0.71    0.00 0.02     0.66     0.69     0.71     0.72     0.75
## q[1541]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1542]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1543]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1544]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1545]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1546]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1547]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1548]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1549]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1550]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1551]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1552]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1553]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1554]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1555]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1556]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1557]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1558]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1559]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1560]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1561]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1562]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1563]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1564]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1565]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1566]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1567]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1568]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1569]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1570]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1571]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1572]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1573]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1574]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1575]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1576]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1577]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1578]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1579]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1580]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1581]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1582]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1583]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1584]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1585]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1586]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1587]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1588]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1589]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1590]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1591]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1592]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1593]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1594]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1595]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1596]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1597]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1598]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1599]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1600]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1601]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1602]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1603]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1604]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1605]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1606]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1607]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1608]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1609]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1610]     0.71    0.00 0.03     0.65     0.69     0.71     0.72     0.75
## q[1611]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1612]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1613]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.82
## q[1614]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1615]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[1616]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1617]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1618]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1619]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1620]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1621]     0.47    0.00 0.04     0.40     0.44     0.47     0.49     0.54
## q[1622]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1623]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1624]     0.50    0.00 0.03     0.43     0.48     0.50     0.52     0.56
## q[1625]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1626]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1627]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1628]     0.65    0.00 0.02     0.60     0.63     0.65     0.66     0.69
## q[1629]     0.65    0.00 0.02     0.60     0.63     0.65     0.66     0.69
## q[1630]     0.62    0.00 0.03     0.57     0.60     0.62     0.64     0.68
## q[1631]     0.73    0.00 0.02     0.70     0.72     0.73     0.74     0.76
## q[1632]     0.73    0.00 0.02     0.70     0.72     0.73     0.74     0.76
## q[1633]     0.62    0.00 0.03     0.57     0.60     0.62     0.64     0.68
## q[1634]     0.73    0.00 0.02     0.70     0.72     0.73     0.74     0.76
## q[1635]     0.73    0.00 0.02     0.70     0.72     0.73     0.74     0.76
## q[1636]     0.73    0.00 0.02     0.70     0.72     0.73     0.74     0.76
## q[1637]     0.73    0.00 0.02     0.70     0.72     0.73     0.74     0.76
## q[1638]     0.65    0.00 0.02     0.60     0.63     0.65     0.66     0.69
## q[1639]     0.73    0.00 0.02     0.70     0.72     0.73     0.74     0.76
## q[1640]     0.65    0.00 0.02     0.60     0.63     0.65     0.66     0.69
## q[1641]     0.62    0.00 0.03     0.57     0.60     0.62     0.64     0.68
## q[1642]     0.73    0.00 0.02     0.70     0.72     0.73     0.74     0.76
## q[1643]     0.73    0.00 0.02     0.70     0.72     0.73     0.74     0.76
## q[1644]     0.73    0.00 0.02     0.70     0.72     0.73     0.74     0.76
## q[1645]     0.65    0.00 0.02     0.60     0.63     0.65     0.66     0.69
## q[1646]     0.73    0.00 0.02     0.70     0.72     0.73     0.74     0.76
## q[1647]     0.62    0.00 0.03     0.57     0.60     0.62     0.64     0.68
## q[1648]     0.73    0.00 0.02     0.70     0.72     0.73     0.74     0.76
## q[1649]     0.65    0.00 0.02     0.60     0.63     0.65     0.66     0.69
## q[1650]     0.65    0.00 0.02     0.60     0.63     0.65     0.66     0.69
## q[1651]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1652]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1653]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1654]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1655]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1656]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1657]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1658]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1659]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1660]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1661]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1662]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1663]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1664]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1665]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1666]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1667]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1668]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1669]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1670]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1671]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1672]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1673]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1674]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1675]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1676]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1677]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1678]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1679]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1680]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1681]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1682]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1683]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1684]     0.62    0.00 0.02     0.57     0.60     0.62     0.63     0.66
## q[1685]     0.59    0.00 0.03     0.54     0.57     0.59     0.61     0.64
## q[1686]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1687]     0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[1688]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1689]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1690]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1691]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1692]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1693]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1694]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1695]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1696]     0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.78
## q[1697]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1698]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1699]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1700]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1701]     0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.78
## q[1702]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1703]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1704]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1705]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1706]     0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.78
## q[1707]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1708]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1709]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1710]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1711]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1712]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1713]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1714]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1715]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1716]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1717]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1718]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1719]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1720]     0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.78
## q[1721]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1722]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1723]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1724]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1725]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1726]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1727]     0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.78
## q[1728]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1729]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1730]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1731]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1732]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1733]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1734]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1735]     0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.78
## q[1736]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1737]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1738]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1739]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1740]     0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.78
## q[1741]     0.75    0.00 0.02     0.72     0.74     0.75     0.77     0.79
## q[1742]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1743]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1744]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1745]     0.73    0.00 0.02     0.69     0.72     0.73     0.75     0.78
## q[1746]     0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[1747]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1748]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1749]     0.74    0.00 0.02     0.70     0.73     0.74     0.76     0.79
## q[1750]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1751]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1752]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1753]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1754]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1755]     0.74    0.00 0.02     0.70     0.73     0.74     0.76     0.79
## q[1756]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1757]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1758]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1759]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1760]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1761]     0.74    0.00 0.02     0.70     0.73     0.74     0.76     0.79
## q[1762]     0.74    0.00 0.02     0.70     0.73     0.74     0.76     0.79
## q[1763]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1764]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1765]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1766]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1767]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1768]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1769]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1770]     0.74    0.00 0.02     0.70     0.73     0.74     0.76     0.79
## q[1771]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1772]     0.74    0.00 0.02     0.70     0.73     0.74     0.76     0.79
## q[1773]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1774]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1775]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1776]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1777]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1778]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1779]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1780]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1781]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1782]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1783]     0.74    0.00 0.02     0.70     0.73     0.74     0.76     0.79
## q[1784]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1785]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1786]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1787]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1788]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1789]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1790]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1791]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1792]     0.74    0.00 0.02     0.70     0.73     0.74     0.76     0.79
## q[1793]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1794]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1795]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1796]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1797]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1798]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1799]     0.76    0.00 0.02     0.73     0.75     0.76     0.78     0.80
## q[1800]     0.83    0.00 0.01     0.80     0.82     0.83     0.83     0.85
## q[1801]     0.74    0.00 0.02     0.70     0.73     0.74     0.76     0.79
## q[1802]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1803]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1804]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1805]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1806]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1807]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1808]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1809]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1810]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1811]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1812]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1813]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1814]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1815]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1816]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1817]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1818]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1819]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1820]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1821]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1822]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1823]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1824]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1825]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1826]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1827]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1828]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1829]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1830]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1831]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1832]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1833]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1834]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1835]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1836]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1837]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1838]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1839]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1840]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1841]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1842]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1843]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1844]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1845]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1846]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1847]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1848]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1849]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1850]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1851]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1852]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1853]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1854]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1855]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1856]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1857]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1858]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1859]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1860]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1861]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1862]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1863]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1864]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1865]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1866]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1867]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1868]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1869]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1870]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1871]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1872]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1873]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1874]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1875]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1876]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1877]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1878]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1879]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1880]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1881]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1882]     0.57    0.00 0.02     0.52     0.56     0.57     0.59     0.62
## q[1883]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1884]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1885]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1886]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1887]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1888]     0.66    0.00 0.02     0.63     0.65     0.66     0.67     0.70
## q[1889]     0.54    0.00 0.03     0.49     0.52     0.54     0.56     0.60
## q[1890]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1891]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1892]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1893]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1894]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1895]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1896]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1897]     0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[1898]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1899]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1900]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1901]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1902]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1903]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1904]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1905]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1906]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1907]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1908]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1909]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1910]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1911]     0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[1912]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1913]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1914]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1915]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1916]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1917]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1918]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1919]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1920]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1921]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1922]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1923]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1924]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1925]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1926]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1927]     0.72    0.00 0.02     0.69     0.71     0.72     0.74     0.76
## q[1928]     0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[1929]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1930]     0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[1931]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1932]     0.70    0.00 0.02     0.65     0.68     0.70     0.72     0.75
## q[1933]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1934]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1935]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1936]     0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.82
## q[1937]     0.68    0.00 0.02     0.63     0.67     0.68     0.70     0.73
## q[1938]     0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.71
## q[1939]     0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.71
## q[1940]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1941]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1942]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1943]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1944]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1945]     0.68    0.00 0.02     0.63     0.67     0.68     0.70     0.73
## q[1946]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1947]     0.68    0.00 0.02     0.63     0.67     0.68     0.70     0.73
## q[1948]     0.68    0.00 0.02     0.63     0.67     0.68     0.70     0.73
## q[1949]     0.68    0.00 0.02     0.63     0.67     0.68     0.70     0.73
## q[1950]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1951]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1952]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1953]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1954]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1955]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1956]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1957]     0.66    0.00 0.03     0.60     0.64     0.66     0.68     0.71
## q[1958]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[1959]     0.68    0.00 0.02     0.63     0.66     0.68     0.70     0.72
## q[1960]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1961]     0.65    0.00 0.03     0.60     0.63     0.65     0.67     0.71
## q[1962]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1963]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1964]     0.68    0.00 0.02     0.63     0.66     0.68     0.70     0.72
## q[1965]     0.65    0.00 0.03     0.60     0.63     0.65     0.67     0.71
## q[1966]     0.68    0.00 0.02     0.63     0.66     0.68     0.70     0.72
## q[1967]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1968]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1969]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1970]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1971]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1972]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1973]     0.68    0.00 0.02     0.63     0.66     0.68     0.70     0.72
## q[1974]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1975]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1976]     0.68    0.00 0.02     0.63     0.66     0.68     0.70     0.72
## q[1977]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1978]     0.68    0.00 0.02     0.63     0.66     0.68     0.70     0.72
## q[1979]     0.65    0.00 0.03     0.60     0.63     0.65     0.67     0.71
## q[1980]     0.68    0.00 0.02     0.63     0.66     0.68     0.70     0.72
## q[1981]     0.68    0.00 0.02     0.63     0.66     0.68     0.70     0.72
## q[1982]     0.68    0.00 0.02     0.63     0.66     0.68     0.70     0.72
## q[1983]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1984]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1985]     0.65    0.00 0.03     0.60     0.63     0.65     0.67     0.71
## q[1986]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1987]     0.65    0.00 0.03     0.60     0.63     0.65     0.67     0.71
## q[1988]     0.68    0.00 0.02     0.63     0.66     0.68     0.70     0.72
## q[1989]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1990]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1991]     0.68    0.00 0.02     0.63     0.66     0.68     0.70     0.72
## q[1992]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1993]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1994]     0.65    0.00 0.03     0.60     0.63     0.65     0.67     0.71
## q[1995]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1996]     0.68    0.00 0.02     0.63     0.66     0.68     0.70     0.72
## q[1997]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1998]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[1999]     0.76    0.00 0.02     0.72     0.74     0.76     0.77     0.79
## q[2000]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2001]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2002]     0.74    0.00 0.02     0.69     0.72     0.74     0.75     0.78
## q[2003]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2004]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2005]     0.74    0.00 0.02     0.69     0.72     0.74     0.75     0.78
## q[2006]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2007]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2008]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2009]     0.74    0.00 0.02     0.69     0.72     0.74     0.75     0.78
## q[2010]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2011]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2012]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2013]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2014]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2015]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2016]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2017]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2018]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2019]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2020]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2021]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2022]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2023]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2024]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2025]     0.74    0.00 0.02     0.69     0.72     0.74     0.75     0.78
## q[2026]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2027]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2028]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2029]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2030]     0.74    0.00 0.02     0.69     0.72     0.74     0.75     0.78
## q[2031]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2032]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2033]     0.74    0.00 0.02     0.69     0.72     0.74     0.75     0.78
## q[2034]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2035]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2036]     0.74    0.00 0.02     0.69     0.72     0.74     0.75     0.78
## q[2037]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2038]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2039]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2040]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2041]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2042]     0.74    0.00 0.02     0.69     0.72     0.74     0.75     0.78
## q[2043]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2044]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2045]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2046]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2047]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2048]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2049]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2050]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2051]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2052]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2053]     0.74    0.00 0.02     0.69     0.72     0.74     0.75     0.78
## q[2054]     0.76    0.00 0.02     0.72     0.75     0.76     0.77     0.79
## q[2055]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2056]     0.82    0.00 0.01     0.80     0.81     0.82     0.83     0.85
## q[2057]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2058]     0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[2059]     0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[2060]     0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[2061]     0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[2062]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2063]     0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[2064]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2065]     0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[2066]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2067]     0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[2068]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2069]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2070]     0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[2071]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2072]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2073]     0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[2074]     0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[2075]     0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[2076]     0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[2077]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2078]     0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[2079]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2080]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2081]     0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[2082]     0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[2083]     0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[2084]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2085]     0.77    0.00 0.02     0.73     0.76     0.77     0.78     0.80
## q[2086]     0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[2087]     0.83    0.00 0.01     0.80     0.82     0.83     0.84     0.85
## q[2088]     0.75    0.00 0.02     0.70     0.73     0.75     0.76     0.79
## q[2089]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2090]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2091]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2092]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2093]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2094]     0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.77
## q[2095]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2096]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2097]     0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.77
## q[2098]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2099]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2100]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2101]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2102]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2103]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2104]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2105]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2106]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2107]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2108]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2109]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2110]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2111]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2112]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2113]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2114]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2115]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2116]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2117]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2118]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2119]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2120]     0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.77
## q[2121]     0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.77
## q[2122]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2123]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2124]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2125]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2126]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2127]     0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.77
## q[2128]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2129]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2130]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2131]     0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.77
## q[2132]     0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.77
## q[2133]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2134]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2135]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2136]     0.75    0.00 0.02     0.71     0.74     0.75     0.76     0.78
## q[2137]     0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.77
## q[2138]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2139]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2140]     0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[2141]     0.72    0.00 0.02     0.68     0.71     0.72     0.74     0.77
## q[2142]     0.79    0.00 0.02     0.76     0.78     0.79     0.80     0.82
## q[2143]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2144]     0.77    0.00 0.02     0.73     0.76     0.77     0.79     0.81
## q[2145]     0.77    0.00 0.02     0.73     0.76     0.77     0.79     0.81
## q[2146]     0.79    0.00 0.02     0.76     0.78     0.79     0.80     0.82
## q[2147]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2148]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2149]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2150]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2151]     0.79    0.00 0.02     0.76     0.78     0.79     0.80     0.82
## q[2152]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2153]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2154]     0.79    0.00 0.02     0.76     0.78     0.79     0.80     0.82
## q[2155]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2156]     0.79    0.00 0.02     0.76     0.78     0.79     0.80     0.82
## q[2157]     0.77    0.00 0.02     0.73     0.76     0.77     0.79     0.81
## q[2158]     0.79    0.00 0.02     0.76     0.78     0.79     0.80     0.82
## q[2159]     0.79    0.00 0.02     0.76     0.78     0.79     0.80     0.82
## q[2160]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2161]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2162]     0.77    0.00 0.02     0.73     0.76     0.77     0.79     0.81
## q[2163]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2164]     0.77    0.00 0.02     0.73     0.76     0.77     0.79     0.81
## q[2165]     0.79    0.00 0.02     0.76     0.78     0.79     0.80     0.82
## q[2166]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2167]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2168]     0.79    0.00 0.02     0.76     0.78     0.79     0.80     0.82
## q[2169]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2170]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2171]     0.79    0.00 0.02     0.76     0.78     0.79     0.80     0.82
## q[2172]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.87
## q[2173]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2174]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2175]     0.84    0.00 0.02     0.80     0.83     0.84     0.86     0.88
## q[2176]     0.82    0.00 0.02     0.78     0.81     0.83     0.84     0.87
## q[2177]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2178]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2179]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2180]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2181]     0.82    0.00 0.02     0.78     0.81     0.83     0.84     0.87
## q[2182]     0.84    0.00 0.02     0.80     0.83     0.84     0.86     0.88
## q[2183]     0.84    0.00 0.02     0.80     0.83     0.84     0.86     0.88
## q[2184]     0.84    0.00 0.02     0.80     0.83     0.84     0.86     0.88
## q[2185]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2186]     0.84    0.00 0.02     0.80     0.83     0.84     0.86     0.88
## q[2187]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2188]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2189]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2190]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2191]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2192]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2193]     0.82    0.00 0.02     0.78     0.81     0.83     0.84     0.87
## q[2194]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2195]     0.89    0.00 0.01     0.85     0.88     0.89     0.90     0.91
## q[2196]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2197]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2198]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2199]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2200]     0.71    0.00 0.02     0.67     0.70     0.72     0.73     0.75
## q[2201]     0.69    0.00 0.03     0.64     0.67     0.69     0.71     0.74
## q[2202]     0.71    0.00 0.02     0.67     0.70     0.72     0.73     0.75
## q[2203]     0.69    0.00 0.03     0.64     0.67     0.69     0.71     0.74
## q[2204]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2205]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2206]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2207]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2208]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2209]     0.71    0.00 0.02     0.67     0.70     0.72     0.73     0.75
## q[2210]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2211]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2212]     0.71    0.00 0.02     0.67     0.70     0.72     0.73     0.75
## q[2213]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2214]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2215]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2216]     0.69    0.00 0.03     0.64     0.67     0.69     0.71     0.74
## q[2217]     0.71    0.00 0.02     0.67     0.70     0.72     0.73     0.75
## q[2218]     0.71    0.00 0.02     0.67     0.70     0.72     0.73     0.75
## q[2219]     0.71    0.00 0.02     0.67     0.70     0.72     0.73     0.75
## q[2220]     0.71    0.00 0.02     0.67     0.70     0.72     0.73     0.75
## q[2221]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2222]     0.69    0.00 0.03     0.64     0.67     0.69     0.71     0.74
## q[2223]     0.69    0.00 0.03     0.64     0.67     0.69     0.71     0.74
## q[2224]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2225]     0.69    0.00 0.03     0.64     0.67     0.69     0.71     0.74
## q[2226]     0.69    0.00 0.03     0.64     0.67     0.69     0.71     0.74
## q[2227]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2228]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2229]     0.71    0.00 0.02     0.67     0.70     0.72     0.73     0.75
## q[2230]     0.71    0.00 0.02     0.67     0.70     0.72     0.73     0.75
## q[2231]     0.69    0.00 0.03     0.64     0.67     0.69     0.71     0.74
## q[2232]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2233]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2234]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2235]     0.69    0.00 0.03     0.64     0.67     0.69     0.71     0.74
## q[2236]     0.69    0.00 0.03     0.64     0.67     0.69     0.71     0.74
## q[2237]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2238]     0.69    0.00 0.03     0.64     0.67     0.69     0.71     0.74
## q[2239]     0.71    0.00 0.02     0.67     0.70     0.72     0.73     0.75
## q[2240]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2241]     0.71    0.00 0.02     0.67     0.70     0.72     0.73     0.75
## q[2242]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2243]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2244]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2245]     0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[2246]     0.69    0.00 0.03     0.64     0.67     0.69     0.71     0.74
## q[2247]     0.57    0.00 0.04     0.49     0.54     0.57     0.60     0.65
## q[2248]     0.60    0.00 0.04     0.52     0.57     0.60     0.62     0.67
## q[2249]     0.60    0.00 0.04     0.52     0.57     0.60     0.62     0.67
## q[2250]     0.60    0.00 0.04     0.52     0.57     0.60     0.62     0.67
## q[2251]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[2252]     0.60    0.00 0.04     0.52     0.57     0.60     0.62     0.67
## q[2253]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[2254]     0.60    0.00 0.04     0.52     0.57     0.60     0.62     0.67
## q[2255]     0.60    0.00 0.04     0.52     0.57     0.60     0.62     0.67
## q[2256]     0.60    0.00 0.04     0.52     0.57     0.60     0.62     0.67
## q[2257]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[2258]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[2259]     0.60    0.00 0.04     0.52     0.57     0.60     0.62     0.67
## q[2260]     0.60    0.00 0.04     0.52     0.57     0.60     0.62     0.67
## q[2261]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[2262]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[2263]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[2264]     0.60    0.00 0.04     0.52     0.57     0.60     0.62     0.67
## q[2265]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[2266]     0.57    0.00 0.04     0.49     0.54     0.57     0.60     0.65
## q[2267]     0.60    0.00 0.04     0.52     0.57     0.60     0.62     0.67
## q[2268]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.74
## q[2269]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2270]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2271]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2272]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2273]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2274]     0.78    0.00 0.02     0.73     0.76     0.78     0.79     0.82
## q[2275]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2276]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2277]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2278]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2279]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2280]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2281]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2282]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2283]     0.78    0.00 0.02     0.73     0.76     0.78     0.79     0.82
## q[2284]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2285]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2286]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2287]     0.78    0.00 0.02     0.73     0.76     0.78     0.79     0.82
## q[2288]     0.78    0.00 0.02     0.73     0.76     0.78     0.79     0.82
## q[2289]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2290]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2291]     0.78    0.00 0.02     0.73     0.76     0.78     0.79     0.82
## q[2292]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2293]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2294]     0.78    0.00 0.02     0.73     0.76     0.78     0.79     0.82
## q[2295]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2296]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2297]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2298]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2299]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2300]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2301]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2302]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2303]     0.80    0.00 0.02     0.76     0.78     0.80     0.81     0.83
## q[2304]     0.78    0.00 0.02     0.73     0.76     0.78     0.79     0.82
## q[2305]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2306]     0.85    0.00 0.01     0.82     0.84     0.85     0.86     0.88
## q[2307]     0.70    0.00 0.02     0.66     0.69     0.70     0.72     0.74
## q[2308]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.73
## q[2309]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.81
## q[2310]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.81
## q[2311]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.73
## q[2312]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.81
## q[2313]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.81
## q[2314]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.81
## q[2315]     0.70    0.00 0.02     0.66     0.69     0.70     0.72     0.74
## q[2316]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.73
## q[2317]     0.70    0.00 0.02     0.66     0.69     0.70     0.72     0.74
## q[2318]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.81
## q[2319]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.81
## q[2320]     0.70    0.00 0.02     0.66     0.69     0.70     0.72     0.74
## q[2321]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.81
## q[2322]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.73
## q[2323]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.81
## q[2324]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.81
## q[2325]     0.70    0.00 0.02     0.66     0.69     0.70     0.72     0.74
## q[2326]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.81
## q[2327]     0.68    0.00 0.03     0.62     0.66     0.68     0.70     0.73
## q[2328]     0.70    0.00 0.02     0.66     0.69     0.70     0.72     0.74
## q[2329]     0.78    0.00 0.02     0.74     0.76     0.78     0.79     0.81
## q[2330]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2331]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2332]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2333]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2334]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2335]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2336]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2337]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[2338]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2339]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2340]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[2341]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2342]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2343]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2344]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2345]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2346]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[2347]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2348]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2349]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2350]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2351]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2352]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2353]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2354]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2355]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2356]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2357]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2358]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2359]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2360]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2361]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2362]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2363]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2364]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[2365]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2366]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2367]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2368]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2369]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2370]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[2371]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[2372]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2373]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2374]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2375]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2376]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2377]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[2378]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2379]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2380]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2381]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2382]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2383]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2384]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[2385]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2386]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2387]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2388]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2389]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2390]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2391]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[2392]     0.56    0.00 0.03     0.51     0.54     0.56     0.58     0.61
## q[2393]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2394]     0.65    0.00 0.02     0.61     0.63     0.65     0.66     0.69
## q[2395]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## q[2396]     0.53    0.00 0.03     0.47     0.51     0.53     0.55     0.59
## lp__    -1379.64    0.04 1.55 -1383.58 -1380.50 -1379.29 -1378.49 -1377.56
##         n_eff Rhat
## b[1]     2165    1
## b[2]     2912    1
## b[3]     2184    1
## b[4]     3323    1
## b[5]     2891    1
## OR1      2931    1
## OR2      2256    1
## OR3      3316    1
## OR4      2857    1
## q[1]     2525    1
## q[2]     2329    1
## q[3]     2636    1
## q[4]     2329    1
## q[5]     2525    1
## q[6]     2525    1
## q[7]     2636    1
## q[8]     2525    1
## q[9]     2329    1
## q[10]    2329    1
## q[11]    2329    1
## q[12]    2636    1
## q[13]    2329    1
## q[14]    2329    1
## q[15]    2329    1
## q[16]    2329    1
## q[17]    2329    1
## q[18]    2525    1
## q[19]    2329    1
## q[20]    2329    1
## q[21]    2525    1
## q[22]    2525    1
## q[23]    2636    1
## q[24]    2636    1
## q[25]    2329    1
## q[26]    2329    1
## q[27]    2525    1
## q[28]    2329    1
## q[29]    2525    1
## q[30]    2329    1
## q[31]    2525    1
## q[32]    2329    1
## q[33]    2525    1
## q[34]    2329    1
## q[35]    2636    1
## q[36]    2329    1
## q[37]    2329    1
## q[38]    2329    1
## q[39]    2525    1
## q[40]    2329    1
## q[41]    2329    1
## q[42]    2525    1
## q[43]    2525    1
## q[44]    2894    1
## q[45]    2894    1
## q[46]    2894    1
## q[47]    3001    1
## q[48]    2894    1
## q[49]    3490    1
## q[50]    3490    1
## q[51]    3490    1
## q[52]    3490    1
## q[53]    2894    1
## q[54]    2894    1
## q[55]    2894    1
## q[56]    2894    1
## q[57]    2894    1
## q[58]    3001    1
## q[59]    2894    1
## q[60]    3001    1
## q[61]    2894    1
## q[62]    2894    1
## q[63]    2894    1
## q[64]    2894    1
## q[65]    3490    1
## q[66]    2894    1
## q[67]    3490    1
## q[68]    3001    1
## q[69]    3490    1
## q[70]    3001    1
## q[71]    3001    1
## q[72]    2894    1
## q[73]    3490    1
## q[74]    2894    1
## q[75]    3490    1
## q[76]    3001    1
## q[77]    2894    1
## q[78]    2894    1
## q[79]    3001    1
## q[80]    3490    1
## q[81]    3490    1
## q[82]    3001    1
## q[83]    3490    1
## q[84]    2894    1
## q[85]    2894    1
## q[86]    2894    1
## q[87]    2894    1
## q[88]    3490    1
## q[89]    2894    1
## q[90]    2894    1
## q[91]    3490    1
## q[92]    2894    1
## q[93]    2894    1
## q[94]    3490    1
## q[95]    3490    1
## q[96]    3490    1
## q[97]    2894    1
## q[98]    2894    1
## q[99]    3001    1
## q[100]   3050    1
## q[101]   3050    1
## q[102]   3327    1
## q[103]   3946    1
## q[104]   3946    1
## q[105]   3050    1
## q[106]   3050    1
## q[107]   3050    1
## q[108]   3327    1
## q[109]   3050    1
## q[110]   3050    1
## q[111]   3050    1
## q[112]   3946    1
## q[113]   3946    1
## q[114]   3327    1
## q[115]   3946    1
## q[116]   3050    1
## q[117]   3327    1
## q[118]   3050    1
## q[119]   3327    1
## q[120]   3946    1
## q[121]   3946    1
## q[122]   3050    1
## q[123]   3050    1
## q[124]   3050    1
## q[125]   3946    1
## q[126]   3050    1
## q[127]   3946    1
## q[128]   3946    1
## q[129]   3050    1
## q[130]   3050    1
## q[131]   3327    1
## q[132]   2890    1
## q[133]   2890    1
## q[134]   2890    1
## q[135]   3152    1
## q[136]   3152    1
## q[137]   2945    1
## q[138]   2890    1
## q[139]   2890    1
## q[140]   2945    1
## q[141]   2890    1
## q[142]   2890    1
## q[143]   2890    1
## q[144]   2890    1
## q[145]   2890    1
## q[146]   3152    1
## q[147]   2890    1
## q[148]   2890    1
## q[149]   2945    1
## q[150]   3152    1
## q[151]   3152    1
## q[152]   3152    1
## q[153]   2945    1
## q[154]   3152    1
## q[155]   2945    1
## q[156]   2890    1
## q[157]   2890    1
## q[158]   2945    1
## q[159]   2890    1
## q[160]   3152    1
## q[161]   2890    1
## q[162]   2945    1
## q[163]   3152    1
## q[164]   2890    1
## q[165]   2890    1
## q[166]   3152    1
## q[167]   2890    1
## q[168]   2890    1
## q[169]   2945    1
## q[170]   2890    1
## q[171]   2945    1
## q[172]   3152    1
## q[173]   2890    1
## q[174]   2890    1
## q[175]   2890    1
## q[176]   2890    1
## q[177]   2823    1
## q[178]   3152    1
## q[179]   3152    1
## q[180]   2823    1
## q[181]   3152    1
## q[182]   2650    1
## q[183]   2650    1
## q[184]   3152    1
## q[185]   2650    1
## q[186]   2650    1
## q[187]   3152    1
## q[188]   3152    1
## q[189]   3152    1
## q[190]   2650    1
## q[191]   3152    1
## q[192]   2650    1
## q[193]   3152    1
## q[194]   3152    1
## q[195]   2650    1
## q[196]   2650    1
## q[197]   3152    1
## q[198]   2650    1
## q[199]   2650    1
## q[200]   2650    1
## q[201]   2650    1
## q[202]   2650    1
## q[203]   3152    1
## q[204]   2650    1
## q[205]   2823    1
## q[206]   2823    1
## q[207]   2650    1
## q[208]   3152    1
## q[209]   2650    1
## q[210]   2998    1
## q[211]   2998    1
## q[212]   2998    1
## q[213]   3292    1
## q[214]   2998    1
## q[215]   4018    1
## q[216]   4018    1
## q[217]   3292    1
## q[218]   4018    1
## q[219]   4018    1
## q[220]   3292    1
## q[221]   2998    1
## q[222]   2998    1
## q[223]   2998    1
## q[224]   3292    1
## q[225]   2998    1
## q[226]   2998    1
## q[227]   2998    1
## q[228]   2998    1
## q[229]   2998    1
## q[230]   4018    1
## q[231]   2998    1
## q[232]   2998    1
## q[233]   2998    1
## q[234]   4018    1
## q[235]   2998    1
## q[236]   3292    1
## q[237]   4018    1
## q[238]   2998    1
## q[239]   4018    1
## q[240]   4018    1
## q[241]   2998    1
## q[242]   2998    1
## q[243]   4018    1
## q[244]   3292    1
## q[245]   4018    1
## q[246]   3292    1
## q[247]   2998    1
## q[248]   2998    1
## q[249]   4018    1
## q[250]   3292    1
## q[251]   2998    1
## q[252]   2998    1
## q[253]   2998    1
## q[254]   2998    1
## q[255]   2998    1
## q[256]   2998    1
## q[257]   3292    1
## q[258]   3292    1
## q[259]   4018    1
## q[260]   4018    1
## q[261]   2998    1
## q[262]   2998    1
## q[263]   2998    1
## q[264]   4018    1
## q[265]   4018    1
## q[266]   2998    1
## q[267]   4018    1
## q[268]   2998    1
## q[269]   3292    1
## q[270]   3292    1
## q[271]   2933    1
## q[272]   3465    1
## q[273]   3465    1
## q[274]   3257    1
## q[275]   2933    1
## q[276]   2933    1
## q[277]   3257    1
## q[278]   2933    1
## q[279]   3465    1
## q[280]   2933    1
## q[281]   2933    1
## q[282]   3465    1
## q[283]   2933    1
## q[284]   3465    1
## q[285]   2933    1
## q[286]   2933    1
## q[287]   3465    1
## q[288]   3257    1
## q[289]   3465    1
## q[290]   2933    1
## q[291]   3465    1
## q[292]   3465    1
## q[293]   3257    1
## q[294]   3465    1
## q[295]   3257    1
## q[296]   2933    1
## q[297]   2933    1
## q[298]   3257    1
## q[299]   2933    1
## q[300]   3465    1
## q[301]   2933    1
## q[302]   3465    1
## q[303]   3257    1
## q[304]   3465    1
## q[305]   2933    1
## q[306]   2933    1
## q[307]   2933    1
## q[308]   2933    1
## q[309]   2933    1
## q[310]   3465    1
## q[311]   2933    1
## q[312]   3465    1
## q[313]   2933    1
## q[314]   3257    1
## q[315]   3465    1
## q[316]   3257    1
## q[317]   2933    1
## q[318]   2933    1
## q[319]   2933    1
## q[320]   3447    1
## q[321]   2850    1
## q[322]   2850    1
## q[323]   2976    1
## q[324]   2850    1
## q[325]   2850    1
## q[326]   3447    1
## q[327]   3447    1
## q[328]   3447    1
## q[329]   2976    1
## q[330]   3447    1
## q[331]   2976    1
## q[332]   2850    1
## q[333]   2850    1
## q[334]   2850    1
## q[335]   2850    1
## q[336]   2976    1
## q[337]   2850    1
## q[338]   2850    1
## q[339]   2850    1
## q[340]   2850    1
## q[341]   2976    1
## q[342]   2850    1
## q[343]   2850    1
## q[344]   2850    1
## q[345]   2850    1
## q[346]   3447    1
## q[347]   2850    1
## q[348]   2850    1
## q[349]   2850    1
## q[350]   2850    1
## q[351]   3447    1
## q[352]   2850    1
## q[353]   3447    1
## q[354]   2976    1
## q[355]   3447    1
## q[356]   3447    1
## q[357]   3447    1
## q[358]   3447    1
## q[359]   2976    1
## q[360]   2850    1
## q[361]   3447    1
## q[362]   2850    1
## q[363]   2976    1
## q[364]   2850    1
## q[365]   2850    1
## q[366]   2976    1
## q[367]   3447    1
## q[368]   2850    1
## q[369]   2850    1
## q[370]   3447    1
## q[371]   2850    1
## q[372]   2850    1
## q[373]   2976    1
## q[374]   3447    1
## q[375]   2850    1
## q[376]   2850    1
## q[377]   2850    1
## q[378]   3447    1
## q[379]   2850    1
## q[380]   2850    1
## q[381]   2850    1
## q[382]   2976    1
## q[383]   2850    1
## q[384]   2976    1
## q[385]   3447    1
## q[386]   2850    1
## q[387]   3447    1
## q[388]   3447    1
## q[389]   2850    1
## q[390]   3447    1
## q[391]   2850    1
## q[392]   2850    1
## q[393]   2850    1
## q[394]   2976    1
## q[395]   2850    1
## q[396]   3767    1
## q[397]   2879    1
## q[398]   2879    1
## q[399]   3204    1
## q[400]   2879    1
## q[401]   2879    1
## q[402]   2879    1
## q[403]   3767    1
## q[404]   3767    1
## q[405]   3767    1
## q[406]   3767    1
## q[407]   3204    1
## q[408]   3767    1
## q[409]   3204    1
## q[410]   2879    1
## q[411]   2879    1
## q[412]   2879    1
## q[413]   2879    1
## q[414]   2879    1
## q[415]   2879    1
## q[416]   3767    1
## q[417]   3204    1
## q[418]   2879    1
## q[419]   2879    1
## q[420]   2879    1
## q[421]   2879    1
## q[422]   2879    1
## q[423]   3767    1
## q[424]   2879    1
## q[425]   2879    1
## q[426]   3767    1
## q[427]   3767    1
## q[428]   2879    1
## q[429]   2879    1
## q[430]   3767    1
## q[431]   3767    1
## q[432]   3767    1
## q[433]   3767    1
## q[434]   2879    1
## q[435]   3204    1
## q[436]   3767    1
## q[437]   2879    1
## q[438]   3767    1
## q[439]   2879    1
## q[440]   3767    1
## q[441]   2879    1
## q[442]   3767    1
## q[443]   3767    1
## q[444]   2879    1
## q[445]   2879    1
## q[446]   2879    1
## q[447]   3767    1
## q[448]   2879    1
## q[449]   2879    1
## q[450]   2879    1
## q[451]   2879    1
## q[452]   2879    1
## q[453]   2879    1
## q[454]   2879    1
## q[455]   2879    1
## q[456]   2879    1
## q[457]   3767    1
## q[458]   2879    1
## q[459]   3204    1
## q[460]   2879    1
## q[461]   3204    1
## q[462]   3767    1
## q[463]   2879    1
## q[464]   2879    1
## q[465]   3204    1
## q[466]   3767    1
## q[467]   2879    1
## q[468]   3767    1
## q[469]   2879    1
## q[470]   2879    1
## q[471]   2879    1
## q[472]   3204    1
## q[473]   2879    1
## q[474]   3790    1
## q[475]   2886    1
## q[476]   2886    1
## q[477]   2886    1
## q[478]   3790    1
## q[479]   3790    1
## q[480]   3209    1
## q[481]   3209    1
## q[482]   3209    1
## q[483]   2886    1
## q[484]   2886    1
## q[485]   2886    1
## q[486]   2886    1
## q[487]   3209    1
## q[488]   2886    1
## q[489]   2886    1
## q[490]   2886    1
## q[491]   3790    1
## q[492]   2886    1
## q[493]   2886    1
## q[494]   2886    1
## q[495]   2886    1
## q[496]   3790    1
## q[497]   2886    1
## q[498]   3790    1
## q[499]   2886    1
## q[500]   2886    1
## q[501]   2886    1
## q[502]   3209    1
## q[503]   3790    1
## q[504]   3790    1
## q[505]   3790    1
## q[506]   3790    1
## q[507]   2886    1
## q[508]   2886    1
## q[509]   3209    1
## q[510]   3209    1
## q[511]   2886    1
## q[512]   3209    1
## q[513]   3209    1
## q[514]   2886    1
## q[515]   2886    1
## q[516]   2886    1
## q[517]   2886    1
## q[518]   3790    1
## q[519]   3790    1
## q[520]   3209    1
## q[521]   2886    1
## q[522]   2886    1
## q[523]   2886    1
## q[524]   2886    1
## q[525]   3209    1
## q[526]   3209    1
## q[527]   3790    1
## q[528]   3790    1
## q[529]   2886    1
## q[530]   2886    1
## q[531]   3790    1
## q[532]   3790    1
## q[533]   2886    1
## q[534]   2886    1
## q[535]   2886    1
## q[536]   3209    1
## q[537]   3209    1
## q[538]   2987    1
## q[539]   2987    1
## q[540]   2987    1
## q[541]   3577    1
## q[542]   3577    1
## q[543]   2987    1
## q[544]   2987    1
## q[545]   3049    1
## q[546]   2987    1
## q[547]   2987    1
## q[548]   2987    1
## q[549]   2987    1
## q[550]   2987    1
## q[551]   3577    1
## q[552]   3049    1
## q[553]   3577    1
## q[554]   3577    1
## q[555]   3049    1
## q[556]   3049    1
## q[557]   2987    1
## q[558]   2987    1
## q[559]   3049    1
## q[560]   3577    1
## q[561]   3049    1
## q[562]   3577    1
## q[563]   2987    1
## q[564]   3577    1
## q[565]   2987    1
## q[566]   3049    1
## q[567]   2987    1
## q[568]   3577    1
## q[569]   2987    1
## q[570]   2987    1
## q[571]   2987    1
## q[572]   2949    1
## q[573]   2949    1
## q[574]   3955    1
## q[575]   3955    1
## q[576]   3258    1
## q[577]   3955    1
## q[578]   2949    1
## q[579]   2949    1
## q[580]   3955    1
## q[581]   3258    1
## q[582]   2949    1
## q[583]   2949    1
## q[584]   3955    1
## q[585]   2949    1
## q[586]   3955    1
## q[587]   2949    1
## q[588]   3955    1
## q[589]   2949    1
## q[590]   2949    1
## q[591]   3955    1
## q[592]   2949    1
## q[593]   2949    1
## q[594]   3258    1
## q[595]   3258    1
## q[596]   3955    1
## q[597]   3955    1
## q[598]   2949    1
## q[599]   3258    1
## q[600]   2949    1
## q[601]   2949    1
## q[602]   2949    1
## q[603]   3955    1
## q[604]   3258    1
## q[605]   3955    1
## q[606]   3955    1
## q[607]   2949    1
## q[608]   2949    1
## q[609]   3955    1
## q[610]   3258    1
## q[611]   3955    1
## q[612]   2949    1
## q[613]   2949    1
## q[614]   3258    1
## q[615]   3258    1
## q[616]   3844    1
## q[617]   3416    1
## q[618]   3416    1
## q[619]   3844    1
## q[620]   3844    1
## q[621]   3199    1
## q[622]   3844    1
## q[623]   3199    1
## q[624]   3416    1
## q[625]   3416    1
## q[626]   3416    1
## q[627]   3416    1
## q[628]   3199    1
## q[629]   3416    1
## q[630]   3199    1
## q[631]   3416    1
## q[632]   3416    1
## q[633]   3416    1
## q[634]   3416    1
## q[635]   3416    1
## q[636]   3416    1
## q[637]   3844    1
## q[638]   3844    1
## q[639]   3416    1
## q[640]   3416    1
## q[641]   3416    1
## q[642]   3844    1
## q[643]   3199    1
## q[644]   3416    1
## q[645]   3416    1
## q[646]   3199    1
## q[647]   3416    1
## q[648]   3199    1
## q[649]   3416    1
## q[650]   3844    1
## q[651]   3416    1
## q[652]   3199    1
## q[653]   3844    1
## q[654]   3199    1
## q[655]   3416    1
## q[656]   3416    1
## q[657]   3844    1
## q[658]   3199    1
## q[659]   3844    1
## q[660]   3844    1
## q[661]   3416    1
## q[662]   3416    1
## q[663]   3844    1
## q[664]   3844    1
## q[665]   3844    1
## q[666]   3416    1
## q[667]   3199    1
## q[668]   3199    1
## q[669]   3465    1
## q[670]   2933    1
## q[671]   3465    1
## q[672]   3257    1
## q[673]   3257    1
## q[674]   3257    1
## q[675]   2933    1
## q[676]   2933    1
## q[677]   2933    1
## q[678]   2933    1
## q[679]   2933    1
## q[680]   2933    1
## q[681]   3465    1
## q[682]   2933    1
## q[683]   3465    1
## q[684]   2933    1
## q[685]   2933    1
## q[686]   2933    1
## q[687]   3465    1
## q[688]   3465    1
## q[689]   3465    1
## q[690]   2933    1
## q[691]   2933    1
## q[692]   3257    1
## q[693]   3257    1
## q[694]   2933    1
## q[695]   2933    1
## q[696]   2933    1
## q[697]   2933    1
## q[698]   3465    1
## q[699]   3257    1
## q[700]   2933    1
## q[701]   2933    1
## q[702]   3257    1
## q[703]   3257    1
## q[704]   3465    1
## q[705]   2933    1
## q[706]   3465    1
## q[707]   2933    1
## q[708]   3257    1
## q[709]   2891    1
## q[710]   2891    1
## q[711]   2891    1
## q[712]   2891    1
## q[713]   3413    1
## q[714]   3413    1
## q[715]   3235    1
## q[716]   3413    1
## q[717]   3413    1
## q[718]   2891    1
## q[719]   2891    1
## q[720]   2891    1
## q[721]   3413    1
## q[722]   3235    1
## q[723]   2891    1
## q[724]   2891    1
## q[725]   3413    1
## q[726]   2891    1
## q[727]   3413    1
## q[728]   2891    1
## q[729]   3413    1
## q[730]   2891    1
## q[731]   2891    1
## q[732]   2891    1
## q[733]   3413    1
## q[734]   2891    1
## q[735]   3235    1
## q[736]   3413    1
## q[737]   2891    1
## q[738]   2891    1
## q[739]   3413    1
## q[740]   3235    1
## q[741]   3235    1
## q[742]   3413    1
## q[743]   3413    1
## q[744]   2891    1
## q[745]   3235    1
## q[746]   2891    1
## q[747]   2891    1
## q[748]   2891    1
## q[749]   2891    1
## q[750]   2891    1
## q[751]   3413    1
## q[752]   3235    1
## q[753]   3413    1
## q[754]   3413    1
## q[755]   2891    1
## q[756]   2891    1
## q[757]   2891    1
## q[758]   3413    1
## q[759]   3235    1
## q[760]   3413    1
## q[761]   2891    1
## q[762]   2891    1
## q[763]   3235    1
## q[764]   3235    1
## q[765]   3569    1
## q[766]   3165    1
## q[767]   3165    1
## q[768]   3165    1
## q[769]   3165    1
## q[770]   3569    1
## q[771]   3569    1
## q[772]   3569    1
## q[773]   3569    1
## q[774]   3086    1
## q[775]   3165    1
## q[776]   3165    1
## q[777]   3165    1
## q[778]   3086    1
## q[779]   3165    1
## q[780]   3165    1
## q[781]   3165    1
## q[782]   3569    1
## q[783]   3165    1
## q[784]   3165    1
## q[785]   3165    1
## q[786]   3569    1
## q[787]   3165    1
## q[788]   3569    1
## q[789]   3569    1
## q[790]   3165    1
## q[791]   3165    1
## q[792]   3569    1
## q[793]   3569    1
## q[794]   3569    1
## q[795]   3165    1
## q[796]   3086    1
## q[797]   3086    1
## q[798]   3165    1
## q[799]   3569    1
## q[800]   3165    1
## q[801]   3569    1
## q[802]   3165    1
## q[803]   3165    1
## q[804]   3569    1
## q[805]   3569    1
## q[806]   3165    1
## q[807]   3086    1
## q[808]   3165    1
## q[809]   3165    1
## q[810]   3165    1
## q[811]   3165    1
## q[812]   3165    1
## q[813]   3165    1
## q[814]   3569    1
## q[815]   3569    1
## q[816]   3086    1
## q[817]   3165    1
## q[818]   3165    1
## q[819]   3569    1
## q[820]   3086    1
## q[821]   3165    1
## q[822]   3165    1
## q[823]   3165    1
## q[824]   2994    1
## q[825]   2994    1
## q[826]   2994    1
## q[827]   3551    1
## q[828]   3551    1
## q[829]   3551    1
## q[830]   2994    1
## q[831]   2994    1
## q[832]   2994    1
## q[833]   3551    1
## q[834]   3285    1
## q[835]   2994    1
## q[836]   3551    1
## q[837]   2994    1
## q[838]   3551    1
## q[839]   2994    1
## q[840]   3551    1
## q[841]   2994    1
## q[842]   3285    1
## q[843]   3551    1
## q[844]   2994    1
## q[845]   3551    1
## q[846]   3551    1
## q[847]   2994    1
## q[848]   2994    1
## q[849]   2994    1
## q[850]   2994    1
## q[851]   2994    1
## q[852]   2994    1
## q[853]   3551    1
## q[854]   3551    1
## q[855]   2994    1
## q[856]   2994    1
## q[857]   3285    1
## q[858]   3551    1
## q[859]   2994    1
## q[860]   2994    1
## q[861]   3285    1
## q[862]   2746    1
## q[863]   2434    1
## q[864]   2434    1
## q[865]   2434    1
## q[866]   2434    1
## q[867]   2434    1
## q[868]   2746    1
## q[869]   2746    1
## q[870]   2746    1
## q[871]   2797    1
## q[872]   2434    1
## q[873]   2434    1
## q[874]   2434    1
## q[875]   2434    1
## q[876]   2434    1
## q[877]   2434    1
## q[878]   2797    1
## q[879]   2434    1
## q[880]   2434    1
## q[881]   2434    1
## q[882]   2746    1
## q[883]   2434    1
## q[884]   2434    1
## q[885]   2746    1
## q[886]   2746    1
## q[887]   2797    1
## q[888]   2434    1
## q[889]   2746    1
## q[890]   2434    1
## q[891]   2746    1
## q[892]   2434    1
## q[893]   2434    1
## q[894]   2434    1
## q[895]   2434    1
## q[896]   2434    1
## q[897]   2797    1
## q[898]   2434    1
## q[899]   2746    1
## q[900]   2434    1
## q[901]   2434    1
## q[902]   2746    1
## q[903]   2434    1
## q[904]   2434    1
## q[905]   2797    1
## q[906]   2434    1
## q[907]   2523    1
## q[908]   2798    1
## q[909]   2975    1
## q[910]   2975    1
## q[911]   2798    1
## q[912]   2523    1
## q[913]   2975    1
## q[914]   2523    1
## q[915]   2523    1
## q[916]   2975    1
## q[917]   2523    1
## q[918]   2975    1
## q[919]   2523    1
## q[920]   2523    1
## q[921]   2975    1
## q[922]   2975    1
## q[923]   2798    1
## q[924]   2975    1
## q[925]   2523    1
## q[926]   2975    1
## q[927]   2975    1
## q[928]   2523    1
## q[929]   2975    1
## q[930]   2798    1
## q[931]   2523    1
## q[932]   2798    1
## q[933]   2975    1
## q[934]   2523    1
## q[935]   2523    1
## q[936]   2975    1
## q[937]   2975    1
## q[938]   2523    1
## q[939]   2523    1
## q[940]   2523    1
## q[941]   2523    1
## q[942]   2523    1
## q[943]   2975    1
## q[944]   2523    1
## q[945]   2523    1
## q[946]   2798    1
## q[947]   2798    1
## q[948]   2523    1
## q[949]   2975    1
## q[950]   2523    1
## q[951]   2523    1
## q[952]   2681    1
## q[953]   2681    1
## q[954]   2681    1
## q[955]   2681    1
## q[956]   2681    1
## q[957]   3216    1
## q[958]   3216    1
## q[959]   2854    1
## q[960]   3216    1
## q[961]   3216    1
## q[962]   2854    1
## q[963]   2681    1
## q[964]   2681    1
## q[965]   2681    1
## q[966]   2681    1
## q[967]   2681    1
## q[968]   2854    1
## q[969]   2681    1
## q[970]   2854    1
## q[971]   2681    1
## q[972]   2681    1
## q[973]   2681    1
## q[974]   2681    1
## q[975]   3216    1
## q[976]   2681    1
## q[977]   2681    1
## q[978]   3216    1
## q[979]   2681    1
## q[980]   2681    1
## q[981]   2681    1
## q[982]   2681    1
## q[983]   2854    1
## q[984]   3216    1
## q[985]   2854    1
## q[986]   3216    1
## q[987]   2854    1
## q[988]   3216    1
## q[989]   3216    1
## q[990]   2681    1
## q[991]   2681    1
## q[992]   3216    1
## q[993]   2854    1
## q[994]   2854    1
## q[995]   2681    1
## q[996]   2681    1
## q[997]   2854    1
## q[998]   2854    1
## q[999]   2681    1
## q[1000]  3216    1
## q[1001]  2681    1
## q[1002]  2854    1
## q[1003]  3216    1
## q[1004]  3216    1
## q[1005]  2854    1
## q[1006]  2681    1
## q[1007]  2681    1
## q[1008]  2681    1
## q[1009]  2681    1
## q[1010]  2681    1
## q[1011]  3216    1
## q[1012]  2681    1
## q[1013]  2681    1
## q[1014]  2854    1
## q[1015]  2854    1
## q[1016]  3216    1
## q[1017]  3216    1
## q[1018]  2681    1
## q[1019]  2681    1
## q[1020]  2681    1
## q[1021]  3216    1
## q[1022]  3216    1
## q[1023]  3216    1
## q[1024]  2681    1
## q[1025]  2681    1
## q[1026]  2681    1
## q[1027]  2854    1
## q[1028]  2854    1
## q[1029]  3152    1
## q[1030]  2890    1
## q[1031]  2890    1
## q[1032]  2890    1
## q[1033]  3152    1
## q[1034]  3152    1
## q[1035]  3152    1
## q[1036]  2945    1
## q[1037]  2945    1
## q[1038]  2890    1
## q[1039]  2890    1
## q[1040]  2945    1
## q[1041]  2890    1
## q[1042]  2890    1
## q[1043]  2890    1
## q[1044]  2890    1
## q[1045]  3152    1
## q[1046]  2890    1
## q[1047]  2890    1
## q[1048]  3152    1
## q[1049]  2890    1
## q[1050]  2890    1
## q[1051]  2890    1
## q[1052]  3152    1
## q[1053]  2890    1
## q[1054]  2890    1
## q[1055]  3152    1
## q[1056]  3152    1
## q[1057]  2890    1
## q[1058]  2945    1
## q[1059]  3152    1
## q[1060]  3152    1
## q[1061]  3152    1
## q[1062]  2890    1
## q[1063]  3152    1
## q[1064]  3152    1
## q[1065]  2945    1
## q[1066]  3152    1
## q[1067]  2890    1
## q[1068]  2945    1
## q[1069]  2890    1
## q[1070]  2890    1
## q[1071]  2945    1
## q[1072]  2890    1
## q[1073]  2890    1
## q[1074]  3152    1
## q[1075]  2890    1
## q[1076]  3152    1
## q[1077]  2890    1
## q[1078]  2945    1
## q[1079]  3152    1
## q[1080]  2890    1
## q[1081]  2890    1
## q[1082]  2890    1
## q[1083]  2890    1
## q[1084]  2890    1
## q[1085]  3152    1
## q[1086]  2890    1
## q[1087]  3152    1
## q[1088]  2890    1
## q[1089]  2945    1
## q[1090]  2890    1
## q[1091]  2945    1
## q[1092]  3152    1
## q[1093]  2945    1
## q[1094]  2890    1
## q[1095]  2890    1
## q[1096]  2890    1
## q[1097]  2890    1
## q[1098]  2890    1
## q[1099]  3343    1
## q[1100]  3343    1
## q[1101]  3343    1
## q[1102]  3343    1
## q[1103]  3343    1
## q[1104]  3737    1
## q[1105]  3162    1
## q[1106]  3737    1
## q[1107]  3737    1
## q[1108]  3737    1
## q[1109]  3737    1
## q[1110]  3162    1
## q[1111]  3343    1
## q[1112]  3343    1
## q[1113]  3343    1
## q[1114]  3162    1
## q[1115]  3343    1
## q[1116]  3343    1
## q[1117]  3737    1
## q[1118]  3343    1
## q[1119]  3343    1
## q[1120]  3343    1
## q[1121]  3737    1
## q[1122]  3343    1
## q[1123]  3737    1
## q[1124]  3343    1
## q[1125]  3343    1
## q[1126]  3737    1
## q[1127]  3343    1
## q[1128]  3343    1
## q[1129]  3343    1
## q[1130]  3737    1
## q[1131]  3737    1
## q[1132]  3343    1
## q[1133]  3162    1
## q[1134]  3737    1
## q[1135]  3162    1
## q[1136]  3737    1
## q[1137]  3737    1
## q[1138]  3343    1
## q[1139]  3343    1
## q[1140]  3737    1
## q[1141]  3162    1
## q[1142]  3343    1
## q[1143]  3162    1
## q[1144]  3343    1
## q[1145]  3737    1
## q[1146]  3343    1
## q[1147]  3737    1
## q[1148]  3162    1
## q[1149]  3737    1
## q[1150]  3343    1
## q[1151]  3162    1
## q[1152]  3343    1
## q[1153]  3343    1
## q[1154]  3343    1
## q[1155]  3343    1
## q[1156]  3343    1
## q[1157]  3343    1
## q[1158]  3737    1
## q[1159]  3343    1
## q[1160]  3737    1
## q[1161]  3162    1
## q[1162]  3162    1
## q[1163]  3343    1
## q[1164]  3162    1
## q[1165]  3737    1
## q[1166]  3343    1
## q[1167]  3343    1
## q[1168]  3737    1
## q[1169]  3737    1
## q[1170]  3162    1
## q[1171]  3343    1
## q[1172]  3343    1
## q[1173]  3343    1
## q[1174]  3343    1
## q[1175]  3162    1
## q[1176]  3703    1
## q[1177]  3309    1
## q[1178]  3309    1
## q[1179]  3148    1
## q[1180]  3703    1
## q[1181]  3148    1
## q[1182]  3703    1
## q[1183]  3148    1
## q[1184]  3703    1
## q[1185]  3309    1
## q[1186]  3309    1
## q[1187]  3703    1
## q[1188]  3309    1
## q[1189]  3309    1
## q[1190]  3309    1
## q[1191]  3703    1
## q[1192]  3309    1
## q[1193]  3309    1
## q[1194]  3703    1
## q[1195]  3309    1
## q[1196]  3703    1
## q[1197]  3309    1
## q[1198]  3703    1
## q[1199]  3703    1
## q[1200]  3309    1
## q[1201]  3309    1
## q[1202]  3703    1
## q[1203]  3309    1
## q[1204]  3148    1
## q[1205]  3703    1
## q[1206]  3703    1
## q[1207]  3309    1
## q[1208]  3703    1
## q[1209]  3309    1
## q[1210]  3309    1
## q[1211]  3309    1
## q[1212]  3148    1
## q[1213]  3148    1
## q[1214]  3309    1
## q[1215]  3148    1
## q[1216]  3703    1
## q[1217]  3148    1
## q[1218]  3309    1
## q[1219]  3703    1
## q[1220]  3309    1
## q[1221]  3703    1
## q[1222]  3703    1
## q[1223]  3309    1
## q[1224]  3148    1
## q[1225]  3309    1
## q[1226]  3309    1
## q[1227]  3703    1
## q[1228]  3309    1
## q[1229]  3309    1
## q[1230]  3148    1
## q[1231]  3703    1
## q[1232]  3309    1
## q[1233]  3703    1
## q[1234]  3148    1
## q[1235]  3703    1
## q[1236]  3309    1
## q[1237]  3309    1
## q[1238]  3148    1
## q[1239]  2939    1
## q[1240]  2939    1
## q[1241]  2939    1
## q[1242]  3025    1
## q[1243]  2939    1
## q[1244]  2939    1
## q[1245]  2939    1
## q[1246]  3534    1
## q[1247]  3534    1
## q[1248]  3534    1
## q[1249]  3534    1
## q[1250]  3534    1
## q[1251]  2939    1
## q[1252]  2939    1
## q[1253]  2939    1
## q[1254]  2939    1
## q[1255]  2939    1
## q[1256]  2939    1
## q[1257]  3534    1
## q[1258]  3025    1
## q[1259]  2939    1
## q[1260]  2939    1
## q[1261]  2939    1
## q[1262]  3534    1
## q[1263]  3534    1
## q[1264]  2939    1
## q[1265]  3534    1
## q[1266]  2939    1
## q[1267]  3534    1
## q[1268]  3025    1
## q[1269]  3534    1
## q[1270]  3534    1
## q[1271]  2939    1
## q[1272]  3534    1
## q[1273]  3025    1
## q[1274]  2939    1
## q[1275]  3534    1
## q[1276]  2939    1
## q[1277]  3534    1
## q[1278]  3025    1
## q[1279]  2939    1
## q[1280]  3025    1
## q[1281]  3534    1
## q[1282]  3534    1
## q[1283]  3534    1
## q[1284]  2939    1
## q[1285]  2939    1
## q[1286]  2939    1
## q[1287]  2939    1
## q[1288]  2939    1
## q[1289]  2939    1
## q[1290]  3534    1
## q[1291]  2939    1
## q[1292]  2939    1
## q[1293]  3025    1
## q[1294]  2939    1
## q[1295]  3534    1
## q[1296]  2939    1
## q[1297]  2939    1
## q[1298]  3025    1
## q[1299]  3534    1
## q[1300]  3534    1
## q[1301]  2939    1
## q[1302]  2939    1
## q[1303]  2939    1
## q[1304]  2939    1
## q[1305]  3025    1
## q[1306]  2939    1
## q[1307]  3417    1
## q[1308]  3417    1
## q[1309]  3417    1
## q[1310]  3839    1
## q[1311]  3839    1
## q[1312]  3839    1
## q[1313]  3839    1
## q[1314]  3417    1
## q[1315]  3417    1
## q[1316]  3417    1
## q[1317]  3417    1
## q[1318]  3417    1
## q[1319]  3198    1
## q[1320]  3839    1
## q[1321]  3198    1
## q[1322]  3417    1
## q[1323]  3417    1
## q[1324]  3839    1
## q[1325]  3417    1
## q[1326]  3839    1
## q[1327]  3417    1
## q[1328]  3839    1
## q[1329]  3417    1
## q[1330]  3198    1
## q[1331]  3198    1
## q[1332]  3839    1
## q[1333]  3417    1
## q[1334]  3839    1
## q[1335]  3417    1
## q[1336]  3839    1
## q[1337]  3839    1
## q[1338]  3198    1
## q[1339]  3417    1
## q[1340]  3417    1
## q[1341]  3417    1
## q[1342]  3417    1
## q[1343]  3417    1
## q[1344]  3417    1
## q[1345]  3417    1
## q[1346]  3839    1
## q[1347]  3839    1
## q[1348]  3839    1
## q[1349]  3417    1
## q[1350]  3417    1
## q[1351]  3839    1
## q[1352]  3198    1
## q[1353]  3839    1
## q[1354]  3417    1
## q[1355]  3417    1
## q[1356]  3198    1
## q[1357]  3294    1
## q[1358]  3294    1
## q[1359]  3294    1
## q[1360]  3294    1
## q[1361]  3294    1
## q[1362]  3805    1
## q[1363]  3170    1
## q[1364]  3805    1
## q[1365]  3805    1
## q[1366]  3170    1
## q[1367]  3294    1
## q[1368]  3294    1
## q[1369]  3294    1
## q[1370]  3294    1
## q[1371]  3294    1
## q[1372]  3294    1
## q[1373]  3805    1
## q[1374]  3294    1
## q[1375]  3294    1
## q[1376]  3294    1
## q[1377]  3294    1
## q[1378]  3805    1
## q[1379]  3170    1
## q[1380]  3805    1
## q[1381]  3805    1
## q[1382]  3805    1
## q[1383]  3294    1
## q[1384]  3294    1
## q[1385]  3805    1
## q[1386]  3170    1
## q[1387]  3170    1
## q[1388]  3294    1
## q[1389]  3294    1
## q[1390]  3805    1
## q[1391]  3170    1
## q[1392]  3294    1
## q[1393]  3294    1
## q[1394]  3294    1
## q[1395]  3294    1
## q[1396]  3170    1
## q[1397]  3170    1
## q[1398]  3294    1
## q[1399]  3170    1
## q[1400]  3805    1
## q[1401]  3294    1
## q[1402]  3294    1
## q[1403]  3805    1
## q[1404]  3294    1
## q[1405]  3294    1
## q[1406]  3294    1
## q[1407]  3170    1
## q[1408]  3317    1
## q[1409]  3055    1
## q[1410]  3055    1
## q[1411]  3753    1
## q[1412]  3753    1
## q[1413]  3317    1
## q[1414]  3055    1
## q[1415]  3055    1
## q[1416]  3055    1
## q[1417]  3055    1
## q[1418]  3055    1
## q[1419]  3753    1
## q[1420]  3753    1
## q[1421]  3753    1
## q[1422]  3055    1
## q[1423]  3753    1
## q[1424]  3753    1
## q[1425]  3055    1
## q[1426]  3055    1
## q[1427]  3055    1
## q[1428]  3055    1
## q[1429]  3055    1
## q[1430]  3317    1
## q[1431]  3055    1
## q[1432]  3317    1
## q[1433]  3055    1
## q[1434]  3753    1
## q[1435]  3055    1
## q[1436]  3055    1
## q[1437]  3055    1
## q[1438]  3753    1
## q[1439]  3317    1
## q[1440]  3055    1
## q[1441]  3753    1
## q[1442]  3055    1
## q[1443]  3753    1
## q[1444]  3055    1
## q[1445]  3753    1
## q[1446]  3055    1
## q[1447]  3055    1
## q[1448]  3753    1
## q[1449]  3317    1
## q[1450]  3753    1
## q[1451]  3055    1
## q[1452]  3753    1
## q[1453]  3753    1
## q[1454]  3753    1
## q[1455]  3317    1
## q[1456]  3055    1
## q[1457]  3317    1
## q[1458]  3055    1
## q[1459]  3055    1
## q[1460]  3753    1
## q[1461]  3753    1
## q[1462]  3055    1
## q[1463]  3055    1
## q[1464]  3055    1
## q[1465]  3055    1
## q[1466]  3055    1
## q[1467]  3753    1
## q[1468]  3055    1
## q[1469]  3317    1
## q[1470]  3317    1
## q[1471]  3055    1
## q[1472]  3055    1
## q[1473]  3055    1
## q[1474]  2739    1
## q[1475]  3439    1
## q[1476]  3066    1
## q[1477]  2739    1
## q[1478]  2739    1
## q[1479]  3439    1
## q[1480]  2739    1
## q[1481]  2739    1
## q[1482]  2739    1
## q[1483]  3066    1
## q[1484]  3066    1
## q[1485]  3439    1
## q[1486]  3066    1
## q[1487]  3066    1
## q[1488]  3439    1
## q[1489]  2739    1
## q[1490]  3439    1
## q[1491]  3066    1
## q[1492]  3515    1
## q[1493]  2974    1
## q[1494]  2974    1
## q[1495]  3515    1
## q[1496]  3515    1
## q[1497]  3277    1
## q[1498]  2974    1
## q[1499]  2974    1
## q[1500]  2974    1
## q[1501]  2974    1
## q[1502]  3515    1
## q[1503]  3277    1
## q[1504]  2974    1
## q[1505]  2974    1
## q[1506]  3515    1
## q[1507]  2974    1
## q[1508]  2974    1
## q[1509]  3515    1
## q[1510]  2974    1
## q[1511]  3515    1
## q[1512]  3515    1
## q[1513]  2974    1
## q[1514]  3277    1
## q[1515]  3515    1
## q[1516]  3515    1
## q[1517]  2974    1
## q[1518]  3515    1
## q[1519]  2974    1
## q[1520]  3277    1
## q[1521]  2974    1
## q[1522]  3277    1
## q[1523]  2974    1
## q[1524]  3515    1
## q[1525]  2974    1
## q[1526]  3515    1
## q[1527]  2974    1
## q[1528]  2974    1
## q[1529]  2974    1
## q[1530]  2974    1
## q[1531]  3515    1
## q[1532]  2974    1
## q[1533]  3515    1
## q[1534]  2974    1
## q[1535]  3277    1
## q[1536]  3515    1
## q[1537]  2974    1
## q[1538]  2974    1
## q[1539]  2974    1
## q[1540]  3277    1
## q[1541]  2555    1
## q[1542]  2555    1
## q[1543]  2555    1
## q[1544]  2724    1
## q[1545]  2955    1
## q[1546]  2955    1
## q[1547]  2724    1
## q[1548]  2955    1
## q[1549]  2955    1
## q[1550]  2724    1
## q[1551]  2555    1
## q[1552]  2555    1
## q[1553]  2555    1
## q[1554]  2955    1
## q[1555]  2724    1
## q[1556]  2555    1
## q[1557]  2555    1
## q[1558]  2555    1
## q[1559]  2555    1
## q[1560]  2955    1
## q[1561]  2555    1
## q[1562]  2955    1
## q[1563]  2555    1
## q[1564]  2955    1
## q[1565]  2555    1
## q[1566]  2555    1
## q[1567]  2955    1
## q[1568]  2555    1
## q[1569]  2955    1
## q[1570]  2555    1
## q[1571]  2724    1
## q[1572]  2955    1
## q[1573]  2555    1
## q[1574]  2955    1
## q[1575]  2955    1
## q[1576]  2555    1
## q[1577]  2955    1
## q[1578]  2555    1
## q[1579]  2724    1
## q[1580]  2724    1
## q[1581]  2555    1
## q[1582]  2724    1
## q[1583]  2955    1
## q[1584]  2724    1
## q[1585]  2555    1
## q[1586]  2555    1
## q[1587]  2955    1
## q[1588]  2955    1
## q[1589]  2955    1
## q[1590]  2555    1
## q[1591]  2724    1
## q[1592]  2555    1
## q[1593]  2555    1
## q[1594]  2555    1
## q[1595]  2555    1
## q[1596]  2555    1
## q[1597]  2955    1
## q[1598]  2555    1
## q[1599]  2555    1
## q[1600]  2724    1
## q[1601]  2724    1
## q[1602]  2955    1
## q[1603]  2955    1
## q[1604]  2555    1
## q[1605]  2555    1
## q[1606]  2955    1
## q[1607]  2724    1
## q[1608]  2955    1
## q[1609]  2555    1
## q[1610]  2955    1
## q[1611]  2555    1
## q[1612]  2555    1
## q[1613]  2555    1
## q[1614]  2724    1
## q[1615]  2724    1
## q[1616]  2699    1
## q[1617]  2699    1
## q[1618]  2804    1
## q[1619]  2699    1
## q[1620]  2699    1
## q[1621]  2818    1
## q[1622]  2804    1
## q[1623]  2699    1
## q[1624]  2804    1
## q[1625]  2699    1
## q[1626]  2699    1
## q[1627]  2699    1
## q[1628]  3640    1
## q[1629]  3640    1
## q[1630]  3082    1
## q[1631]  3060    1
## q[1632]  3060    1
## q[1633]  3082    1
## q[1634]  3060    1
## q[1635]  3060    1
## q[1636]  3060    1
## q[1637]  3060    1
## q[1638]  3640    1
## q[1639]  3060    1
## q[1640]  3640    1
## q[1641]  3082    1
## q[1642]  3060    1
## q[1643]  3060    1
## q[1644]  3060    1
## q[1645]  3640    1
## q[1646]  3060    1
## q[1647]  3082    1
## q[1648]  3060    1
## q[1649]  3640    1
## q[1650]  3640    1
## q[1651]  3839    1
## q[1652]  3839    1
## q[1653]  3190    1
## q[1654]  3364    1
## q[1655]  3364    1
## q[1656]  3190    1
## q[1657]  3839    1
## q[1658]  3364    1
## q[1659]  3364    1
## q[1660]  3839    1
## q[1661]  3364    1
## q[1662]  3364    1
## q[1663]  3839    1
## q[1664]  3839    1
## q[1665]  3364    1
## q[1666]  3839    1
## q[1667]  3190    1
## q[1668]  3839    1
## q[1669]  3364    1
## q[1670]  3364    1
## q[1671]  3839    1
## q[1672]  3364    1
## q[1673]  3839    1
## q[1674]  3190    1
## q[1675]  3364    1
## q[1676]  3364    1
## q[1677]  3364    1
## q[1678]  3364    1
## q[1679]  3364    1
## q[1680]  3839    1
## q[1681]  3364    1
## q[1682]  3839    1
## q[1683]  3190    1
## q[1684]  3839    1
## q[1685]  3190    1
## q[1686]  3364    1
## q[1687]  3364    1
## q[1688]  3970    1
## q[1689]  3051    1
## q[1690]  3051    1
## q[1691]  3051    1
## q[1692]  3970    1
## q[1693]  3970    1
## q[1694]  3970    1
## q[1695]  3970    1
## q[1696]  3325    1
## q[1697]  3051    1
## q[1698]  3051    1
## q[1699]  3051    1
## q[1700]  3051    1
## q[1701]  3325    1
## q[1702]  3051    1
## q[1703]  3051    1
## q[1704]  3051    1
## q[1705]  3970    1
## q[1706]  3325    1
## q[1707]  3051    1
## q[1708]  3051    1
## q[1709]  3051    1
## q[1710]  3051    1
## q[1711]  3970    1
## q[1712]  3051    1
## q[1713]  3970    1
## q[1714]  3970    1
## q[1715]  3051    1
## q[1716]  3970    1
## q[1717]  3970    1
## q[1718]  3970    1
## q[1719]  3051    1
## q[1720]  3325    1
## q[1721]  3051    1
## q[1722]  3051    1
## q[1723]  3051    1
## q[1724]  3970    1
## q[1725]  3970    1
## q[1726]  3051    1
## q[1727]  3325    1
## q[1728]  3051    1
## q[1729]  3051    1
## q[1730]  3051    1
## q[1731]  3051    1
## q[1732]  3051    1
## q[1733]  3970    1
## q[1734]  3970    1
## q[1735]  3325    1
## q[1736]  3051    1
## q[1737]  3970    1
## q[1738]  3051    1
## q[1739]  3970    1
## q[1740]  3325    1
## q[1741]  3970    1
## q[1742]  3051    1
## q[1743]  3051    1
## q[1744]  3051    1
## q[1745]  3325    1
## q[1746]  3051    1
## q[1747]  3020    1
## q[1748]  3020    1
## q[1749]  3305    1
## q[1750]  3020    1
## q[1751]  4041    1
## q[1752]  4041    1
## q[1753]  4041    1
## q[1754]  4041    1
## q[1755]  3305    1
## q[1756]  3020    1
## q[1757]  3020    1
## q[1758]  3020    1
## q[1759]  3020    1
## q[1760]  3020    1
## q[1761]  3305    1
## q[1762]  3305    1
## q[1763]  3020    1
## q[1764]  3020    1
## q[1765]  3020    1
## q[1766]  3020    1
## q[1767]  3020    1
## q[1768]  3020    1
## q[1769]  4041    1
## q[1770]  3305    1
## q[1771]  4041    1
## q[1772]  3305    1
## q[1773]  3020    1
## q[1774]  4041    1
## q[1775]  4041    1
## q[1776]  3020    1
## q[1777]  4041    1
## q[1778]  3020    1
## q[1779]  4041    1
## q[1780]  3020    1
## q[1781]  4041    1
## q[1782]  3020    1
## q[1783]  3305    1
## q[1784]  3020    1
## q[1785]  3020    1
## q[1786]  3020    1
## q[1787]  3020    1
## q[1788]  3020    1
## q[1789]  4041    1
## q[1790]  3020    1
## q[1791]  3020    1
## q[1792]  3305    1
## q[1793]  4041    1
## q[1794]  3020    1
## q[1795]  3020    1
## q[1796]  4041    1
## q[1797]  4041    1
## q[1798]  3020    1
## q[1799]  4041    1
## q[1800]  3020    1
## q[1801]  3305    1
## q[1802]  3685    1
## q[1803]  3290    1
## q[1804]  3290    1
## q[1805]  3290    1
## q[1806]  3290    1
## q[1807]  3290    1
## q[1808]  3290    1
## q[1809]  3685    1
## q[1810]  3140    1
## q[1811]  3685    1
## q[1812]  3685    1
## q[1813]  3685    1
## q[1814]  3140    1
## q[1815]  3140    1
## q[1816]  3290    1
## q[1817]  3290    1
## q[1818]  3290    1
## q[1819]  3290    1
## q[1820]  3290    1
## q[1821]  3685    1
## q[1822]  3290    1
## q[1823]  3290    1
## q[1824]  3685    1
## q[1825]  3290    1
## q[1826]  3290    1
## q[1827]  3290    1
## q[1828]  3685    1
## q[1829]  3290    1
## q[1830]  3685    1
## q[1831]  3290    1
## q[1832]  3290    1
## q[1833]  3685    1
## q[1834]  3685    1
## q[1835]  3290    1
## q[1836]  3290    1
## q[1837]  3290    1
## q[1838]  3290    1
## q[1839]  3140    1
## q[1840]  3685    1
## q[1841]  3685    1
## q[1842]  3685    1
## q[1843]  3290    1
## q[1844]  3685    1
## q[1845]  3140    1
## q[1846]  3685    1
## q[1847]  3685    1
## q[1848]  3290    1
## q[1849]  3685    1
## q[1850]  3290    1
## q[1851]  3290    1
## q[1852]  3685    1
## q[1853]  3140    1
## q[1854]  3140    1
## q[1855]  3290    1
## q[1856]  3140    1
## q[1857]  3140    1
## q[1858]  3290    1
## q[1859]  3290    1
## q[1860]  3290    1
## q[1861]  3685    1
## q[1862]  3290    1
## q[1863]  3685    1
## q[1864]  3685    1
## q[1865]  3290    1
## q[1866]  3140    1
## q[1867]  3290    1
## q[1868]  3290    1
## q[1869]  3290    1
## q[1870]  3290    1
## q[1871]  3290    1
## q[1872]  3290    1
## q[1873]  3685    1
## q[1874]  3290    1
## q[1875]  3140    1
## q[1876]  3140    1
## q[1877]  3290    1
## q[1878]  3140    1
## q[1879]  3685    1
## q[1880]  3290    1
## q[1881]  3290    1
## q[1882]  3685    1
## q[1883]  3140    1
## q[1884]  3290    1
## q[1885]  3290    1
## q[1886]  3290    1
## q[1887]  3290    1
## q[1888]  3290    1
## q[1889]  3140    1
## q[1890]  2912    1
## q[1891]  2912    1
## q[1892]  2912    1
## q[1893]  2912    1
## q[1894]  3439    1
## q[1895]  3439    1
## q[1896]  3439    1
## q[1897]  3247    1
## q[1898]  2912    1
## q[1899]  2912    1
## q[1900]  2912    1
## q[1901]  3439    1
## q[1902]  2912    1
## q[1903]  3439    1
## q[1904]  2912    1
## q[1905]  2912    1
## q[1906]  3439    1
## q[1907]  2912    1
## q[1908]  3439    1
## q[1909]  3439    1
## q[1910]  2912    1
## q[1911]  3247    1
## q[1912]  3439    1
## q[1913]  3439    1
## q[1914]  3439    1
## q[1915]  2912    1
## q[1916]  3439    1
## q[1917]  2912    1
## q[1918]  2912    1
## q[1919]  3439    1
## q[1920]  2912    1
## q[1921]  2912    1
## q[1922]  2912    1
## q[1923]  2912    1
## q[1924]  2912    1
## q[1925]  2912    1
## q[1926]  2912    1
## q[1927]  3439    1
## q[1928]  3247    1
## q[1929]  2912    1
## q[1930]  3247    1
## q[1931]  2912    1
## q[1932]  3247    1
## q[1933]  2912    1
## q[1934]  2912    1
## q[1935]  2912    1
## q[1936]  2912    1
## q[1937]  2891    1
## q[1938]  2906    1
## q[1939]  2906    1
## q[1940]  2519    1
## q[1941]  2519    1
## q[1942]  2519    1
## q[1943]  2519    1
## q[1944]  2519    1
## q[1945]  2891    1
## q[1946]  2519    1
## q[1947]  2891    1
## q[1948]  2891    1
## q[1949]  2891    1
## q[1950]  2519    1
## q[1951]  2519    1
## q[1952]  2519    1
## q[1953]  2519    1
## q[1954]  2519    1
## q[1955]  2519    1
## q[1956]  2519    1
## q[1957]  2906    1
## q[1958]  2519    1
## q[1959]  2870    1
## q[1960]  2506    1
## q[1961]  2889    1
## q[1962]  2506    1
## q[1963]  2506    1
## q[1964]  2870    1
## q[1965]  2889    1
## q[1966]  2870    1
## q[1967]  2506    1
## q[1968]  2506    1
## q[1969]  2506    1
## q[1970]  2506    1
## q[1971]  2506    1
## q[1972]  2506    1
## q[1973]  2870    1
## q[1974]  2506    1
## q[1975]  2506    1
## q[1976]  2870    1
## q[1977]  2506    1
## q[1978]  2870    1
## q[1979]  2889    1
## q[1980]  2870    1
## q[1981]  2870    1
## q[1982]  2870    1
## q[1983]  2506    1
## q[1984]  2506    1
## q[1985]  2889    1
## q[1986]  2506    1
## q[1987]  2889    1
## q[1988]  2870    1
## q[1989]  2506    1
## q[1990]  2506    1
## q[1991]  2870    1
## q[1992]  2506    1
## q[1993]  2506    1
## q[1994]  2889    1
## q[1995]  2506    1
## q[1996]  2870    1
## q[1997]  2506    1
## q[1998]  2506    1
## q[1999]  2506    1
## q[2000]  4027    1
## q[2001]  3041    1
## q[2002]  3316    1
## q[2003]  4027    1
## q[2004]  4027    1
## q[2005]  3316    1
## q[2006]  4027    1
## q[2007]  3041    1
## q[2008]  3041    1
## q[2009]  3316    1
## q[2010]  3041    1
## q[2011]  3041    1
## q[2012]  4027    1
## q[2013]  3041    1
## q[2014]  3041    1
## q[2015]  3041    1
## q[2016]  4027    1
## q[2017]  3041    1
## q[2018]  3041    1
## q[2019]  4027    1
## q[2020]  3041    1
## q[2021]  4027    1
## q[2022]  4027    1
## q[2023]  3041    1
## q[2024]  4027    1
## q[2025]  3316    1
## q[2026]  4027    1
## q[2027]  4027    1
## q[2028]  3041    1
## q[2029]  4027    1
## q[2030]  3316    1
## q[2031]  3041    1
## q[2032]  3041    1
## q[2033]  3316    1
## q[2034]  3041    1
## q[2035]  3041    1
## q[2036]  3316    1
## q[2037]  4027    1
## q[2038]  3041    1
## q[2039]  4027    1
## q[2040]  4027    1
## q[2041]  3041    1
## q[2042]  3316    1
## q[2043]  4027    1
## q[2044]  3041    1
## q[2045]  3041    1
## q[2046]  3041    1
## q[2047]  3041    1
## q[2048]  4027    1
## q[2049]  4027    1
## q[2050]  3041    1
## q[2051]  3041    1
## q[2052]  4027    1
## q[2053]  3316    1
## q[2054]  4027    1
## q[2055]  3041    1
## q[2056]  3041    1
## q[2057]  2998    1
## q[2058]  4018    1
## q[2059]  3292    1
## q[2060]  4018    1
## q[2061]  4018    1
## q[2062]  2998    1
## q[2063]  4018    1
## q[2064]  2998    1
## q[2065]  4018    1
## q[2066]  2998    1
## q[2067]  4018    1
## q[2068]  2998    1
## q[2069]  2998    1
## q[2070]  4018    1
## q[2071]  2998    1
## q[2072]  2998    1
## q[2073]  3292    1
## q[2074]  3292    1
## q[2075]  4018    1
## q[2076]  4018    1
## q[2077]  2998    1
## q[2078]  3292    1
## q[2079]  2998    1
## q[2080]  2998    1
## q[2081]  4018    1
## q[2082]  3292    1
## q[2083]  4018    1
## q[2084]  2998    1
## q[2085]  4018    1
## q[2086]  3292    1
## q[2087]  2998    1
## q[2088]  3292    1
## q[2089]  3858    1
## q[2090]  3058    1
## q[2091]  3058    1
## q[2092]  3058    1
## q[2093]  3858    1
## q[2094]  3326    1
## q[2095]  3858    1
## q[2096]  3858    1
## q[2097]  3326    1
## q[2098]  3058    1
## q[2099]  3058    1
## q[2100]  3058    1
## q[2101]  3858    1
## q[2102]  3058    1
## q[2103]  3058    1
## q[2104]  3058    1
## q[2105]  3858    1
## q[2106]  3058    1
## q[2107]  3858    1
## q[2108]  3058    1
## q[2109]  3858    1
## q[2110]  3858    1
## q[2111]  3058    1
## q[2112]  3058    1
## q[2113]  3058    1
## q[2114]  3858    1
## q[2115]  3858    1
## q[2116]  3858    1
## q[2117]  3058    1
## q[2118]  3058    1
## q[2119]  3058    1
## q[2120]  3326    1
## q[2121]  3326    1
## q[2122]  3058    1
## q[2123]  3858    1
## q[2124]  3058    1
## q[2125]  3858    1
## q[2126]  3058    1
## q[2127]  3326    1
## q[2128]  3058    1
## q[2129]  3058    1
## q[2130]  3858    1
## q[2131]  3326    1
## q[2132]  3326    1
## q[2133]  3058    1
## q[2134]  3858    1
## q[2135]  3058    1
## q[2136]  3858    1
## q[2137]  3326    1
## q[2138]  3058    1
## q[2139]  3058    1
## q[2140]  3058    1
## q[2141]  3326    1
## q[2142]  3722    1
## q[2143]  2864    1
## q[2144]  3191    1
## q[2145]  3191    1
## q[2146]  3722    1
## q[2147]  2864    1
## q[2148]  2864    1
## q[2149]  2864    1
## q[2150]  2864    1
## q[2151]  3722    1
## q[2152]  2864    1
## q[2153]  2864    1
## q[2154]  3722    1
## q[2155]  2864    1
## q[2156]  3722    1
## q[2157]  3191    1
## q[2158]  3722    1
## q[2159]  3722    1
## q[2160]  2864    1
## q[2161]  2864    1
## q[2162]  3191    1
## q[2163]  2864    1
## q[2164]  3191    1
## q[2165]  3722    1
## q[2166]  2864    1
## q[2167]  2864    1
## q[2168]  3722    1
## q[2169]  2864    1
## q[2170]  2864    1
## q[2171]  3722    1
## q[2172]  2864    1
## q[2173]  2546    1
## q[2174]  2546    1
## q[2175]  3027    1
## q[2176]  2829    1
## q[2177]  2546    1
## q[2178]  2546    1
## q[2179]  2546    1
## q[2180]  2546    1
## q[2181]  2829    1
## q[2182]  3027    1
## q[2183]  3027    1
## q[2184]  3027    1
## q[2185]  2546    1
## q[2186]  3027    1
## q[2187]  2546    1
## q[2188]  2546    1
## q[2189]  2546    1
## q[2190]  2546    1
## q[2191]  2546    1
## q[2192]  2546    1
## q[2193]  2829    1
## q[2194]  2546    1
## q[2195]  2546    1
## q[2196]  2806    1
## q[2197]  2806    1
## q[2198]  2806    1
## q[2199]  2806    1
## q[2200]  3303    1
## q[2201]  3185    1
## q[2202]  3303    1
## q[2203]  3185    1
## q[2204]  2806    1
## q[2205]  2806    1
## q[2206]  2806    1
## q[2207]  2806    1
## q[2208]  2806    1
## q[2209]  3303    1
## q[2210]  2806    1
## q[2211]  2806    1
## q[2212]  3303    1
## q[2213]  2806    1
## q[2214]  2806    1
## q[2215]  2806    1
## q[2216]  3185    1
## q[2217]  3303    1
## q[2218]  3303    1
## q[2219]  3303    1
## q[2220]  3303    1
## q[2221]  2806    1
## q[2222]  3185    1
## q[2223]  3185    1
## q[2224]  2806    1
## q[2225]  3185    1
## q[2226]  3185    1
## q[2227]  2806    1
## q[2228]  2806    1
## q[2229]  3303    1
## q[2230]  3303    1
## q[2231]  3185    1
## q[2232]  2806    1
## q[2233]  2806    1
## q[2234]  2806    1
## q[2235]  3185    1
## q[2236]  3185    1
## q[2237]  2806    1
## q[2238]  3185    1
## q[2239]  3303    1
## q[2240]  2806    1
## q[2241]  3303    1
## q[2242]  2806    1
## q[2243]  2806    1
## q[2244]  2806    1
## q[2245]  2806    1
## q[2246]  3185    1
## q[2247]  2486    1
## q[2248]  2365    1
## q[2249]  2365    1
## q[2250]  2365    1
## q[2251]  2257    1
## q[2252]  2365    1
## q[2253]  2257    1
## q[2254]  2365    1
## q[2255]  2365    1
## q[2256]  2365    1
## q[2257]  2257    1
## q[2258]  2257    1
## q[2259]  2365    1
## q[2260]  2365    1
## q[2261]  2257    1
## q[2262]  2257    1
## q[2263]  2257    1
## q[2264]  2365    1
## q[2265]  2257    1
## q[2266]  2486    1
## q[2267]  2365    1
## q[2268]  2257    1
## q[2269]  2847    1
## q[2270]  3676    1
## q[2271]  3676    1
## q[2272]  2847    1
## q[2273]  2847    1
## q[2274]  3176    1
## q[2275]  2847    1
## q[2276]  3676    1
## q[2277]  2847    1
## q[2278]  2847    1
## q[2279]  3676    1
## q[2280]  3676    1
## q[2281]  2847    1
## q[2282]  3676    1
## q[2283]  3176    1
## q[2284]  3676    1
## q[2285]  2847    1
## q[2286]  3676    1
## q[2287]  3176    1
## q[2288]  3176    1
## q[2289]  2847    1
## q[2290]  2847    1
## q[2291]  3176    1
## q[2292]  3676    1
## q[2293]  3676    1
## q[2294]  3176    1
## q[2295]  3676    1
## q[2296]  2847    1
## q[2297]  2847    1
## q[2298]  2847    1
## q[2299]  2847    1
## q[2300]  3676    1
## q[2301]  3676    1
## q[2302]  2847    1
## q[2303]  3676    1
## q[2304]  3176    1
## q[2305]  2847    1
## q[2306]  2847    1
## q[2307]  3137    1
## q[2308]  3082    1
## q[2309]  2685    1
## q[2310]  2685    1
## q[2311]  3082    1
## q[2312]  2685    1
## q[2313]  2685    1
## q[2314]  2685    1
## q[2315]  3137    1
## q[2316]  3082    1
## q[2317]  3137    1
## q[2318]  2685    1
## q[2319]  2685    1
## q[2320]  3137    1
## q[2321]  2685    1
## q[2322]  3082    1
## q[2323]  2685    1
## q[2324]  2685    1
## q[2325]  3137    1
## q[2326]  2685    1
## q[2327]  3082    1
## q[2328]  3137    1
## q[2329]  2685    1
## q[2330]  3569    1
## q[2331]  3165    1
## q[2332]  3165    1
## q[2333]  3165    1
## q[2334]  3165    1
## q[2335]  3569    1
## q[2336]  3569    1
## q[2337]  3086    1
## q[2338]  3569    1
## q[2339]  3569    1
## q[2340]  3086    1
## q[2341]  3165    1
## q[2342]  3165    1
## q[2343]  3165    1
## q[2344]  3165    1
## q[2345]  3569    1
## q[2346]  3086    1
## q[2347]  3165    1
## q[2348]  3165    1
## q[2349]  3165    1
## q[2350]  3165    1
## q[2351]  3569    1
## q[2352]  3165    1
## q[2353]  3569    1
## q[2354]  3165    1
## q[2355]  3569    1
## q[2356]  3569    1
## q[2357]  3165    1
## q[2358]  3165    1
## q[2359]  3165    1
## q[2360]  3165    1
## q[2361]  3569    1
## q[2362]  3569    1
## q[2363]  3165    1
## q[2364]  3086    1
## q[2365]  3165    1
## q[2366]  3569    1
## q[2367]  3165    1
## q[2368]  3165    1
## q[2369]  3569    1
## q[2370]  3086    1
## q[2371]  3086    1
## q[2372]  3165    1
## q[2373]  3569    1
## q[2374]  3165    1
## q[2375]  3569    1
## q[2376]  3165    1
## q[2377]  3086    1
## q[2378]  3165    1
## q[2379]  3165    1
## q[2380]  3165    1
## q[2381]  3165    1
## q[2382]  3165    1
## q[2383]  3569    1
## q[2384]  3086    1
## q[2385]  3569    1
## q[2386]  3569    1
## q[2387]  3165    1
## q[2388]  3165    1
## q[2389]  3165    1
## q[2390]  3569    1
## q[2391]  3086    1
## q[2392]  3569    1
## q[2393]  3165    1
## q[2394]  3165    1
## q[2395]  3086    1
## q[2396]  3086    1
## lp__     1673    1
## 
## Samples were drawn using NUTS(diag_e) at Tue Nov 26 18:02:43 2019.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;檢查模型參數的收斂情況&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;檢查模型參數的收斂情況&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(bayesplot)

color_scheme_set(&amp;quot;mix-brightblue-gray&amp;quot;)

posterior5.5 &amp;lt;- rstan::extract(fit1, inc_warmup = TRUE, permuted = FALSE)

p &amp;lt;- mcmc_trace(posterior5.5, n_warmup = 0, pars = c(&amp;quot;b[1]&amp;quot;, &amp;quot;b[2]&amp;quot;, &amp;quot;b[3]&amp;quot;,   &amp;quot;lp__&amp;quot;), facet_args = list(nrow = 2, labeller = label_parsed))

p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:chapter5-5&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-27-logistic2-rstan_files/figure-html/chapter5-5-1.png&#34; alt=&#34;用 bayesplot包數繪製的模型5-5的MCMC鏈式軌跡圖 (trace plot)。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: 用 bayesplot包數繪製的模型5-5的MCMC鏈式軌跡圖 (trace plot)。
&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- mcmc_acf_bar(posterior5.5, pars = c(&amp;quot;b[1]&amp;quot;, &amp;quot;b[2]&amp;quot;, &amp;quot;b[3]&amp;quot;,   &amp;quot;lp__&amp;quot;))
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:chapter5-5-acf&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-27-logistic2-rstan_files/figure-html/chapter5-5-acf-1.png&#34; alt=&#34;用 bayesplot包數繪製的事後樣本自相關圖(autocorrelation)。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: 用 bayesplot包數繪製的事後樣本自相關圖(autocorrelation)。
&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- mcmc_dens_overlay(posterior5.5, pars = c(&amp;quot;b[1]&amp;quot;, &amp;quot;b[2]&amp;quot;, &amp;quot;b[3]&amp;quot;, &amp;quot;OR1&amp;quot;,  &amp;quot;OR2&amp;quot;, &amp;quot;lp__&amp;quot;), color_chains = T)
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step5-5-density&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-27-logistic2-rstan_files/figure-html/step5-5-density-1.png&#34; alt=&#34;用 bayesplot包數繪製的事後樣本密度分佈圖。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: 用 bayesplot包數繪製的事後樣本密度分佈圖。
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;檢查模型的擬合情況&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;檢查模型的擬合情況&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ms &amp;lt;- rstan::extract(fit1)
set.seed(123)
logistic &amp;lt;- function(x) 1/(1+exp(-x))
X &amp;lt;- 30:200
q_qua &amp;lt;- logistic(t(sapply(1:length(X), function(i) {
  q_mcmc &amp;lt;- ms$b[,1] + ms$b[,3]*X[i]/200
  quantile(q_mcmc, probs=c(0.1, 0.5, 0.9))
})))
d_est &amp;lt;- data.frame(X, q_qua)
colnames(d_est) &amp;lt;- c(&amp;#39;X&amp;#39;, &amp;#39;p10&amp;#39;, &amp;#39;p50&amp;#39;, &amp;#39;p90&amp;#39;)
d$A &amp;lt;- as.factor(d$A)

p &amp;lt;- ggplot(d_est, aes(x=X, y=p50))
p &amp;lt;- p + theme_bw(base_size=18)
p &amp;lt;- p + geom_ribbon(aes(ymin=p10, ymax=p90), fill=&amp;#39;black&amp;#39;, alpha=2/6)
p &amp;lt;- p + geom_line(size=1)
p &amp;lt;- p + geom_point(data=subset(d, A==0 &amp;amp; Weather==&amp;#39;A&amp;#39;), aes(x=Score, y=Y, color=A),
  position=position_jitter(w=0, h=0.1), size=1)
p &amp;lt;- p + labs(x=&amp;#39;Score&amp;#39;, y=&amp;#39;q&amp;#39;)
p &amp;lt;- p + scale_color_manual(values=c(&amp;#39;black&amp;#39;))
p &amp;lt;- p + scale_y_continuous(breaks=seq(0, 1, 0.2))
p &amp;lt;- p + xlim(30, 200)
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:validity-of-model&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-27-logistic2-rstan_files/figure-html/validity-of-model-1.png&#34; alt=&#34;不喜歡打工，且天氣晴天的情況下，分數在 30-200 點之間的學生的出勤概率 q 和它的 80% 可信區間範圍。圖中黑色實線是預測概率的事後分佈的中央值，灰色帶是可信區間範圍。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: 不喜歡打工，且天氣晴天的情況下，分數在 30-200 點之間的學生的出勤概率 q 和它的 80% 可信區間範圍。圖中黑色實線是預測概率的事後分佈的中央值，灰色帶是可信區間範圍。
&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# ggsave(file=&amp;#39;output/fig5-9.png&amp;#39;, plot=p, dpi=300, w=4.5, h=3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;圖&lt;a href=&#34;#fig:validity-of-model&#34;&gt;4&lt;/a&gt;試圖把分數範圍在 30-200 之間的學生中，通過模型計算獲得的，在天氣晴朗，且不愛打工的孩子們的事後出勤概率的預測值(黑色實線)，和它的事後概率80%可信區間，以及對應的實際觀測值的結果(黑點)。但是，當預測變量越來越多，模型結果的可視化變得越來越困難。下面我們介紹兩種常見的評價邏輯回歸擬合結果的可視化圖。&lt;/p&gt;
&lt;p&gt;首先是圖 &lt;a href=&#34;#fig:validity-of-model1&#34;&gt;5&lt;/a&gt; 顯示的事後出勤概率，和實際觀察出勤結果之間的關係圖。在這個圖中，橫軸是 &lt;span class=&#34;math inline&#34;&gt;\(q[i]\)&lt;/span&gt; 的事後分佈的中央值(每名學生都有自己的事後出勤概率預測，它的中央值)，縱軸是該名學生實際是否在該次課上出勤的觀察結果。如果模型擬合的理想的話，那麼在 &lt;span class=&#34;math inline&#34;&gt;\(Y=0\)&lt;/span&gt;，也就是圖中的下半部分，大多數的預測點應該靠近概率較低的部分(也就是靠近左側)，同時，&lt;span class=&#34;math inline&#34;&gt;\(y = 1\)&lt;/span&gt; 的部分預測概率應該大多數在靠近左側的部分。此圖其實提示我們該模型的擬合效果不理想。不能明顯地將出勤與不出勤較爲準確地區分開來。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
ms &amp;lt;- rstan::extract(fit1)
d_qua &amp;lt;- t(apply(ms$q, 2, quantile, prob=c(0.1, 0.5, 0.9)))
colnames(d_qua) &amp;lt;- c(&amp;#39;p10&amp;#39;, &amp;#39;p50&amp;#39;, &amp;#39;p90&amp;#39;)
d_qua &amp;lt;- data.frame(d, d_qua)
d_qua$Y &amp;lt;- as.factor(d_qua$Y)
d_qua$A &amp;lt;- as.factor(d_qua$A)

p &amp;lt;- ggplot(data=d_qua, aes(x=Y, y=p50))
p &amp;lt;- p + theme_bw(base_size=18)
p &amp;lt;- p + coord_flip()
p &amp;lt;- p + geom_violin(trim=FALSE, size=1.5, color=&amp;#39;grey80&amp;#39;)
p &amp;lt;- p + geom_point(aes(color=A), position=position_jitter(w=0.4, h=0), size=1)
p &amp;lt;- p + scale_color_manual(values=c(&amp;#39;grey5&amp;#39;, &amp;#39;grey50&amp;#39;))
p &amp;lt;- p + labs(x=&amp;#39;Y&amp;#39;, y=&amp;#39;q&amp;#39;)
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:validity-of-model1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-27-logistic2-rstan_files/figure-html/validity-of-model1-1.png&#34; alt=&#34;把計算獲得的事後概率的中央值作爲每名學生是否出勤的概率預測(x 軸)，和實際觀察的出勤結果(y 軸)，繪製的散點圖。其中，灰色的小提琴圖其實是根據獲得的事後概率的中央值的概率密度曲線，繪製的上下對稱的圖形，形似小提琴。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: 把計算獲得的事後概率的中央值作爲每名學生是否出勤的概率預測(x 軸)，和實際觀察的出勤結果(y 軸)，繪製的散點圖。其中，灰色的小提琴圖其實是根據獲得的事後概率的中央值的概率密度曲線，繪製的上下對稱的圖形，形似小提琴。
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Rstan Wonderful R-(4)</title>
      <link>https://wangcc.me/post/logistic-rstan/</link>
      <pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/logistic-rstan/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#邏輯回歸模型的-rstan-貝葉斯實現&#34;&gt;邏輯回歸模型的 Rstan 貝葉斯實現&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#確定分析目的&#34;&gt;確定分析目的&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#確認數據分佈&#34;&gt;確認數據分佈&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#寫下數學模型表達式&#34;&gt;寫下數學模型表達式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#確認收斂效果&#34;&gt;確認收斂效果&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;邏輯回歸模型的-rstan-貝葉斯實現&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;邏輯回歸模型的 Rstan 貝葉斯實現&lt;/h1&gt;
&lt;p&gt;本小節使用的&lt;a href=&#34;https://raw.githubusercontent.com/MatsuuraKentaro/RStanBook/master/chap05/input/data-attendance-2.txt&#34;&gt;數據&lt;/a&gt;，和前一節的出勤率數據很類似:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;- read.table(&amp;quot;https://raw.githubusercontent.com/winterwang/RStanBook/master/chap05/input/data-attendance-2.txt&amp;quot;, 
                     sep = &amp;quot;,&amp;quot;, header = T)
head(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   PersonID A Score  M  Y
## 1        1 0    69 43 38
## 2        2 1   145 56 40
## 3        3 0   125 32 24
## 4        4 1    86 45 33
## 5        5 1   158 33 23
## 6        6 0   133 61 60&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;PersonID&lt;/code&gt;: 是學生的編號；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A&lt;/code&gt;, &lt;code&gt;Score&lt;/code&gt;: 和之前一樣用來預測出勤率的兩個預測變量，分別是表示是否喜歡打工的 &lt;code&gt;A&lt;/code&gt;，和表示對學習本身是否喜歡的評分 (滿分200)；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;M&lt;/code&gt;: 過去三個月內，該名學生一共需要上課的總課時數；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Y&lt;/code&gt;: 過去三個月內，該名學生實際上出勤的課時數。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;確定分析目的&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;確定分析目的&lt;/h1&gt;
&lt;p&gt;需要回答的問題依然是，&lt;span class=&#34;math inline&#34;&gt;\(A, Score\)&lt;/span&gt; 分別在多大程度上預測學生的出勤率？另外，我們希望知道的是，當需要修的課時數固定的事後，這兩個預測變量能準確提供 &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; 的多少信息？&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;確認數據分佈&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;確認數據分佈&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(GGally)

set.seed(1)
d &amp;lt;- d[, -1]
# d &amp;lt;- read.csv(file=&amp;#39;input/data-attendance-2.txt&amp;#39;)[,-1]
d$A &amp;lt;- as.factor(d$A)
d &amp;lt;- transform(d, ratio=Y/M)
N_col &amp;lt;- ncol(d)
ggp &amp;lt;- ggpairs(d, upper=&amp;#39;blank&amp;#39;, diag=&amp;#39;blank&amp;#39;, lower=&amp;#39;blank&amp;#39;)

for(i in 1:N_col) {
  x &amp;lt;- d[,i]
  p &amp;lt;- ggplot(data.frame(x, A=d$A), aes(x))
  p &amp;lt;- p + theme_bw(base_size=14)
  p &amp;lt;- p + theme(axis.text.x=element_text(angle=40, vjust=1, hjust=1))
  if (class(x) == &amp;#39;factor&amp;#39;) {
    p &amp;lt;- p + geom_bar(aes(fill=A), color=&amp;#39;grey20&amp;#39;)
  } else {
    bw &amp;lt;- (max(x)-min(x))/10
    p &amp;lt;- p + geom_histogram(aes(fill=A), color=&amp;#39;grey20&amp;#39;, binwidth=bw)
    p &amp;lt;- p + geom_line(eval(bquote(aes(y=..count..*.(bw)))), stat=&amp;#39;density&amp;#39;)
  }
  p &amp;lt;- p + geom_label(data=data.frame(x=-Inf, y=Inf, label=colnames(d)[i]), aes(x=x, y=y, label=label), hjust=0, vjust=1)
  p &amp;lt;- p + scale_fill_manual(values=alpha(c(&amp;#39;white&amp;#39;, &amp;#39;grey40&amp;#39;), 0.5))
  ggp &amp;lt;- putPlot(ggp, p, i, i)
}

zcolat &amp;lt;- seq(-1, 1, length=81)
zcolre &amp;lt;- c(zcolat[1:40]+1, rev(zcolat[41:81]))

for(i in 1:(N_col-1)) {
  for(j in (i+1):N_col) {
    x &amp;lt;- as.numeric(d[,i])
    y &amp;lt;- as.numeric(d[,j])
    r &amp;lt;- cor(x, y, method=&amp;#39;spearman&amp;#39;, use=&amp;#39;pairwise.complete.obs&amp;#39;)
    zcol &amp;lt;- lattice::level.colors(r, at=zcolat, col.regions=grey(zcolre))
    textcol &amp;lt;- ifelse(abs(r) &amp;lt; 0.4, &amp;#39;grey20&amp;#39;, &amp;#39;white&amp;#39;)
    ell &amp;lt;- ellipse::ellipse(r, level=0.95, type=&amp;#39;l&amp;#39;, npoints=50, scale=c(.2, .2), centre=c(.5, .5))
    p &amp;lt;- ggplot(data.frame(ell), aes(x=x, y=y))
    p &amp;lt;- p + theme_bw() + theme(
      plot.background=element_blank(),
      panel.grid.major=element_blank(), panel.grid.minor=element_blank(),
      panel.border=element_blank(), axis.ticks=element_blank()
    )
    p &amp;lt;- p + geom_polygon(fill=zcol, color=zcol)
    p &amp;lt;- p + geom_text(data=NULL, x=.5, y=.5, label=100*round(r, 2), size=6, col=textcol)
    ggp &amp;lt;- putPlot(ggp, p, i, j)
  }
}

for(j in 1:(N_col-1)) {
  for(i in (j+1):N_col) {
    x &amp;lt;- d[,j]
    y &amp;lt;- d[,i]
    p &amp;lt;- ggplot(data.frame(x, y, gr=d$A), aes(x=x, y=y, fill=gr, shape=gr))
    p &amp;lt;- p + theme_bw(base_size=14)
    p &amp;lt;- p + theme(axis.text.x=element_text(angle=40, vjust=1, hjust=1))
    if (class(x) == &amp;#39;factor&amp;#39;) {
      p &amp;lt;- p + geom_boxplot(aes(group=x), alpha=3/6, outlier.size=0, fill=&amp;#39;white&amp;#39;)
      p &amp;lt;- p + geom_point(position=position_jitter(w=0.4, h=0), size=2)
    } else {
      p &amp;lt;- p + geom_point(size=2)
    }
    p &amp;lt;- p + scale_shape_manual(values=c(21, 24))
    p &amp;lt;- p + scale_fill_manual(values=alpha(c(&amp;#39;white&amp;#39;, &amp;#39;grey40&amp;#39;), 0.5))
    ggp &amp;lt;- putPlot(ggp, p, i, j)
  }
}

ggp&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-27-logistic-rstan_files/figure-html/step1-1.png&#34; alt=&#34;三個變量的分佈觀察圖，相比之前增加了 $ratio = Y/M$ 列。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: 三個變量的分佈觀察圖，相比之前增加了 &lt;span class=&#34;math inline&#34;&gt;\(ratio = Y/M\)&lt;/span&gt; 列。
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;從圖 &lt;a href=&#34;#fig:step1&#34;&gt;1&lt;/a&gt; 還可以看出，由於總課時數越多，學生實際出勤的課時數也會越多所以 &lt;span class=&#34;math inline&#34;&gt;\(M, Y\)&lt;/span&gt; 兩者之間理應有很強的正相關。另外可能可以推測的是 &lt;span class=&#34;math inline&#34;&gt;\(Ratio\)&lt;/span&gt; 和是否愛學習的分數之間大概有可能有正相關，和是否喜歡打工之間大概可能有負相關。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;寫下數學模型表達式&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;寫下數學模型表達式&lt;/h1&gt;
&lt;p&gt;在 Stan 的語法中，使用的是反邏輯函數 (inverse logit): &lt;code&gt;inv_logit&lt;/code&gt; 來描述下面的邏輯回歸模型 5-4。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{array}{l}
q[n] = \text{inv_logit}(b_1 + b_2 A[n] + b_3Score[n]) &amp;amp; n = 1, 2, \dots, N \\
Y[n] \sim \text{Binomial}(M[n], q[n])                 &amp;amp; n = 1, 2, \dots, N \\
\end{array}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;上面的數學模型，可以被翻譯成下面的 Stan 語言:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data {
  int N; 
  int&amp;lt;lower=0, upper=1&amp;gt; A[N]; 
  real&amp;lt;lower=0, upper=1&amp;gt; Score[N]; 
  int&amp;lt;lower=0&amp;gt; M[N];
  int&amp;lt;lower=0&amp;gt; Y[N];
}

parameters {
  real b1; 
  real b2; 
  real b3;
}

transformed parameters {
  real q[N];
  for (n in 1:N) {
    q[n] = inv_logit(b1 + b2*A[n] + b3*Score[n]);
  }
}

model {
  for (n in 1:N) {
    Y[n] ~ binomial(M[n], q[n]); 
  }
}

generated quantities {
  real y_pred[N]; 
  for (n in 1:N) {
    y_pred[n] = binomial_rng(M[n], q[n]);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面的 R 代碼用來實現對上面 Stan 模型的擬合:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstan)
d &amp;lt;- read.csv(file=&amp;#39;https://raw.githubusercontent.com/winterwang/RStanBook/master/chap05/input/data-attendance-2.txt&amp;#39;, header = T)
data &amp;lt;- list(N=nrow(d), A=d$A, Score=d$Score/200, M=d$M, Y=d$Y)
fit &amp;lt;- stan(file=&amp;#39;stanfiles/model5-4.stan&amp;#39;, data=data, seed=1234)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;model5-4&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 1.5e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.129287 seconds (Warm-up)
## Chain 1:                0.13611 seconds (Sampling)
## Chain 1:                0.265397 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;model5-4&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 8e-06 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.131371 seconds (Warm-up)
## Chain 2:                0.133643 seconds (Sampling)
## Chain 2:                0.265014 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;model5-4&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 8e-06 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.128284 seconds (Warm-up)
## Chain 3:                0.133711 seconds (Sampling)
## Chain 3:                0.261995 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;model5-4&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 8e-06 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.128226 seconds (Warm-up)
## Chain 4:                0.140913 seconds (Sampling)
## Chain 4:                0.269139 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: model5-4.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##                mean se_mean   sd     2.5%      25%      50%      75%    97.5%
## b1             0.09    0.01 0.22    -0.37    -0.05     0.09     0.24     0.53
## b2            -0.62    0.00 0.09    -0.80    -0.68    -0.62    -0.56    -0.44
## b3             1.90    0.01 0.36     1.19     1.67     1.90     2.13     2.64
## q[1]           0.68    0.00 0.02     0.63     0.66     0.68     0.69     0.72
## q[2]           0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[3]           0.78    0.00 0.01     0.76     0.77     0.78     0.79     0.80
## q[4]           0.57    0.00 0.02     0.53     0.56     0.57     0.59     0.62
## q[5]           0.73    0.00 0.02     0.69     0.71     0.73     0.74     0.76
## q[6]           0.79    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[7]           0.76    0.00 0.01     0.73     0.75     0.76     0.77     0.78
## q[8]           0.70    0.00 0.02     0.67     0.69     0.70     0.72     0.74
## q[9]           0.81    0.00 0.01     0.79     0.81     0.81     0.82     0.84
## q[10]          0.81    0.00 0.01     0.79     0.80     0.81     0.82     0.84
## q[11]          0.69    0.00 0.02     0.66     0.68     0.69     0.70     0.72
## q[12]          0.80    0.00 0.01     0.78     0.79     0.80     0.81     0.82
## q[13]          0.64    0.00 0.01     0.62     0.63     0.64     0.65     0.67
## q[14]          0.76    0.00 0.01     0.73     0.75     0.76     0.77     0.78
## q[15]          0.76    0.00 0.01     0.73     0.75     0.76     0.76     0.78
## q[16]          0.60    0.00 0.02     0.57     0.59     0.60     0.61     0.64
## q[17]          0.76    0.00 0.01     0.74     0.76     0.76     0.77     0.79
## q[18]          0.70    0.00 0.02     0.66     0.69     0.71     0.72     0.74
## q[19]          0.86    0.00 0.02     0.83     0.85     0.86     0.87     0.89
## q[20]          0.72    0.00 0.02     0.69     0.71     0.72     0.73     0.76
## q[21]          0.57    0.00 0.02     0.53     0.56     0.57     0.59     0.62
## q[22]          0.62    0.00 0.02     0.59     0.61     0.62     0.63     0.65
## q[23]          0.62    0.00 0.02     0.59     0.61     0.62     0.63     0.65
## q[24]          0.70    0.00 0.02     0.67     0.69     0.70     0.71     0.73
## q[25]          0.64    0.00 0.01     0.61     0.63     0.64     0.65     0.67
## q[26]          0.67    0.00 0.01     0.64     0.66     0.67     0.68     0.69
## q[27]          0.77    0.00 0.01     0.75     0.76     0.77     0.78     0.79
## q[28]          0.77    0.00 0.01     0.75     0.76     0.77     0.78     0.79
## q[29]          0.83    0.00 0.01     0.81     0.83     0.84     0.84     0.86
## q[30]          0.76    0.00 0.01     0.74     0.75     0.76     0.77     0.79
## q[31]          0.74    0.00 0.02     0.70     0.73     0.74     0.75     0.78
## q[32]          0.54    0.00 0.03     0.49     0.53     0.54     0.56     0.60
## q[33]          0.69    0.00 0.01     0.66     0.68     0.69     0.70     0.72
## q[34]          0.66    0.00 0.01     0.63     0.65     0.66     0.67     0.69
## q[35]          0.78    0.00 0.01     0.76     0.78     0.78     0.79     0.81
## q[36]          0.79    0.00 0.01     0.77     0.78     0.79     0.80     0.81
## q[37]          0.62    0.00 0.02     0.58     0.60     0.62     0.63     0.65
## q[38]          0.76    0.00 0.01     0.73     0.75     0.76     0.77     0.78
## q[39]          0.72    0.00 0.02     0.68     0.71     0.72     0.73     0.75
## q[40]          0.72    0.00 0.02     0.68     0.70     0.72     0.73     0.75
## q[41]          0.79    0.00 0.01     0.76     0.78     0.79     0.80     0.81
## q[42]          0.79    0.00 0.01     0.77     0.79     0.80     0.80     0.82
## q[43]          0.78    0.00 0.01     0.75     0.77     0.78     0.79     0.80
## q[44]          0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[45]          0.86    0.00 0.02     0.83     0.85     0.86     0.87     0.89
## q[46]          0.75    0.00 0.01     0.72     0.74     0.75     0.76     0.77
## q[47]          0.64    0.00 0.03     0.57     0.62     0.64     0.66     0.70
## q[48]          0.82    0.00 0.01     0.79     0.81     0.82     0.83     0.84
## q[49]          0.74    0.00 0.01     0.71     0.73     0.74     0.75     0.76
## q[50]          0.60    0.00 0.02     0.57     0.59     0.60     0.61     0.64
## y_pred[1]     29.19    0.05 3.21    23.00    27.00    29.00    31.00    35.00
## y_pred[2]     39.25    0.06 3.56    32.00    37.00    39.00    42.00    46.00
## y_pred[3]     25.07    0.04 2.38    20.00    24.00    25.00    27.00    29.00
## y_pred[4]     25.76    0.06 3.43    19.00    23.00    26.00    28.00    32.00
## y_pred[5]     23.89    0.04 2.62    19.00    22.00    24.00    26.00    29.00
## y_pred[6]     48.46    0.05 3.24    42.00    46.00    49.00    51.00    54.00
## y_pred[7]     37.21    0.05 3.10    31.00    35.00    37.00    39.00    43.00
## y_pred[8]     53.44    0.07 4.12    45.00    51.00    54.00    56.00    61.00
## y_pred[9]     63.52    0.06 3.54    56.00    61.00    64.00    66.00    70.00
## y_pred[10]    51.98    0.05 3.21    45.00    50.00    52.00    54.00    58.00
## y_pred[11]    23.50    0.05 2.73    18.00    22.00    24.00    25.00    29.00
## y_pred[12]    35.26    0.04 2.68    30.00    33.00    35.00    37.00    40.00
## y_pred[13]    34.17    0.06 3.53    27.00    32.00    34.00    37.00    41.00
## y_pred[14]    30.39    0.04 2.73    25.00    29.00    30.00    32.00    35.00
## y_pred[15]    42.23    0.05 3.23    36.00    40.00    42.00    44.00    48.00
## y_pred[16]    35.48    0.06 3.88    28.00    33.00    36.00    38.00    43.00
## y_pred[17]    28.97    0.04 2.69    23.00    27.00    29.00    31.00    34.00
## y_pred[18]    31.67    0.05 3.12    25.00    30.00    32.00    34.00    38.00
## y_pred[19]    38.81    0.04 2.39    34.00    37.00    39.00    40.00    43.00
## y_pred[20]    55.48    0.07 4.26    47.00    53.00    56.00    58.00    63.00
## y_pred[21]    40.16    0.07 4.39    32.00    37.00    40.00    43.00    49.00
## y_pred[22]    47.97    0.08 4.48    39.00    45.00    48.00    51.00    56.03
## y_pred[23]    38.94    0.06 3.89    32.00    36.00    39.00    42.00    46.00
## y_pred[24]    47.35    0.06 3.87    40.00    45.00    47.00    50.00    55.00
## y_pred[25]    32.10    0.06 3.42    25.00    30.00    32.00    34.00    39.00
## y_pred[26]    34.02    0.05 3.38    27.00    32.00    34.00    36.00    40.00
## y_pred[27]    22.42    0.04 2.29    18.00    21.00    23.00    24.00    27.00
## y_pred[28]    28.59    0.04 2.57    23.00    27.00    29.00    30.00    33.00
## y_pred[29]    15.08    0.02 1.59    12.00    14.00    15.00    16.00    18.00
## y_pred[30]    37.37    0.05 3.02    31.00    35.00    37.00    39.00    43.00
## y_pred[31]    55.42    0.07 4.05    47.00    53.00    56.00    58.00    63.00
## y_pred[32]     6.50    0.03 1.75     3.00     5.00     7.00     8.00    10.00
## y_pred[33]    15.82    0.04 2.24    11.00    14.00    16.00    17.00    20.00
## y_pred[34]    24.33    0.05 2.88    19.00    22.00    24.00    26.00    30.00
## y_pred[35]    46.26    0.05 3.27    39.00    44.00    46.00    49.00    52.00
## y_pred[36]    43.51    0.05 3.06    37.00    41.75    44.00    46.00    49.00
## y_pred[37]    54.28    0.08 4.82    45.00    51.00    54.00    58.00    63.00
## y_pred[38]    35.60    0.05 3.04    29.00    34.00    36.00    38.00    41.00
## y_pred[39]    15.84    0.04 2.19    11.00    14.00    16.00    17.00    20.00
## y_pred[40]    29.39    0.05 2.98    23.00    27.00    29.00    31.00    35.00
## y_pred[41]    45.05    0.05 3.14    39.00    43.00    45.00    47.00    51.00
## y_pred[42]    25.43    0.04 2.34    21.00    24.00    26.00    27.00    30.00
## y_pred[43]    41.18    0.05 3.07    35.00    39.00    41.00    43.00    47.00
## y_pred[44]    25.37    0.03 2.16    21.00    24.00    25.00    27.00    29.00
## y_pred[45]    19.76    0.03 1.74    16.00    19.00    20.00    21.00    23.00
## y_pred[46]    38.21    0.05 3.19    32.00    36.00    38.00    40.00    44.00
## y_pred[47]    14.09    0.04 2.37     9.00    12.00    14.00    16.00    18.00
## y_pred[48]    31.20    0.04 2.41    26.00    30.00    31.00    33.00    36.00
## y_pred[49]    16.90    0.03 2.12    12.00    16.00    17.00    18.00    21.00
## y_pred[50]    40.34    0.07 4.25    32.00    37.00    40.00    43.00    48.00
## lp__       -1389.32    0.03 1.20 -1392.42 -1389.91 -1389.01 -1388.42 -1387.95
##            n_eff Rhat
## b1          1443    1
## b2          2052    1
## b3          1519    1
## q[1]        1523    1
## q[2]        2412    1
## q[3]        2751    1
## q[4]        2023    1
## q[5]        2065    1
## q[6]        2718    1
## q[7]        2352    1
## q[8]        2345    1
## q[9]        2443    1
## q[10]       2467    1
## q[11]       2561    1
## q[12]       2648    1
## q[13]       3089    1
## q[14]       2352    1
## q[15]       2267    1
## q[16]       2372    1
## q[17]       2483    1
## q[18]       1617    1
## q[19]       1891    1
## q[20]       2106    1
## q[21]       2023    1
## q[22]       2727    1
## q[23]       2642    1
## q[24]       2484    1
## q[25]       3065    1
## q[26]       3059    1
## q[27]       2648    1
## q[28]       2648    1
## q[29]       2149    1
## q[30]       2439    1
## q[31]       1948    1
## q[32]       1839    1
## q[33]       2682    1
## q[34]       3131    1
## q[35]       2757    1
## q[36]       2743    1
## q[37]       2600    1
## q[38]       2309    1
## q[39]       1707    1
## q[40]       1691    1
## q[41]       2757    1
## q[42]       2718    1
## q[43]       2713    1
## q[44]       2398    1
## q[45]       1913    1
## q[46]       2111    1
## q[47]       1470    1
## q[48]       2354    1
## q[49]       1919    1
## q[50]       2372    1
## y_pred[1]   3738    1
## y_pred[2]   3669    1
## y_pred[3]   3582    1
## y_pred[4]   3362    1
## y_pred[5]   3706    1
## y_pred[6]   3914    1
## y_pred[7]   3706    1
## y_pred[8]   3447    1
## y_pred[9]   3934    1
## y_pred[10]  3907    1
## y_pred[11]  3488    1
## y_pred[12]  4354    1
## y_pred[13]  3685    1
## y_pred[14]  3854    1
## y_pred[15]  3715    1
## y_pred[16]  3841    1
## y_pred[17]  3972    1
## y_pred[18]  3780    1
## y_pred[19]  3683    1
## y_pred[20]  3505    1
## y_pred[21]  3841    1
## y_pred[22]  3432    1
## y_pred[23]  3919    1
## y_pred[24]  3814    1
## y_pred[25]  3828    1
## y_pred[26]  3793    1
## y_pred[27]  3778    1
## y_pred[28]  4052    1
## y_pred[29]  4096    1
## y_pred[30]  3820    1
## y_pred[31]  3352    1
## y_pred[32]  3583    1
## y_pred[33]  3970    1
## y_pred[34]  3628    1
## y_pred[35]  3789    1
## y_pred[36]  3968    1
## y_pred[37]  3355    1
## y_pred[38]  3092    1
## y_pred[39]  3815    1
## y_pred[40]  3738    1
## y_pred[41]  4172    1
## y_pred[42]  4290    1
## y_pred[43]  3624    1
## y_pred[44]  4023    1
## y_pred[45]  3531    1
## y_pred[46]  3976    1
## y_pred[47]  3218    1
## y_pred[48]  3811    1
## y_pred[49]  3951    1
## y_pred[50]  3826    1
## lp__        1381    1
## 
## Samples were drawn using NUTS(diag_e) at Tue Jan  7 14:48:25 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;把獲得的參數事後樣本的均值代入上面的數學模型中可得:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{array}{l}
q[n] = \text{inv_logit}(0.09 - 0.62 A[n] + 1.90Score[n]) &amp;amp; n = 1, 2, \dots, N \\
Y[n] \sim \text{Binomial}(M[n], q[n])                 &amp;amp; n = 1, 2, \dots, N \\
\end{array}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;確認收斂效果&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;確認收斂效果&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(bayesplot)

color_scheme_set(&amp;quot;mix-brightblue-gray&amp;quot;)

posterior2 &amp;lt;- rstan::extract(fit, inc_warmup = TRUE, permuted = FALSE)

p &amp;lt;- mcmc_trace(posterior2, n_warmup = 0, pars = c(&amp;quot;b1&amp;quot;, &amp;quot;b2&amp;quot;, &amp;quot;b3&amp;quot;, &amp;quot;lp__&amp;quot;),
                facet_args = list(nrow = 2, labeller = label_parsed))
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step53&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-27-logistic-rstan_files/figure-html/step53-1.png&#34; alt=&#34;用 bayesplot包數繪製的模型5-3的MCMC鏈式軌跡圖 (trace plot)。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: 用 bayesplot包數繪製的模型5-3的MCMC鏈式軌跡圖 (trace plot)。
&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ms &amp;lt;- rstan::extract(fit)

d_qua &amp;lt;- t(apply(ms$y_pred, 2, quantile, prob=c(0.1, 0.5, 0.9)))
colnames(d_qua) &amp;lt;- c(&amp;#39;p10&amp;#39;, &amp;#39;p50&amp;#39;, &amp;#39;p90&amp;#39;)
d_qua &amp;lt;- data.frame(d, d_qua)
d_qua$A &amp;lt;- as.factor(d_qua$A)

p &amp;lt;- ggplot(data=d_qua, aes(x=Y, y=p50, ymin=p10, ymax=p90, shape=A, fill=A))
p &amp;lt;- p + theme_bw(base_size=18) + theme(legend.key.height=grid::unit(2.5,&amp;#39;line&amp;#39;))
p &amp;lt;- p + coord_fixed(ratio=1, xlim=c(5, 70), ylim=c(5, 70))
p &amp;lt;- p + geom_pointrange(size=0.8, color=&amp;#39;grey5&amp;#39;)
p &amp;lt;- p + geom_abline(aes(slope=1, intercept=0), color=&amp;#39;black&amp;#39;, alpha=3/5, linetype=&amp;#39;31&amp;#39;)
p &amp;lt;- p + scale_shape_manual(values=c(21, 24))
p &amp;lt;- p + scale_fill_manual(values=c(&amp;#39;white&amp;#39;, &amp;#39;grey70&amp;#39;))
p &amp;lt;- p + labs(x=&amp;#39;Observed&amp;#39;, y=&amp;#39;Predicted&amp;#39;)
p &amp;lt;- p + scale_x_continuous(breaks=seq(from=0, to=70, by=20))
p &amp;lt;- p + scale_y_continuous(breaks=seq(from=0, to=70, by=20))
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:fig58&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-27-logistic-rstan_files/figure-html/fig58-1.png&#34; alt=&#34;觀測值(x)，和預測值(y)的散點圖，以及預測值的80%預測區間。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: 觀測值(x)，和預測值(y)的散點圖，以及預測值的80%預測區間。
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Rstan Wonderful R-(3)</title>
      <link>https://wangcc.me/post/rstan-wonderful-r3/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/rstan-wonderful-r3/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#多重回歸-multiple-regression&#34;&gt;多重回歸 multiple regression&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#step-1.-確認數據分佈&#34;&gt;Step 1. 確認數據分佈&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-2.-寫下數學模型&#34;&gt;Step 2. 寫下數學模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-3.-看圖確認模型擬合狀況&#34;&gt;Step 3. 看圖確認模型擬合狀況&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-4.-mcmc-樣本的散點圖矩陣&#34;&gt;Step 4. MCMC 樣本的散點圖矩陣&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;多重回歸-multiple-regression&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;多重回歸 multiple regression&lt;/h1&gt;
&lt;p&gt;本章使用的數據，大學生出勤記錄也是&lt;a href=&#34;https://raw.githubusercontent.com/winterwang/RStanBook/master/chap05/input/data-attendance-1.txt&#34;&gt;架空的數據&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;有大學記錄了50名大學生的出勤狀況：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A,Score,Y
0,69,0.286
1,145,0.196
0,125,0.261
1,86,0.109
1,158,0.23
0,133,0.35
0,111,0.33
1,147,0.194
0,146,0.413
0,145,0.36
1,141,0.225
0,137,0.423
1,118,0.186
0,111,0.287
...
0,99,0.268
1,99,0.234&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;: 是學生大學二年級時進行的問卷調查時回答是否喜歡打零工的結果（0:不喜歡打工；1:喜歡打工）&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Score\)&lt;/span&gt;: 是大學二年級時進行的問卷調查時計算的該學生對學習是否感興趣的數值評分(200分滿分，分數越高，該學生越熱愛學習)&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;: 是該學生一年內的出勤率&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在本次分析範例中，把&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;出勤率當作是連續型結果變量，我們來用Stan實施多重回歸分析，回答學生喜歡打零工與否，和學生對學習的熱情程度兩個變量能解釋多少出勤率。&lt;/p&gt;
&lt;div id=&#34;step-1.-確認數據分佈&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1. 確認數據分佈&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# The following figure codes come from the authors website: 
# https://github.com/MatsuuraKentaro/RStanBook/blob/master/chap05/fig5-1.R
library(ggplot2)
library(GGally)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;GGally&amp;#39;:
##   method from   
##   +.gg   ggplot2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
d &amp;lt;- read.csv(file=&amp;#39;https://raw.githubusercontent.com/winterwang/RStanBook/master/chap05/input/data-attendance-1.txt&amp;#39;, header = T)
d$A &amp;lt;- as.factor(d$A)

N_col &amp;lt;- ncol(d)
ggp &amp;lt;- ggpairs(d, upper=&amp;#39;blank&amp;#39;, diag=&amp;#39;blank&amp;#39;, lower=&amp;#39;blank&amp;#39;)

for(i in 1:N_col) {
  x &amp;lt;- d[,i]
  p &amp;lt;- ggplot(data.frame(x, A=d$A), aes(x))
  p &amp;lt;- p + theme_bw(base_size=14)
  p &amp;lt;- p + theme(axis.text.x=element_text(angle=40, vjust=1, hjust=1))
  if (class(x) == &amp;#39;factor&amp;#39;) {
    p &amp;lt;- p + geom_bar(aes(fill=A), color=&amp;#39;grey5&amp;#39;)
  } else {
    bw &amp;lt;- (max(x)-min(x))/10
    p &amp;lt;- p + geom_histogram(binwidth=bw, aes(fill=A), color=&amp;#39;grey5&amp;#39;) #繪製柱狀圖
    p &amp;lt;- p + geom_line(eval(bquote(aes(y=..count..*.(bw)))), stat=&amp;#39;density&amp;#39;) #添加概率密度曲線
  }
  p &amp;lt;- p + geom_label(data=data.frame(x=-Inf, y=Inf, label=colnames(d)[i]), aes(x=x, y=y, label=label), hjust=0, vjust=1)
  p &amp;lt;- p + scale_fill_manual(values=alpha(c(&amp;#39;white&amp;#39;, &amp;#39;grey40&amp;#39;), 0.5))
  ggp &amp;lt;- putPlot(ggp, p, i, i)
}

zcolat &amp;lt;- seq(-1, 1, length=81)
zcolre &amp;lt;- c(zcolat[1:40]+1, rev(zcolat[41:81]))

for(i in 1:(N_col-1)) {
  for(j in (i+1):N_col) {
    x &amp;lt;- as.numeric(d[,i])
    y &amp;lt;- as.numeric(d[,j])
    r &amp;lt;- cor(x, y, method=&amp;#39;spearman&amp;#39;, use=&amp;#39;pairwise.complete.obs&amp;#39;)
    zcol &amp;lt;- lattice::level.colors(r, at=zcolat, col.regions=grey(zcolre))
    textcol &amp;lt;- ifelse(abs(r) &amp;lt; 0.4, &amp;#39;grey20&amp;#39;, &amp;#39;white&amp;#39;)
    ell &amp;lt;- ellipse::ellipse(r, level=0.95, type=&amp;#39;l&amp;#39;, npoints=50, scale=c(.2, .2), centre=c(.5, .5))
    p &amp;lt;- ggplot(data.frame(ell), aes(x=x, y=y))
    p &amp;lt;- p + theme_bw() + theme(
      plot.background=element_blank(),
      panel.grid.major=element_blank(), panel.grid.minor=element_blank(),
      panel.border=element_blank(), axis.ticks=element_blank()
    )
    p &amp;lt;- p + geom_polygon(fill=zcol, color=zcol)
    p &amp;lt;- p + geom_text(data=NULL, x=.5, y=.5, label=100*round(r, 2), size=6, col=textcol)
    ggp &amp;lt;- putPlot(ggp, p, i, j)
  }
}

for(j in 1:(N_col-1)) {
  for(i in (j+1):N_col) {
    x &amp;lt;- d[,j]
    y &amp;lt;- d[,i]
    p &amp;lt;- ggplot(data.frame(x, y, gr=d$A), aes(x=x, y=y, fill=gr, shape=gr))
    p &amp;lt;- p + theme_bw(base_size=14)
    p &amp;lt;- p + theme(axis.text.x=element_text(angle=40, vjust=1, hjust=1))
    if (class(x) == &amp;#39;factor&amp;#39;) {
      p &amp;lt;- p + geom_boxplot(aes(group=x), alpha=3/6, outlier.size=0, fill=&amp;#39;white&amp;#39;)
      p &amp;lt;- p + geom_point(position=position_jitter(w=0.4, h=0), size=2)
    } else {
      p &amp;lt;- p + geom_point(size=2)
    }
    p &amp;lt;- p + scale_shape_manual(values=c(21, 24))
    p &amp;lt;- p + scale_fill_manual(values=alpha(c(&amp;#39;white&amp;#39;, &amp;#39;grey40&amp;#39;), 0.5))
    ggp &amp;lt;- putPlot(ggp, p, i, j)
  }
}

ggp&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-22-rstan-wonderful-r-multi-lm_files/figure-html/step1-1.png&#34; alt=&#34;三個變量的分佈觀察圖，對角線上是三個變量各自的柱狀圖 (histogram) 和計算獲得的概率密度函數曲線；左下角三個圖是三個變量的箱式圖和散點圖；右上角三個圖是三個變量兩兩計算獲得的 Spearman 秩相關乘以100之後的數值。對角線上及左下角三個圖中數據點和形狀的不同分別表示學生喜歡(三角形)和不喜歡(圓形)打工。右上角表示秩相關的數值越接近0，顏色越白圖形越接近圓形，相關係數的絕對值越接近1，則顏色越深，橢圓越細長。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: 三個變量的分佈觀察圖，對角線上是三個變量各自的柱狀圖 (histogram) 和計算獲得的概率密度函數曲線；左下角三個圖是三個變量的箱式圖和散點圖；右上角三個圖是三個變量兩兩計算獲得的 Spearman 秩相關乘以100之後的數值。對角線上及左下角三個圖中數據點和形狀的不同分別表示學生喜歡(三角形)和不喜歡(圓形)打工。右上角表示秩相關的數值越接近0，顏色越白圖形越接近圓形，相關係數的絕對值越接近1，則顏色越深，橢圓越細長。
&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# png(file=&amp;#39;output/fig5-1.png&amp;#39;, w=1600, h=1600, res=300)
# print(ggp, left=0.3, bottom=0.3)
# dev.off()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2.-寫下數學模型&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2. 寫下數學模型&lt;/h2&gt;
&lt;p&gt;Model can be written as (Model5-1):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{array}{l}
Y[n]        = b_1 + b_2A[n] + b_3Sore[n] + \varepsilon [n]&amp;amp;  n = 1,2,\dots,N \\
\varepsilon[n] \sim \text{Normal}(0, \sigma) &amp;amp; n = 1,2,\dots,N \\ 
\end{array}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; 表示學生的人數，&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;則是學生編號的下標；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_1\)&lt;/span&gt; 是回歸直線的截距；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_2\)&lt;/span&gt; 是&lt;span class=&#34;math inline&#34;&gt;\(Score\)&lt;/span&gt;保持不變時，&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;從&lt;span class=&#34;math inline&#34;&gt;\(0\rightarrow 1\)&lt;/span&gt;時出勤率的變化(增加，或者減少)；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_3\)&lt;/span&gt; 是&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;保持不變時，&lt;span class=&#34;math inline&#34;&gt;\(Score\)&lt;/span&gt;增加一個單位時出勤率的變化(增加，或者減少)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Model can also be written as (Model5-2):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{array}{l}
Y[n]       \sim \text{Normal}(b_1 + b_2A[n] + b_3Score[n], \sigma) &amp;amp;  n = 1,2,\dots,N \\
\end{array}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果認爲&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(Score\)&lt;/span&gt;所能預測的出勤率有一個基礎的均值 &lt;span class=&#34;math inline&#34;&gt;\(\mu[n]\)&lt;/span&gt;，剩下的每名學生的出勤率服從這個均值和標準差爲 &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; 的正態分佈，那麼模型又可以繼續改寫成爲下面的 Model 5-3:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{array}{l}
\mu[n]        = b_1 + b_2A[n] + b_3Sore[n] &amp;amp;  n = 1,2,\dots,N \\
Y[n] \sim \text{Normal}(\mu[n], \sigma) &amp;amp; n = 1,2,\dots,N \\ 
\end{array}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;下面的 Stan 模型是按照 Model 5-3 寫的，它的模型參數有四個，&lt;span class=&#34;math inline&#34;&gt;\(b_1, b_2, b_3, \sigma\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(\mu[n]\)&lt;/span&gt;通過 &lt;code&gt;transformed parameter&lt;/code&gt; 計算獲得:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data {
  int N; 
  int&amp;lt;lower=0, upper=1&amp;gt; A[N];
  real&amp;lt;lower=0, upper=1&amp;gt; Score[N];
  real&amp;lt;lower=0, upper=1&amp;gt; Y[N];
}

parameters {
  real b1; 
  real b2;
  real b3;
  real&amp;lt;lower=0&amp;gt; sigma;
}

transformed parameters {
  real mu[N];
  for (n in 1:N) {
    mu[n] = b1 + b2*A[n] + b3*Score[n];
  }
}

model {
  for (n in 1:N) {
    Y[n] ~ normal(mu[n], sigma);
  }
}

generated quantities {
  real y_pred[N];
  for (n in 1:N) {
    y_pred[n] = normal_rng(mu[n], sigma);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面的 R 代碼用來實現對上面 Stan 模型的擬合:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstan)
d &amp;lt;- read.csv(file=&amp;#39;https://raw.githubusercontent.com/winterwang/RStanBook/master/chap05/input/data-attendance-1.txt&amp;#39;, header = T)
data &amp;lt;- list(N=nrow(d), A=d$A, Score=d$Score/200, Y=d$Y)
fit &amp;lt;- stan(file=&amp;#39;stanfiles/model5-3.stan&amp;#39;, data=data, seed=1234)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;model5-3&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 2e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.116273 seconds (Warm-up)
## Chain 1:                0.117482 seconds (Sampling)
## Chain 1:                0.233755 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;model5-3&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 8e-06 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.114043 seconds (Warm-up)
## Chain 2:                0.109094 seconds (Sampling)
## Chain 2:                0.223137 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;model5-3&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 6e-06 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.114931 seconds (Warm-up)
## Chain 3:                0.10347 seconds (Sampling)
## Chain 3:                0.218401 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;model5-3&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 7e-06 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.121109 seconds (Warm-up)
## Chain 4:                0.115413 seconds (Sampling)
## Chain 4:                0.236522 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: model5-3.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
## b1           0.12    0.00 0.03   0.06   0.10   0.12   0.15   0.19  1707    1
## b2          -0.14    0.00 0.02  -0.18  -0.15  -0.14  -0.13  -0.11  2308    1
## b3           0.32    0.00 0.05   0.22   0.29   0.32   0.36   0.42  1747    1
## sigma        0.05    0.00 0.01   0.04   0.05   0.05   0.06   0.06  2065    1
## mu[1]        0.24    0.00 0.02   0.20   0.22   0.24   0.25   0.27  1827    1
## mu[2]        0.22    0.00 0.01   0.19   0.21   0.22   0.22   0.24  2610    1
## mu[3]        0.33    0.00 0.01   0.31   0.32   0.33   0.33   0.35  3101    1
## mu[4]        0.12    0.00 0.02   0.09   0.11   0.12   0.13   0.15  2251    1
## mu[5]        0.24    0.00 0.01   0.21   0.23   0.24   0.25   0.27  2377    1
## mu[6]        0.34    0.00 0.01   0.32   0.33   0.34   0.35   0.36  3091    1
## mu[7]        0.30    0.00 0.01   0.28   0.30   0.30   0.31   0.32  2666    1
## mu[8]        0.22    0.00 0.01   0.19   0.21   0.22   0.23   0.24  2572    1
## mu[9]        0.36    0.00 0.01   0.34   0.35   0.36   0.37   0.38  2841    1
## mu[10]       0.36    0.00 0.01   0.34   0.35   0.36   0.37   0.38  2863    1
## mu[11]       0.21    0.00 0.01   0.18   0.20   0.21   0.22   0.23  2684    1
## mu[12]       0.35    0.00 0.01   0.33   0.34   0.35   0.35   0.37  3032    1
## mu[13]       0.17    0.00 0.01   0.15   0.16   0.17   0.18   0.20  2864    1
## mu[14]       0.30    0.00 0.01   0.28   0.30   0.30   0.31   0.32  2666    1
## mu[15]       0.30    0.00 0.01   0.28   0.29   0.30   0.31   0.32  2592    1
## mu[16]       0.14    0.00 0.01   0.11   0.13   0.14   0.15   0.17  2477    1
## mu[17]       0.31    0.00 0.01   0.29   0.30   0.31   0.31   0.33  2777    1
## mu[18]       0.26    0.00 0.01   0.23   0.25   0.26   0.27   0.28  1935    1
## mu[19]       0.42    0.00 0.02   0.39   0.41   0.42   0.44   0.46  2192    1
## mu[20]       0.23    0.00 0.01   0.20   0.22   0.23   0.24   0.26  2413    1
## mu[21]       0.12    0.00 0.02   0.09   0.11   0.12   0.13   0.15  2251    1
## mu[22]       0.16    0.00 0.01   0.13   0.15   0.16   0.16   0.18  2714    1
## mu[23]       0.15    0.00 0.01   0.13   0.14   0.15   0.16   0.18  2653    1
## mu[24]       0.21    0.00 0.01   0.19   0.20   0.21   0.22   0.24  2647    1
## mu[25]       0.17    0.00 0.01   0.15   0.16   0.17   0.18   0.19  2855    1
## mu[26]       0.19    0.00 0.01   0.16   0.18   0.19   0.20   0.21  2867    1
## mu[27]       0.32    0.00 0.01   0.30   0.31   0.32   0.32   0.34  2994    1
## mu[28]       0.32    0.00 0.01   0.30   0.31   0.32   0.32   0.34  2994    1
## mu[29]       0.38    0.00 0.01   0.36   0.38   0.38   0.39   0.41  2507    1
## mu[30]       0.31    0.00 0.01   0.29   0.30   0.31   0.31   0.33  2740    1
## mu[31]       0.25    0.00 0.02   0.22   0.24   0.25   0.26   0.28  2266    1
## mu[32]       0.10    0.00 0.02   0.07   0.09   0.10   0.11   0.13  2090    1
## mu[33]       0.20    0.00 0.01   0.18   0.20   0.20   0.21   0.23  2737    1
## mu[34]       0.18    0.00 0.01   0.16   0.17   0.18   0.19   0.20  2885    1
## mu[35]       0.33    0.00 0.01   0.31   0.32   0.33   0.33   0.35  3109    1
## mu[36]       0.34    0.00 0.01   0.32   0.33   0.34   0.34   0.36  3109    1
## mu[37]       0.15    0.00 0.01   0.13   0.14   0.15   0.16   0.18  2622    1
## mu[38]       0.30    0.00 0.01   0.28   0.30   0.30   0.31   0.32  2629    1
## mu[39]       0.27    0.00 0.01   0.24   0.26   0.27   0.28   0.29  2033    1
## mu[40]       0.27    0.00 0.01   0.24   0.26   0.27   0.27   0.29  2016    1
## mu[41]       0.33    0.00 0.01   0.31   0.33   0.33   0.34   0.35  3117    1
## mu[42]       0.34    0.00 0.01   0.32   0.33   0.34   0.35   0.36  3091    1
## mu[43]       0.32    0.00 0.01   0.30   0.31   0.32   0.33   0.34  3059    1
## mu[44]       0.36    0.00 0.01   0.34   0.36   0.36   0.37   0.39  2796    1
## mu[45]       0.42    0.00 0.02   0.38   0.41   0.42   0.43   0.45  2220    1
## mu[46]       0.29    0.00 0.01   0.27   0.29   0.29   0.30   0.31  2445    1
## mu[47]       0.21    0.00 0.02   0.17   0.19   0.21   0.22   0.25  1757    1
## mu[48]       0.37    0.00 0.01   0.34   0.36   0.37   0.37   0.39  2752    1
## mu[49]       0.28    0.00 0.01   0.26   0.28   0.28   0.29   0.31  2253    1
## mu[50]       0.14    0.00 0.01   0.11   0.13   0.14   0.15   0.17  2477    1
## y_pred[1]    0.24    0.00 0.05   0.13   0.20   0.24   0.27   0.34  3502    1
## y_pred[2]    0.22    0.00 0.05   0.11   0.18   0.21   0.25   0.32  3776    1
## y_pred[3]    0.33    0.00 0.05   0.22   0.29   0.33   0.36   0.43  4029    1
## y_pred[4]    0.12    0.00 0.05   0.01   0.08   0.12   0.16   0.23  3814    1
## y_pred[5]    0.24    0.00 0.05   0.13   0.20   0.23   0.27   0.35  3842    1
## y_pred[6]    0.34    0.00 0.05   0.24   0.30   0.34   0.37   0.45  4033    1
## y_pred[7]    0.30    0.00 0.05   0.20   0.27   0.30   0.34   0.41  3727    1
## y_pred[8]    0.22    0.00 0.05   0.11   0.18   0.22   0.25   0.32  3946    1
## y_pred[9]    0.36    0.00 0.05   0.26   0.32   0.36   0.39   0.47  3768    1
## y_pred[10]   0.36    0.00 0.05   0.26   0.33   0.36   0.40   0.46  3771    1
## y_pred[11]   0.21    0.00 0.05   0.11   0.17   0.21   0.25   0.31  3793    1
## y_pred[12]   0.35    0.00 0.05   0.24   0.31   0.35   0.38   0.45  3946    1
## y_pred[13]   0.17    0.00 0.05   0.07   0.14   0.17   0.21   0.28  3833    1
## y_pred[14]   0.30    0.00 0.05   0.20   0.27   0.30   0.34   0.41  3925    1
## y_pred[15]   0.30    0.00 0.05   0.20   0.27   0.30   0.34   0.41  3654    1
## y_pred[16]   0.14    0.00 0.05   0.03   0.10   0.14   0.18   0.25  3850    1
## y_pred[17]   0.31    0.00 0.05   0.20   0.27   0.31   0.34   0.41  3951    1
## y_pred[18]   0.26    0.00 0.05   0.15   0.22   0.26   0.29   0.37  4036    1
## y_pred[19]   0.42    0.00 0.06   0.31   0.39   0.42   0.46   0.53  3723    1
## y_pred[20]   0.23    0.00 0.05   0.13   0.20   0.23   0.27   0.34  3819    1
## y_pred[21]   0.12    0.00 0.05   0.01   0.08   0.12   0.15   0.23  3751    1
## y_pred[22]   0.15    0.00 0.05   0.05   0.12   0.15   0.19   0.26  3798    1
## y_pred[23]   0.15    0.00 0.05   0.05   0.12   0.15   0.19   0.26  3729    1
## y_pred[24]   0.21    0.00 0.05   0.11   0.18   0.21   0.25   0.32  4087    1
## y_pred[25]   0.17    0.00 0.05   0.07   0.13   0.17   0.20   0.27  3712    1
## y_pred[26]   0.19    0.00 0.05   0.08   0.15   0.19   0.22   0.29  3800    1
## y_pred[27]   0.32    0.00 0.05   0.21   0.28   0.32   0.35   0.42  3845    1
## y_pred[28]   0.32    0.00 0.05   0.21   0.28   0.32   0.35   0.42  3892    1
## y_pred[29]   0.38    0.00 0.05   0.28   0.35   0.38   0.42   0.49  3995    1
## y_pred[30]   0.31    0.00 0.05   0.20   0.27   0.31   0.34   0.41  3878    1
## y_pred[31]   0.25    0.00 0.05   0.14   0.21   0.25   0.28   0.35  3631    1
## y_pred[32]   0.10    0.00 0.06  -0.01   0.06   0.10   0.14   0.21  3584    1
## y_pred[33]   0.20    0.00 0.05   0.10   0.17   0.20   0.24   0.31  3110    1
## y_pred[34]   0.18    0.00 0.05   0.08   0.15   0.18   0.22   0.29  3853    1
## y_pred[35]   0.33    0.00 0.05   0.22   0.29   0.33   0.36   0.43  4012    1
## y_pred[36]   0.34    0.00 0.05   0.23   0.30   0.34   0.37   0.44  4012    1
## y_pred[37]   0.15    0.00 0.05   0.04   0.11   0.15   0.19   0.25  4071    1
## y_pred[38]   0.30    0.00 0.05   0.20   0.27   0.30   0.34   0.41  4043    1
## y_pred[39]   0.27    0.00 0.05   0.16   0.23   0.27   0.30   0.37  3757    1
## y_pred[40]   0.27    0.00 0.05   0.16   0.23   0.27   0.30   0.37  3630    1
## y_pred[41]   0.33    0.00 0.05   0.22   0.30   0.33   0.37   0.44  3497    1
## y_pred[42]   0.34    0.00 0.05   0.24   0.30   0.34   0.37   0.45  4219    1
## y_pred[43]   0.32    0.00 0.05   0.22   0.29   0.32   0.35   0.43  4143    1
## y_pred[44]   0.36    0.00 0.05   0.26   0.33   0.36   0.40   0.47  4066    1
## y_pred[45]   0.42    0.00 0.05   0.31   0.38   0.42   0.46   0.53  3410    1
## y_pred[46]   0.29    0.00 0.05   0.19   0.26   0.29   0.33   0.40  4211    1
## y_pred[47]   0.21    0.00 0.06   0.10   0.17   0.21   0.24   0.32  3319    1
## y_pred[48]   0.37    0.00 0.05   0.26   0.33   0.37   0.40   0.47  3699    1
## y_pred[49]   0.28    0.00 0.05   0.18   0.25   0.28   0.32   0.39  4135    1
## y_pred[50]   0.14    0.00 0.05   0.03   0.10   0.14   0.17   0.24  3753    1
## lp__       120.89    0.04 1.47 117.17 120.14 121.24 121.98 122.70  1620    1
## 
## Samples were drawn using NUTS(diag_e) at Wed Jan  8 22:23:46 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上述代碼中值得注意的是我們對 &lt;span class=&#34;math inline&#34;&gt;\(Score\)&lt;/span&gt; 進行了全部除以 &lt;span class=&#34;math inline&#34;&gt;\(200\)&lt;/span&gt; 的數據縮放調整 (scaling)。這樣有助於我們的模型在進行 MCMC 計算時加速其達到收斂時所需要的時間。&lt;/p&gt;
&lt;p&gt;把計算獲得的事後模型參數平均值代入模型 Model 5-3:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{array}{l}
\mu[n]        = 0.12 - 0.14A[n] + 0.32Sore[n] &amp;amp;  n = 1,2,\dots,N \\
Y[n] \sim \text{Normal}(\mu[n], 0.05) &amp;amp; n = 1,2,\dots,N \\ 
\end{array}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;從輸出的結果報告來看，所有的 &lt;code&gt;Rhat&lt;/code&gt; 都小於1.1，可以認爲採樣已經達到收斂效果，再來確認一下軌跡圖：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(bayesplot)

color_scheme_set(&amp;quot;mix-brightblue-gray&amp;quot;)

posterior2 &amp;lt;- rstan::extract(fit, inc_warmup = TRUE, permuted = FALSE)

p &amp;lt;- mcmc_trace(posterior2, n_warmup = 0, pars = c(&amp;quot;b1&amp;quot;, &amp;quot;b2&amp;quot;, &amp;quot;b3&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;lp__&amp;quot;),
                facet_args = list(nrow = 2, labeller = label_parsed))
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step53&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-22-rstan-wonderful-r-multi-lm_files/figure-html/step53-1.png&#34; alt=&#34;用 bayesplot包數繪製的模型5-3的MCMC鏈式軌跡圖 (trace plot)。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: 用 bayesplot包數繪製的模型5-3的MCMC鏈式軌跡圖 (trace plot)。
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;收斂效果很不錯，下面來解釋回歸係數的事後均值的涵義：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;b3&lt;/code&gt;的事後均值是&lt;span class=&#34;math inline&#34;&gt;\(0.32\)&lt;/span&gt;，所以，&lt;span class=&#34;math inline&#34;&gt;\(Score=150\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(Score=50\)&lt;/span&gt;的兩名學生，當他們同時都是喜歡或者同時都不喜歡打工時，&lt;span class=&#34;math inline&#34;&gt;\(Score = 150\)&lt;/span&gt;的學生的出勤率平均比 &lt;span class=&#34;math inline&#34;&gt;\(Score = 50\)&lt;/span&gt; 的學生的出勤率高 &lt;span class=&#34;math inline&#34;&gt;\(0.32 \times (150-50)/200 = 0.16\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;b2&lt;/code&gt;的事後均值是&lt;span class=&#34;math inline&#34;&gt;\(-0.14\)&lt;/span&gt;，所以，同樣地，&lt;span class=&#34;math inline&#34;&gt;\(Score\)&lt;/span&gt;相同的兩名學生，喜歡打工的學生比不喜歡打工的學生出勤率平均要低 &lt;span class=&#34;math inline&#34;&gt;\(0.14\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3.-看圖確認模型擬合狀況&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3. 看圖確認模型擬合狀況&lt;/h2&gt;
&lt;p&gt;下圖繪製了上面貝葉斯多重線性回歸模型計算獲得的事後貝葉斯預測區間，和觀測值&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;出勤率之間的直觀關係：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;source(&amp;quot;commonRstan.R&amp;quot;)

ms &amp;lt;- rstan::extract(fit)

Score_new &amp;lt;- 50:200
N_X &amp;lt;- length(Score_new)
N_mcmc &amp;lt;- length(ms$lp__)

set.seed(1234)
y_base_mcmc &amp;lt;- as.data.frame(matrix(nrow=N_mcmc, ncol=N_X))
y_base_a0_mcmc &amp;lt;- as.data.frame(matrix(nrow = N_mcmc, ncol = N_X))
y_mcmc &amp;lt;- as.data.frame(matrix(nrow=N_mcmc, ncol=N_X))
y_a0_mcmc &amp;lt;- as.data.frame(matrix(nrow=N_mcmc, ncol=N_X))

for (i in 1:N_X) {
  y_base_mcmc[,i] &amp;lt;- ms$b1 + ms$b2 + ms$b3 * Score_new[i]/200
  y_base_a0_mcmc[] &amp;lt;- ms$b1 + ms$b2*0 + ms$b3 * Score_new[i]/200
  y_mcmc[,i] &amp;lt;- rnorm(n=N_mcmc, mean=y_base_mcmc[,i], sd=ms$sigma)
  y_a0_mcmc[,i] &amp;lt;- rnorm(n=N_mcmc, mean=y_base_a0_mcmc[,i], sd=ms$sigma)
}

customize.ggplot.axis &amp;lt;- function(p) {
  p &amp;lt;- p + labs(x=&amp;#39;Score&amp;#39;, y=&amp;#39;Y&amp;#39;)
  p &amp;lt;- p + scale_y_continuous(breaks=seq(from=-0.2, to=0.8, by=0.2))
  p &amp;lt;- p + coord_cartesian(xlim=c(50, 200), ylim=c(-0.2, 0.6))
  return(p)
}

d_est &amp;lt;- data.frame.quantile.mcmc(x=Score_new, y_mcmc=y_mcmc)
d_esta0 &amp;lt;- data.frame.quantile.mcmc(x=Score_new, y_mcmc=y_a0_mcmc)
# p &amp;lt;- ggplot.5quantile(data=d_est)
# p2 &amp;lt;- ggplot.5quantile(data = d_esta0)
# p &amp;lt;- p + geom_point(data=d[d$A==1, ], aes(x=Score, y=Y), shape=24, size=5)
# p2 &amp;lt;- p2 + geom_point(data=d[d$A==0, ], aes(x=Score, y=Y), shape=1, size=5)
# p &amp;lt;- customize.ggplot.axis(p)
# p2 &amp;lt;- customize.ggplot.axis(p2)

visuals = rbind(d_est,d_esta0)
visuals$A=c(rep(1,151),rep(0,151)) # 151 points of each flavour

qn &amp;lt;- colnames(visuals)[-1]
p &amp;lt;- ggplot(data=visuals, aes(x=X, y=p50, group = A))
p &amp;lt;- p + my_theme()
p &amp;lt;- p + geom_ribbon(aes_string(ymin=qn[1], ymax=qn[5]), fill=&amp;#39;black&amp;#39;, alpha=1/6)
p &amp;lt;- p + geom_ribbon(aes_string(ymin=qn[2], ymax=qn[4]), fill=&amp;#39;black&amp;#39;, alpha=2/6)
p &amp;lt;- p + geom_line(size=1)
p &amp;lt;- p + geom_point(data=d[d$A==1, ], aes(x=Score, y=Y), shape=24, size=5)
p &amp;lt;- p + geom_point(data=d[d$A==0, ], aes(x=Score, y=Y), shape=20, size=5)
p &amp;lt;- customize.ggplot.axis(p)
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:fig52&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-22-rstan-wonderful-r-multi-lm_files/figure-html/fig52-1.png&#34; alt=&#34;黑色原點(不喜歡打工)，和無色三角形(喜歡打工)的學生的出勤率，和模型計算獲得的貝葉斯事後預測區間。黑色線是中位數，灰色帶是50%預測區間和95%預測區間。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: 黑色原點(不喜歡打工)，和無色三角形(喜歡打工)的學生的出勤率，和模型計算獲得的貝葉斯事後預測區間。黑色線是中位數，灰色帶是50%預測區間和95%預測區間。
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;上述觀察預測值區間和實際觀測之間的關係的視覺化圖形，在多重線性回歸模型只有兩個預測變量的事後還較爲容易獲得，當模型中有三個或以上的預測變量時，可視化變得困難重重。&lt;/p&gt;
&lt;p&gt;此時我們推薦繪製“實際觀測值和預測值”，以及模型給出的每個預測值的隨機誤差&lt;span class=&#34;math inline&#34;&gt;\(\varepsilon\)&lt;/span&gt;分佈範圍，相結合的圖形來判斷模型擬合程度。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_qua &amp;lt;- t(apply(ms$y_pred, 2, quantile, prob=c(0.1, 0.5, 0.9)))
colnames(d_qua) &amp;lt;- c(&amp;#39;p10&amp;#39;, &amp;#39;p50&amp;#39;, &amp;#39;p90&amp;#39;)
d_qua &amp;lt;- data.frame(d, d_qua)
d_qua$A &amp;lt;- as.factor(d_qua$A)

p &amp;lt;- ggplot(data=d_qua, aes(x=Y, y=p50, ymin=p10, ymax=p90, shape=A, fill=A))
p &amp;lt;- p + theme_bw(base_size=18) + theme(legend.key.height=grid::unit(2.5,&amp;#39;line&amp;#39;))
p &amp;lt;- p + coord_fixed(ratio=1, xlim=c(0, 0.5), ylim=c(0, 0.5))
p &amp;lt;- p + geom_pointrange(size=0.8, color=&amp;#39;grey5&amp;#39;)
p &amp;lt;- p + geom_abline(aes(slope=1, intercept=0), color=&amp;#39;black&amp;#39;, alpha=3/5, linetype=&amp;#39;31&amp;#39;)
p &amp;lt;- p + scale_shape_manual(values=c(21, 24))
p &amp;lt;- p + scale_fill_manual(values=c(&amp;#39;white&amp;#39;, &amp;#39;grey70&amp;#39;))
p &amp;lt;- p + labs(x=&amp;#39;Observed&amp;#39;, y=&amp;#39;Predicted&amp;#39;)
p &amp;lt;- p + scale_x_continuous(breaks=seq(from=0, to=0.5, by=0.1))
p &amp;lt;- p + scale_y_continuous(breaks=seq(from=0, to=0.5, by=0.1))
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:fig53&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-22-rstan-wonderful-r-multi-lm_files/figure-html/fig53-1.png&#34; alt=&#34;觀測值(x)，和預測值(y)的散點圖，以及預測值的80%預測區間。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: 觀測值(x)，和預測值(y)的散點圖，以及預測值的80%預測區間。
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;從上圖中可以看出，大多數的觀測點和預測點以及預測的80%區間基本都在 &lt;span class=&#34;math inline&#34;&gt;\(y = x\)&lt;/span&gt; 這條對角線上。大致可以認爲本次貝葉斯多重線性回歸擬合效果尚且能夠接受。&lt;/p&gt;
&lt;p&gt;隨機誤差 &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon[n]\)&lt;/span&gt; 被認爲服從 &lt;span class=&#34;math inline&#34;&gt;\(\text{Normal}(0, \sigma)\)&lt;/span&gt; 的正態分佈。從模型中可以計算獲得每個學生出勤率的預測值和實際觀測值之間的差，這就是隨機誤差。貝葉斯框架之下，我們實際獲得的會是每名學生隨機誤差的分佈：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;N_mcmc &amp;lt;- length(ms$lp__)

d_noise &amp;lt;- data.frame(t(-t(ms$mu) + d$Y))
colnames(d_noise) &amp;lt;- paste0(&amp;#39;noise&amp;#39;, 1:nrow(d))
d_est &amp;lt;- data.frame(mcmc=1:N_mcmc, d_noise)
d_melt &amp;lt;- reshape2::melt(d_est, id=c(&amp;#39;mcmc&amp;#39;), variable.name=&amp;#39;X&amp;#39;)

d_mode &amp;lt;- data.frame(t(apply(d_noise, 2, function(x) {
  dens &amp;lt;- density(x)
  mode_i &amp;lt;- which.max(dens$y)
  mode_x &amp;lt;- dens$x[mode_i]
  mode_y &amp;lt;- dens$y[mode_i]
  c(mode_x, mode_y)
})))
colnames(d_mode) &amp;lt;- c(&amp;#39;X&amp;#39;, &amp;#39;Y&amp;#39;)

p &amp;lt;- ggplot()
p &amp;lt;- p + theme_bw(base_size=18)
p &amp;lt;- p + geom_line(data=d_melt, aes(x=value, group=X), stat=&amp;#39;density&amp;#39;, color=&amp;#39;black&amp;#39;, alpha=0.4)
p &amp;lt;- p + geom_segment(data=d_mode, aes(x=X, xend=X, y=Y, yend=0), color=&amp;#39;black&amp;#39;, linetype=&amp;#39;dashed&amp;#39;, alpha=0.4)
p &amp;lt;- p + geom_rug(data=d_mode, aes(x=X), sides=&amp;#39;b&amp;#39;)
p &amp;lt;- p + labs(x=&amp;#39;value&amp;#39;, y=&amp;#39;density&amp;#39;)
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:fig54left&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-22-rstan-wonderful-r-multi-lm_files/figure-html/fig54left-1.png&#34; alt=&#34;每名學生的出勤率隨機誤差的分佈&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: 每名學生的出勤率隨機誤差的分佈
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;實際上我們只需要選取每名學生模型計算獲得的事後隨機誤差的代表值，比如可以是平均值，中央值，或者是MAP值（事後確率最大推定値，maximum a posteriori estimate），來觀察就可以了：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s_dens &amp;lt;- density(ms$s)
s_MAP &amp;lt;- s_dens$x[which.max(s_dens$y)]
bw &amp;lt;- 0.01
p &amp;lt;- ggplot(data=d_mode, aes(x=X))
p &amp;lt;- p + theme_bw(base_size=18)
p &amp;lt;- p + geom_histogram(binwidth=bw, color=&amp;#39;black&amp;#39;, fill=&amp;#39;white&amp;#39;)
p &amp;lt;- p + geom_density(eval(bquote(aes(y=..count..*.(bw)))), alpha=0.5, color=&amp;#39;black&amp;#39;, fill=&amp;#39;gray20&amp;#39;)
p &amp;lt;- p + stat_function(fun=function(x) nrow(d)*bw*dnorm(x, mean=0, sd=s_MAP), linetype=&amp;#39;dashed&amp;#39;)
p &amp;lt;- p + labs(x=&amp;#39;value&amp;#39;, y=&amp;#39;count&amp;#39;)
p &amp;lt;- p + xlim(range(density(d_mode$X)$x))
p&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 2 rows containing missing values (geom_bar).&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:fig54right&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-22-rstan-wonderful-r-multi-lm_files/figure-html/fig54right-1.png&#34; alt=&#34;每名學生事後出勤率隨機誤差的MAP值的柱狀圖，和相應的概率密度函數（灰色鐘罩），點狀虛線是均值爲0，標準差是模型計算的事後隨機誤差標準差的 MAP 值的正態分佈的形狀。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 6: 每名學生事後出勤率隨機誤差的MAP值的柱狀圖，和相應的概率密度函數（灰色鐘罩），點狀虛線是均值爲0，標準差是模型計算的事後隨機誤差標準差的 MAP 值的正態分佈的形狀。
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4.-mcmc-樣本的散點圖矩陣&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 4. MCMC 樣本的散點圖矩陣&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(GGally)
library(hexbin)


d &amp;lt;- data.frame(b1=ms$b1, b2=ms$b2, b3=ms$b3, sigma=ms$sigma, mu1=ms$mu[,1], mu50=ms$mu[,50], lp__=ms$lp__)
N_col &amp;lt;- ncol(d)
ggp &amp;lt;- ggpairs(d, upper=&amp;#39;blank&amp;#39;, diag=&amp;#39;blank&amp;#39;, lower=&amp;#39;blank&amp;#39;)

label_list &amp;lt;- list(b1=&amp;#39;b1&amp;#39;, b2=&amp;#39;b2&amp;#39;, b3=&amp;#39;b3&amp;#39;, sigma=&amp;#39;sigma&amp;#39;, mu1=&amp;#39;mu[1]&amp;#39;, mu50=&amp;#39;mu[50]&amp;#39;, lp__=&amp;#39;lp__&amp;#39;)
for(i in 1:N_col) {
  x &amp;lt;- d[,i]
  bw &amp;lt;- (max(x)-min(x))/10
  p &amp;lt;- ggplot(data.frame(x), aes(x))
  p &amp;lt;- p + theme_bw(base_size=14)
  p &amp;lt;- p + theme(axis.text.x=element_text(angle=60, vjust=1, hjust=1))
  p &amp;lt;- p + geom_histogram(binwidth=bw, fill=&amp;#39;white&amp;#39;, color=&amp;#39;grey5&amp;#39;)
  p &amp;lt;- p + geom_line(eval(bquote(aes(y=..count..*.(bw)))), stat=&amp;#39;density&amp;#39;)
  p &amp;lt;- p + geom_label(data=data.frame(x=-Inf, y=Inf, label=label_list[[colnames(d)[i]]]), aes(x=x, y=y, label=label), hjust=0, vjust=1)
  ggp &amp;lt;- putPlot(ggp, p, i, i)
}

zcolat &amp;lt;- seq(-1, 1, length=81)
zcolre &amp;lt;- c(zcolat[1:40]+1, rev(zcolat[41:81]))

for(i in 1:(N_col-1)) {
  for(j in (i+1):N_col) {
    x &amp;lt;- as.numeric(d[,i])
    y &amp;lt;- as.numeric(d[,j])
    r &amp;lt;- cor(x, y, method=&amp;#39;spearman&amp;#39;, use=&amp;#39;pairwise.complete.obs&amp;#39;)
    zcol &amp;lt;- lattice::level.colors(r, at=zcolat, col.regions=grey(zcolre))
    textcol &amp;lt;- ifelse(abs(r) &amp;lt; 0.4, &amp;#39;grey20&amp;#39;, &amp;#39;white&amp;#39;)
    ell &amp;lt;- ellipse::ellipse(r, level=0.95, type=&amp;#39;l&amp;#39;, npoints=50, scale=c(.2, .2), centre=c(.5, .5))
    p &amp;lt;- ggplot(data.frame(ell), aes(x=x, y=y))
    p &amp;lt;- p + theme_bw() + theme(
      plot.background=element_blank(),
      panel.grid.major=element_blank(), panel.grid.minor=element_blank(),
      panel.border=element_blank(), axis.ticks=element_blank()
    )
    p &amp;lt;- p + geom_polygon(fill=zcol, color=zcol)
    p &amp;lt;- p + geom_text(data=NULL, x=.5, y=.5, label=100*round(r, 2), size=6, col=textcol)
    ggp &amp;lt;- putPlot(ggp, p, i, j)
  }
}

for(j in 1:(N_col-1)) {
  for(i in (j+1):N_col) {
    x &amp;lt;- d[,j]
    y &amp;lt;- d[,i]
    p &amp;lt;- ggplot(data.frame(x, y), aes(x=x, y=y))
    p &amp;lt;- p + theme_bw(base_size=14)
    p &amp;lt;- p + theme(axis.text.x=element_text(angle=60, vjust=1, hjust=1))
    p &amp;lt;- p + geom_hex()
    p &amp;lt;- p + scale_fill_gradientn(colours=gray.colors(7, start=0.1, end=0.9))
    ggp &amp;lt;- putPlot(ggp, p, i, j)
  }
}
ggp&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:fig55&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-22-rstan-wonderful-r-multi-lm_files/figure-html/fig55-1.png&#34; alt=&#34;MCMC樣本的事後矩陣。對角線上是各個參數事後樣本的柱狀圖和相應的概率密度曲線。右上角是各個參數事後樣本之間的 Spearman 秩相關係數。左下角是兩兩的散點圖。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 7: MCMC樣本的事後矩陣。對角線上是各個參數事後樣本的柱狀圖和相應的概率密度曲線。右上角是各個參數事後樣本之間的 Spearman 秩相關係數。左下角是兩兩的散點圖。
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simple linear regression using Rstan--Rstan Wonderful R-(2)</title>
      <link>https://wangcc.me/post/simple-linear-regression-using-rstan/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/simple-linear-regression-using-rstan/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#step-1-確認數據分佈&#34;&gt;Step 1, 確認數據分佈&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-2-描述線性模型&#34;&gt;Step 2, 描述線性模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-3-寫下stan模型&#34;&gt;Step 3, 寫下Stan模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-4-診斷stan貝葉斯模型的收斂程度&#34;&gt;Step 4, 診斷Stan貝葉斯模型的收斂程度&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-5修改mcmc條件設定&#34;&gt;Step 5，修改MCMC條件設定&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-6-並行平行計算的設定&#34;&gt;Step 6, 並行（平行）計算的設定&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-7-計算貝葉斯可信區間和貝葉斯預測區間&#34;&gt;Step 7, 計算貝葉斯可信區間和貝葉斯預測區間&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#練習題&#34;&gt;練習題&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/winterwang/RStanBook/master/chap04/input/data-salary.txt&#34;&gt;數據 data-salary.txt&lt;/a&gt;是架空的。&lt;/p&gt;
&lt;p&gt;某公司社員的年齡 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;（歲），和年收入 &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;（萬日元）的數據如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;X,Y
24,472
24,403
26,454
32,575
33,546
35,781
38,750
40,601
40,814
43,792
43,745
44,837
48,868
52,988
56,1092
56,1007
57,1233
58,1202
59,1123
59,1314
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;年收入 &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; 被認爲是由基本年收 &lt;span class=&#34;math inline&#34;&gt;\(y_{base}\)&lt;/span&gt; 和其他影響因素 &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon\)&lt;/span&gt; 構成。由於該公司是典型的年功序列式的日本傳統企業，所以基本年收本身和社員年齡成正比例。 &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon\)&lt;/span&gt; 則被認爲是由該員工當年的業績等隨機誤差造成的，但是所有員工的 &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon\)&lt;/span&gt; 的均值被認爲是零。&lt;/p&gt;
&lt;p&gt;g分析目的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;借用這個數據來分析並回答如下的問題：在該公司如果採用了一名50歲的員工，他/她的年收入的預期值會是多少。&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;step-1-確認數據分佈&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1, 確認數據分佈&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Salary &amp;lt;- read.table(&amp;quot;https://raw.githubusercontent.com/winterwang/RStanBook/master/chap04/input/data-salary.txt&amp;quot;, 
                     sep = &amp;quot;,&amp;quot;, header = T)
library(ggplot2)

ggplot(Salary, aes(x = X, y = Y)) + 
  geom_point(shape = 1, size = 4)  + theme(plot.subtitle = element_text(vjust = 1), 
    plot.caption = element_text(vjust = 1), 
    axis.line = element_line(colour = &amp;quot;bisque4&amp;quot;, 
        size = 0.2, linetype = &amp;quot;solid&amp;quot;), 
    axis.ticks = element_line(size = 0.7), 
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 16, colour = &amp;quot;gray0&amp;quot;), 
    panel.background = element_rect(fill = &amp;quot;gray98&amp;quot;)) +
  scale_y_continuous(limits = c(200, 1400), breaks = c(200, 600, 1000, 1400))&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-15-simple-linear-regression-using-rstan_files/figure-html/step1-1.png&#34; alt=&#34;橫軸爲 $X$，縱軸爲 $Y$ 的散點圖&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: 橫軸爲 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;，縱軸爲 &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; 的散點圖
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;從這個散點圖的特徵可以看出年收入確實似乎和年齡呈線性正相關。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-描述線性模型&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2, 描述線性模型&lt;/h2&gt;
&lt;p&gt;這個簡單線性回歸模型的數學表達式可以描述如下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{array}{l}
Y[n]        = y_{base}[n] + \varepsilon [n]&amp;amp;  n = 1,2,\dots,N \\
y_{base}[n] = a + bX[n]                    &amp;amp;  n = 1,2,\dots,N \\
\varepsilon[n] \sim \text{Normal}(0, \sigma) &amp;amp; n = 1,2,\dots,N \\ 
\end{array}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同樣的模型你可以簡化描述成爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Y[n] \sim \text{Normal}(a + bX[n], \sigma)\;\; n = 1,2,\dots,N
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那麼如果一個統計師只有經過傳統概率論觀點的訓練，他/她會在R裏面這樣來分析這個數據：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res_lm &amp;lt;- lm(Y ~ X, data = Salary)
summary(res_lm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Y ~ X, data = Salary)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -155.471  -51.523   -6.663   52.822  141.349 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) -119.697     68.148  -1.756    0.096 .  
## X             21.904      1.518  14.428 2.47e-11 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 79.1 on 18 degrees of freedom
## Multiple R-squared:  0.9204, Adjusted R-squared:  0.916 
## F-statistic: 208.2 on 1 and 18 DF,  p-value: 2.466e-11&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 用這個線性回歸模型來對上面模型中的參數作出預測：

X_new &amp;lt;- data.frame(X=23:60)
conf_95 &amp;lt;- predict(res_lm, X_new, interval = &amp;quot;confidence&amp;quot;, level = 0.95)
pred_95 &amp;lt;- predict(res_lm, X_new, interval = &amp;quot;prediction&amp;quot;, level = 0.95)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;temp_var &amp;lt;- predict(res_lm, interval=&amp;quot;prediction&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in predict.lm(res_lm, interval = &amp;quot;prediction&amp;quot;): predictions on current data refer to _future_ responses&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_df &amp;lt;- cbind(Salary, temp_var)

ggplot(new_df, aes(x = X, y = Y)) + 
  geom_point(shape = 1, size = 4)  + theme(plot.subtitle = element_text(vjust = 1), 
    plot.caption = element_text(vjust = 1), 
    axis.line = element_line(colour = &amp;quot;bisque4&amp;quot;, 
        size = 0.2, linetype = &amp;quot;solid&amp;quot;), 
    axis.ticks = element_line(size = 0.7), 
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 16, colour = &amp;quot;gray0&amp;quot;), 
    panel.background = element_rect(fill = &amp;quot;gray98&amp;quot;)) + 
  geom_smooth(method = lm, se=TRUE, size = 0.3)+
  scale_y_continuous(limits = c(200, 1400), breaks = c(200, 600, 1000, 1400)) +
   geom_line(aes(y=lwr), color = &amp;quot;red&amp;quot;, linetype = &amp;quot;dashed&amp;quot;)+
    geom_line(aes(y=upr), color = &amp;quot;red&amp;quot;, linetype = &amp;quot;dashed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-15-simple-linear-regression-using-rstan_files/figure-html/step2-1.png&#34; alt=&#34;用簡單線性回歸模型計算的基本年收的信賴區間(灰色陰影)和預測區間(紅色點線)。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: 用簡單線性回歸模型計算的基本年收的信賴區間(灰色陰影)和預測區間(紅色點線)。
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-寫下stan模型&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3, 寫下Stan模型&lt;/h2&gt;
&lt;pre class=&#34;stan&#34;&gt;&lt;code&gt;data {
    int N; 
    real X[N]; 
    real Y[N];
}

parameters {
    real a;
    real b;
    real&amp;lt;lower=0&amp;gt; sigma;
}

model {
    for(n in 1:N) {
        Y[n] ~ normal(a + b*X[n], sigma);
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;參數部分 &lt;code&gt;real&amp;lt;lower=0&amp;gt; sigma&lt;/code&gt; 的代碼表示標準差不可採集負數作爲樣本。&lt;/p&gt;
&lt;p&gt;實際運行上面的Stan代碼：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstan)
data &amp;lt;- list(N=nrow(Salary), X=Salary$X, Y = Salary$Y)
fit &amp;lt;- sampling(model4_5, data, seed = 1234) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;5b73686886069c0bad70513d4ea4141a&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 1.5e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.093322 seconds (Warm-up)
## Chain 1:                0.054914 seconds (Sampling)
## Chain 1:                0.148236 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;5b73686886069c0bad70513d4ea4141a&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 4e-06 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.098838 seconds (Warm-up)
## Chain 2:                0.061329 seconds (Sampling)
## Chain 2:                0.160167 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;5b73686886069c0bad70513d4ea4141a&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 4e-06 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.091017 seconds (Warm-up)
## Chain 3:                0.053765 seconds (Sampling)
## Chain 3:                0.144782 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;5b73686886069c0bad70513d4ea4141a&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 4e-06 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.100685 seconds (Warm-up)
## Chain 4:                0.062005 seconds (Sampling)
## Chain 4:                0.16269 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: 5b73686886069c0bad70513d4ea4141a.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##          mean se_mean    sd    2.5%     25%     50%    75%  97.5% n_eff Rhat
## a     -117.45    1.93 71.31 -257.66 -164.65 -119.17 -71.98  23.17  1358 1.00
## b       21.86    0.04  1.60   18.68   20.83   21.89  22.91  24.97  1331 1.00
## sigma   84.51    0.41 15.21   61.09   73.72   82.41  93.18 120.03  1381 1.01
## lp__   -93.61    0.04  1.26  -96.86  -94.19  -93.27 -92.69 -92.14  1164 1.01
## 
## Samples were drawn using NUTS(diag_e) at Mon May 18 14:21:36 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;輸出結果的前三行，是該次MCMC的設定條件，其中模型名稱是Rmarkdown文件中隨機產生的。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;第二行則說明的是該次MCMC進行了4條鏈的採樣，每條鏈2000次，其中前1000次被當作是 burn-in (或者叫 warmup)。可以看到一共獲得了4000個事後樣本。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;接下來的五行是參數的事後樣本的事後分析總結，一共有11列。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第1列是參數名稱，最後一個 &lt;code&gt;lp__&lt;/code&gt;是Stan特有的算法得到的產物，具體解釋爲對數事後概率 (log posterior)，當然它也需要得到收斂才行。&lt;/li&gt;
&lt;li&gt;第2列是獲得的4000個參數的事後樣本的事後平均值(posterior mean)。例如&lt;code&gt;b&lt;/code&gt;（回歸直線的斜率）的事後平均值是21.96，也就是說年齡每增加一歲，基本年收入平均增加21.96萬日元。你可以和之前的概率論算法相比較(&lt;code&gt;b = 21.904&lt;/code&gt;)。&lt;/li&gt;
&lt;li&gt;第3列&lt;code&gt;se_mean&lt;/code&gt;是事後平均值的標準誤(standard error of posterior mean)。說白了是MCMC事後樣本的方差除以第10列的有效樣本量&lt;code&gt;n_eff&lt;/code&gt;之後取根號獲得的值。&lt;/li&gt;
&lt;li&gt;第4列&lt;code&gt;sd&lt;/code&gt;是MCMC事後樣本的標準差(standard deviation of posterior MCMC sample)。&lt;/li&gt;
&lt;li&gt;第5-9列是MCMC事後樣本的四分位點。也就是貝葉斯統計算法獲得的事後可信區間。&lt;/li&gt;
&lt;li&gt;第10列&lt;code&gt;n_eff&lt;/code&gt;是Stan在基於事後樣本自相關程度來判斷的有效事後樣本量大小。爲了有效地計算和繪製事後分佈的統計量，這個有效樣本量需要至少有100個以上吧（作者觀點）。如果報告給出的事後有效樣本量過小的話也是模型收斂不佳的表現之一。&lt;/li&gt;
&lt;li&gt;第11列&lt;code&gt;Rhat&lt;/code&gt;&lt;span class=&#34;math inline&#34;&gt;\((\hat R)\)&lt;/span&gt;是主要用於判斷模型是否達到收斂的重要指標，每個參數都會被計算一個&lt;code&gt;Rhat&lt;/code&gt;值。當MCMC鏈條數在3以上，且同時所有的模型參數的 &lt;code&gt;Rhat &amp;lt; 1.1&lt;/code&gt;的話，可以認爲模型達到了良好的收斂。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4-診斷stan貝葉斯模型的收斂程度&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 4, 診斷Stan貝葉斯模型的收斂程度&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggmcmc)

ggmcmc(ggs(fit, inc_warmup = TRUE, stan_include_auxiliar = TRUE), plot = &amp;quot;traceplot&amp;quot;, dev_type_html = &amp;quot;png&amp;quot;, 
       file = &amp;quot;trace.html&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面的代碼，會自動生成四個模型參數的軌跡MCMC鏈式圖報告。&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step4&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;../../static/img/traceplot-model4-5.png&#34; alt=&#34;用ggmcmc函數製作而成的MCMC鏈式圖報告。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: 用ggmcmc函數製作而成的MCMC鏈式圖報告。
&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(bayesplot)

color_scheme_set(&amp;quot;mix-brightblue-gray&amp;quot;)

posterior2 &amp;lt;- rstan::extract(fit, inc_warmup = TRUE, permuted = FALSE)

p &amp;lt;- mcmc_trace(posterior2, n_warmup = 0,
                facet_args = list(nrow = 2, labeller = label_parsed))
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step41&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-15-simple-linear-regression-using-rstan_files/figure-html/step41-1.png&#34; alt=&#34;用 bayesplot包數繪製的MCMC鏈式圖。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: 用 bayesplot包數繪製的MCMC鏈式圖。
&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- mcmc_acf_bar(posterior2)
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step42&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-15-simple-linear-regression-using-rstan_files/figure-html/step42-1.png&#34; alt=&#34;用 bayesplot包數繪製的事後樣本自相關圖(autocorrelation)。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: 用 bayesplot包數繪製的事後樣本自相關圖(autocorrelation)。
&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- mcmc_dens_overlay(posterior2, color_chains = T)
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step43&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-15-simple-linear-regression-using-rstan_files/figure-html/step43-1.png&#34; alt=&#34;用 bayesplot包數繪製的事後樣本密度分佈圖。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 6: 用 bayesplot包數繪製的事後樣本密度分佈圖。
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;step-5修改mcmc條件設定&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 5，修改MCMC條件設定&lt;/h2&gt;
&lt;p&gt;進行貝葉斯模型擬合的過程中，常常需要不停地修改模型的條件，例如縮短warm-up等。下面的Rstan代碼可以實現簡便地頻繁修改MCMC條件設定：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(rstan) uncomment if run for the first time
data &amp;lt;- list(N=nrow(Salary), X=Salary$X, Y = Salary$Y)
fit2 &amp;lt;- sampling(
    model4_5, 
    data = data, 
    pars = c(&amp;quot;b&amp;quot;, &amp;quot;sigma&amp;quot;), 
    init = function(){
      list(a = runif(1, -10, 10), b = runif(1, 0, 10), sigma = 10)
    },
    seed = 123,
    chains = 3, iter = 1000, warmup = 200, thin = 2
) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;5b73686886069c0bad70513d4ea4141a&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 1.2e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)
## Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)
## Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)
## Chain 1: Iteration: 201 / 1000 [ 20%]  (Sampling)
## Chain 1: Iteration: 300 / 1000 [ 30%]  (Sampling)
## Chain 1: Iteration: 400 / 1000 [ 40%]  (Sampling)
## Chain 1: Iteration: 500 / 1000 [ 50%]  (Sampling)
## Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)
## Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)
## Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)
## Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)
## Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.05316 seconds (Warm-up)
## Chain 1:                0.036218 seconds (Sampling)
## Chain 1:                0.089378 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;5b73686886069c0bad70513d4ea4141a&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 2e-06 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup)
## Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)
## Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)
## Chain 2: Iteration: 201 / 1000 [ 20%]  (Sampling)
## Chain 2: Iteration: 300 / 1000 [ 30%]  (Sampling)
## Chain 2: Iteration: 400 / 1000 [ 40%]  (Sampling)
## Chain 2: Iteration: 500 / 1000 [ 50%]  (Sampling)
## Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)
## Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)
## Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)
## Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)
## Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.052191 seconds (Warm-up)
## Chain 2:                0.036956 seconds (Sampling)
## Chain 2:                0.089147 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;5b73686886069c0bad70513d4ea4141a&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 2e-06 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:   1 / 1000 [  0%]  (Warmup)
## Chain 3: Iteration: 100 / 1000 [ 10%]  (Warmup)
## Chain 3: Iteration: 200 / 1000 [ 20%]  (Warmup)
## Chain 3: Iteration: 201 / 1000 [ 20%]  (Sampling)
## Chain 3: Iteration: 300 / 1000 [ 30%]  (Sampling)
## Chain 3: Iteration: 400 / 1000 [ 40%]  (Sampling)
## Chain 3: Iteration: 500 / 1000 [ 50%]  (Sampling)
## Chain 3: Iteration: 600 / 1000 [ 60%]  (Sampling)
## Chain 3: Iteration: 700 / 1000 [ 70%]  (Sampling)
## Chain 3: Iteration: 800 / 1000 [ 80%]  (Sampling)
## Chain 3: Iteration: 900 / 1000 [ 90%]  (Sampling)
## Chain 3: Iteration: 1000 / 1000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.052083 seconds (Warm-up)
## Chain 3:                0.042977 seconds (Sampling)
## Chain 3:                0.09506 seconds (Total)
## Chain 3:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(fit2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: 5b73686886069c0bad70513d4ea4141a.
## 3 chains, each with iter=1000; warmup=200; thin=2; 
## post-warmup draws per chain=400, total post-warmup draws=1200.
## 
##         mean se_mean    sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
## b      21.90    0.06  1.56  18.56  20.96  21.92  22.91  24.83   587 1.00
## sigma  85.49    0.58 15.60  61.11  74.29  83.15  94.85 122.67   727 1.01
## lp__  -93.62    0.05  1.29 -96.82 -94.22 -93.30 -92.70 -92.16   609 1.00
## 
## Samples were drawn using NUTS(diag_e) at Mon May 18 14:27:30 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中&lt;code&gt;fit&lt;/code&gt;的最後一行是修改各種條件的示例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;chains&lt;/code&gt;至少要三條；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;iter&lt;/code&gt;一開始可以設定在500~1000左右，確定模型可以收斂以後，再加大這個數值以獲得穩定的事後統計量，多多益善；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;warmup&lt;/code&gt;，也就MCMC採樣開始後多少樣本可以丟棄。這個數值需要參考trace plot；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;thin&lt;/code&gt;，通常只需要保持默認值 1。和WinBUGS, JAGS相比Stan算法採集的事後樣本自相關比較低。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;step-6-並行平行計算的設定&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 6, 並行（平行）計算的設定&lt;/h2&gt;
&lt;p&gt;如果你寫出來的貝葉斯模型需要很長時間的計算和收斂，可以充分利用你的計算機的多核計算，把每條MCMC鏈單獨進行計算加速這個過程：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;parallel::detectCores() #我的桌上型電腦有8個核可以用於平行計算&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但是平行計算時如果計算中出錯則由於每條鏈都是相互獨立地進行，報錯就減少了。所以如果要使用多核同時計算的話，建議先減少採樣數，確認不會報錯以後再用多核平行計算增加採樣量。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-7-計算貝葉斯可信區間和貝葉斯預測區間&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 7, 計算貝葉斯可信區間和貝葉斯預測區間&lt;/h2&gt;
&lt;p&gt;這一步就又回到一開始提出的研究問題上來，我們來計算基本年收的貝葉斯可信區間和貝葉斯預測區間。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ms &amp;lt;- rstan::extract(fit)

quantile(ms$b, probs = c(0.025, 0.975))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     2.5%    97.5% 
## 18.67987 24.97108&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_mcmc &amp;lt;- data.frame(a = ms$a, b = ms$b, sigma = ms$sigma)

head(d_mcmc)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            a        b    sigma
## 1 -103.92295 22.04743 70.39829
## 2  -30.41656 20.16582 74.35210
## 3  -95.35165 21.32534 75.19714
## 4  -10.88849 19.01547 68.02757
## 5 -177.04183 23.49984 81.40161
## 6 -146.45260 22.73838 95.97706&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- ggplot(d_mcmc, aes(x = a, y = b)) + 
 geom_point(shape = 1, size = 4)

ggExtra::ggMarginal(
  p = p1,
  type = &amp;#39;density&amp;#39;,
  margins = &amp;#39;both&amp;#39;,
  size = 4,
  colour = &amp;#39;black&amp;#39;,
  fill = &amp;#39;#2D077A&amp;#39;
)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step71&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-15-simple-linear-regression-using-rstan_files/figure-html/step71-1.png&#34; alt=&#34;MCMC樣本的兩個模型參數的事後散點圖，及它們之間的邊緣分佈密度圖。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 7: MCMC樣本的兩個模型參數的事後散點圖，及它們之間的邊緣分佈密度圖。
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;從圖&lt;a href=&#34;#fig:step71&#34;&gt;7&lt;/a&gt;中可觀察到該貝葉斯線性模型獲得的事後模型參數樣本中，截距&lt;code&gt;a&lt;/code&gt;，和斜率&lt;code&gt;b&lt;/code&gt;之間呈極強的負相關關係。也就是說，截距是工資的起點（年齡爲0歲時），這個起點的理論值越低，斜率越大（歲年齡增加工資上升的速度越大）。&lt;/p&gt;
&lt;p&gt;根據上面分析的結果，下面的R代碼可以計算一名50歲的人被這家公司採用的時候，她/他的預期基本年收入的分佈（中獲得的MCMC樣本），和她/他的預期總年收的預測分佈（中獲得的MCMC樣本）。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;N_mcmc &amp;lt;- length(ms$lp__)
y50_base &amp;lt;- ms$a + ms$b*50
y50 &amp;lt;- rnorm(n = N_mcmc, mean = y50_base, sd = ms$sigma)
d_mcmc &amp;lt;- data.frame(a = ms$a, b = ms$b, sigma = ms$sigma, y50_base, y50)
head(d_mcmc)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            a        b    sigma y50_base       y50
## 1 -103.92295 22.04743 70.39829 998.4488  953.4024
## 2  -30.41656 20.16582 74.35210 977.8746  861.2176
## 3  -95.35165 21.32534 75.19714 970.9152 1076.7587
## 4  -10.88849 19.01547 68.02757 939.8852  877.2139
## 5 -177.04183 23.49984 81.40161 997.9499 1109.8183
## 6 -146.45260 22.73838 95.97706 990.4664 1063.0656&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the following codes are also available from the author&amp;#39;s page:
# https://github.com/MatsuuraKentaro/RStanBook/blob/master/chap04/fig4-8.R
# library(ggplot2)
source(&amp;#39;commonRstan.R&amp;#39;)

# load(&amp;#39;output/result-model4-5.RData&amp;#39;)
ms &amp;lt;- rstan::extract(fit)

X_new &amp;lt;- 23:60
N_X &amp;lt;- length(X_new)
N_mcmc &amp;lt;- length(ms$lp__)

set.seed(1234)
y_base_mcmc &amp;lt;- as.data.frame(matrix(nrow=N_mcmc, ncol=N_X))
y_mcmc &amp;lt;- as.data.frame(matrix(nrow=N_mcmc, ncol=N_X))
for (i in 1:N_X) {
  y_base_mcmc[,i] &amp;lt;- ms$a + ms$b * X_new[i]
  y_mcmc[,i] &amp;lt;- rnorm(n=N_mcmc, mean=y_base_mcmc[,i], sd=ms$sigma)
}

customize.ggplot.axis &amp;lt;- function(p) {
  p &amp;lt;- p + labs(x=&amp;#39;X&amp;#39;, y=&amp;#39;Y&amp;#39;)
  p &amp;lt;- p + scale_y_continuous(breaks=seq(from=200, to=1400, by=400))
  p &amp;lt;- p + coord_cartesian(xlim=c(22, 61), ylim=c(200, 1400))
  return(p)
}

d_est &amp;lt;- data.frame.quantile.mcmc(x=X_new, y_mcmc=y_base_mcmc)
p &amp;lt;- ggplot.5quantile(data=d_est)
p &amp;lt;- p + geom_point(data=Salary, aes(x=X, y=Y), shape=1, size=3)
p &amp;lt;- customize.ggplot.axis(p)
# ggsave(file=&amp;#39;output/fig4-8-left.png&amp;#39;, plot=p, dpi=300, w=4, h=3)
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step72&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-15-simple-linear-regression-using-rstan_files/figure-html/step72-1.png&#34; alt=&#34;MCMC樣本計算獲得的基本年收的貝葉斯可信區間。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 8: MCMC樣本計算獲得的基本年收的貝葉斯可信區間。
&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_est &amp;lt;- data.frame.quantile.mcmc(x=X_new, y_mcmc=y_mcmc)
p &amp;lt;- ggplot.5quantile(data=d_est)
p &amp;lt;- p + geom_point(data=Salary, aes(x=X, y=Y), shape=1, size=3)
p &amp;lt;- customize.ggplot.axis(p)
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:step73&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-15-simple-linear-regression-using-rstan_files/figure-html/step73-1.png&#34; alt=&#34;MCMC樣本計算獲得的預期總年收的貝葉斯預測區間。（顏色較深的是50%預測區間帶，黑線是事後樣本的中央值）&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 9: MCMC樣本計算獲得的預期總年收的貝葉斯預測區間。（顏色較深的是50%預測區間帶，黑線是事後樣本的中央值）
&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# ggsave(file=&amp;#39;output/fig4-8-right.png&amp;#39;, plot=p, dpi=300, w=4, h=3)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;練習題&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;練習題&lt;/h2&gt;
&lt;p&gt;用模擬數據來嘗試進行貝葉斯t檢驗&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
N1 &amp;lt;- 30
N2 &amp;lt;- 20
Y1 &amp;lt;- rnorm(n=N1, mean=0, sd=5)
Y2 &amp;lt;- rnorm(n=N2, mean=1, sd=4)&lt;/code&gt;&lt;/pre&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;請繪製上面代碼生成的兩組數據的示意圖&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d1 &amp;lt;- data.frame(group=1, Y=Y1)
d2 &amp;lt;- data.frame(group=2, Y=Y2)
d &amp;lt;- rbind(d1, d2)
d$group &amp;lt;- as.factor(d$group)

p &amp;lt;- ggplot(data=d, aes(x=group, y=Y, group=group, col=group))
p &amp;lt;- p + geom_boxplot(outlier.size=0)
p &amp;lt;- p + geom_point(position=position_jitter(w=0.4, h=0), size=2)
p&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:exe11&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://wangcc.me/post/2019-01-15-simple-linear-regression-using-rstan_files/figure-html/exe11-1.png&#34; alt=&#34;隨機生成的兩組數據的散點圖和箱式圖。&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 10: 隨機生成的兩組數據的散點圖和箱式圖。
&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#ggsave(file=&amp;#39;fig-ex1.png&amp;#39;, plot=p, dpi=300, w=4, h=3)&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;寫下相當於t檢驗的數學式，表示各組之間方差或者標準差如果相等時，均值比較的檢驗模型。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;hypotheses:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;observations in each group follow a normal distribution&lt;/li&gt;
&lt;li&gt;all observations are independent&lt;/li&gt;
&lt;li&gt;The two population variance/standard deviations are known (and can be considered equal)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{H}_0: \mu_2 - \mu_1 = 0 \\
\text{H}_1: \mu_2 - \mu_1 \neq 0 \\ 
\text{If H}_0 \text{ is true, then:} \\
Z=\frac{\bar{Y_2} - \bar{Y_1}}{\sqrt{(\sigma_2^2/n_2) + (\sigma_1^2/n_1)}} \\
\text{follows a standard normal distribution with zero mean} \\
\Rightarrow \text{ if two variances are considered the same}\\ 
Y_1[n] \sim N(\mu_1, \sigma) \;\; n = 1,2,\dots,N \\
Y_2[n] \sim N(\mu_2, \sigma) \;\; n = 1,2,\dots,N
\]&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;寫下上一步模型的Stan代碼，並嘗試在R裏運行&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Stan代碼如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data {
  int N1;
  int N2;
  real Y1[N1];
  real Y2[N2];
}

parameters {
  real mu1;
  real mu2;
  real&amp;lt;lower=0&amp;gt; sigma;
}

model {
  for (n in 1:N1)
    Y1[n] ~ normal(mu1, sigma);
  for (n in 1:N2)
    Y2[n] ~ normal(mu2, sigma);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R代碼如下：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstan)
data &amp;lt;- list(N1=N1, N2=N2, Y1=Y1, Y2=Y2)
exe13 &amp;lt;- stan_model(file = &amp;quot;stanfiles/ex3.stan&amp;quot;)
fit &amp;lt;- sampling(exe13, data=data, seed=1234)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;ex3&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 1.6e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.02842 seconds (Warm-up)
## Chain 1:                0.023398 seconds (Sampling)
## Chain 1:                0.051818 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;ex3&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 5e-06 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.028177 seconds (Warm-up)
## Chain 2:                0.021224 seconds (Sampling)
## Chain 2:                0.049401 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;ex3&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 3e-06 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.026653 seconds (Warm-up)
## Chain 3:                0.022362 seconds (Sampling)
## Chain 3:                0.049015 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;ex3&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 5e-06 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.02661 seconds (Warm-up)
## Chain 4:                0.021456 seconds (Sampling)
## Chain 4:                0.048066 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: ex3.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##         mean se_mean   sd    2.5%    25%    50%    75%  97.5% n_eff Rhat
## mu1    -0.24    0.01 0.84   -1.93  -0.80  -0.23   0.30   1.40  3805    1
## mu2     1.59    0.02 0.99   -0.32   0.92   1.61   2.25   3.50  3739    1
## sigma   4.46    0.01 0.46    3.66   4.14   4.42   4.76   5.45  3402    1
## lp__  -97.74    0.03 1.23 -100.89 -98.32 -97.42 -96.84 -96.33  1879    1
## 
## Samples were drawn using NUTS(diag_e) at Mon May 18 14:28:06 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;從獲取到的事後參數的MCMC樣本計算 &lt;span class=&#34;math inline&#34;&gt;\(\text{Prob}[\mu_1 &amp;lt; \mu_2]\)&lt;/span&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ms &amp;lt;- extract(fit)
prob &amp;lt;- mean(ms$mu1 &amp;lt; ms$mu2)  #=&amp;gt; 0.932
prob&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9235&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;所以可以認爲地一組均值，小於第二組均值的事後概率是93.2%&lt;/p&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;如果不能認爲兩組的方差相等的話，模型又該改成什麼樣子？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Y_1[n] \sim N(\mu_1, \sigma_1) \;\; n = 1,2,\dots,N \\
Y_2[n] \sim N(\mu_2, \sigma_2) \;\; n = 1,2,\dots,N
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data {
  int N1;
  int N2;
  real Y1[N1];
  real Y2[N2];
}

parameters {
  real mu1;
  real mu2;
  real&amp;lt;lower=0&amp;gt; sigma1;
  real&amp;lt;lower=0&amp;gt; sigma2;
}

model {
  for (n in 1:N1)
    Y1[n] ~ normal(mu1, sigma1);
  for (n in 1:N2)
    Y2[n] ~ normal(mu2, sigma2);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面的代碼相當於實施Welch的t檢驗：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstan)
data &amp;lt;- list(N1=N1, N2=N2, Y1=Y1, Y2=Y2)
exe15 &amp;lt;- stan_model(file = &amp;quot;stanfiles/ex5.stan&amp;quot;)

fit &amp;lt;- sampling(exe15, data=data, seed=1234)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;ex5&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 1e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.028096 seconds (Warm-up)
## Chain 1:                0.024392 seconds (Sampling)
## Chain 1:                0.052488 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;ex5&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 5e-06 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.029221 seconds (Warm-up)
## Chain 2:                0.02848 seconds (Sampling)
## Chain 2:                0.057701 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;ex5&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 5e-06 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.030482 seconds (Warm-up)
## Chain 3:                0.025653 seconds (Sampling)
## Chain 3:                0.056135 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;ex5&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 5e-06 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.027327 seconds (Warm-up)
## Chain 4:                0.024552 seconds (Sampling)
## Chain 4:                0.051879 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: ex5.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##          mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
## mu1     -0.22    0.01 0.94  -2.07  -0.85  -0.23   0.40   1.68  4084    1
## mu2      1.63    0.01 0.82   0.04   1.09   1.62   2.15   3.25  4068    1
## sigma1   5.12    0.01 0.71   3.94   4.62   5.05   5.53   6.74  3863    1
## sigma2   3.63    0.01 0.64   2.66   3.18   3.55   3.98   5.08  3002    1
## lp__   -95.33    0.03 1.44 -98.86 -96.05 -95.04 -94.28 -93.52  1916    1
## 
## Samples were drawn using NUTS(diag_e) at Mon May 18 14:28:40 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ms &amp;lt;- rstan::extract(fit)
prob &amp;lt;- mean(ms$mu1 &amp;lt; ms$mu2)  #=&amp;gt; 0.93725
prob&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9345&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>2018-12 todo</title>
      <link>https://wangcc.me/post/2018-12-todo/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2018-12-todo/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;2018-12-03
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=16Rd46SE-20&amp;amp;list=PL7F907999BA1994A1&#34;&gt;Learn Emacs;&lt;/a&gt; day 1 done&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Return the email from LP;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;learn &lt;a href=&#34;https://github.com/noamross/redoc&#34;&gt;reversible R markdown /MS word documents package&lt;/a&gt;;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Pay the you-know-what ticket;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Read &lt;a href=&#34;https://www.amazon.com/Evidence-Evolution-Logic-Behind-Science-ebook/dp/B00KILLNIO/ref=mt_kindle?_encoding=UTF8&amp;amp;me=&amp;amp;qid=1543812059&#34;&gt;Evidence and Evolution&lt;/a&gt; 1%&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-12-04
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Prepare the manuscript for AJCN 10% left; FINALLY!!!!!&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=16Rd46SE-20&amp;amp;list=PL7F907999BA1994A1&#34;&gt;Learn Emacs;&lt;/a&gt; day 2&amp;amp;3 done;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-12-05
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Read the victim book, and keep memo to P151;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=16Rd46SE-20&amp;amp;list=PL7F907999BA1994A1&#34;&gt;Learn Emacs;&lt;/a&gt; day 4&amp;amp;5 done;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-12-06
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Move all todo to &lt;a href=&#34;https://wangcc.me/Emacsnotes/TODO.html&#34;&gt;Org-mode page&lt;/a&gt;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Rstan Wonderful R-(1)</title>
      <link>https://wangcc.me/post/rstan-wonderful-r/</link>
      <pubDate>Thu, 22 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/rstan-wonderful-r/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;P16&lt;/p&gt;
&lt;p&gt;事後分布 &lt;span class=&#34;math inline&#34;&gt;\(p(\theta | Y)\)&lt;/span&gt;の値が最大になる点&lt;span class=&#34;math inline&#34;&gt;\(\theta^*\)&lt;/span&gt;を事後確率最大推定値 (maximum a posteriori estimate)と呼ぶ．略してMAP推定値 (MAP estimate)．&lt;/p&gt;
&lt;p&gt;我們把能夠將事後概率分布取極大值的參數點 &lt;span class=&#34;math inline&#34;&gt;\(\theta^*\)&lt;/span&gt; 稱爲事後概率的最大似然估計值 (maximum a posteriori estimate)，簡稱 MAP估計值 (MAP estimate)。&lt;/p&gt;
&lt;p&gt;P19&lt;/p&gt;
&lt;p&gt;統計建模的一般順序&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;確定分析目的&lt;/li&gt;
&lt;li&gt;確定數據分布&lt;/li&gt;
&lt;li&gt;想象數據產生本身的機制：思考數據與數據之間可能的關系&lt;/li&gt;
&lt;li&gt;寫下你所認爲的數據模型的數學表達式&lt;/li&gt;
&lt;li&gt;用 R 模擬(simulation)並確認前一步寫下的數學模型的性質，特點&lt;/li&gt;
&lt;li&gt;用 Stan 實際進行模型參數的推斷&lt;/li&gt;
&lt;li&gt;獲得推斷結果，解釋其事後概率分布的意義，繪制易於理解的模型示意圖&lt;/li&gt;
&lt;li&gt;繪制成功之後的模型示意圖和最先使用的模型之間進行比對，重新查缺補漏&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;P23&lt;/p&gt;
&lt;p&gt;ただいたずらにモデルを複雑化させるのは解釈のしにくさを招く．&lt;/p&gt;
&lt;p&gt;P30&lt;/p&gt;
&lt;p&gt;最初にmodel ブロックの尤度の部分（と事前分布の部分）を書く．その尤度の部分に登場した変数のうち，データの変数をdataブロックに，残りの変数をparametersブロックに書いていく．&lt;/p&gt;
&lt;p&gt;Stan的基本文法構成&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data {
 數據描述
}

parameters {
 想要進行MCMC事後樣本採集的參數描述
}

model {
 p(Y|theta) 似然的描述
 先驗概率分布 p(theta) 的描述
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;把下面的模型&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
Y[n] &amp;amp; \sim \text{Normal}(\mu, 1) \;\; n = 1, \dots, N \\
\mu  &amp;amp; \sim \text{Normal}(0, 100)
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;翻譯成爲 Stan 模型語言是：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data {
  int N;
  real Y[N];
}

parameters {
  real mu;
}

model {
  for (n in 1:N) {
    Y[n] ~ normal(mu, 1);
  }
  mu ~ normal(0, 100);
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中我們按照實際模型書寫的順序 model -&amp;gt; data -&amp;gt; parameter 來逐個解釋：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;model&lt;/code&gt; 模塊中 &lt;code&gt;for (n in 1:N)&lt;/code&gt; 開始的循環部分（三行）對應數學模型的 $Y[n] (, 1) n = 1, , N $　部分。&lt;/li&gt;
&lt;li&gt;Stan 語言中，每一行描述的結尾需要用分號 &lt;code&gt;;&lt;/code&gt; 來結束。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mu ~ normal(0,100)&lt;/code&gt; 則對應數學模型中寫的先驗概率 &lt;span class=&#34;math inline&#34;&gt;\(\mu \sim \text{Normal}(0, 100)\)&lt;/span&gt; 部分。這裏給均值的先驗概率分佈是一個方差很大的無信息先驗概率分佈 (noninformative prior)。事實上在 Stan 軟件語言中，如果不特別指出先驗概率分佈，系統會默認給參數以無信息的先驗概率分佈，這樣即使沒有這一行，模型也是可以跑的。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;data&lt;/code&gt; 模塊中寫明的是 &lt;code&gt;model&lt;/code&gt; 模塊中描述的模型將要使用的數據。它包括宣示數據的個數（樣本量 &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;），以及數據本身。其中 &lt;code&gt;int N&lt;/code&gt; 意爲樣本量的數量是整數個 (integer)，&lt;code&gt;real Y[N]&lt;/code&gt; 則宣示實數有 N 個作爲數據。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;parameter&lt;/code&gt; 模塊是告訴軟件需要採樣且關注的未知參數 (parameter) 是 &lt;code&gt;mu&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在 Stan 語言中，還可以和其他語言一樣爲模型加註解釋的文字，只需要在想要做註釋的文字最開始的部分增加 &lt;code&gt;//&lt;/code&gt;，如果註釋的文字超過一行，那麼在註釋的模塊前後加上 &lt;code&gt;/*&lt;/code&gt; 和 &lt;code&gt;*/&lt;/code&gt; 即可。&lt;/li&gt;
&lt;li&gt;另外，目前爲止主流的貝葉斯模型軟件中使用精確度 (precision) ，也就是方差的倒數來描述正態分佈 &lt;code&gt;normal(mean, 1/variance)&lt;/code&gt; ，但是在Stan的語法中使用的是 &lt;code&gt;normal(mean, sd)&lt;/code&gt;，也就是用標準差來描述正態分佈。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;寫Stan（或者說寫大多數的代碼）時，請遵守以下的原則：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;適當縮進，以便於閱讀；&lt;/li&gt;
&lt;li&gt;表示數據的部分用大寫字母，表示參數的部分，用小寫字母；&lt;/li&gt;
&lt;li&gt;每個部分之間至少使用一個空行加以區分；&lt;/li&gt;
&lt;li&gt;請不要用&lt;code&gt;camelCase&lt;/code&gt;這樣的方式（單詞之間用大寫隔開），請在單詞之間用下劃線 &lt;code&gt;camel_case&lt;/code&gt; 的標記方法；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;~&lt;/code&gt;或者&lt;code&gt;=&lt;/code&gt;前後用一個字符大小的空格來隔開。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最低限度的話，也請依照1,2兩個標準來書寫你的Stan代碼。不爲他人，也爲自己將來再讀代碼時能快速理解其涵義。往Stan的官方論壇投稿時，也必須遵守它們在手冊裏提供的 “Stan Program Style Guide” 代碼書寫規則，也是對其他寫，讀代碼的人的尊重。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2018-11 todo</title>
      <link>https://wangcc.me/post/2018-11-todo/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2018-11-todo/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;2018-11-05
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Paper comments to Lin;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Cancel the tsumitate;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Ask about the insurance;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Submit nenmatsu;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Modify the poster (adding logo), etc;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-06
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-85.html#practical-bayesian-statistics-06&#34;&gt;Bayesian statistics practical 6&lt;/a&gt; done;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Prepare AJCN template (Rmd) file;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Prepare AJCN draft (.docx) file;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;MLCA analyses done stratified by men and women;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-07
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;fix the racket before Wed.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-85.html&#34;&gt;Bayesian statistics Chapter 7&lt;/a&gt; done 20%;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Check the problem of the gh-page on github.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-08~11
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Search for guideline of eradication among adolescents of H. &lt;em&gt;pylori&lt;/em&gt; in the world;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Protocol comments to TMS;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Read the victim book, and keep memo;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Prepare the manuscript for AJCN 10%;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Modify the Presentation Slides&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-12
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-85.html&#34;&gt;Bayesian statistics Chapter 7&lt;/a&gt; done 80%;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Read the victim book, and keep memo;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Comment the Presentation Slides from LP;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Labeling the learning note bookdown book.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-13
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-85.html&#34;&gt;Bayesian statistics Chapter 7&lt;/a&gt; done 100%;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Prepare the manuscript for AJCN 25%;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Comment the manuscript from Lin;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Domestic travel paper work&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-14
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Read the victim book, and keep memo;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Prepare the manuscript for AJCN 40%;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-15~16
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-85.html#practical-bayesian-statistics-07&#34;&gt;Bayesian statistics practical 7&lt;/a&gt; done 100%;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Prepare the manuscript for AJCN the tables, figures done;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-19
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Prepare the manuscript for AJCN 80%;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Confirm the feedback of the project;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-20
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Comment KS application form (2018-11-21).&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Perform the analyses using sex as an interaction, combine three tables. done 20%&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Read the victim book, and keep memo;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-86.html&#34;&gt;Bayesian statistics Chapter 8&lt;/a&gt; 20% done;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-21
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Learn Stan for Bayesian stats 1%;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Perform the analyses using sex as an interaction, combine three tables. done;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-86.html&#34;&gt;Bayesian statistics Chapter 8&lt;/a&gt; 30% done;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-22
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Learn Stan for Bayesian stats 5%;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-86.html&#34;&gt;Bayesian statistics Chapter 8&lt;/a&gt; 35% done;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Manuscript to AMU about the overseas study&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-24
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Learn Stan for Bayesian stats 6%;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Review the JAT meta-ana paper (deadline: 2018-11-28);&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-11-25~12-02 (annual leave)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2018_10 todo</title>
      <link>https://wangcc.me/post/2018-10-todo/</link>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2018-10-todo/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;2018-10-02 ~ 2018-10-17
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Prepare the proposal to JSPS.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-10-02
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Background, key questions&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;objective, importance&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-10-09
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-80.html&#34;&gt;Bayesian statistics Chapter 1&lt;/a&gt; done;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-10-10
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/MC-estimation.html&#34;&gt;Bayesian statistics Chapter 2&lt;/a&gt; done;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-10-11~12
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/-conjugate-priors.html&#34;&gt;Bayesian statistics Chapter 3&lt;/a&gt; done;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-10-13
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Review of the paper about HIV;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-10-15
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Wait for the comments from LP, SA;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-10-16
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Modification of the proposal;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Submission of the proposal;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Learn how to apply for the data usage of Japan National Nutrional Survey;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-10-17~19
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/mcmcbugs.html&#34;&gt;Bayesian statistics Chapter 4&lt;/a&gt; done;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-10-23
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-84.html&#34;&gt;Bayesian statistics Chapter 5&lt;/a&gt; done;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-10-24
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Learn how to use Stan (just a beginning);&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-10-25
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://github.com/winterwang/PAC_PAM&#34;&gt;Some preliminary analysis&lt;/a&gt; using vague prior to do &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S1341321X18300783&#34;&gt;MabeRCT&lt;/a&gt;;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;https://wangcc.me/LSHTMlearningnote/section-85.html&#34;&gt;Bayesian statistics Chapter 6&lt;/a&gt; done;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Talk with LP AS, the next steps of writing the carb paper;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-10-26~31
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Prepare poster for &lt;a href=&#34;https://www.bna.org.uk/mediacentre/events/chrononutrition-from-epidemiology-to-molecular-mechanism-symposium-london/&#34;&gt;conference&lt;/a&gt;.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;LCA analyses done stratified by men and women;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Summer Project Schedule</title>
      <link>https://wangcc.me/post/summer-project-schedule/</link>
      <pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/summer-project-schedule/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Data analysis finish by 2018-07-&lt;del&gt;24&lt;/del&gt;31&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Paper structure confirm by 2018-08-01&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Paper draft complete by 2018-08-16&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;2018-06-24
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Read and try to repeat Rll&amp;rsquo;s method in R and familarize the dataset ASAP&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Two papers applying Repeated Measures LCA&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-06-25
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Meeting with supervisor and Susanna&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Confirm the cutoff of carborhydrate consumption&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Talk with Rll ask about the methodology and dataset&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-06-26
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Send the summarised memo of meeting to Supervisor and etc.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Read the first part fundamentals of LCA.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-06-27
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://www.londonr.org/&#34;&gt;London R in UCL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Germany lost their game against South Korea, UNBELIEVEABLE&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-06-28
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Read the book collins2010latent - Latent Class and Latent Transition Analysis: With Applications in the Social, Behavioral, and Health Sciences (Done until 4.2)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Learn how to do LCA in R&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-06-29
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Read the book collins2010latent - Latent Class and Latent Transition Analysis: With Applications in the Social, Behavioral, and Health Sciences (Done until 4.3)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Data management for NDNS 8 years data (70%)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Learn how to do LCA in R&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Start to analysis the data according to the discussion on 25th(30%)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Day1 data analysis results summary&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-07-01
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Relax and do nothing&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Buy some drink to enjoy the night with classmates(HB)&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-07-02/03
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Send some preliminary results to co-authors&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&lt;a href=&#34;http://www.the-afc.com/competitions/fifa-world-cup/latest/news/japan-fa-president-proud-of-blue-samurai&#34;&gt;Japan lost the game to Belgium, but they are the glory of Asia&amp;ndash;heartbreaking&lt;/a&gt;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-07-04
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&amp;quot;consider separating weekdays from weekends if we are not averaging the four days?&amp;ldquo;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-07-05
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Test and confirm the availability of LCA in SAS&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Learn how to do LCA in SAS with NDNS data&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-07-06
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Learn how to do LCA with random effects in SAS&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Find whether there is any possibility of conducting the same method in R or STATA (no there is no way)&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-07-07~09
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;&amp;quot;Maybe we should try with the threshold at 25% only as per the existing guidelines (although those are per meal)?&amp;ldquo;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-07-10
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; ~~Meet with tutor;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Start writing about the methodology;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Try to start writing about the introduction;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-07-11
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Try to summarise the meeting memo yesterday;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Re-analyse the data with new cut-off values (25, 50, 75);&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Re-analyse the data with new cut-off values (50);&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-07-12~22
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Use latent class growth analysis;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Use multilevel latent class analysis;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Think about the mathmatical theory behind the mixed LCA, write to PROC LCA group if necessary;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-07-23~25
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Learn about the survey package in R&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Finish writing about the methodology;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Write some introduction;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-07-26
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Let&amp;rsquo;s finish analysis of the classes and health outcomes.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Read about the carbo-fibre ratio references.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-08-15
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;PM review&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Finish most of the discussion outlines and 2 pages of them.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2018-08-31
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Finish revising the report according to comments from LP and SAM;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Read RT&amp;rsquo;s report and send the comments;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Confirm the deadline for funding applications;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Prepare the abstract for conferences (UK and JP);&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Start preparing the paper for submit (MLCA part alone);&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Think about the schedules and plans after leaving London;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Finish the post of Scotland trip.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>蘇格蘭高地7日公路之旅</title>
      <link>https://wangcc.me/post/scotland-highland-road-trip/</link>
      <pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/scotland-highland-road-trip/</guid>
      <description>&lt;p&gt;本次高地旅行（2018-06-13～2018-06-20）值得紀念，我們一行三人，在蘇格蘭自駕開了一個圈。沿路看過的高山流水，懸崖峭壁，狂風暴雨，和那些雨過天晴，都讓人久久難以忘懷。我們還經歷了頭一天輪胎爆胎，最後一天在愛丁堡城堡被偷錢包等各種奇葩的經歷。深感有必要在此簡單記錄下這段旅程，為了將來還記得這一年在英國的腳印。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;2018-06-13-倫敦出發&#34;&gt;2018-06-13 倫敦出發&lt;/h1&gt;
&lt;p&gt;出發之前，秀一下我們訂的20英鎊的機票（比機場市區往返的火車還便宜&amp;hellip;&amp;hellip;）：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180613_180804.jpg&#34; alt=&#34;at the airport&#34;&gt;&lt;/p&gt;
&lt;p&gt;當天無事，我們降落愛丁堡時蘇格蘭展示了北方的大風夾着冰涼的雨水，警告我們即使是夏季的夜晚也是那麼的寒冷。順利在機場取了車（其實花了一個半小時，牆裂&lt;strong&gt;不推薦&lt;/strong&gt;蘇格蘭當地的租車公司 &lt;a href=&#34;https://greenmotion.com/&#34;&gt;Greenmotion&lt;/a&gt;，效率低下而且合同上陷阱不少，最後我們實在是覺得很煩，直接上了最高等級的整車安心保險&amp;ndash;後來的事實證明我們當初的選擇是那麼的正確），我們終於踏上了蘇格蘭之行的第一步。先在愛丁堡大學附近和多年未見的好友見面聊天吃吃吃了之後，我們找到了本次旅途中的第一家 Airbnb 房東在海邊的家。當晚其實下了一夜的狂風驟雨，透過閣樓的房間房頂上的玻璃，我們可以直接看到外面不停被風吹亂猙獰的樹枝。第二天一早風依然很大，但是我們無法克制想立刻看到大海的慾望，頂着狂風步行到了沙灘，看到那令人窒息的海邊的愛丁堡：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2018-06-24-scotland-highland-road-trip_files/IMG_20180614_093604.jpg&#34; alt=&#34;Edinburgh beach&#34;&gt;&lt;/p&gt;
&lt;p&gt;這是我們租來的寶獅（标致）3008 SUV，7天保險全包，每天差不多63英鎊（約10000日元/560軟妹幣）：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;這輛車表面上看起來瀟洒，其實個人感覺不太耐用，華而不實。&lt;/p&gt;
&lt;p&gt;白天離開房東家以後我們車停在愛丁堡車站南的一個立體停車場，之後趁着天氣晴朗（但是大風四起，把許多路人吹得很凌亂），我們參觀了愛丁堡大學神學院：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;天氣雖然好，大風讓愛丁堡城堡關閉了遊客參觀，但是並不妨礙我們感受這座古老城市的藝術氣息：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.ed.ac.uk/visit/museums-galleries/anatomical&#34;&gt;麥克尤恩大禮堂(McEwan Hall, The University of Edinburgh)&lt;/a&gt;
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.stgilescathedral.org.uk/&#34;&gt;聖基爾斯大教堂(St Giles&amp;rsquo; Cathedral)&lt;/a&gt;
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.edinburghmuseums.org.uk/venue/scott-monument&#34;&gt;斯科特紀念塔(Scott Monument)&lt;/a&gt;
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;路邊的行為藝術：
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;登上&lt;a href=&#34;https://www.google.com/maps/place/Calton+Hill/@55.9521378,-3.1854529,16.42z/data=!4m5!3m4!1s0x4887c7896e46c799:0x9181b664f75766dd!8m2!3d55.9550468!4d-3.1827414&#34;&gt;卡爾頓山 (Calton Hill)&lt;/a&gt;俯瞰這座蘇格蘭的首府，安靜而令人嚮往。
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;2018-06-14-爱丁堡到格拉斯哥&#34;&gt;2018-06-14 爱丁堡到格拉斯哥&lt;/h1&gt;
&lt;p&gt;傍晚離開了愛丁堡，我們向西驅車開往另一座老城，格拉斯哥。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;這一晚我們預定的 Airbnb 在格拉斯哥的郊區，是一排連排別墅中的一棟。這天入住的時候，由於沒有仔細閱讀房東在 Airbnb 上留下的入住須知，導致用鑰匙打開門之後警報聲大作，直至隔壁鄰居實在是受不了了跑來幫忙關掉警鈴整個世界才安靜。在此友情提醒諸位使用 Airbnb 時注意閱讀房東留下的入住須知。房東當日不在家，所以我們沒有浪費他們家的廚房設施，從超市採購了一大桶雞腿嘗試了白斬雞的做法（味道好極了！多謝 Linda）。&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;2018-06-15-從格拉斯哥離開飛馳在高地去往天空島&#34;&gt;2018-06-15 從格拉斯哥離開，飛馳在高地去往天空島&lt;/h1&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;一早從格拉斯哥離開後要先經過洛蒙德湖泊 (Loch Lomond)，沿着A82號公路，一路上一會兒下雨，一會兒天晴。在湖邊一個叫做路斯 (Luss) 的小鎮，我們在雨中下來看了看湖邊雲霧繚繞的碼頭，水很清澈，水鴨子們也悠閑地在游泳：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;樹林里，清澈見底的溪流：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;雲霧中，在停車時發現山上是一個水力發電廠：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;洛蒙德湖在籠罩在水氣中：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;之後，我們在路上就經歷了爆胎事件。其經過其實很簡單:離開路斯往北行進的路上，其實道路是十分狹窄的。在某路段我眼角發現左前方路面上有一個拳頭大小的黑色障礙物 (後來想應該是塊山上掉下來的碎石)，當時如果路足夠寬的話，我當然可以躲閃一下。無奈右側迎面而來是一輛大卡車，無法躲閃，後面又有車跟着，不能剎車，於是就只好硬着頭皮前行，心裏希望只是個不太堅硬的小石子。結果過去以後，&amp;ldquo;咣噹&amp;quot;一聲，左前方的輪胎明顯下沉，握方向盤的雙手明顯有左右不平衡的感覺，於是滑行了幾百米後在一段正好施工路段的中間處停下查看輪胎狀況。不出所料，左前方輪胎癟了。此時距離我們離開格拉斯哥大概只有一個半小時左右的路程。圖中是我們等待了兩次雷雨，三集 Friends 過後，才姍姍來遲的路上救援小哥。幸好該寶獅（标致）SUV的後備箱里有一個備胎。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;換備胎的小哥讓我們開車開到前面去找輪胎廠換一個新的輪胎，這樣才不至於一直使用備胎，車速要總是限制在50邁以下。於是我們查了查地圖，確定最近的輪胎店的位置。發現如果往南走要回到格拉斯哥，往北則是越來越荒蕪，只有往西靠海邊有個叫做奧本的小鎮有輪胎修理點。於是我們驅車出發去之前並未計劃要去的這個叫做奧本的海港小鎮。想起來之前在愛丁堡，好友還推薦說你們如果順路可以去奧本的港口吃海鮮路邊攤 (seafood hut)，當時我們還想這樣會繞遠路，就沒有把奧本放進行程裏，結果我們這半路爆胎&amp;quot;因禍得福&amp;rdquo;，來到了這個本來並沒有在行程中的西海岸邊的小漁村。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;抵達奧本，換了兩三家輪胎廠，都說我們租的這輛寶獅款式太新，並沒有庫存的相同輪胎，真的是運氣不佳。於是我們只好停車在港口的碼頭之後去路邊攤邊吃海鮮，邊思考接下來腫麼辦 (其實主要就是來吃海鮮的)。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;一盤大龍蝦，就水裏撈上來直接清煮的那種，大約15鎊左右，吃的是大快朵頤！
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;後來我們又點了一只麪包蟹，膏滿肉肥。
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;搞笑的是我們先飽餐了一頓之後離開海鮮攤位，經過下面的奧本火車站在附近散步一圈，同行的一個小朋友可憐兮兮地說，晚上還能不能再吃海鮮呀。於是我們回過頭第二次又去光顧了同一家 seafood hut. 奧本的海鮮真是讓人一步三回頭。
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;這是在去往天空島的路上經過的廣闊的高地，我們停車在一個紀念二戰時陣亡英格蘭蘇格蘭將士的廣場:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;2018-06-16-離開時而暴雨傾盆時而天氣晴朗的天空島去往德內斯-durness&#34;&gt;2018-06-16 離開時而暴雨傾盆，時而天氣晴朗的天空島，去往德內斯 (Durness)&lt;/h1&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;在天空島的早上，天氣陰沉沉，我們開車繞着整個半島走了一圈，也沒等到天晴可以看懸崖的時刻。倒是中途發現了一個極爲清澈的海水池&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;之後來到蘇格萊最北的懸崖處，這裏名叫德內斯
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;一個陰森森的洞窟在懸崖下&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;我們步行到深藍色海邊的黑色懸崖上，再往北就是北冰洋&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;2018-06-17-在靠近-shetland-的無路可走的盡頭&#34;&gt;2018-06-17 在靠近 Shetland 的無路可走的盡頭&lt;/h1&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;確切地說，這裏才能算是蘇格蘭和英格蘭島上地理位置上的最北端。地標在這裏顯示往北是 &lt;a href=&#34;https://zh.wikipedia.org/wiki/%E8%AE%BE%E5%BE%B7%E5%85%B0&#34;&gt;Shetland&lt;/a&gt; 往南則距離倫敦690英里 (1100公里左右)。許多人來到了這個道路終結的地方，在那一排色彩斑斕的小房子前，面朝大海。估計這裏的春暖花開一年也就幾天時間。抵達這裏，意味着我們脫繮的道路到了終點，天公作美，我們到此一遊相片留下之後，終於開始了往南回到現實的旅程。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;晚上到了因弗尼斯 (Inverness)， Airbnb 房東家的廚房又一次發揮了極爲重要的作用:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;房東給準備的早餐堪比4星級酒店&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;2018-06-18-inverness-和尼斯湖水怪&#34;&gt;2018-06-18 Inverness 和尼斯湖水怪&lt;/h1&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;尼斯湖是一個顏色暗黑似乎深度內傷的湖，如果你看地圖，它是又細又長的一個小湖泊，這天天氣很冷 (六月)，寒風逼人，不知冬季時這裏的人要如何度過。無法想象。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;湖岸邊有個據說曾經是這附近土地領主的破敗城堡 Urquhart Castle。
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;處處可見飄揚的蘇格蘭旗，然而並沒有人因此逼着誰必須表態然後撕破臉，說你搞蘇獨，社會的包容度差距可見一斑。嘴上不用說，每個人內心都應該首先是個&amp;quot;獨立&amp;quot;的人，有獨立思想的個體。記得去臺灣的時候，不光有中華民國的青天白日旗，也有人拿着赤色紅旗，海峽對岸流淌着同樣華人血液的社會早已經進步到可以包容各種思想不同的意見的和諧，這一文明的光芒就如同太平洋上的燈塔。盼望有一天，中國，只有一個名字，沒有別的亂七八糟的定語，也不需要在這兩個字中間加各種各樣標新立異的字眼，只有一個 China 去代表這塊土地和有相同認同感的社會。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;晚上下榻的農家旅社
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h1 id=&#34;2018-06-19-回到愛丁堡&#34;&gt;2018-06-19 回到愛丁堡&lt;/h1&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;回到愛丁堡之後，我們的大廚 Linda 又跟我展示了一手好廚藝&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Todo 2018 June-September</title>
      <link>https://wangcc.me/post/todo-2018-june/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/todo-2018-june/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 大塚敏美財団メールを返信する&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;PCA analysis learning&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Cluster analysis learning&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;建立一個論文日程表格&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;日程計劃包括每周進度&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;分析進度&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;論文寫作進度&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;學習 Latent Class Analysis 方法;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;熟悉 NDNS 數據框架結構，思考分析方法;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Comment and response to AACE&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Test on Ubuntu 18.04&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;尝试从Ubuntu, 日本語を試す&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;更新 &lt;a href=&#34;http://wangcc.me/LSHTMlearningnote/&#34;&gt;LSHTM 統計學學習筆記&lt;/a&gt; &lt;a href=&#34;http://wangcc.me/LSHTMlearningnote/cox-.html&#34;&gt;生存分析章節-Cox-models&lt;/a&gt;;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 更新 LSHTM 統計學學習筆記，GLM Multinomial logistic regression model;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 更新 LSHTM 統計學學習筆記，GLM Oridinal logisitic regression model;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 更新 LSHTM 統計學學習筆記，貝葉斯進階章節;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 更新 LSHTM 統計學學習筆記，用 STATA 或者 R 分析 SME 流行病學數據的實踐部分;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 更新生存分析，更多具體細節及練習[Cox];&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 更新生存分析，更多具體細節及練習[AFT];&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;辦理法國簽證所需的材料; 法國行程取消(2018-06-20)&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;大學學生在校證明;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;銀行三個月存款證明&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;歐洲之星(7月)訂票;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;巴黎青年旅館訂房 (聯繫下正好在法國的 なっちゃん家?);&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;旅行保險;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;BRP 複印;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;護照複印;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;[xa] &lt;del&gt;簽證申請書;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;近三个月内的证件照，尺寸3.5cm x 4.5cm，白底&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 把 &lt;a href=&#34;https://github.com/winterwang/overleaf-thesis-template&#34;&gt;LaTeX 模板&lt;/a&gt; 調整到 &lt;a href=&#34;https://github.com/pzhaonet/bookdownplus&#34;&gt;Bookdownplus 的模板之一&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;複習 Bayesian&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-1;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-3&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-4;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-7;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-1;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-06-03 17:00, mean and variance for data transformation]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-3;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-06-03 17:30 linear regression, really need to pay attention in reading the question]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-4;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-7;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-06-03 22:30 Binomial exact test]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-1;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test done, coefficient and rho, 75% about]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-2;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-3;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-4;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test done, too much to write as a survival question, about 80%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test done, too much to write about 80%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-6;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-8;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test done, GLM about 90%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-1;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-4;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>To do list 2018 May</title>
      <link>https://wangcc.me/post/todotest/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/todotest/</guid>
      <description>&lt;p&gt;試試看用 &lt;a href=&#34;https://shrektan.com/post/2018/04/02/blogdown-todo/&#34;&gt;Blogdown 來管理自己的待辦事項&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;Causal inference 作業&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-18 12:00]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;學習去年的 Hierarchical discrete data modeling Lecture 1-4;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-08 23:45 done]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;學習去年的 Generalised linear mixed effect modelling lecture 5-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-12 16:00 done]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;完成 ASM Edmund 作業;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-18 03:20 done]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;寫一篇日志回顧最近 LSHTM 的生活;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-06 done]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;複習 Probablity;(2018-05-16 to 17)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;複習 Inference;(2018-05-17 to 18)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;複習 Clinical Trial;(2018-05-19 to 20)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;複習 Basic Epi; (2018-05-20 to 21)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;複習 Analytical Technique;(2018-05-22 to 24)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;複習 Regression; (2018-05-24 to 25)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;複習 Robust statistics; (2018-05-27)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;複習 GLM (2018-05-28 to 29)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;複習 Survival Analysis (2018-05-39 to 31)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;反省自己爲什麼效率這麼低。。。。。&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;解決辦法就是把自己的 to do 放在網頁上，刺激自己。(2018-05-06 done)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2008年 LSHTM 試題 Paper 2-2 (survival question);&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-29 17:01]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2009 年 LSHTM 試題 Paper 2-3 (survival question);&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-29 18:19]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-2;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-24 17:01 40 min used]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-18 12:21 done]&lt;/li&gt;
&lt;li&gt;[2018-06-03 12:51 done again 80% 17 min]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 11:15]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2011年 LSHTM 試題 Paper 1-8;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-19 22:50 done]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-2;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-19 23:43 done]&lt;/li&gt;
&lt;li&gt;[2018-06-03 16:30 Wald test, MLE, compare the inverse of mean]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-25 21:32 done 35 min]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 1-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-27 13:39 done 15 min]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 2012年 LSHTM 試題 Paper 1-8;
&lt;ul&gt;
&lt;li&gt;[2018-05-18 22:00 done]&lt;/li&gt;
&lt;li&gt;[2018-06-04 11:27 done again, when use transformation for MLE, we need to substitute it back to the loglikelihood function to find the standard error of the newly transformed variable]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2012年 LSHTM 試題 Paper 2-7;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 35 min but brutally beaten]&lt;/li&gt;
&lt;li&gt;[done 2018-06-04 20:00 Mock test 90%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-2;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-04-30, challenged again 2018-05-25 quadratic term interpration is needed]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-3;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-20 01:00 done]&lt;/li&gt;
&lt;li&gt;[done again on 2018-06-04 12:22 score test and comparison with lrt, hard way of doing lrt with binomial data, time consuming, about 80% got]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-4;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-04-30]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 23:38]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-04-30]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-03 15 min 80%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-7;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 14:09 18 min used]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 1-8;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 23:38]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-1&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-07 1800]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-2&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-07 1900]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-3&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-07 2230; challenged again 2018-05-25 20:58 35 min used]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-28 extreeeeeeeemely^99^ difficult GLM]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 21:21 in 37 min]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-7;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-28 巨難無比，條件邏輯回歸的推導和證明]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2013年 LSHTM 試題 Paper 2-8;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 23:38]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-1;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-04-23]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-2;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 27 min but only get about 60% poor and brutal&amp;hellip;&amp;hellip; what should I do&amp;hellip;]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-3;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-04-23]&lt;/li&gt;
&lt;li&gt;[done 2018-06-04 done in 29 min 90% got]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-4;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-20 22:56]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 18:33]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-19 13:43]&lt;/li&gt;
&lt;li&gt;[done agian 2018-06-03 11:18 17 min 80%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-7;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 15:07,278 min used]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 1-8;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-21 14:50]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-1;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-24 15:01]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-2;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-04-23]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-3;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-14 23:18; twice challenge 2018-05-25 17:20 better now]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-15 01:30; challenged again 2018-05-28 15:47 much better now]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-15 11:30]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-7;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-28 16:50 got 19 points out of 20 I like this one]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2014年 LSHTM 試題 Paper 2-8;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 18:38 36 min used, survival questions]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-1;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-19 14:53]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-03 00:05 17 min 80%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-2;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-20 13:46 20 min used]&lt;/li&gt;
&lt;li&gt;[done 2018-06-04 14:08 12 min used well done]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-3;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-20 22:15 20 min used but only get 50%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-4;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-23 21:00]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 12:16]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 12:06 25 min used but only get 60%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-7;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 16:57  28 min used]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 1-8;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 12:44]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-1;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-24 13:56]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-2;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 16:14 29 min used, somewhat easy I can have about 80%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-3;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 13:58]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-28 12:42]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-28 14:15 done within 25 min, Poisson regression model is within my range of ability]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-7;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-30 17:07 done. 40 min used. Quite difficult Weibull model with AFT feature.]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2015年 LSHTM 試題 Paper 2-8;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-22 00:58]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-1;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-02]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-03 00:04 30 min 80%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-2;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-02]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-04 14:40 20 80%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-3;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-02]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-4;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-02]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-02 and 2018-05-24 22:58 33 min used]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-03]&lt;/li&gt;
&lt;li&gt;[done 2018-06-02 17:41 about 80%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-7;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-03]&lt;/li&gt;
&lt;li&gt;[done 2018-06-02 17:41 about 80%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 1-8;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-03]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-1;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-23 18:00]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-2;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 01:03 very difficult competing risk(subdistribution) model]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-01 11:59, more than 80% get, answers improved]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-3;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-25 01:38 40 min used]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 23:58 45 min used]&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 2018-05-31 15:22 challenged again 32 min used, answers improved.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-28 11:55 matched case-control study]&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 2018-05-31 16:04 challenged again 27 min used, answers improved.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-7;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-30 13:09 Weibull model with connection to AFT model]&lt;/li&gt;
&lt;li&gt;[done again 2018-06-01 12:00 more than 80% got, answers improved]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2016年 LSHTM 試題 Paper 2-8;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-21 13:00]&lt;/li&gt;
&lt;li&gt;[done 2018-06-02 17:40 again, about 80%]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-1;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-19 20:02 done]&lt;/li&gt;
&lt;li&gt;[2018-06-03 00:03 17 min done 80% got]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-2;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-20 16:07 史上最難]&lt;/li&gt;
&lt;li&gt;[2018-06-04 20 min 90% got, MSE = Variance + (Bias)^2]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-3;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-20 18:30]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-4;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-23 01:45 done]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-24 21:57 done]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-21 02:35 被虐慘了]&lt;/li&gt;
&lt;li&gt;[2018-06-02 14:49 largely improved]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-7;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-21 11:09 答案可能有錯的 AT?]&lt;/li&gt;
&lt;li&gt;[2018-06-02 14:48 done again, Good]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 1-8;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-27 12:34 done, 28 min used, but only had 60%. &lt;strong&gt;Read your question carefully!!!&lt;/strong&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-1;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-21 12:49 done 17]&lt;/li&gt;
&lt;li&gt;[2018-06-02 14:48 done again, largely improved]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-2;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[done 2018-05-27 23:09 extremely difficult GLM]&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; challenged again 2018-05-31 21 min done with quick smash&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-3;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-27 20:00 very difficult combined with ordinal logistic regression]&lt;/li&gt;
&lt;li&gt;[2018-05-31 14:35 challenged again, 40 min, still very difficult but improved]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-5;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-29 20:11 done, not very difficult survival question, but you only got about 50%]&lt;/li&gt;
&lt;li&gt;[2018-06-01 13:52 challenged again, answers improved, some time-dependent variable in survival analysis is quite interesting]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-6;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-29 22:47 done, not very difficult, but less than 50% obtained]&lt;/li&gt;
&lt;li&gt;[2018-06-01 13:55 done again, answers improved.]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-7;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-24 18:43 done 45 min used. too much time wasted!!!]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;del&gt;2017年 LSHTM 試題 Paper 2-8;&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;[2018-05-20]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>你靜靜地睡在琥珀裏</title>
      <link>https://wangcc.me/post/sleep/</link>
      <pubDate>Sun, 06 May 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/sleep/</guid>
      <description>&lt;p&gt;媽在電話裏說，今年要是期末考試考不過，明年把妹妹(我女兒)背去倫敦再考。(T_T) 突然我就想起快離開廈門的前一天，帶着兒子去大榕樹底下玩。他興奮地要玩我新買的乒乓球和乒乓球拍。可我心裏舍不得新的球和球拍弄髒了，就故意拿小汽車和其他的東西分散他的注意力。回到家裏了才給了他一個乒乓球玩。其實那天本來還想帶他去買肉包給他吃，可是領了快遞以後我沒有手再拿東西，就直接帶兒子回家了。那天兒子女兒和妻還要坐火車回榕城外婆家，一路顛簸誰也沒想起來，兒子還沒吃早飯。火車上聽說他也一直沒吃東西，不知道他三歲的心裏在想什麼。到了外婆家裏也很晚了，男孩子興奮哭鬧總是比女孩子激烈。我一聽電話裏他哭的聲音，心裏就不由得難受極了。怎麼就舍不得把乒乓球給他一個呢，我真是個自私極了的爸爸。忘了兒子沒吃早飯，也舍不得把他想玩的乒乓球送給他。也許他早就不記得了，但是我總惦記着這一天發生的事。也許在我心裏，那段美好時光在琥珀中靜止在了廈門開往島外的那列送行的地鐵上。&lt;/p&gt;
&lt;p&gt;我又想起在學習&lt;a href=&#34;http://wangcc.me/LSHTMlearningnote/causal-languages-.html&#34;&gt;因果推斷&lt;/a&gt;的時候，每次老師都要強調那三個永世不能忘記的推斷前提:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;無相互幹擾 no interference;&lt;/li&gt;
&lt;li&gt;一致性 consistency;&lt;/li&gt;
&lt;li&gt;條件可置換性 conditional exchangeability;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;每當老師提問說，我們現在的前提是什麼？全班同學總能異口同聲地念出上面那三句咒語，場景仿佛間諜與間諜之間對暗號。又有點像黑幫入會時指天發誓的三句誓言。還有就是那個老師可愛的法文味道的英文，標準誤的英文是 standard error，她總是說 standard &amp;ldquo;唉河&amp;rdquo;。另一個教生存分析的法國人老師就更有趣了，每次舉例子都說，比方說我們拿&amp;ndash;法國做例子，隨機選一個國家嘛。。blablabla&amp;hellip;&lt;/p&gt;
&lt;p&gt;今天，響子同學說要去阿根廷完成自己的碩士課題。我們下午坐在 SOAS 的草地上一邊從作業間隙中休息，一邊喝着咖啡，突然意識到，再過一陣子，新學生就又要來了呢。去年這時候我們都還在世界各地，響子在危地馬拉給 JICA 幹活，說着流利的西班牙語; 我在名古屋一邊給日本學生講課，一邊內心充滿了期待快出生的妹妹和快要出發來倫敦的復雜又忐忑的心情，如今我們竟然已經在討論彼此回程的機票訂了幾號，想起3月我們還在寒風中頂着大雪抱怨着留英這一年碰到數十年最嚴重的大學罷課，這一段時光，竟也這樣偷偷溜走，沒有琥珀可以給它定格。&lt;/p&gt;
&lt;p&gt;直到兩天前，同班同學在因果推斷下課後，復習完了我們每次課上對完的暗號，突然有同學提議說，我們去學校門口拍一張集體照片吧，學校年度學生畫冊 (Yearbook) 的內容我們還沒人提交吶，至少要有一張咱們的集體照片吧！ 於是我們有了封面的那張照片。總算是用 LOMO 的隨手拍記錄下這年我們在 LSHTM 待過的證據。這年，我們這十幾個在 LSHTM 推倒公式，背誦&amp;quot;間諜暗號&amp;rdquo;，倒騰貝葉斯，糾結着那些回歸模型的殘差，還有那個永遠也搞不懂的似然。一瞬間留在相紙上，一轉眼可能就要各奔四方。傷感不由就從心中涌出，蔓延到大西洋。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>日落在下午四點</title>
      <link>https://wangcc.me/post/luan/</link>
      <pubDate>Sun, 14 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/luan/</guid>
      <description>&lt;p&gt;倫敦的生活已經過去四個月，每天和統計學公式打交道的我，今天不想在這裏寫任何公式。說說這四個月想更新一直偷懶沒更新的那些在倫敦衛生與熱帶醫學院度過的平凡的日子。&lt;/p&gt;
&lt;p&gt;寒假時去了普利茅斯，和康沃爾。康沃爾是個很有意思的名字 Cornwall。字面意思是玉米牆。我是去自己本來計劃聖誕節想去的 Homestay。&lt;a href=&#34;http://www.hostuk.org/&#34;&gt;HOST UK&lt;/a&gt; 本來負責我的人告訴我聖誕節可能有點困難，聖誕節前的週末可以的話就去康沃爾的一對退休的老人家裏去做客吧。於是週五一早踏上了一個多月前就從網上訂好的倫敦的帕丁頓去往卡爾斯托克 (Calstock) 的西大不列顛列車。說來諷刺的是，大英帝國建立了世界上第一條火車，如今我一個老外來到這個國家卻在嫌棄這裏的火車慢如老牛拉車。&lt;/p&gt;
&lt;p&gt;和我一起享受英國農村四天三晚的 Homestay 的還有另一個來自毛里求斯的印度人學生。我們一路同行從倫敦出發。整列火車從離開倫敦時的滿員，乘客隨着車窗外樓房的減少而逐漸減少。&lt;del&gt;腦海裏推算了一下，這絕對是有意義的正相關。&lt;/del&gt; 到了普利茅斯只剩下包括我倆在內，絕對只有個位數的人。&lt;/p&gt;
&lt;p&gt;我也沒打算把整個四天三晚都去了哪裏在這裏記流水帳，印象深刻的是我們和老爺爺老太太每晚每晚的長談。還好來自毛里求斯的印度人英文流利，我一個人跟這些老人肯定是無法聊到深夜的。他們聊他們的老當益壯，用腳丈量非洲大陸的那些經歷和記憶，我們侃我們的年輕氣盛和那些無處發泄的憂國憂民。走時，老爺爺把自己收藏了多年的一個據說來自唐朝中國的佛像給了我，說，我希望你帶它回到它來自的地方。我想起我們都站在康沃爾的大西洋沿岸峭壁懸崖，放眼望着法國的方向，腳下全是泥巴。&lt;/p&gt;
&lt;p&gt;我在老人家的留言本上寫下了我在中國和日本的地址電話，中日英三語，生怕他們真的會在中國或者日本迷路。隔天回到了倫敦的房間，我收到老爺爺發來的郵件，淡然如水，卻彷若那些夜晚我們促膝長談時說的話：“你豐富了我們的人生，在你我的道路重新交集前，保重。You have enriched our lives. Until our paths cross again, take care.”&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;英國冬季的日照時間短得可憐。白天離開宿舍去大學時天黑着，下午下課離開大學時，天依然是黑着的。加上我們統計系的課許多都在地下的教室裏，我跟其他人打趣說，我現在的生活像一隻土撥鼠。我在地下，推導着讓我內心無比踏實的那些數學公式。&lt;/p&gt;
&lt;p&gt;有時候，我會十分的想念日本的生活。有時候，我又會無比的思念廈門的日子。這些落腳過的地方，只有上海的感覺越來越模糊。不知道我懷念的是名古屋乾淨的街道，是廈門的沙茶面的味道，還是那些夜晚打完工以後路邊的便利店門口騎着腳踏車路過的那時的我，也許還有那個在白城沙灘上可以悠閒地聽海浪拍岸聲的那個無腦少年。不清楚緣由地，只有上海的記憶在大腦中逐漸變得不那麼色彩斑斕。我也很好奇多年以後我會怎樣回憶倫敦？ 也許只剩下記憶裏土撥鼠一樣的無聊日子，還有貴死你不償命的宿舍房租。&lt;/p&gt;
&lt;p&gt;跨年那晚我和幾個同學走在滿目瘡痍的倫敦街頭，焰火散去，人去城空，2018年就已經被我們踩在了腳下。眼看着這新的一年在凌亂中開始，但願過程也不要太過殘酷。這一年唯一的目標是順利完成這沒日沒夜 (說好聽是朝思暮想) 的醫學統計學碩士。還有的話就是希望家人孩子平安，待我回到你們身邊，我們再也不要用小的可憐的手機屏幕來看彼此，我要帶你們去看整個世界。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>萬衆期待，英國黑暗料理</title>
      <link>https://wangcc.me/post/black-meal/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/black-meal/</guid>
      <description>&lt;h3 id=&#34;康沃爾的牛肉餡餅-贊-2017-12-16-the-shop-in-the-squarehttpswwwgooglecommapsplacetheshopinthesquare503310101-4202101421zdata4m131m73m61s0x00x02zntdcsde5jzuyljaitia0wraxmicwny4yilc3b18m23d5033114d-42023m41s0x486c94411d32061f0xc6ba3bcac8fcc9318m23d503310874d-42021739&#34;&gt;康沃爾的牛肉餡餅！ 贊！ (2017-12-16 @&lt;a href=&#34;https://www.google.com/maps/place/The+Shop+in+the+Square/@50.3310101,-4.2021014,21z/data=!4m13!1m7!3m6!1s0x0:0x0!2zNTDCsDE5JzUyLjAiTiA0wrAxMicwNy4yIlc!3b1!8m2!3d50.3311!4d-4.202!3m4!1s0x486c94411d32061f:0xc6ba3bcac8fcc931!8m2!3d50.331087!4d-4.2021739&#34;&gt;The Shop in the Square&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1483.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;看起來美味但是甜到牙痛的聖誕蛋糕-2017-12-17-calstock-homestay&#34;&gt;看起來美味但是甜到牙痛的聖誕蛋糕 (2017-12-17 @Calstock Homestay)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1559.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;香腸美味烤雞美味洋蔥有點糊但是還是很美味-2017-12-16-janeians-homestay&#34;&gt;香腸美味！烤雞美味！洋蔥有點糊但是還是很美味！ (2017-12-16 @Jane&amp;amp;Ian&amp;rsquo;s Homestay)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_20171217_045212.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;在中國城買到最贊的國貨廈門鐵觀音-2017-12-09-london-china-town&#34;&gt;在中國城買到最贊的國貨！廈門鐵觀音 (2017-12-09 @London China Town)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1374.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;貴到無法下手的三文魚壽司-2017-12-06-waitrose&#34;&gt;貴到無法下手的三文魚壽司 (2017-12-06 @Waitrose)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1356.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;和日本一風堂味道一樣但是貴一倍的豚骨拉麵-2017-12-02-london-ippudohttpwwwippudocouk&#34;&gt;和日本一風堂味道一樣但是貴一倍的豚骨拉麵 (2017-12-02 @&lt;a href=&#34;http://www.ippudo.co.uk/&#34;&gt;London Ippudo&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1312.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;學校附近和同學一起去喝過最棒的拿鐵缺點是杯子太小-2017-12-01-tap-caffeehttpwwwtapcoffeecouk&#34;&gt;學校附近和同學一起去喝過最棒的拿鐵，缺點是杯子太小 (2017-12-01 @&lt;a href=&#34;http://www.tapcoffee.co.uk/&#34;&gt;Tap Caffee&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1306.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;brunch-在長頸鹿餐廳可以打8折-2017-11-29-giraffehttpswwwgiraffenet&#34;&gt;Brunch 在長頸鹿餐廳可以打8折 (2017-11-29 @&lt;a href=&#34;https://www.giraffe.net/&#34;&gt;Giraffe&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1293.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;約克郡的傳統午餐美味牛肉-2017-11-26-the-judges-lodginghttpswwwthwaitescoukhotels-and-innsinnsjudges-lodging-at-yorkfood-and-drinkmenus&#34;&gt;約克郡的傳統午餐，美味牛肉 (2017-11-26 @&lt;a href=&#34;https://www.thwaites.co.uk/hotels-and-inns/inns/judges-lodging-at-york/food-and-drink/menus/&#34;&gt;The Judge&amp;rsquo;s Lodging&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1244.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;謝菲爾德的聖誕街市賣的烤香腸-2017-11-25-sheffield&#34;&gt;謝菲爾德的聖誕街市賣的烤香腸 (2017-11-25 @Sheffield)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1143.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;日本同學從日本帶來的速食味增湯美味至極-2017-11-23-international-hall&#34;&gt;日本同學從日本帶來的速食味增湯，美味至極 (2017-11-23 @International Hall)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_1118.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;國王十字車站對面的新加坡華人餐廳海南雞飯不錯-2017-11-01-chop-chop-noodle-barhttpswwwgooglecommapsplacechopchopnoodlebar515303949-0122624919zdata4m131m73m61s0x00x02znthcsdmxjzq5ljgitiawwrawnycyms43ilc3b18m23d5153054d-012273m41s0x00x252e2c027563f1e48m23d5153039594d-0122609&#34;&gt;國王十字車站對面的新加坡華人餐廳，海南雞飯不錯 (2017-11-01 @&lt;a href=&#34;https://www.google.com/maps/place/Chop+Chop+Noodle+Bar/@51.5303949,-0.1226249,19z/data=!4m13!1m7!3m6!1s0x0:0x0!2zNTHCsDMxJzQ5LjgiTiAwwrAwNycyMS43Ilc!3b1!8m2!3d51.5305!4d-0.1227!3m4!1s0x0:0x252e2c027563f1e4!8m2!3d51.5303959!4d-0.122609&#34;&gt;Chop Chop Noodle Bar&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0649.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;同學宿舍裏的自制小炒-2017-10-21-the-garden-hall&#34;&gt;同學宿舍裏的自制小炒 (2017-10-21 @The Garden Hall)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0548.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;大英博物館前的中餐館的水煮魚-2017-10-20-changs-noodlehttpswwwgooglecommapsplacechangsnoodle51517143-0125633421zdata4m131m73m61s0x00x02znthcsdmxjzaxljyitiawwrawnyczms44ilc3b18m23d5151714d-012553m41s0x48761b3301f99d9d0x3ba6ded2ee933a5a8m23d5151723644d-01254925&#34;&gt;大英博物館前的中餐館的水煮魚 (2017-10-20 @&lt;a href=&#34;https://www.google.com/maps/place/Chang&#39;s+Noodle/@51.517143,-0.1256334,21z/data=!4m13!1m7!3m6!1s0x0:0x0!2zNTHCsDMxJzAxLjYiTiAwwrAwNyczMS44Ilc!3b1!8m2!3d51.5171!4d-0.1255!3m4!1s0x48761b3301f99d9d:0x3ba6ded2ee933a5a!8m2!3d51.5172364!4d-0.1254925&#34;&gt;Chang&amp;rsquo;s Noodle&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0537.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;大英博物館前的都可茶飲買到的原味珍珠奶茶-35-有學生優惠-2017-10-20-cocohttpencoco-teacom&#34;&gt;大英博物館前的都可茶飲買到的原味珍珠奶茶 £3.5 有學生優惠 (2017-10-20 @&lt;a href=&#34;http://en.coco-tea.com/&#34;&gt;Coco&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0534.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;雞腿不錯但是旁邊的配菜有點像中藥味的壓縮餅乾-2017-10-08-ihdining-room&#34;&gt;雞腿不錯但是旁邊的配菜有點像中藥味的壓縮餅乾 (2017-10-08 @IHdining room)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/953062095.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;哈利波特特約飲料-butterbeer-奶油啤酒2017-10-07-warner-bros-studio-tour-londonhttpswwwwbstudiotourcouk&#34;&gt;哈利波特特約飲料 Butterbeer （奶油啤酒）(2017-10-07 @&lt;a href=&#34;https://www.wbstudiotour.co.uk/&#34;&gt;Warner Bros. Studio Tour London&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/244977493.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;以爲是甜食的派結果裏面包着牛肉的奇怪料理-2017-10-07-ihdining-room&#34;&gt;以爲是甜食的派結果裏面包着牛肉的奇怪料理 (2017-10-07 @IHdining room)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1959199628.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;羅素廣場地鐵站門口的小攤賣的超划算味道很正的新鮮草莓2017-10-05-russel-square-stationhttpswwwgooglecoukmapsplacerussellsquarestation51523111-0126573117zdata3m14b14m53m41s0x48761b30d8fe51730xcf6c5a59086862108m23d515231114d-01243844hlen&#34;&gt;羅素廣場地鐵站門口的小攤賣的超划算味道很正的新鮮草莓！(2017-10-05 @&lt;a href=&#34;https://www.google.co.uk/maps/place/Russell+Square+Station/@51.523111,-0.1265731,17z/data=!3m1!4b1!4m5!3m4!1s0x48761b30d8fe5173:0xcf6c5a5908686210!8m2!3d51.523111!4d-0.1243844?hl=en&#34;&gt;Russel Square Station&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1040178656.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;价值5镑的食堂素食色拉一盒-2017-10-02lshtm食堂&#34;&gt;价值5镑的食堂素食色拉一盒 (2017-10-02@LSHTM食堂)&lt;/h3&gt;
&lt;p&gt;新鮮，但是米飯有點夾生。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/41913438.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;味道超讚牛肉披薩-diavolo-2017-09-28-pizza-express-in-charlotte-streethttpswwwpizzaexpresscomcharlotte-streetutm_sourcegoogleutm_mediumplacesutm_campaigncharlotte-street&#34;&gt;味道超讚牛肉披薩 Diavolo (2017-09-28 @&lt;a href=&#34;https://www.pizzaexpress.com/charlotte-street?utm_source=Google&amp;amp;utm_medium=Places&amp;amp;utm_campaign=charlotte-street&#34;&gt;Pizza Express in Charlotte Street&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_20170928_184500.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;菜單上的說明是這樣滴：
Hot spiced beef, pepperoni, mozzarella, tomato, green pepper, red onion and Tabasco, with your choice of hot green, Roquito or jalapeño peppers. Available as Classic or Romana&lt;/p&gt;
&lt;h3 id=&#34;羊肉味的奶油夾心三明治-2017-09-24-store-street-espressohttpwwwstorestespressocouk&#34;&gt;羊肉味的奶油夾心三明治 (2017-09-24 @&lt;a href=&#34;http://www.storestespresso.co.uk/&#34;&gt;Store Street Espresso&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;我點菜之前還故意跟收銀員小妹搭訕，讓她推薦一下今天的特色三明治。
她推薦的這個 Goat Cheese Sandwich。 當然我一開始聽到這名字的時候就有點猶豫。但是想說既然是推薦的應該至少不會有什麼怪味道。結果事實證明了，我的想法是多麼的幼稚。&lt;/p&gt;
&lt;p&gt;看這剛出爐的香噴噴的三明治，我咬下第一口就差點吐了。羊羶味在我喉嚨和鼻腔中打轉。後悔也來不及了。另外我同同時還點了 Espresso。就是特濃咖啡。口味超重！不能喝濃咖啡的一定要慎點！！！！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1388034054.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;酸酸的不知道怎麼形容的麵包-日期忘了估計是剛到的第二個早晨的早餐ihdining-room&#34;&gt;酸酸的不知道怎麼形容的麵包 (日期忘了，估計是剛到的第二個早晨的早餐@IHdining room)&lt;/h3&gt;
&lt;p&gt;這麵包吃起來鬆鬆的，然額，麵的味道有些酸，又不像是過期食品，而像是本來就應該是這樣的味道的酸麵包。讓人不想再嘗試第二次。。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/890249589.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;美味海鮮飯-2017-09-24-ciao-bellahttpciaobellarestaurantcouk&#34;&gt;美味海鮮飯 (2017-09-24 @&lt;a href=&#34;http://ciaobellarestaurant.co.uk/&#34;&gt;Ciao Bella&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;感謝&lt;a href=&#34;https://kclpure.kcl.ac.uk/portal/li.yan.html&#34;&gt;顏師兄&lt;/a&gt;帶領，終於找到了一家可以吃到正常大米的飯店了！且海鮮量超足！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/737031981.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;看起來很奇怪的整魚炸薯條&#34;&gt;看起來很奇怪的整魚炸薯條&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/656438330.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;外觀其實讓人沒什麼食慾的烤魚&#34;&gt;外觀其實讓人沒什麼食慾的烤魚&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1628745573.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;酸奶放在白煮雞胸肉上&#34;&gt;酸奶放在白煮雞胸肉上&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0185.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>對數似然比 Log-likelihood ratio</title>
      <link>https://wangcc.me/post/log-likelihood-ratio/</link>
      <pubDate>Sun, 05 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/log-likelihood-ratio/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;對數似然比-log-likelihood-ratio&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;對數似然比 Log-likelihood ratio&lt;/h3&gt;
&lt;p&gt;對數似然比的想法來自於將對數似然方程圖形的 &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 軸重新調節 (rescale) 使之最大值爲零。這可以通過計算該分佈方程的&lt;strong&gt;對數似然比 (log-likelihood ratio)&lt;/strong&gt; 來獲得：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\theta)=\ell(\theta|data)-\ell(\hat{\theta}|data)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由於 &lt;span class=&#34;math inline&#34;&gt;\(\ell(\theta)\)&lt;/span&gt; 的最大值在 &lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}\)&lt;/span&gt; 時， 所以，&lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)\)&lt;/span&gt; 就是個當 &lt;span class=&#34;math inline&#34;&gt;\(\theta=\hat{\theta}\)&lt;/span&gt; 時取最大值，且最大值爲零的方程。很容易理解我們叫這個方程爲對數似然比，因爲這個方程就是將似然比 &lt;span class=&#34;math inline&#34;&gt;\(LR(\theta)=\frac{L(\theta)}{L(\hat{\theta})}\)&lt;/span&gt; 取對數而已。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/post/likelihood/&#34;&gt;之前&lt;/a&gt;我們也確證了，不包含我們感興趣的參數的方程部分可以忽略掉。還是用上一節 10人中4人患病的例子：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\pi|X=4)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\\
\Rightarrow \ell(\pi)=log[\pi^4(1-\pi)^{10-4}]\\
\Rightarrow llr(\pi)=\ell(\pi)-\ell(\hat{\pi})=log\frac{\pi^4(1-\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其實由上也可以看出 &lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)\)&lt;/span&gt; 只是將對應的似然方程的 &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 軸重新調節了一下而已。形狀是沒有改變的：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow=c(1,2))
x &amp;lt;- seq(0,1,by=0.001)
y &amp;lt;- (x^4)*((1-x)^6)/(0.4^4*0.6^6)
z &amp;lt;- log((x^4)*((1-x)^6))-log(0.4^4*0.6^6)
plot(x, y, type = &amp;quot;l&amp;quot;, ylim = c(0,1.1),yaxt=&amp;quot;n&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;LR(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
axis(2, at=seq(0,1, 0.2), las=2)
title(main = &amp;quot;Binomial likelihood ratio&amp;quot;)
abline(h=1.0, lty=2)
segments(x0=0.4, y0=0, x1=0.4, y1=1, lty = 2)
plot(x, z, type = &amp;quot;l&amp;quot;, ylim = c(-10, 1), yaxt=&amp;quot;n&amp;quot;, frame.plot = FALSE,
     ylab = &amp;quot;llr(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot; )
axis(2, at=seq(-10, 0, 2), las=2)
title(main = &amp;quot;Binomial log-likelihood ratio&amp;quot;)
abline(h=0, lty=2)
segments(x0=0.4, y0=-10, x1=0.4, y1=0, lty = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;正態分佈數據的最大似然和對數似然比&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;正態分佈數據的最大似然和對數似然比&lt;/h4&gt;
&lt;p&gt;假設單個樣本 &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 是來自一組服從正態分佈數據的觀察值：&lt;span class=&#34;math inline&#34;&gt;\(Y\sim N(\mu, \tau^2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那麼有：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
f(y|\mu) &amp;amp;= \frac{1}{\sqrt{2\pi\tau^2}}e^{(-\frac{1}{2}(\frac{y-\mu}{\tau})^2)} \\
\Rightarrow L(\mu|y) &amp;amp;=\frac{1}{\sqrt{2\pi\tau^2}}e^{(-\frac{1}{2}(\frac{y-\mu}{\tau})^2)} \\
\Rightarrow \ell(\mu)&amp;amp;=log(\frac{1}{\sqrt{2\pi\tau^2}})-\frac{1}{2}(\frac{y-\mu}{\tau})^2\\
omitting&amp;amp;\;terms\;not\;in\;\mu \\
&amp;amp;= -\frac{1}{2}(\frac{y-\mu}{\tau})^2 \\
\Rightarrow \ell^\prime(\mu) &amp;amp;= 2\cdot[-\frac{1}{2}(\frac{y-\mu}{\tau})\cdot\frac{-1}{\tau}] \\
&amp;amp;=\frac{y-\mu}{\tau^2} \\
let \; \ell^\prime(\mu) &amp;amp;= 0 \\
\Rightarrow \frac{y-\mu}{\tau^2} &amp;amp;= 0 \Rightarrow \hat{\mu} = y\\
\because \ell^{\prime\prime}(\mu) &amp;amp;=  \frac{-1}{\tau^2} &amp;lt; 0 \\
\therefore \hat{\mu} &amp;amp;= y \Rightarrow \ell(\hat{\mu}=y)_{max}=0 \\
llr(\mu)&amp;amp;=\ell(\mu)-\ell(\hat{\mu})=\ell(\mu)\\
&amp;amp;=-\frac{1}{2}(\frac{y-\mu}{\tau})^2
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;n-個獨立正態分佈樣本的對數似然比&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立正態分佈樣本的對數似然比&lt;/h3&gt;
&lt;p&gt;假設一組觀察值來自正態分佈 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu,\sigma^2)\)&lt;/span&gt;，先假設 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 已知。將觀察數據 &lt;span class=&#34;math inline&#34;&gt;\(x_1,\cdots, x_n\)&lt;/span&gt; 標記爲 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt;。 那麼：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
L(\mu|\underline{x}) &amp;amp;=\prod_{i=1}^nf(x_i|\mu)\\
\Rightarrow \ell(\mu|\underline{x}) &amp;amp;=\sum_{i=1}^nlogf(x_i|\mu)\\
&amp;amp;=\sum_{i=1}^n[-\frac{1}{2}(\frac{x_i-\mu}{\sigma})^2]\\
&amp;amp;=-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\\
&amp;amp;=-\frac{1}{2\sigma^2}[\sum_{i=1}^n(x_i-\bar{x})^2+\sum_{i=1}^n(\bar{x}-\mu)^2]\\
omitting&amp;amp;\;terms\;not\;in\;\mu \\
&amp;amp;=-\frac{1}{2\sigma^2}\sum_{i=1}^n(\bar{x}-\mu)^2\\
&amp;amp;=-\frac{n}{2\sigma^2}(\bar{x}-\mu)^2 \\
&amp;amp;=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\\
\because \ell(\hat{\mu}) &amp;amp;= 0 \\
\therefore llr(\mu) &amp;amp;= \ell(\mu)-\ell(\hat{\mu}) = \ell(\mu)
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;n-個獨立正態分佈樣本的對數似然比的分佈&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立正態分佈樣本的對數似然比的分佈&lt;/h3&gt;
&lt;p&gt;假設我們用 &lt;span class=&#34;math inline&#34;&gt;\(\mu_0\)&lt;/span&gt; 表示總體均數這一參數的值。要注意的是，每當樣本被重新取樣，似然，對數似然方程，對數似然比都隨着觀察值而變 (即有自己的分佈)。&lt;/p&gt;
&lt;p&gt;考慮一個服從正態分佈的單樣本 &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(Y\sim N(\mu_0,\tau^2)\)&lt;/span&gt;。那麼它的對數似然比：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\mu_0|Y)=\ell(\mu_0)-\ell(\hat{\mu})=-\frac{1}{2}(\frac{Y-\mu_0}{\tau})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;根據&lt;a href=&#34;https://winterwang.github.io/post/chi-square-distribution/&#34;&gt;卡方分佈&lt;/a&gt;的定義：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\because \frac{Y-\mu_0}{\tau}\sim N(0,1)\\
\Rightarrow (\frac{Y-\mu_0}{\tau})^2 \sim \mathcal{X}_1^2\\
\therefore -2llr(\mu_0|Y) \sim \mathcal{X}_1^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，如果有一組服從正態分佈的觀察值：&lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu_0,\sigma^2)\)&lt;/span&gt;，且 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 已知的話：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2llr(\mu_0|\bar{X})\sim \mathcal{X}_1^2\]&lt;/span&gt;&lt;/p&gt;
根據&lt;a href=&#34;https://winterwang.github.io/post/central-limit-theory/&#34;&gt;中心極限定理&lt;/a&gt;，可以將上面的結論一般化：

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-2&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 1  &lt;/strong&gt;&lt;/span&gt;如果 &lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}f(x|\theta)\)&lt;/span&gt;。 那麼當重複多次從參數爲 &lt;span class=&#34;math inline&#34;&gt;\(\theta_0\)&lt;/span&gt; 的總體中取樣時，那麼統計量 &lt;span class=&#34;math inline&#34;&gt;\(-2llr(\theta_0)\)&lt;/span&gt; 會漸進於自由度爲 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; 的卡方分佈： &lt;span class=&#34;math display&#34;&gt;\[-2llr(\theta_0)=-2\{\ell(\theta_0)-\ell(\hat{\theta})\}\xrightarrow[n\rightarrow\infty]{}\;\sim \mathcal{X}_1^2\]&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;似然比信賴區間&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;似然比信賴區間&lt;/h3&gt;
&lt;p&gt;如果樣本量 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 足夠大 (通常應該大於 &lt;span class=&#34;math inline&#34;&gt;\(30\)&lt;/span&gt;)，根據上面的定理：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2llr(\theta_0)=-2\{\ell(\theta_0)-\ell(\hat{\theta})\}\sim \mathcal{X}_1^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Prob(-2llr(\theta_0)\leqslant \mathcal{X}_{1,0.95}^2=3.84) = 0.95\\
\Rightarrow Prob(llr(\theta_0)\geqslant-3.84/2=-1.92) = 0.95\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;故似然比的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間就是能夠滿足 &lt;span class=&#34;math inline&#34;&gt;\(llr(\theta)=-1.92\)&lt;/span&gt; 的兩個 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; 值。&lt;/p&gt;
&lt;div id=&#34;以二項分佈數據爲例&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以二項分佈數據爲例&lt;/h4&gt;
&lt;p&gt;繼續用本文開頭的例子：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\pi)=\ell(\pi)-\ell(\hat{\pi})=log\frac{\pi^4(1-\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果令 &lt;span class=&#34;math inline&#34;&gt;\(llr(\pi)=-1.92\)&lt;/span&gt; 在代數上可能較難獲得答案。然而從圖形上，如果我們在 &lt;span class=&#34;math inline&#34;&gt;\(y=-1.92\)&lt;/span&gt; 畫一條橫線，和該似然比方程曲線相交的兩個點就是我們想要求的信賴區間的上限和下限：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(0,1,by=0.001)
z &amp;lt;- log((x^4)*((1-x)^6))-log(0.4^4*0.6^6)
plot(x, z, type = &amp;quot;l&amp;quot;, ylim = c(-10, 1), yaxt=&amp;quot;n&amp;quot;, frame.plot = FALSE,
     ylab = &amp;quot;llr(\U03C0)&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot; )
axis(2, at=seq(-10, 0, 2), las=2)
abline(h=0, lty=2)
abline(h=-1.92, lty=2)
segments(x0=0.15, y0=-12, x1=0.15, y1=-1.92, lty = 2)
segments(x0=0.7, y0=-12, x1=0.7, y1=-1.92, lty = 2)
axis(1, at=c(0.15,0.7))
text(0.9, -1, &amp;quot;-1.92&amp;quot;)
arrows(0.8, -1.92, 0.8, 0, lty = 1, length = 0.08)
arrows( 0.8, 0, 0.8, -1.92, lty = 1, length = 0.08)
title(main = &amp;quot;Log-likelihood ratio for binomial example, \n with 95% likelihood confidence interval shown&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;從上圖中可以讀出，&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 對數似然比信賴區間就是 &lt;span class=&#34;math inline&#34;&gt;\((0.15, 0.7)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;以正態分佈數據爲例&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;以正態分佈數據爲例&lt;/h4&gt;
&lt;p&gt;本文前半部分證明過，
&lt;span class=&#34;math inline&#34;&gt;\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu,\sigma^2)\)&lt;/span&gt;，先假設 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; 已知。將觀察數據 &lt;span class=&#34;math inline&#34;&gt;\(x_1,\cdots, x_n\)&lt;/span&gt; 標記爲 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt;。 那麼：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[llr(\mu|\underline{x}) = \ell(\mu|\underline{x})-\ell(\hat{\mu}) = \ell(\mu|\underline{x}) \\
=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;很顯然，這是一個關於 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 的二次方程，且最大值在 MLE &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mu}=\bar{x}\)&lt;/span&gt; 時取值 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;。所以可以通過對數似然比法求出均值的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間公式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[-2\times[-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2]=3.84\\
\Rightarrow L=\bar{x}-\sqrt{3.84}\frac{\sigma}{\sqrt{n}} \\
U=\bar{x}+\sqrt{3.84}\frac{\sigma}{\sqrt{n}} \\
note: \;\sqrt{3.84}=1.96\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注意到這和我們&lt;a href=&#34;https://winterwang.github.io/post/frequentist-statistical-inference02/&#34;&gt;之前&lt;/a&gt;求的正態分佈均值的信賴區間公式完全一致。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exercise&lt;/h3&gt;
&lt;div id=&#34;q1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q1&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;假設十個對象中有三人死亡，用二項分佈模型來模擬這個例子，求這個例子中參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 的似然方程和圖形 (likelihood) ?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;解&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  L(\pi|3) &amp;amp;= \binom{10}{3}\pi^3(1-\pi)^{10-3} \\  omitting\;&amp;amp;terms\;not\;in\;\mu \\  \Rightarrow \ell(\pi|3) &amp;amp;= log[\pi^3(1-\pi)^7] \\  &amp;amp;= 3log\pi+7log(1-\pi)\\  \Rightarrow \ell^\prime(\pi|3)&amp;amp;= \frac{3}{\pi}-\frac{7}{1-\pi} \\  let \; \ell^\prime&amp;amp; =0\\  &amp;amp;\frac{3}{\pi}-\frac{7}{1-\pi} = 0 \\  &amp;amp;\frac{3-10\pi}{\pi(1-\pi)} = 0 \\  \Rightarrow MLE &amp;amp;= \hat\pi = 0.3 \end{aligned}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;計算似然比，並作圖，注意方程圖形未變，&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; 軸的變化；取對數似然比，並作圖&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;LR &amp;lt;- L/max(L) ; head(LR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0000000000 0.0004191759 0.0031233631 0.0098110584 0.0216286076
## [6] 0.0392577320&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(pi, LR, type = &amp;quot;l&amp;quot;, ylim = c(0, 1),yaxt=&amp;quot;n&amp;quot;, col=&amp;quot;darkblue&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
grid(NA, 5, lwd = 1)
axis(2, at=seq(0,1,0.2), las=2)
title(main = &amp;quot;Binomial likelihood ratio function\n 3 out of 10 subjects&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;logLR &amp;lt;- log(L/max(L))
plot(pi, logLR, type = &amp;quot;l&amp;quot;, ylim = c(-4, 0),yaxt=&amp;quot;n&amp;quot;, col=&amp;quot;darkblue&amp;quot;,
     frame.plot = FALSE, ylab = &amp;quot;&amp;quot;, xlab = &amp;quot;\U03C0&amp;quot;)
grid(NA, 5, lwd = 1)
axis(2, at=seq(-4,0,1), las=2)
title(main = &amp;quot;Binomial log-likelihood ratio function\n 3 out of 10 subjects&amp;quot;)
abline(h=-1.92, lty=1, col=&amp;quot;red&amp;quot;)
axis(4, at=-1.92, las=0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q2&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;與上面用同樣的模型，但是觀察人數變爲 &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; 人 患病人數爲 &lt;span class=&#34;math inline&#34;&gt;\(30\)&lt;/span&gt; 人，試作對數似然比方程之圖形，與上圖對比：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;可以看出，兩組數據的 MLE 都是一致的， &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.3\)&lt;/span&gt;，但是對數似然比方程圖形在 樣本量爲 &lt;span class=&#34;math inline&#34;&gt;\(n=100\)&lt;/span&gt; 時比 &lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt; 時窄很多，由此產生的似然比信賴區間也就窄很多（精確很多）。所以對數似然比方程的曲率（二階導數），反映了觀察獲得數據提供的對總體參數 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 推斷過程中的信息量。而且當樣本量較大時，對數似然比方程也更加接近左右對稱的二次方程曲線。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;q3&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Q3&lt;/h4&gt;
&lt;p&gt;在一個實施了160人年的追蹤調查中，觀察到8個死亡案例。使用泊松分佈模型，繪製對數似然比方程圖形，從圖形上目視推測極大似然比的 &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; 信賴區間。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;解-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{aligned}  d = 8, \;p &amp;amp;= 160\; person\cdot year \\  \Rightarrow D\sim Poi(\mu &amp;amp;=\lambda p) \\  L(\lambda|data) &amp;amp;= Prob(D=d=8) \\  &amp;amp;= e^{-\mu}\frac{\mu^d}{d!} \\  &amp;amp;= e^{-\lambda p}\frac{\lambda^d p^d}{d!} \\  omitting&amp;amp;\;terms\;not\;in\;\lambda \\  &amp;amp;= e^{-\lambda p}\lambda^d \\ \Rightarrow \ell(\lambda|data)&amp;amp;= log(e^{-\lambda p}\lambda^d) \\  &amp;amp;= d\cdot log(\lambda)-\lambda p \\  &amp;amp; = 8\times log(\lambda) - 160\times\lambda \end{aligned}\)&lt;/span&gt;&lt;/p&gt;
&lt;img src=&#34;https://wangcc.me/post/2017-11-05-log-likelihood-ratio_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;480&#34; /&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
lambda
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
LogLR
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.010
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-6.4755033
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.011
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-5.8730219
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.012
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-5.3369308
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.013
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.8565892
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.014
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.4237254
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.015
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.0317824
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.016
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.6754743
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.017
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.3504773
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.018
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.0532100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.019
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.7806722
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.020
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.5303259
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.021
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.3000045
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
0.022
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
-2.0878444
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
0.023
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
-1.8922303
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.024
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.7117534
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.025
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.5451774
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.026
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.3914117
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.027
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.2494891
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.028
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.1185480
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.029
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.9978174
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.030
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.8866050
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.031
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.7842864
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6902968
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.033
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6041236
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.034
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5252998
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.035
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.4533996
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.036
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3880325
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.037
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3288407
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.038
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2754948
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.039
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2276909
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.040
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1851484
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.041
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1476075
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.042
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1148271
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.043
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0865831
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.044
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0626670
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.045
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0428841
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.046
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0270529
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.047
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0150032
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.048
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0065760
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0016217
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.050
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.051
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0015790
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.052
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0062343
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.053
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0138487
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.054
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0243117
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.055
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0375186
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.056
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0533705
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.057
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0717739
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.058
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0926400
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.059
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1158845
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.060
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1414275
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.061
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1691931
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.062
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1991090
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.063
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2311062
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.064
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2651194
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.065
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3010859
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.066
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3389461
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.067
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.3786431
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.068
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.4201224
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.069
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.4633320
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.070
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5082221
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.071
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5547450
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.072
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6028551
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.073
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.6525085
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.074
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.7036633
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.075
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.7562791
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.076
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.8103173
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.077
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.8657407
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.078
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.9225134
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.079
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.9806012
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.080
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.0399710
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.081
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.1005908
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.082
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.1624301
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.083
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.2254592
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.084
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.2896497
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.085
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.3549740
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.086
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.4214057
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.087
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.4889191
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.088
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.5574895
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.089
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.6270931
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.090
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.6977067
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.091
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.7693080
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.092
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.8418754
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
0.093
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
-1.9153881
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
0.094
&lt;/td&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;&#34;&gt;
-1.9898258
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.095
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.0651689
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.096
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.1413985
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.097
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.2184962
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.098
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.2964442
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.099
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.3752252
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.100
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2.4548226
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;所以從列表數據結合圖形， 可以找到信賴區間的下限在 0.022~0.023 之間， 上限在 0.093～0.094 之間。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>偉大的中心極限定理</title>
      <link>https://wangcc.me/post/central-limit-theory/</link>
      <pubDate>Thu, 19 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/central-limit-theory/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;最近明顯可以感覺到課程的步驟開始加速。看我的課表：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0522.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;手機畫面太小了。早上都是9點半開始，下午基本都是到5點。週一更慘，到7點。週二-週五中午都被統計中心的講座佔據。簡直是非人的生活。&lt;/p&gt;
&lt;p&gt;這周概率論基礎結束。中心極限定理講完以後我們正式進入了 Inference 統計推斷的課程。我們花了一天時間講什麼是樣本估計 (Estimation)，什麼是參數精確度 (Precision)，什麼是自由度 (degree of freedom)，怎樣進行不偏的估計 (unbiased inference)。然後還有似然方程 (likelihood function)。&lt;/p&gt;
&lt;p&gt;今天的更新還是簡單的把概率論掃尾一下。感受一下中心極限定理的偉大。&lt;/p&gt;
&lt;div id=&#34;協方差-covariance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;協方差 Covariance&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/post/probability2-4/&#34;&gt;之前我們定義過&lt;/a&gt;，兩個獨立連續隨機變量 &lt;span class=&#34;math inline&#34;&gt;\(X,Y\)&lt;/span&gt; 之和的方差 Variance ：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var(X+Y)=Var(X)+Var(Y)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然而如果他們並不相互獨立的話：&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
Var(X+Y) &amp;amp;= E[((X+Y)-E(X+Y))^2] \\
         &amp;amp;= E[(X+Y)-(E(X)+E(Y))^2] \\
         &amp;amp;= E[(X-E(X)) - (Y-E(Y))^2] \\
         &amp;amp;= E[(X-E(X))^2+(Y-E(Y))^2 \\
         &amp;amp; \;\;\; +2(X-E(X))(Y-E(Y))] \\
         &amp;amp;= Var(X)+Var(Y)+2E[(X-E(X))(Y-E(Y))]
\end{aligned}\]&lt;/span&gt;
&lt;p&gt;可以發現在兩者和的方差公式展開之後多了一部分 &lt;span class=&#34;math inline&#34;&gt;\(E[(X-E(X))(Y-E(Y))]\)&lt;/span&gt;。 這個多出來的一部分就說明了二者 &lt;span class=&#34;math inline&#34;&gt;\((X, Y)\)&lt;/span&gt; 之間的關係。它被定義爲協方差 (Covariance):
&lt;span class=&#34;math display&#34;&gt;\[Cov(X,Y) = E[(X-E(X))(Y-E(Y))]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    要記住，協方差只能用於評價&lt;!-- raw HTML omitted --&gt;(X,Y)&lt;!-- raw HTML omitted --&gt;之間的線性關係 (Linear Association)。
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;以下是協方差 (Covariance) 的一些特殊性質：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(X,X)=Var(X)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(X,Y)=Cov(Y,X)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(aX,bY)=ab\:Cov(X,Y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(aR+bS,cX+dY)=ac\:Cov(R,X)+ad\:Cov(R,Y)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+bc\:Cov(S,X)+bd\:Cov(S,Y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(aX+bY,cX+dY)=ac\:Var(X)+ad\:Var(Y)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+(ad+bc)Cov(X,Y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cov(X+Y,X-Y)=Var(X)-Var(Y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;If &lt;span class=&#34;math inline&#34;&gt;\(X, Y\)&lt;/span&gt; are independent. &lt;span class=&#34;math inline&#34;&gt;\(Cov(X,Y)=0\)&lt;/span&gt; &lt;span class=&#34;diff_alert&#34;&gt;But not vise-versa !&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;相關-correlation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;相關 Correlation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;協方差雖然&lt;span class=&#34;math inline&#34;&gt;\(Cov(X,Y)\)&lt;/span&gt; 的大小很大程度上會被他們各自的單位和波動大小左右。&lt;/li&gt;
&lt;li&gt;我們將協方差標準化(除以各自的標準差 s.d.) (standardization) 之後，就可以得到相關係數 Corr (&lt;span class=&#34;math inline&#34;&gt;\(-1\sim1\)&lt;/span&gt;):
&lt;span class=&#34;math display&#34;&gt;\[Corr(X,Y)=\frac{Cov(X,Y)}{SD(X)SD(Y)}=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;中心極限定理-the-central-limit-theory&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;中心極限定理 the Central Limit Theory&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;diff_add&#34;&gt;&lt;strong&gt;如果從人羣中多次選出樣本量爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 的樣本，並計算樣本均值, &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}_n\)&lt;/span&gt;。那麼這個樣本均值 &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}_n\)&lt;/span&gt; 的分佈，會隨着樣本量增加 &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow\infty\)&lt;/span&gt;，而接近正態分佈。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;偉大的中心極限定理告訴我們：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;diff_alert&#34;&gt;&lt;strong&gt;當樣本量足夠大時，樣本均值 &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}_n\)&lt;/span&gt; 的分佈爲正態分佈，這個特性與樣本來自的人羣的分佈 &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt; 無關。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;再說一遍：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果對象是獨立同分佈 i.i.d (identically and independently distributed)。那麼它的總體期望和方差分別是: &lt;span class=&#34;math inline&#34;&gt;\(E(X)=\mu;\;Var(X)=\sigma^2\)&lt;/span&gt;。
根據中心極限定理，可以得到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;當樣本量增加，樣本均值的分佈服從正態分佈：
&lt;span class=&#34;math display&#34;&gt;\[\bar{X}_n\sim N(\mu, \frac{\sigma^2}{n})\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;也可以寫作，當樣本量增加：
&lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^nX_i \sim N(n\mu,n\sigma^2)\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;有了這個定理，我們可以拋開樣本空間(&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;)的分佈，也不用假定它服從正態分佈。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;diff_alert&#34;&gt;但是樣本的均值，卻總是服從正態分佈的。&lt;/span&gt;簡直是太完美了！！！！！！&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>你買的彩票中獎概率到底有多少？</title>
      <link>https://wangcc.me/post/probability3/</link>
      <pubDate>Wed, 11 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/probability3/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;二項分佈的概念-binomial-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;二項分佈的概念 Binomial distribution&lt;/h3&gt;
&lt;p&gt;二項分佈在醫學研究中至關重要，一組二項分佈的數據，指的通常是 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 次相互獨立的&lt;a href=&#34;https://winterwang.github.io/post/probability2-4/&#34;&gt;成功率爲 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; 的伯努利實驗&lt;/a&gt; (&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; independent Bernoulli trials) 中成功的次數。&lt;/p&gt;
&lt;p&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 服從二項分佈，記爲 &lt;span class=&#34;math inline&#34;&gt;\(X \sim binomial(n, \pi)\)&lt;/span&gt; 或&lt;span class=&#34;math inline&#34;&gt;\(X \sim bin(n, \pi)\)&lt;/span&gt;。它的(第 &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; 次實驗的)概率被定義爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
P(X=x) &amp;amp;= ^nC_x\pi^x(1-\pi)^{n-x} \\
       &amp;amp;= \binom{n}{x}\pi^x(1-\pi)^{n-x} \\
       &amp;amp; for\;\; x = 0,1,2,\dots,n
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;二項分佈的期望和方差&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;二項分佈的期望和方差&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;期望 &lt;span class=&#34;math inline&#34;&gt;\(E(X)\)&lt;/span&gt;
&lt;ul&gt;
&lt;li&gt;若 &lt;span class=&#34;math inline&#34;&gt;\(X \sim bin(n,\pi)\)&lt;/span&gt;，那麼 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 就是這一系列獨立伯努利實驗中成功的次數。&lt;/li&gt;
&lt;li&gt;用 &lt;span class=&#34;math inline&#34;&gt;\(X_i, i =1,\dots, n\)&lt;/span&gt; 標記每個相互獨立的伯努利實驗。&lt;/li&gt;
&lt;li&gt;那麼我們可以知道 &lt;span class=&#34;math inline&#34;&gt;\(X=\sum_{i=1}^nX_i\)&lt;/span&gt;。
&lt;span class=&#34;math display&#34;&gt;\[\begin{align} E(X) &amp;amp;= E(\sum_{i=1}^nX_i)\\
                   &amp;amp;= E(X_1+X_2+\cdots+X_n) \\
                   &amp;amp;= E(X_1)+E(X_2)+\cdots+E(X_n)\\
                   &amp;amp;= \sum_{i=1}^nE(X_i)\\
                   &amp;amp;= \sum_{i=1}^n\pi \\
                   &amp;amp;= n\pi
\end{align}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;方差 &lt;span class=&#34;math inline&#34;&gt;\(Var(X)\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
Var(X) &amp;amp;= Var(\sum_{i=1}^nX_i) \\
      &amp;amp;= Var(X_i+X_2+\cdots+X_n) \\
      &amp;amp;= Var(X_i)+Var(X_2)+\cdots+Var(X_n) \\
      &amp;amp;= \sum_{i=1}^nVar(X_i) \\
      &amp;amp;= n\pi(1-\pi) \\
\end{align}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;超幾何分佈-hypergeometric-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;超幾何分佈 hypergeometric distribution&lt;/h3&gt;
&lt;p&gt;假設我們從總人數爲 &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; 的人羣中，採集一個樣本 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;。假如已知在總體人羣中(&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;)有 &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; 人患有某種疾病。請問採集的樣本 &lt;span class=&#34;math inline&#34;&gt;\(X=n\)&lt;/span&gt; 中患有這種疾病的人，服從怎樣的分佈？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;從人羣(&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;)中取出樣本(&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;)，有 &lt;span class=&#34;math inline&#34;&gt;\(^NC_n\)&lt;/span&gt; 種方法。&lt;/li&gt;
&lt;li&gt;從患病人羣(&lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;)中取出患有該病的人(&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;)有 &lt;span class=&#34;math inline&#34;&gt;\(^MC_x\)&lt;/span&gt; 種方法。&lt;/li&gt;
&lt;li&gt;樣本中不患病的人(&lt;span class=&#34;math inline&#34;&gt;\(n-x\)&lt;/span&gt;)被採樣的方法有 &lt;span class=&#34;math inline&#34;&gt;\(^{N-M}C_{n-x}\)&lt;/span&gt; 種。&lt;/li&gt;
&lt;li&gt;採集一次 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 人作爲樣本的概率都一樣。因此：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(X=x)=\frac{\binom{M}{x}\binom{N-M}{n-x}}{\binom{N}{n}}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;樂透中獎概率問題&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;樂透中獎概率問題：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;從數字 &lt;span class=&#34;math inline&#34;&gt;\(1\sim59\)&lt;/span&gt; 中選取 &lt;span class=&#34;math inline&#34;&gt;\(6\)&lt;/span&gt; 個任意號碼&lt;/li&gt;
&lt;li&gt;開獎時從 &lt;span class=&#34;math inline&#34;&gt;\(59\)&lt;/span&gt; 個號碼球中隨機抽取 &lt;span class=&#34;math inline&#34;&gt;\(6\)&lt;/span&gt; 個&lt;/li&gt;
&lt;li&gt;如果六個號碼全部猜中(不分順序)，你可以成爲百萬富翁。請問一次猜中全部 &lt;span class=&#34;math inline&#34;&gt;\(6\)&lt;/span&gt; 個號碼的概率是多少？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;從 &lt;span class=&#34;math inline&#34;&gt;\(59\)&lt;/span&gt; 個號碼中隨機取出任意 &lt;span class=&#34;math inline&#34;&gt;\(6\)&lt;/span&gt; 個號碼的方法有 &lt;span class=&#34;math inline&#34;&gt;\(^{59}C_6\)&lt;/span&gt; 種。
&lt;span class=&#34;math display&#34;&gt;\[^{59}C_6=\frac{59!}{6!(59-6)!}=45,057,474\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;每次選取六個號碼做爲一組的可能性相同，所以，你買了一組樂透號碼，能中獎的概率就是 &lt;span class=&#34;math inline&#34;&gt;\(1/45,057,474 = 0.00000002219\)&lt;/span&gt;。你還會再去買彩票麼？&lt;/p&gt;
&lt;div id=&#34;如果我只想中其中的-3-個號碼概率有多大&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;如果我只想中其中的 &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; 個號碼，概率有多大？&lt;/h4&gt;
&lt;p&gt;用超幾何分佈的概率公式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
P(X=3) &amp;amp;= \frac{^6C_3\times ^{53}C_3}{^{59}C_6} \\
       &amp;amp;= 0.010
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;你有 &lt;span class=&#34;math inline&#34;&gt;\(1\%\)&lt;/span&gt; 的可能中獎。換句話說，如果中三個以上的數字算中獎的話，你買的彩票中獎的概率低於 &lt;span class=&#34;math inline&#34;&gt;\(1\%\)&lt;/span&gt;。是不是覺得下次送錢給博彩公司的時候還不如跟我一起喝一杯咖啡划算？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;泊松分佈-poisson-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;泊松分佈 Poisson Distribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;當一個事件，在一段時間 (&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;) 中可能發生的次數是 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 。那麼我們可以認爲，經過時間 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;，該時間發生的期望次數是 &lt;span class=&#34;math inline&#34;&gt;\(E(X)=\lambda T\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;利用微分思想，將這段時間 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 等分成 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個時間段，當 &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow\infty\)&lt;/span&gt; 直到每個微小的時間段內最多發生一次該事件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那麼&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每個微小的時間段，可以視爲是一個伯努利實驗（有事件發生或者沒有）&lt;/li&gt;
&lt;li&gt;那麼這整段時間 &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; 內發生的事件可以視爲是一個二項分佈實驗。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;令 &lt;span class=&#34;math inline&#34;&gt;\(X=\)&lt;/span&gt; 一次事件發生時所經過的所有時間段。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(X \sim Bin(n, \pi)\)&lt;/span&gt;，其中 &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow\infty\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 爲時間段。&lt;/li&gt;
&lt;li&gt;在每個分割好的時間段內，事件發生的概率都是：&lt;span class=&#34;math inline&#34;&gt;\(\pi=\frac{\lambda T}{n}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;期望 &lt;span class=&#34;math inline&#34;&gt;\(\mu=\lambda T \Rightarrow \pi=\mu/n\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;所以 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 的概率方程就是：
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
P(X=x) &amp;amp;= \binom{n}{x}\pi^x(1-\pi)^{n-x} \\
     &amp;amp;= \binom{n}{x}(\frac{\mu}{n})^x(1-\frac{\mu}{n})^{n-x} \\
     &amp;amp;= \frac{n!}{x!(n-x)!}(\frac{\mu}{n})^x(1-\frac{\mu}{n})^{n-x} \\
     &amp;amp;=\frac{n!}{n^x(n-x)!}\frac{\mu^x}{x!}(1-\frac{\mu}{n})^{n-x}\\
當 n\rightarrow\infty   &amp;amp;\; x \ll n (x遠小於n) 時\\
\frac{n!}{n^x(n-x)!} &amp;amp;=\frac{n(n-1)\dots(n-x+1)}{n^x} \rightarrow 1\\
(1-\frac{\mu}{n})^{n-x} &amp;amp;\approx  (1-\frac{\mu}{n})^n \rightarrow e^{-\mu}\\
所以 我們可&amp;amp;以得到泊松分佈的概率公式：   \\
P(X=x) &amp;amp;\rightarrow \frac{\mu^x}{x!}e^{-\mu}
\end{align}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當數據服從泊松分佈時，記爲 &lt;span class=&#34;math inline&#34;&gt;\(X\sim Poisson(\mu=\lambda T)\;\; or\;\; X\sim Poi(\mu)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;證明泊松分佈的參數特徵&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;證明泊松分佈的參數特徵：&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(E(X)=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
E(X)  &amp;amp;=  \sum_{x=0}^\infty xP(X=x) \\
      &amp;amp;=  \sum_{x=0}^\infty x\frac{\mu^x}{x!}e^{-\mu} \\
      &amp;amp;= 0+ \sum_{x=1}^\infty x\frac{\mu^x}{x!}e^{-\mu} \\
      &amp;amp;=  \sum_{x=1}^\infty \frac{\mu^x}{(x-1)!}e^{-\mu} \\
      &amp;amp;=  \mu\sum_{x=1}^\infty \frac{\mu^{x-1}}{(x-1)!}e^{-\mu} \\
這個時候我們用i&amp;amp;=x-1 替換掉所有的 x \\
      &amp;amp;=  \mu\sum_{i=0}^\infty \frac{\mu^{i}}{i!}e^{-\mu} \\
注意到右半部分 &amp;amp;\sum_{i=0}^\infty \frac{\mu^{i}}{i!}e^{-\mu}=1 是一個\\泊松分佈的所有&amp;amp;概率和 \\
      &amp;amp;= \mu
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Var(x)=\mu\)&lt;/span&gt;
爲了找到 &lt;span class=&#34;math inline&#34;&gt;\(Var(X)\)&lt;/span&gt;，我們用公式 &lt;span class=&#34;math inline&#34;&gt;\(Var(X)=E(X^2)-E(X)^2\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我們需要找到 &lt;span class=&#34;math inline&#34;&gt;\(E(X^2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
E(X^2) &amp;amp;= \sum_{x=0}^\infty x^2\frac{\mu^x}{x!}e^{-\mu} \\
       &amp;amp;= \mu \sum_{x=1}^\infty x\frac{\mu^{x-1}}{(x-1)!}e^{-\mu} \\
這個時候我們用i&amp;amp;=x-1 替換掉所有的 x \\
       &amp;amp;= \mu \sum_{i=0}^\infty (i+1)\frac{\mu^{i}}{i!}e^{-\mu} \\
       &amp;amp;= \mu(\sum_{i=0}^\infty i\frac{\mu^i}{i!}e^{-\mu} + \sum_{i=0}^\infty \frac{\mu^i}{i!}e^{-\mu}) \\
       &amp;amp;= \mu(E(X)+1) \\
       &amp;amp;= \mu^2+\mu \\
因此，代入上面&amp;amp;提到的方差公式： \\
Var(X) &amp;amp;= E(X^2) - E(X)^2 \\
       &amp;amp;= \mu^2 + \mu -\mu^2 \\
       &amp;amp;= \mu
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>正態分佈</title>
      <link>https://wangcc.me/post/normal-distribution/</link>
      <pubDate>Wed, 11 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/normal-distribution/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;概率密度曲線-probability-density-function-pdf&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;概率密度曲線 probability density function， PDF&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;一個隨機連續型變量 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 它的性質由一個對應的&lt;strong&gt;概率密度方程 (probability density function, PDF)&lt;/strong&gt; 決定。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在給定的範圍區間內，如 &lt;span class=&#34;math inline&#34;&gt;\(a\sim b, (a &amp;lt; b)\)&lt;/span&gt;，它的概率滿足:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(a\leqslant X \leqslant b) = \int_a^bf(x)dx\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;這個相關的方程，在 &lt;span class=&#34;math inline&#34;&gt;\(a\sim b\)&lt;/span&gt; 區間內的積分，就是這個連續變量在這個區間內取值的概率。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# R codes for drawing a standard normal distribution by using ggplot2
library(ggplot2)
p &amp;lt;- ggplot(data.frame(x=c(-3,3)), aes(x=x)) +
  stat_function(fun = dnorm)
p + annotate(&amp;quot;text&amp;quot;, x=2, y=0.3, parse=TRUE, label=&amp;quot;frac(1, sqrt(2*pi)) * e ^(-z^2/2)&amp;quot;) +
  theme(plot.subtitle = element_text(vjust = 1),
        plot.caption = element_text(vjust = 1),
        axis.text.x = element_text(size = 12),
        axis.text.y = element_text(size = 12),
        plot.title = element_text(size = 10, face = &amp;quot;bold&amp;quot;, hjust = 0.5),
        panel.background = element_rect(fill = &amp;quot;ivory&amp;quot;)) +
  labs(title = &amp;quot;Probability density functions \n for standard normal distribution&amp;quot;,
       x = NULL, y = NULL) +
  stat_function(fun = dnorm,
                xlim = c(-1.3,0.4),
                geom = &amp;quot;area&amp;quot;,fill=&amp;quot;#00688B&amp;quot;, alpha= 0.2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-10-11-normal-distribution_files/figure-html/normal%20distribution%20graph-1.png&#34; width=&#34;528&#34; /&gt;&lt;/p&gt;
&lt;p&gt;注意：整個方程的曲線下面積等於 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;：
&lt;span class=&#34;math display&#34;&gt;\[\int_{-\infty}^\infty f(x)dx=1\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;期望 &lt;span class=&#34;math inline&#34;&gt;\(E(X)=\int_{-\infty}^\infty xf(x)dx\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;方差 &lt;span class=&#34;math inline&#34;&gt;\(Var(X)=\int_{-\infty}^\infty (x-\mu)^2f(x)dx\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;正態分佈&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;正態分佈&lt;/h3&gt;
&lt;p&gt;如果一組數據服從正態分佈，我們通常用它的期望（或者叫平均值）&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;，和它的方差 &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;，來描述這組數據。記爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X \sim N(\mu, \sigma^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;它的概率密度方程可以表述爲：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}exp(-\frac{(x-\mu)^2}{2\sigma^2})\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(E(x) =\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Var(x)=\sigma^2\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;標準正態分佈&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;標準正態分佈&lt;/h3&gt;
&lt;p&gt;標準正態分佈的期望（或者均值）爲 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;，方差爲 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;記爲：&lt;span class=&#34;math inline&#34;&gt;\(Z \sim N(0,1)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;它的概率密度方程表述爲：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{1}{\sqrt{2\pi}}exp(-\frac{z^2}{2})\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;它的累積分佈方程 (cumulative distribution function， CDF)，是將概率密度方程 (PDF) 積分以後獲得的方程。通常我們記爲 &lt;span class=&#34;math inline&#34;&gt;\(\Phi(z)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;再看一下標準正態分佈的概率密度方程曲線：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/post/2017-10-11-normal-distribution_files/figure-html/normal%20distribution%20graph2-1.png&#34; width=&#34;528&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;95% 的曲線下面積在標準差 standard deviation &lt;span class=&#34;math inline&#34;&gt;\(-1.96\sim1.96\)&lt;/span&gt; 之間的區域。&lt;/li&gt;
&lt;li&gt;而且，&lt;span class=&#34;math inline&#34;&gt;\(\phi(-x)=1-\phi(x)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;任何一個正態分佈都可以通過下面的公式，標準化成爲標準正態分佈：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Z=\frac{X-\mu}{\sigma}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>概率論2</title>
      <link>https://wangcc.me/post/probability2-4/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/probability2-4/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;bayes-理論的概念&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bayes 理論的概念&lt;/h3&gt;
&lt;p&gt;許多時候，我們需要將概率中的條件相互對調。
例如：
在已知該人羣中有20%的人有吸菸習慣(&lt;span class=&#34;math inline&#34;&gt;\(P(S)\)&lt;/span&gt;)，吸菸的人有9%的概率有哮喘(&lt;span class=&#34;math inline&#34;&gt;\(P(A|S)\)&lt;/span&gt;)，不吸菸的人有7%的概率有哮喘(&lt;span class=&#34;math inline&#34;&gt;\(P(A|\bar{S})\)&lt;/span&gt;)的前提下，有個人前來門診，發現是哮喘患者，那麼這個人有多大的概率是一個菸民？也就是要求 &lt;span class=&#34;math inline&#34;&gt;\(P(S|A)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這裏先引入貝葉斯的概念：&lt;/p&gt;
&lt;p&gt;我們可以將 &lt;span class=&#34;math inline&#34;&gt;\(P(A\cap S)\)&lt;/span&gt; 寫成：
&lt;span class=&#34;math display&#34;&gt;\[P(A\cap S)=P(A|S)P(S)\\or\\
P(A\cap S)=P(S|A)P(A)\]&lt;/span&gt;
這兩個等式是完全等價的。我們將他們連起來：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(S|A)P(A)=P(A|S)P(S)\\
\Rightarrow P(S|A)=\frac{P(A|S)P(S)}{P(A)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;是不是看起來又像是寫了一堆&lt;strong&gt;廢話&lt;/strong&gt;？
沒錯，你看出來是一堆廢話的時候，證明你也同意這背後的簡單邏輯。&lt;/p&gt;
&lt;p&gt;再繼續，我們可以利用另外一個&lt;strong&gt;廢話&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(\because S+\bar{S}=1\\ \therefore P(A)=P(A\cap S)+P(A\cap\bar{S})\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;用上面的公式替換掉 &lt;span class=&#34;math inline&#34;&gt;\(P(A\cap S)+P(A\cap\bar{S}） \\ \therefore P(A)=P(A|S)P(S)+P(A|\bar{S})P(\bar{S})\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;可以得到&lt;strong&gt;貝葉斯理論公式&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(S|A)=\frac{P(A|S)P(S)}{P(A|S)P(S)+P(A|\bar{S})P(\bar{S})}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;回到上面說到的哮喘人中有多少比例吸菸的問題。可以繼續使用概率樹來方便的計算：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Selection_073.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
P(S|A) &amp;amp;= \frac{P(A|S)P(S)}{P(A|S)P(S)+P(A|\bar{S})P(\bar{S})} \\
        &amp;amp;= \frac{0.09\times0.2}{0.09\times0.2+0.07\times0.8} \\
        &amp;amp;= 0.24
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以我們的結論就是，在已知該人羣中有20%的人有吸菸習慣(&lt;span class=&#34;math inline&#34;&gt;\(P(S)\)&lt;/span&gt;)，吸菸的人有9%的概率有哮喘(&lt;span class=&#34;math inline&#34;&gt;\(P(A|S)\)&lt;/span&gt;)，不吸菸的人有7%的概率有哮喘(&lt;span class=&#34;math inline&#34;&gt;\(P(A|\bar{S})\)&lt;/span&gt;)的前提下，有個人前來門診，發現是哮喘患者，那麼這個人有24% 的概率是一個菸民(&lt;span class=&#34;math inline&#34;&gt;\(P(S|A)\)&lt;/span&gt;)。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;期望-expectation-或均值-or-mean-和-方差-variance&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;期望 Expectation (或均值 or mean) 和 方差 Variance&lt;/h3&gt;
&lt;p&gt;期望（或均值）是用來描述一組數據中心位置的指標（另一個是中位數 Median）。
對於離散型隨機變量 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; (discrete random variables)，它的期望被定義爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(X)=\sum_x xP(X=x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以就是將所有 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 可能取到的值乘以相應的概率後求和。這個期望（或均值）常常用希臘字母 &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; 來標記。&lt;/p&gt;
&lt;p&gt;方差 Variance 是衡量一組數據變化幅度(dispersion/variability)的指標之一。 方差的定義是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var(X)=E((X-\mu)^2)\\其中，\mu=E(x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;實際上我們更加常用的是它的另外一個公式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var(X)=E(X^2)-E(X)^2\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;證明-上面兩個方差公式相等&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明 上面兩個方差公式相等&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
Var(x)  &amp;amp;= E((X-\mu)^2) \\
        &amp;amp;= E(X^2-2X\mu+\mu^2)\\
        &amp;amp;= E(X^2) - 2\mu E(X) + \mu^2\\
        &amp;amp;= E(X^2) - 2\mu^2 + \mu^2 \\
        &amp;amp;= E(X^2) - \mu^2 \\
        &amp;amp;= E(X^2) - E(X)^2
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;方差的性質&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;方差的性質：&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Var(X+b)=Var(X)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Var(aX)=a^2Var(X)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Var(aX+b)=a^2Var(X)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;伯努利分佈-bernoulli-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;伯努利分佈 Bernoulli distribution&lt;/h3&gt;
&lt;p&gt;伯努利分佈，說的就是一個簡單的二分變量 (1, 0)，它取1時的概率如果是 &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;。那麼我們可以計算這個分佈的期望值:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
E(X) &amp;amp;=\sum_x xP(X=x) \\
     &amp;amp;=1\times\pi + 0\times(1-\pi)\\
     &amp;amp;=\pi
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由於 &lt;span class=&#34;math inline&#34;&gt;\(x=x^2\)&lt;/span&gt;，因爲 &lt;span class=&#34;math inline&#34;&gt;\(x=0,1\)&lt;/span&gt;, 所以 &lt;span class=&#34;math inline&#34;&gt;\(E[X^2]=E[X]\)&lt;/span&gt;，那麼方差爲：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
Var(X) &amp;amp;=E[X^2]-E[X]^2 \\
       &amp;amp;=E[X]-E[X]^2 \\
       &amp;amp;=\pi - \pi^2 \\
       &amp;amp;=\pi(1-\pi)
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;證明xy-爲互爲獨立的隨機離散變量時-a-exyexey-b-varxyvarxvary&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;證明，&lt;span class=&#34;math inline&#34;&gt;\(X,Y\)&lt;/span&gt; 爲互爲獨立的隨機離散變量時，&lt;br&gt;a) &lt;span class=&#34;math inline&#34;&gt;\(E(XY)=E(X)E(Y)\)&lt;/span&gt; ; &lt;br&gt;b) &lt;span class=&#34;math inline&#34;&gt;\(Var(X+Y)=Var(X)+Var(Y)\)&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;strong&gt;證明&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
E(XY) &amp;amp;= \sum_x\sum_y xyP(X=x, Y=y) \\
\because &amp;amp;\; X,Y are\;independent\;to\;each\;other \\
\therefore &amp;amp;= \sum_x\sum_y xyP(X=x)P(Y=y)\\
      &amp;amp;=\sum_x xP(X=x)\sum_y yP(Y=y)\\
      &amp;amp;=E(X)E(Y)
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;ol start=&#34;2&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;strong&gt;證明&lt;/strong&gt;
根據方差的定義：
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
Var(X+Y) &amp;amp;= E((X+Y)^2)-E(X+Y)^2 \\
    &amp;amp; \; Expand \\
    &amp;amp;=E(X^2+2XY+Y^2)-(E(X)+E(Y))^2\\
    &amp;amp;=E(X^2)+E(Y^2)+2E(XY)\\
    &amp;amp;\;\;\; - E(X)^2-E(Y)^2-2E(X)E(Y)\\
    &amp;amp;\; We\;just\;showed\; E(XY)=E(X)E(Y)\\
    &amp;amp;=E(X^2)-E(X)^2+E(Y^2)-E(Y)^2 \\
    &amp;amp;=Var(X)+Var(Y)
\end{align}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>你會用概率論來賭博嗎？</title>
      <link>https://wangcc.me/post/probability-gambling/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/probability-gambling/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;轉眼我已經進入課程的第二週了，總體來說，我們一半的時間都在電腦房練習 Stata 的數據清理和簡單的描述統計 (descriptive statistics)。從我個人的經驗來說，數據分析的過程，其實一大半的時間是消耗在 data cleaning 上的，即使手頭拿到了所謂的乾淨的數據，到真正要分析的時候就會發現一大堆的問題在裏面，需要重新整理，重新添加標記以使之變得更加讓人類可以讀懂。電腦是機器，他是不管你的數據是否乾淨的。只要你放了數據進去，邏輯還可以，沒有編程上的語法錯誤，它總歸會出來一些報告和結果的。如果就這麼直接用的話，大部分的人就會掉進陷阱。畢竟數據不光會說出事實真相，&lt;strong&gt;更多的情況下還會把真相給掩蓋住了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我的其餘大部分時間都用在了複習高等數學的微積分上了。感覺好似回到了高中時代。其實大學的時候線性代數得分還是接近滿分的。後來多年不用，生疏了。剛打開複習的書的時候，許多微分積分的規則都已經忘記。通過這一週的辛苦練習，終於是找回了一點狀態。如果你也想有空的時候複習以下高中數學知識，這本書可以推薦給你：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.uk/gp/product/0471827223/ref=oh_aui_detailpage_o04_s00?ie=UTF8&amp;amp;psc=1&#34;&gt;Quick Calculus: Short Manual of Self-instruction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Selection_070.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;上面這本書的內容可以一邊閱讀，一邊練習。實在是複習的一本好書。我花了一週的課餘時間，從頭到尾把裏面的習題和解答全部完成。收穫很大。感覺年輕時的數學思維又開始在大腦裏復甦了。一身輕鬆。&lt;/p&gt;
&lt;p&gt;下面想介紹一下上週學習的概率的基礎問題。&lt;/p&gt;
&lt;div id=&#34;首先是最基礎的三個概率的公理&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;首先是最基礎的&lt;strong&gt;三個概率的公理&lt;/strong&gt;：&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;對於任意事件 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;，它發生的概率 &lt;span class=&#34;math inline&#34;&gt;\(P(A)\)&lt;/span&gt; 滿足這樣的不等式： &lt;span class=&#34;math inline&#34;&gt;\(0 \leqslant P(A) \leqslant 1\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(\Omega)=1\)&lt;/span&gt; , &lt;span class=&#34;math inline&#34;&gt;\(\Omega\)&lt;/span&gt; 是全樣本空間 (total sample space)&lt;/li&gt;
&lt;li&gt;對於互斥（相互獨立）的事件 &lt;span class=&#34;math inline&#34;&gt;\(A_1, A_2, \dots, A_n\)&lt;/span&gt; 有如下的等式關係： &lt;span class=&#34;math inline&#34;&gt;\(P(A_1\cup A_2 \cup \cdots \cup A_n)=P(A_1)+P(A_2)+\cdots+P(A_n)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;你是不是覺得上面三條公理都是&lt;strong&gt;廢話&lt;/strong&gt;。
不用擔心，我也是這麼覺得的。因爲所有人都認同的道理，才能成爲公理 (axiom)，因爲它們是不需要證明的自然而然形成的人人都接受的觀念。&lt;code&gt;(axiom: a saying that is widely accepted on its own merits; its truth is assumed to be self-evident)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;然而，正是這樣顯而易見的道理，確是拿來建築理論的基石，千萬不能小看了他們。例如，我們看下面這個看似也應該成爲公理的公式，你能證明嗎：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A_1\cup A_2) = P(A_1) + P(A_2) - P(A_1 \cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/venngram.png&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;證明&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明：&lt;/h4&gt;
&lt;p&gt;先考慮 &lt;span class=&#34;math inline&#34;&gt;\(A_1 \cup A_2\)&lt;/span&gt; 是什麼（拆分成三個互斥事件）&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A_1 \cup A_2 = (A_1\cap \bar{A_2})\cup(\bar{A_1}\cap A_2)\cup(A_1\cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;運用上面的公理&lt;del&gt;2&lt;/del&gt; 3&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\therefore P(A_1 \cup A_2) = P(A_1\cap \bar{A_2}) + P(\bar{A_1}\cap A_2) + P(A_1\cap A_2) \;\;\;\;\;\;(1)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;再考慮 &lt;span class=&#34;math inline&#34;&gt;\(A_1=(A_1\cap A_2)\cup(A_1\cap\bar{A_2})\)&lt;/span&gt; 繼續拆分成兩個互斥事件&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\therefore P(A_1)=P(A_1\cap A_2)+P(A_1\cap\bar{A_2})\)&lt;/span&gt; 整理一下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A_1\cap\bar{A_2})=P(A_1)-P(A_1\cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同理可得: &lt;span class=&#34;math inline&#34;&gt;\(P(\bar{A_1}\cap A_2)=P(A_2)-P(A_1\cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;代入上面第(1)式可得：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A_1 \cup A_2) =P(A_1)-P(A_1\cap A_2)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+P(A_2)-P(A_1\cap A_2)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+P(A_1\cap A_2)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;=P(A_1) + P(A_2) - P(A_1 \cap A_2)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;條件概率-conditional-probability&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;條件概率 Conditional probability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A|S)=\frac{P(A\cap S)}{P(S)}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(A\cap S) = P(A|S)P(S)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;獨立-independence-的定義&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;獨立 (independence) 的定義&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;兩個事件定義爲互爲獨立時 (&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; are said to be independent &lt;strong&gt;if and only if&lt;/strong&gt;)
&lt;span class=&#34;math display&#34;&gt;\[P(A\cap B)=P(A)P(B)\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;因爲從條件概率的概念我們已知&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(P(A\cap B) = P(A|B)P(B)\)&lt;/span&gt; &lt;br&gt;所以&lt;span class=&#34;math inline&#34;&gt;\(P(A|B)=P(A)\)&lt;/span&gt; 即：事件 &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; 無法提供事件 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的任何有效訊息 (&lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(A, B\)&lt;/span&gt; 互相獨立&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;賭博問題&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;賭博問題&lt;/h2&gt;
&lt;p&gt;終於來到本次話題的重點了。我要扣題了哦。語文老師快在此加分。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Selection_071.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;假設你在一個電視遊戲節目。有上圖一樣的三扇門。其中一扇門後面有一輛保時捷，另兩扇門後面則是&lt;a href=&#34;https://winterwang.github.io/post/black-meal/&#34;&gt;(味道奇特的)山羊&lt;/a&gt;。遊戲規則是主持人會讓你先選擇其中一扇門（先不打開你選的這扇門）。主持人隨後打開另外兩扇門中的一扇沒有保時捷的門。主持人問你，你要堅持選擇之前選中的那扇門，還是要改變主意換一扇門去猜是否可以猜中保時捷。
請問，堅持選擇之前選中的門猜中保時捷的概率高，還是主持人打開一扇門以後改變主意猜中保時捷的概率更高呢？&lt;/p&gt;
&lt;p&gt;答案明天揭曉。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Matrix Revisions</title>
      <link>https://wangcc.me/post/matrix-revision/</link>
      <pubDate>Sat, 30 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/matrix-revision/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;basic-definition-and-notations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Basic Definition and notations:&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;An &lt;span class=&#34;math inline&#34;&gt;\(m\times n\)&lt;/span&gt; &lt;strong&gt;matrix &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;&lt;/strong&gt; is a rectangular array of numbers with &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; rows and &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; columns.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;strong&gt;elements&lt;/strong&gt; of a matrix &lt;span class=&#34;math inline&#34;&gt;\(A_{m\times n}\)&lt;/span&gt; are &lt;span class=&#34;math inline&#34;&gt;\(a_{ij}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;strong&gt;order&lt;/strong&gt; of a matrix is the number of rows by the number of columns, i.e. &lt;span class=&#34;math inline&#34;&gt;\(m\times n\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A &lt;strong&gt;column vector&lt;/strong&gt; with &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; elements, &lt;span class=&#34;math inline&#34;&gt;\(y = \left( \begin{array}{c} y_1\\ y_2\\ \vdots\\ y_n \end{array} \right)\)&lt;/span&gt;, is a matrix with only one column i.e. an &lt;span class=&#34;math inline&#34;&gt;\(m\times 1\)&lt;/span&gt; matrix.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A &lt;strong&gt;row vector&lt;/strong&gt; with &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; elements, &lt;span class=&#34;math inline&#34;&gt;\(x=(x_1,x_2,x_3, \cdots, x_n)\)&lt;/span&gt;, is a matrix with only one row, i.e. an &lt;span class=&#34;math inline&#34;&gt;\(1\times n\)&lt;/span&gt; matrix.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Transposed matrix&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(A^T\)&lt;/span&gt; (or &lt;span class=&#34;math inline&#34;&gt;\(A&amp;#39;\)&lt;/span&gt;) arises from the matrix &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; by interchanging the column vectors and the row vectors i.e. &lt;span class=&#34;math inline&#34;&gt;\(a_{ij}^T = a_{ji}\)&lt;/span&gt; (so a column vector is converted into a row vector and vise versa)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A partitioned matrix&lt;/strong&gt; is a matrix written in terms of sub-matrices. &lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} A_{11} &amp;amp; A_{12}\\ A_{21} &amp;amp; A_{22}\\ \end{array} \right)\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(A_{11},A_{12},A_{21},A_{22}\)&lt;/span&gt; are sub-matrices&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A_{11}, A_{21}\)&lt;/span&gt; have the same number of columns, so do &lt;span class=&#34;math inline&#34;&gt;\(A_{12}, A_{22}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A_{11}, A_{12}\)&lt;/span&gt; have the same number of rows, so do &lt;span class=&#34;math inline&#34;&gt;\(A_{21}, A_{22}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;partitioning is not restricted to dividing a matrix into just four sub-matrices&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A square matrix&lt;/strong&gt; has exactly as many rows as it has columns i.e. the order of the matrix is &lt;span class=&#34;math inline&#34;&gt;\(n\times n\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The main diagonal&lt;/strong&gt; (or leading diagnonal) of a square matrix &lt;span class=&#34;math inline&#34;&gt;\(A (n\times n)\)&lt;/span&gt; are the elements lying on the diagnoal &lt;strong&gt;from top left to bottom right.&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(a_{11},a_{22},a_{33},\cdots,a_{nn}\)&lt;/span&gt; i.e. all &lt;span class=&#34;math inline&#34;&gt;\(a_{ii}, i= 1,\cdots, n\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The trace &lt;/strong&gt; of a square matrix is the sum of the diagonal elements &lt;span class=&#34;math inline&#34;&gt;\(tr(A)=a_{11}+a_{22}+\cdots+a_{nn}=\sum_{i=1}^na_{ii}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;special-matrices&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Special matrices&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;A symmetric matrix&lt;/strong&gt; is a square matrix for which the following is true for all the off diagonal elements. &lt;span class=&#34;math inline&#34;&gt;\(a_{ij}=a_{ji}\)&lt;/span&gt; i.e. &lt;span class=&#34;math inline&#34;&gt;\(A^T=A\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Diagonal matrix&lt;/strong&gt; is a square matrix having zero for all the non-diagonal elements i.e. &lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} a_{11} &amp;amp; \cdots &amp;amp; 0\\ \vdots &amp;amp; \ddots &amp;amp; \vdots\\ 0 &amp;amp; \cdots &amp;amp; a_{nn} \end{array} \right)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Zero matrix&lt;/strong&gt; (null matrix) is a matrix whose all elements are zero&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Identity matrix&lt;/strong&gt; (or unit matrix) is a diagonal matrix having all diagonal elements equal to 1 and off diagonal elements equal to zero. i.e. &lt;span class=&#34;math inline&#34;&gt;\(I=\left( \begin{array}{c} 1 &amp;amp; \cdots &amp;amp; 0\\ \vdots &amp;amp; \ddots &amp;amp; \vdots\\ 0 &amp;amp; \cdots &amp;amp; 1 \end{array} \right)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;“Summing vector”&lt;/strong&gt; is a vector whose every element is 1 i.e. &lt;span class=&#34;math inline&#34;&gt;\(1_{n}=(1\cdots1)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;“J matrix”&lt;/strong&gt; is a matrix (not necessarily square) whose every element is 1 i.e. &lt;span class=&#34;math inline&#34;&gt;\(J_{m\times n}=\left( \begin{array}{c} 1 &amp;amp; 1 &amp;amp; \cdots &amp;amp; 1\\ 1 &amp;amp; 1 &amp;amp; \cdots &amp;amp; 1 \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ 1 &amp;amp; 1 &amp;amp; \cdots &amp;amp; 1 \end{array} \right)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;basic-operations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Basic Operations&lt;/h2&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;!-- raw HTML omitted --&gt;Addition (Substraction)&lt;!-- raw HTML omitted --&gt; can take place only when the matrices involved are of the same order. i.e.
Two matrices can be added (subtracted) only if they have the same numbers of rows and the same numbers of columns.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A+B=B+A\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((A+B)+C=A+(B+C)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A+0=0+A=A\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A+(-A)=0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((A+B)^T=A^T+B^T\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Multiplication by scalar:&lt;/strong&gt;
- &lt;span class=&#34;math inline&#34;&gt;\(cA=Ac\)&lt;/span&gt;
- &lt;span class=&#34;math inline&#34;&gt;\(c(dA)=(cd)A\)&lt;/span&gt;
- &lt;span class=&#34;math inline&#34;&gt;\((c\pm d)A=cA\pm dA\)&lt;/span&gt;
- &lt;span class=&#34;math inline&#34;&gt;\(c(A\pm B)=cA \pm cB\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Multiplication of an &lt;span class=&#34;math inline&#34;&gt;\(2\times2\)&lt;/span&gt; matrix by a column vector which has 2 rows yields a column vector with &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; rows.&lt;/strong&gt;
&lt;span class=&#34;math display&#34;&gt;\[Ax=\left(
\begin{array}{c}
a_{11} &amp;amp; a_{12}\\
a_{21} &amp;amp; a_{22}\\
\end{array}
\right)\left(
\begin{array}{c}
x_{1}\\
x_{2}\\
\end{array}
\right)=\left(
\begin{array}{c}
a_{11}x_1+a_{12}x_2\\
a_{21}x_1+a_{22}x_2\\
\end{array}
\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;generally&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Generally:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Multiplication of an &lt;span class=&#34;math inline&#34;&gt;\(m\times n\)&lt;/span&gt; matrix&lt;/strong&gt; by a &lt;strong&gt;column vector&lt;/strong&gt; which has &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; rows &lt;strong&gt;yields a column vector&lt;/strong&gt; with &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; rows.
&lt;span class=&#34;math display&#34;&gt;\[Ax=\left(
\begin{array}{c}
a_{11} &amp;amp; \cdots &amp;amp; a_{1n} \\
\vdots &amp;amp; \ddots &amp;amp; \vdots \\
a_{m1} &amp;amp; \cdots &amp;amp; a_{mn}
\end{array}
\right)\left(
\begin{array}{c}
x_{1}\\
x_{2}\\
\vdots \\
x_{n}
\end{array}
\right)=\left(
\begin{array}{c}
a_{11}x_{1}+a_{12}x_2+\cdots+a_{1n}x_n\\
\vdots \\
a_{m1}x_{1}+a_{m2}x_2+\cdots+a_{mn}x_n
\end{array}
\right)=y \\
i.e. y_i=\sum_{j=1}^na_{ij}x_j, \; i=1,\cdots, m\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://winterwang.github.io/post/2017-02-22/&#34;&gt;Multiplication of matrices&lt;/a&gt;:&lt;/strong&gt; The product &lt;span class=&#34;math inline&#34;&gt;\(AB=C\)&lt;/span&gt; is &lt;strong&gt;defined only when &lt;span class=&#34;math inline&#34;&gt;\(A_{m\times r}\)&lt;/span&gt; has exactly as many columns as &lt;span class=&#34;math inline&#34;&gt;\(B_{r\times n}\)&lt;/span&gt; has rows&lt;/strong&gt;. And the elements of &lt;span class=&#34;math inline&#34;&gt;\(C_{m\times n}\)&lt;/span&gt; are given as
&lt;span class=&#34;math display&#34;&gt;\[c_{ij}=\sum_{l=1}^na_{il}b_{lj}, \;\; i=1,\cdots,m \; and \; j=1,\cdots, n\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(AB \neq BA\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((AB)C=A(BC)=ABC\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A(B+C)=AB+AC\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((B+C)A=BA+CA\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(IA=AI=A\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;further-definitions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Further definitions&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/post/2017-03-15/&#34;&gt;&lt;strong&gt;The determinant&lt;/strong&gt;&lt;/a&gt; of a second order square matrix is &lt;span class=&#34;math inline&#34;&gt;\(det(A)=|A|=\begin{vmatrix} a_{11} &amp;amp; a_{12} \\ a_{21} &amp;amp; a_{22} \end{vmatrix}=a_{11}a_{22}-a_{12}a_{21}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://winterwang.github.io/post/2017-07-06/&#34;&gt;The inverse of a matrix&lt;/a&gt;&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(A^{-1}\)&lt;/span&gt; if it exists, is a matrix whose product with &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is the identity matrix i.e. &lt;span class=&#34;math inline&#34;&gt;\(AA^{-1}=A^{-1}A=I\)&lt;/span&gt;. (&lt;strong&gt;Note: both &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(A^{-1}\)&lt;/span&gt; have to be square&lt;/strong&gt;) For second order matrices:&lt;span class=&#34;math inline&#34;&gt;\(A^{-1}=\frac{1}{det(A)}\left( \begin{array}{c} a_{22} &amp;amp; -a_{12}\\ -a_{21} &amp;amp; a_{11}\\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://winterwang.github.io/post/2017-07-06/&#34;&gt;Singular or non-invertible matrix&lt;/a&gt;&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(det(A)=0\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Idempotent matrices(冪等矩陣)&lt;/strong&gt; are square and the following is true: &lt;span class=&#34;math inline&#34;&gt;\(AA=A^2=A\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://winterwang.github.io/post/2017-03-08/&#34;&gt;Orthogonal matrices&lt;/a&gt;&lt;/strong&gt; have the following property: &lt;span class=&#34;math inline&#34;&gt;\(AA^T=A^TA=I\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>倫敦城漫步 (2)</title>
      <link>https://wangcc.me/post/first-impression-of-london2/</link>
      <pubDate>Wed, 27 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/first-impression-of-london2/</guid>
      <description>&lt;p&gt;我們學科 (Medical Statistics) 是爲數不多的在 Orientation 周就有一半以上的時間在上課的學科。別的學科像 Epidemiology 這周還集體去劍橋大學見學啥的。幾乎都是第二周，也就是10月2日週一開始的時候才有大量的必修和選修課。所以不見得再有太多時間寫見聞和體驗。（也沒有時間出去玩了&amp;hellip;..）不過學習的內容還是會來更新一下，給各位有個印象，也讓大家都來判斷以下，這裏的碩士課程的內容和質量到底如何。&lt;/p&gt;
&lt;h4 id=&#34;9月22日-isw--ucl--福爾摩斯博物館的紀念品商店&#34;&gt;9月22日 ISW &amp;amp; UCL &amp;amp; 福爾摩斯博物館（的紀念品商店）&lt;/h4&gt;
&lt;p&gt;忘了交代，9月21日和22日都是 Internatioanal Student Welcome (留學生歡迎會, ISW) 的日子。充滿對這一年的期待，和但是是否自己能最終倖存下來的不安，坐在這樣壓力巨大的梯形教室裏，我和這麼多來自世界各地的年輕人成爲了同學：
&lt;img src=&#34;https://wangcc.me/img/1015171443.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;這個教室就是大名鼎鼎的 &lt;a href=&#34;http://johnsnowbicentenary.lshtm.ac.uk/about-john-snow/&#34;&gt;John Snow&lt;/a&gt; Lecture Theatre。我就知道你以爲是這個人：
&lt;img src=&#34;https://wangcc.me/img/Jonsnow.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;其實歷史上的 Snow 同學可是奠定了近代流行病學基礎的巨人。比這個 bastard 強$^{9999999}$ 多了好麼，快去維基百科自學去。&lt;/p&gt;
&lt;p&gt;這個大名鼎鼎的水泵就是他拆的！
&lt;img src=&#34;https://wangcc.me/img/1759791785.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;閒話少敘，註冊參加時，排隊的樣子：
&lt;img src=&#34;https://wangcc.me/img/1738788923.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;領到自己的卡，寫上自己的名，和課程名稱 (原諒我的粗鄙的筆跡)：
&lt;img src=&#34;https://wangcc.me/img/39418260.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;看這梯形教室有多陡峭：（據說梯形教室陡峭的程度和學習壓力成正比）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/876198141.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;學校還請來了倫敦警察（可愛壞）薯熟來跟大家講我以前感覺只有在中國才會有的防盜防火防學長的故事：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/697554235.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;22日中午結束以後我就步行在大學附近閒逛，UCL就在我們大學 Keppel Street 往北一點點。連3分鐘都不到。看這&lt;strong&gt;大學&lt;/strong&gt;，真有&lt;strong&gt;大學&lt;/strong&gt;的感覺：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/761318563.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;爲數不多的晴天在這一週已經碰到兩天了。是不是應該買張彩票試試看？（笑）
UCL是以前高中同班同學待過（一個已經回廈門），和正在待的地方（一個正在博士後/Research Assistant?）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/16618557.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;大學對面是UCL的醫學院：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/979802270.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;有那麼一點點霍格沃茨的感覺。我在校內略逛了以下，起身前去貝克街。如果你聽說過貝克街，那你一定聽說過221號B。因爲這是小說裏福爾摩斯和華生的住址。來之前我就查過了，距離倫敦大學步行半個小時左右，中途還會經過杜莎夫人蠟像館（聽起來就令人覺得索然無味的地方）。&lt;/p&gt;
&lt;p&gt;當我來到貝克街的時候，路邊有個福爾摩斯的雕像，許多人駐足和心目中世界上最聰明的男人合影留念：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/801300689.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;旁邊還有一個貝克街的公共汽車站證明了這可是真實存在的地址哦：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1411584999.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;但是其實這裏只是貝克街的起點。走到 Baker Street 221 B 之後我被門口排的長隊驚呆了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1790216276.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;於是我趕緊跟在隊的最後面排隊，大概五分鐘過後有個老頭過來問說，你買了門票了嗎？ 我說我還以爲這裏就是排隊買門票呢。他說這些人都是排隊進福爾摩斯紀念館的。旁邊的小房間現在是紀念品商店，可以在那裏買到門票。所以我就轉身進入了紀念品商店。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1556464625.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;商店裏還真是應有盡有。你能想到的關於福爾摩斯的任何東西。而且大多數價格都不便宜：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/2032661472.jpg&#34; alt=&#34;&#34;&gt;
這個杯子賣八鎊，低下寫着英國製造。&lt;/p&gt;
&lt;p&gt;這頂帽子，全羊毛手工製作，也寫着英國製造，49鎊一頂：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_20170922_165434.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;這兩個東西正好也是我現在需要的。所以我就買了下來。但是進入紀念館的門票竟然要16英鎊。我想還是等我有學生優惠了以後再來問問看吧。說不定可以便宜一些。打道回府的路上又經過UCL，在這棟標誌性的建築物門口的長椅上坐了許久，休息，沉思。側面的角度還是很有感覺的呢。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1277846351.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>漫步倫敦城 (1)</title>
      <link>https://wangcc.me/post/first-impression-of-london/</link>
      <pubDate>Tue, 26 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/first-impression-of-london/</guid>
      <description>&lt;p&gt;在倫敦生活過完了第一周，似乎快要步入正軌了。因為許許多多的前輩告誡說，第一周是唯一可以輕鬆度過的時間，一定要珍惜好好利用。多看看倫敦，多四處走走。&lt;/p&gt;
&lt;p&gt;於是我很聽話的每天都四處走走。接下來打算把這幾天去過的地方盡量根據回憶都列舉一下：&lt;/p&gt;
&lt;h4 id=&#34;9月19日-大英博物館初體驗&#34;&gt;9月19日 大英博物館初體驗&lt;/h4&gt;
&lt;p&gt;國王十字車站附近的郵局 → 大英博物館&lt;/p&gt;
&lt;p&gt;從宿舍往北步行十五分鐘左右，就是大英圖書館，圖書館的旁邊就能看到國王十字車站 (King&amp;rsquo;s Cross Station)。所有剛到英國的留學生（簽證在6個月以上的吧？），都要去自己申請簽證時登記的郵局領取BRP卡。BRP卡就相當於日本的在留卡，也就是登記一下外國人的個人信息，住址和在留期限。我當時登記的是這個最近的郵局，叫做國王十字車站郵局 (Kings Cross Post Office)。&lt;/p&gt;
&lt;p&gt;去郵局的路上看到了兩個騎著高頭大馬的帥氣警察。不敢從正面拍，所以走到了後面才趕緊拍了一張：
&lt;img src=&#34;https://wangcc.me/img/188242805.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;然後你也會看到一個非常有巴洛克風的建築物：
&lt;img src=&#34;https://wangcc.me/img/1279177784.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;這個叫做 &lt;a href=&#34;http://www.marriott.com/hotels/travel/lonpr-st-pancras-renaissance-hotel-london/?scid=bb1a189a-fec3-4d19-a255-54ba596febe2&#34;&gt;St. Pancras Renaissance Hotel London&lt;/a&gt;，中文名應該是聖潘克拉斯萬麗酒店。如果你玩過&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%88%BA%E5%AE%A2%E6%95%99%E6%A2%9D%EF%BC%9A%E6%A2%9F%E9%9B%84&#34;&gt;刺客信條梟雄&lt;/a&gt;。一定會對這樣的建築印象深刻。&lt;/p&gt;
&lt;p&gt;郵局內部真的是破爛不堪，連中國三線城市的郵政儲蓄營業廳都不如，櫃檯工作的好多是黑人和印度人，口音很重，態度蠻橫。要做好心理準備。而且標識十分不明，你必須問周圍的人我現在排的隊是幹什麼的。&lt;/p&gt;
&lt;p&gt;領完我的BRP卡之後，又往回走，到宿舍以南步行也是10分鐘左右，進入大英博物館。從正門走時，因為每個進入大英博物館的人如果有帶包都要打開給警備員查看。所以入口處隊伍非常的長。後來聽說從後門走的話人就少很多。不過這天不是週末，所以我得以很快的通過安檢進入博物館。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;大英博物館外觀：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0123.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;進入大英博物館的玄關以後，視野一下子就開闊起來:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0129.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;果然從世界各地搶來的東西展覽起來就是有底氣！ 呵呵！&lt;/p&gt;
&lt;p&gt;當然英國人對世界人類瑰寶的保存還是花了不少力氣。我花了一個小時左右看了古埃及部分，一點點古希臘，還有一個專門展覽人類各種貨幣的展廳。&lt;strong&gt;牆裂推薦！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0125.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0124.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;9月20日-暴走倫敦城&#34;&gt;9月20日 暴走倫敦城&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1865771317.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;谷歌事無鉅細記錄了我一天的行程。早晨我起床吃了早飯就離開宿舍前往&lt;a href=&#34;https://skygarden.london/&#34;&gt;天空花園 (Sky Garden)&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;出發來倫敦之前，通過閱讀學校給的關於倫敦的簡單介紹，知道了這個地方。應該是類似新加坡 &lt;a href=&#34;http://www.marinabaysands.com/sands-skypark/observation-deck.html&#34;&gt;Sky Park&lt;/a&gt;。的空中花園。天氣晴朗的時候可以俯瞰全城的地標性建築物。
不同的是倫敦的天空花園是免費，且要預約的。如果你打開上面天空花園的網頁鏈接，就能看見預約的方法。我提前預約了週三早晨10點半進入參觀的門票。如果我沒有記錯的話，新加坡的空中花園不用預約，但是需要在門口乘電梯的地方購買門票，一個人應該是15新幣的樣子。&lt;/p&gt;
&lt;p&gt;Sky Garden 的外觀：
&lt;img src=&#34;https://wangcc.me/img/508099424.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;週三天氣很不好，看不清楚太遠的地方。不過畢竟登高望遠，泰晤士河兩岸，倫敦塔橋等建築物還是能看得見：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0130.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/453454807.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;霧濛濛的是不是感覺比北京天氣還糟糕？！ 這麼說有點不公平，因為我沒在北京生活過。客觀點說倫敦空氣質量還不錯，天氣很不好。據說到了冬天抑鬱症的人就會增加。&lt;/p&gt;
&lt;p&gt;雖然預約的是10點半到11點半一個小時，不過整個花園不大，天氣不好所以也沒什麼看頭，十五分鐘我就下來了。看著地圖又繼續往泰晤士河邊走。中途路過&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%80%AB%E6%95%A6%E5%A4%A7%E7%81%AB&#34;&gt;倫敦大火&lt;/a&gt;紀念碑：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0136.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;經過倫敦橋(你以為倫敦橋有多壯觀？看了你會失望)以後你會發現這種橋在黃浦江上可能還根本算不上是一座橋。也就跟我們村里小河邊看櫻花的那個橋差不太多。。。&lt;/p&gt;
&lt;p&gt;可能倫敦“城裡人”會不同意我的話哈哈，請多見諒，您是城里人嘛。&lt;/p&gt;
&lt;p&gt;到了泰晤士河南岸，往西走，去塔橋 (Tower Bridge) 的路上會看見一艘軍艦停靠在港口：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0137.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;估計和停靠在珍珠港的軍艦一樣曾經在戰爭中服役。只不過從外觀規模上來看這艘軍艦顯然小很多。門票有點小貴，所以我也沒有花錢進去。經過軍艦以後是個不大不小的廣場。讓我想起了廈門輪渡碼頭。不過，再往前就是壯觀的塔橋了 (Tower Bridge)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IMG_0144-EFFECTS.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;塔橋在大船要進入泰晤士河的時候是可以從中間舉起，讓船通過然後再放下的。之前都只在風景明信片裡面看過的建築物，我終於有幸在上面留下我的足跡。走上塔橋意味著就離開南岸，又回到北岸了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/1101681166.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/584841134.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;回宿舍的路上，我注意觀察了路邊的ATM機器。絕大部分都是只在牆壁上挖了一個洞，放個機器。讓人超級沒有安全感的。密碼被周圍的人看了咋辦？ 取了多少錢都被周圍的人看見了，有人見財起意咋辦？ 英國人都不在乎這些嗎？ 好像銀行的建築物裡面的ATM機器可能可以多少讓人有點安全感吧。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/860210008.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;機器上方的字的意思是取錢不收手續費。這非常的好。於是我在一個車站的較為隱蔽的角落裡的 ATM 嘗試著用 manepartners 的卡著取了些現金。後來手機一查，還是扣了我 1.5 鎊的手續費。估計多半是 manepartners 扣去了的。&lt;/p&gt;
&lt;p&gt;回到宿舍，我暴走了近 10 公里的腳都已不聽使喚，我還盤算著這樣白天足夠累了的話，夜裡就能多睡睡，把時差快點調整過來。誒，調整時差也應該有個人區別，也許我就是屬於不太容易調整時差的那類吧。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>London Baby !</title>
      <link>https://wangcc.me/post/london-life-started/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/london-life-started/</guid>
      <description>&lt;h4 id=&#34;離開&#34;&gt;離開&lt;/h4&gt;
&lt;p&gt;飛機翱翔在俄羅斯上空。我在機艙內拿出手機，再一次看老友記第四季的最後一集。講的是 Ross 和 Emily 在倫敦的婚禮。
熟悉的歡樂劇情，不熟悉的城市。如果你對老友記像我一樣熟悉，快來跟我做朋友吧！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/friends.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;十三個小時的飛行，我一直無法休息。我在憧憬這一年如痴如醉的傲遊知識海洋嗎？我離開家，離開愛妻，離開親愛的孩子們，是多麼的捨不得。我才剛踏上旅程，思念就如同潮水在心中湧起。在中部機場和妻告別時，她拿出一個小小的粉紅色信封。依依不捨的告訴我說上了飛機再看。想來和妻在一起這幾年，這是她第一次這樣細膩又柔軟的感情表達。可是我卻把整個家留在了身後，全部交給了她。這一年，要辛苦你了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/taifeng.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;就在離開日本的前一日，名古屋還在18號颱風的正面襲擊之下。夜晚狂風驟雨，摧枯拉朽地吹散整個城市的思念。早晨醒來，天空還是陰沉沉的，颱風仍然沒有完全過去。全家人擔心著飛機的起飛是否被影響。我們還是毅然決然地開著心愛的小西沖向了機場。在日航的櫃檯等待行李寄存時，抬頭看見大屏幕上的航班信息，名古屋-沖繩 取消， 名古屋-札幌 取消，名古屋-成田（東京） 取消。。。。 一整個屏幕都是航班取消的紅色信號。可是最後，名古屋-羽田（東京）的航班竟然顯示的是 &amp;lsquo;計劃&amp;rsquo;。拿到機票進入候機大樓以後才看見，這時天空的烏雲已經開始逐漸散去。原來，我的航班真的可以按時離開了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/ontheflight.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;抵達&#34;&gt;抵達&lt;/h4&gt;
&lt;p&gt;同行的本田是一個日本人小兒科醫生。她跟我很早就通過 Facebook 聯絡，並且發現我們恰好訂了同一天的航班，宿舍距離也不遠。於是順理成章地，我們到了希思羅機場以後準備一起乘 Uber 去我們各自的宿舍。希思羅機場乘 Uber 時要先去出發的航站樓的停車場，才能順利上車。推著行李過去停車場的一路上我們是真切的感受到了9月倫敦的氣溫是多麼的冷。我趕快拿出放在包裏的羽絨服披上才算沒有被凍到。&lt;/p&gt;
&lt;p&gt;不過奇怪的是我的 uber 賬號本來在美國西雅圖，新加坡等地方都用的好好的，在倫敦卻一直提示我支付用的信用卡信息有誤。就算我立刻更新了信用卡信息，或者是從 mastercard 換成 visa 均不能成功。真是尷尬死了。正在此時，旁邊另一個留學生模樣的女生湊過來說，“我可以借一下你的 wifi 熱點嗎？”。原來此人來自香港，在 LSE （倫敦政經學院）做交換留學生一年。真是巧了。宿舍也離我們的不太遠。所以果斷把我租的小米全球上網分享給她：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/xiaomiwifi.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;三個剛剛踏上留學生活的陌生人，就這樣乘了同一輛車進入這個陌生的大城市。倫敦，I am coming。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/internationalhall.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;順利抵達我的&lt;a href=&#34;https://www.internationalhall.com/&#34;&gt;宿舍 International Hall&lt;/a&gt;，領了房間卡之後，住進了我此生租過的最貴的每週200鎊的單身無廁所無浴室學習房間 (Study Room) :&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/studyroom.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;大學附贈了一套被褥床單和浴巾。房間的暖氣片暫時還不能使用。夜裡的溫度已經降到10度以下了呢！！！衣櫃裡的鏡子已經碎了，不過我很喜歡這個特別長的書桌，上面的書櫃，還有牆壁上的這塊掛墊：(我的兩個小寶貝的照片被我第一時間貼了上去。)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/room2.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;宿舍附近就有 Tesco，是個24小時開門的小超市。類似在日本的7/11。也是應有盡有，甚至還能買到新鮮果蔬：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/avocadotesco.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我的宿舍之所以這麼貴，是有原因的！因為住在這裡，旁邊就是大英博物館：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Britshmuseum.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;進去走馬觀花看了一個半小時，又在附近逛了逛，和一個正在 LSHTM 讀博士學位的日本人見面送了東西，然後又和闊別多年的高中同學吃了午餐。&lt;/p&gt;
&lt;p&gt;壽司果然在這裡價格不菲：
&lt;img src=&#34;https://wangcc.me/img/sushilondon.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;當然更不能錯過美好的天氣，還有我將要奉獻一年時間的夢想中的大學： 倫敦衛生學與熱帶醫學學院 (London School of Hygiene and Tropical Medicine)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/LSHTMdoor.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;初來乍到的幾天，時差還根本轉不過來，晚上8點多就困的不省人事，現在半夜三點又精神抖擻。希望能快點適應這裡的生活。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>UK visa succeed</title>
      <link>https://wangcc.me/post/uk-visa-succeed/</link>
      <pubDate>Tue, 29 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/uk-visa-succeed/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/post/visa-application/&#34;&gt;我在近一個月前去了大阪的英國簽證中心申請了去英國的簽證。&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;當時大英帝國的簽證申請就給我留下極差的印象。結果後來我的等待才是最漫長的。&lt;/p&gt;
&lt;p&gt;理一下時間線：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;7月31日 提交簽證材料&lt;/li&gt;
&lt;li&gt;8月16日 收到郵件提示，護照抵達馬尼拉&lt;/li&gt;
&lt;li&gt;8月23日 打電話給大英帝國高貴的&lt;a href=&#34;https://www.gov.uk/contact-ukvi-inside-outside-uk/y/outside-the-uk/english&#34;&gt;移民局(UK Visas and Immigration)&lt;/a&gt; (下面詳述)&lt;/li&gt;
&lt;li&gt;8月23日 收到郵件提示，護照抵達日本大阪簽證申請中心&lt;/li&gt;
&lt;li&gt;8月24日 下午查詢郵局訂單號發現已經到了我所在的城市，晚上，配送完畢，簽證到手:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/UKvisa.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;當時提交簽證材料時，告訴我的是，提交之日起15個工作日，所以我的預計是8月中旬能入手簽證。結果，實際上8月中旬才剛剛寄到馬尼拉。也許是因爲這個時期有許多學生簽證申請，比較擁擠。我又不樂意去花錢買他們所謂的加急服務。因爲付錢等於我承認了這樣的做法是合理的。反而會助長這種依靠金錢來獲取方便的惡習。（當然我相信他們也不缺我一個人）
申請的順序，爲什麼不是按照申請的時間順序來呢？有人晚來了，付了錢加急就可以排到我前面去，這哪裏公平了？這在日本根本無法想象。最可恨的是，23日那天我實在是等不及了，早晨給移民局打電話去詢問簽證狀態，電話接通以後是機器聲音，提示先輸入有效的信用卡或者借記卡號碼，方便他們收取諮詢費用(1.37 £/min)。&lt;/p&gt;
&lt;p&gt;這一趟簽證申請體驗下來，只能令人感嘆大英帝國真的是沒落了。做事情效率之低下，每一個環節透露出來的全部都是赤裸裸的金錢至上主義。&lt;/p&gt;
&lt;p&gt;回想起當日在大阪簽證中心提交材料時，電視屏幕上循環播放着大英帝國的宣傳片。介紹着英國的方方面面，從工業革命，到互聯網的發明，以及優越先進的醫療和社會制度，無處沒有英國在其中起到的關鍵或者領導式的作用。這不是讓人覺得極爲諷刺嗎？過去的強盛，給他們留下的只有傲慢嗎？&lt;/p&gt;
&lt;p&gt;可能上面的體驗只是我還沒出發之前，體會到的十分侷限的部份，但願接下來一年英國風調雨順。&lt;/p&gt;
&lt;p&gt;大概我除了讀書一無是處，所以畢業應該（希望）是沒有問題！&lt;/p&gt;
&lt;p&gt;還有一個月不到就要出發了，倫敦，我來也！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ACC in Tokyo &amp; IEA in Saitama</title>
      <link>https://wangcc.me/post/iea-in-saitama/</link>
      <pubDate>Thu, 24 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/iea-in-saitama/</guid>
      <description>&lt;h4 id=&#34;acctokyo&#34;&gt;ACC@Tokyo&lt;/h4&gt;
&lt;p&gt;8月18日-8月22日期間，我先是去了東京參加學習了 &lt;a href=&#34;https://www.asiacohort.org/index.html&#34;&gt;ACC (Asia Cohort Consortium)&lt;/a&gt;，&lt;a href=&#34;https://www.asiacohort.org/accmeetings/individual.html?entry_id=56&#34;&gt;內容&lt;/a&gt;主要是亞洲地區進行過的，以及正在進行的隊列研究的大集合。&lt;del&gt;當然還有很多隊列由於各種原因不能加入這個大家庭。&lt;/del&gt; 這之後又離開東京去了琦玉的大宮，參加那裏舉辦的第21屆國際流行病學會。&lt;/p&gt;
&lt;p&gt;在東京的ACC其實挺豐富的，最近的課題彙報，還有就是來自亞洲各地的老師們暢所欲言，提供分析或者論文討論的建議。印象深刻的如：&lt;/p&gt;
&lt;p&gt;(1) 臺灣Biobank的近況介紹
&lt;img src=&#34;https://wangcc.me/img/taiwanbiobank.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;(2) 來自范德堡大學 (Vanderbilt University) 的&lt;a href=&#34;http://www.vicc.org/dd/display.php?person=wei.zheng&#34;&gt;Wei Zheng&lt;/a&gt;教授的課題內容更新:
&lt;img src=&#34;https://wangcc.me/img/zhengwei.jpg&#34; alt=&#34;&#34;&gt;
照片的老師是來自新加坡國立大學的&lt;a href=&#34;https://sph.nus.edu.sg/about/faculty-directory/chia-kee-seng&#34;&gt;Chia Kee Seng&lt;/a&gt;教授。&lt;/p&gt;
&lt;p&gt;大名鼎鼎的BMI和總死亡的關係的&lt;a href=&#34;www.nejm.org/doi/full/10.1056/NEJMoa1010679&#34;&gt;論文&lt;/a&gt;：
&lt;img src=&#34;https://wangcc.me/img/BMIACC.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;(3) 當然不能錯過我們研究室林老師的發表啦：
&lt;img src=&#34;https://wangcc.me/img/linyingsong.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;(4) 休息時間還不忘來一個日本拉麵的報告（笑）：
&lt;img src=&#34;https://wangcc.me/img/ramenpresentation.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;結束了ACC以後，晚上去往宴會的路上我們還能看見之前&lt;a href=&#34;http://www.bbc.com/japanese/40822629&#34;&gt;築地市場火災&lt;/a&gt;發生後的痕跡：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/tsukichifire.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;發生火災的店鋪是個拉麵店，之前我和西山來癌症中心的時候有路過，當時還有不少人排隊吃麵，我們也曾猶豫過，不過後來還是吃了壽司。當然沒有人想到幾周之後就在同一個地方起火燒掉了許多老店鋪。&lt;/p&gt;
&lt;h4 id=&#34;ieaomiya-day-1&#34;&gt;IEA@Omiya Day 1&lt;/h4&gt;
&lt;p&gt;第二天離開了東京以後乘上電車去往埼玉縣，大宮市。&lt;/p&gt;
&lt;p&gt;原本我應該乘坐的電車時間和線路是這樣的:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/yahootransitOmiya.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;可是等到11點半我發現外面越來越荒涼，好像不太對勁，因爲我一邊在電車裏，一邊聽着有的沒的廣播和播客，所以很有可能聽漏了報站。打開地圖一看我已經超過好多站了，於是決定等到下一個停靠站就下來坐車再往回走。於是摘掉了耳機認真聽廣播報的站名，聽到報下一站站名的時候一時被愣住了，一時沒緩過神來：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;下一站是，桶川。&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;這個站名太熟悉了，瞬間想起之前剛看過的一些列&lt;a href=&#34;https://zhuanlan.zhihu.com/p/23255253&#34;&gt;文章&lt;/a&gt;。講的就是發生在這裏的故事吧。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Okegawa1.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;到站下車以後隨手拍了一下站牌：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Okegawa.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;跑步去了對面站臺，上了回頭車後，不到15分鍾回到了大宮站：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Omiya.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;午飯在車站裏的餐廳解決，美味的鹿肉漢堡：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Deermeat.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;飽餐以後找到了我租的Airbnb（距離車站有點遠，推着行李箱步行過去差點被曬成狗），放了行李，我便來到會場，Sonic City。也許是來得太早了。完全沒有國際會議的感覺，會場十分空曠：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/OpeningIEA.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;等到下午正式開會，會長中村好一致辭時，也未見增加多少參會者：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/OpeningIEA1.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;第一日成功和曾經在倫敦衛校留學的潘師兄見面。遙想三年前在阿拉斯加，真是時光如梭，當時我還不知自己今日會有機會去倫敦留學。如今潘師兄已經是孩子爸了，也如願以償在同濟醫學院做了老師。所以我來之前就決定，一定要抓住這次機會跟潘老師多了解了解在倫敦的生活。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記 25</title>
      <link>https://wangcc.me/post/cramers-formula/</link>
      <pubDate>Wed, 09 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/cramers-formula/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;克萊姆法則-cramers-formula&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;克萊姆法則 Cramer’s Formula&lt;/h3&gt;
&lt;p&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 爲&lt;a href=&#34;https://winterwang.github.io/post/2017-07-06/&#34;&gt;正則矩陣&lt;/a&gt;（&lt;span class=&#34;math inline&#34;&gt;\(|X|\neq0\)&lt;/span&gt;）時 連立一次方程式：&lt;span class=&#34;math inline&#34;&gt;\(X\underline{a}=\underline{y}\)&lt;/span&gt; 的解可以寫作：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[a_j=\frac{|X_j|}{|X|} (j=1,2,\cdots, n)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中： &lt;span class=&#34;math inline&#34;&gt;\(|X_j|\)&lt;/span&gt; 爲矩陣 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 的第 &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; 列替換爲 &lt;span class=&#34;math inline&#34;&gt;\(\underline{y}\)&lt;/span&gt; 以後的矩陣的行列式。&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;練習-解下列連立一次方程式&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;練習 解下列連立一次方程式&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
\left\{
\begin{array}{ll}
a_1+2a_2+a_3  = 2\\
2a_1+a_2+a_3  = 3\\
a_1+a_2+2a_3  = 3
\end{array}
\right.
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;解&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X=\left(
\begin{array}{c}
1 &amp;amp; 2 &amp;amp; 1 \\
2 &amp;amp; 1 &amp;amp; 1 \\
1 &amp;amp; 1 &amp;amp; 2
\end{array}
\right), \underline{a}=\left(
\begin{array}{c}
a_1 \\
a_2 \\
a_3 \\
\end{array}
\right), \underline{y}=\left(
\begin{array}{c}
2 \\
3 \\
3 \\
\end{array}
\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;span class=&#34;math inline&#34;&gt;\(|X|=-4\)&lt;/span&gt; &lt;a href=&#34;https://winterwang.github.io/post/2017-03-15/&#34;&gt;(三次行列式的計算)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 的第一列置換成 &lt;span class=&#34;math inline&#34;&gt;\(\underline{y}\)&lt;/span&gt; 則:
&lt;span class=&#34;math display&#34;&gt;\[|X_1|=\begin{vmatrix}
2 &amp;amp; 2 &amp;amp;  1\\
3 &amp;amp; 1 &amp;amp;  1\\
3 &amp;amp; 1 &amp;amp;  2\\
\end{vmatrix}=-4\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 的第二列置換成 &lt;span class=&#34;math inline&#34;&gt;\(\underline{y}\)&lt;/span&gt; 則:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[|X_2|=\begin{vmatrix}
1 &amp;amp; 2 &amp;amp;  1\\
2 &amp;amp; 3 &amp;amp;  1\\
1 &amp;amp; 3 &amp;amp;  2\\
\end{vmatrix}=0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 的第三列置換成 &lt;span class=&#34;math inline&#34;&gt;\(\underline{y}\)&lt;/span&gt; 則:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[|X_3|=\begin{vmatrix}
1 &amp;amp; 2 &amp;amp;  2\\
2 &amp;amp; 1 &amp;amp;  3\\
1 &amp;amp; 1 &amp;amp;  3\\
\end{vmatrix}=-4\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\therefore a_1=\frac{|X_1|}{|X|}=1, \\
a_2=\frac{|X_2|}{|X|}=0, \\
a_3=\frac{|X_3|}{|X|}=1\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記 24</title>
      <link>https://wangcc.me/post/inverse-matrix-method/</link>
      <pubDate>Sun, 06 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/inverse-matrix-method/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;逆矩陣法解連立一次方程式&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;逆矩陣法解連立一次方程式&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 為&lt;a href=&#34;https://winterwang.github.io/post/2017-07-06/&#34;&gt;正則矩陣&lt;/a&gt;時(&lt;span class=&#34;math inline&#34;&gt;\(|X|\neq0\)&lt;/span&gt;)，給 &lt;span class=&#34;math inline&#34;&gt;\(X\underline{a}=\underline{y}\)&lt;/span&gt; 等式兩邊同時乘以 &lt;span class=&#34;math inline&#34;&gt;\(X^{-1}\)&lt;/span&gt;，可以得到 &lt;span class=&#34;math inline&#34;&gt;\(X^{-1}X\underline{a}=X^{-1}\underline{y}\rightarrow E\underline{a}=X^{-1}\underline{y}\)&lt;/span&gt;。由此方法可以得到 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=X^{-1}\underline{y}\)&lt;/span&gt;。&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;練習-解下列連立一次方程式&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;練習 解下列連立一次方程式&lt;/h4&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
\left\{
\begin{array}{ll}
a_1+2a_2+a_3  = 2\\
2a_1+a_2+a_3  = 3\\
a_1+a_2+2a_3  = 3
\end{array}
\right.
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;解&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;p&gt;元連立方程式可以寫作&lt;span class=&#34;math inline&#34;&gt;\(X\underline{a}=\underline{y}\)&lt;/span&gt;，其中
&lt;span class=&#34;math display&#34;&gt;\[X=\left(
\begin{array}{c}
1 &amp;amp; 2 &amp;amp; 1 \\
2 &amp;amp; 1 &amp;amp; 1 \\
1 &amp;amp; 1 &amp;amp; 2
\end{array}
\right), \underline{a}=\left(
\begin{array}{c}
a_1 \\
a_2 \\
a_3 \\
\end{array}
\right), \underline{y}=\left(
\begin{array}{c}
2 \\
3 \\
3 \\
\end{array}
\right)\]&lt;/span&gt;
之前我們已經用&lt;a href=&#34;https://winterwang.github.io/post/2017-07-07/&#34;&gt;行的基本變形法&lt;/a&gt;和&lt;a href=&#34;https://winterwang.github.io/post/inverse-matrix/&#34;&gt;逆矩陣法&lt;/a&gt;分別計算過了 &lt;span class=&#34;math inline&#34;&gt;\(X^{-1}\)&lt;/span&gt; ：
&lt;span class=&#34;math display&#34;&gt;\[X^{-1}=\left(\begin{array}{c}
-1/4 &amp;amp; 3/4 &amp;amp; -1/4\\
3/4 &amp;amp; -1/4 &amp;amp; -1/4\\
-1/4 &amp;amp; -1/4 &amp;amp; -3/4\\
\end{array}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\therefore\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
\underline{a} &amp;amp; =X^{-1}\underline{y} \\
&amp;amp; =\left(\begin{array}{c}
-1/4 &amp;amp; 3/4 &amp;amp; -1/4\\
3/4 &amp;amp; -1/4 &amp;amp; -1/4\\
-1/4 &amp;amp; -1/4 &amp;amp; 3/4\\
\end{array}\right)\left(
\begin{array}{c}
2 \\
3 \\
3 \\
\end{array}
\right)\\
&amp;amp;=\left(
\begin{array}{c}
-1/4\times2+3/4\times3-1/4\times3 \\
3/4\times1+(-1/4)\times3-1/4\times3 \\
-1/4\times2-1/4\times3+3/4\times3 \\
\end{array}
\right) \\
&amp;amp; = \left(
\begin{array}{c}
1 \\
0 \\
1 \\
\end{array}
\right)
\end{align} \]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記22</title>
      <link>https://wangcc.me/post/inverse-matrix/</link>
      <pubDate>Thu, 03 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/inverse-matrix/</guid>
      <description>&lt;p&gt;正方形矩陣 $A$ 的行列式滿足 $|A| \neq 0$ 時，逆矩陣可以表達爲(當 $|A|=0$ 時，正方形矩陣 $A$ 沒有逆矩陣)：
$$A^{-1}=\frac{1}{|A|}adj(A)=\frac{1}{|A|}(A_{ij})^t$$&lt;/p&gt;
&lt;p&gt;$$=\frac{1}{|A|}\lbrace(-1)^{i+j}D_{ij}\rbrace^t$$&lt;/p&gt;
&lt;p&gt;其中:&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$adj(A)$ 爲&lt;a href=&#34;https://winterwang.github.io/post/2017-03-15/&#34;&gt;餘因子矩陣&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;$A_{ij}$ 爲&lt;a href=&#34;https://winterwang.github.io/post/2017-03-15/&#34;&gt;餘因子&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;$D_{ij}$ &lt;a href=&#34;https://winterwang.github.io/post/2017-03-15/&#34;&gt;爲小行列式&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(1) 之前舉過的例子再拿來試試看：&lt;/p&gt;
&lt;p&gt;$$X=\left(
\begin{array}{c}
1 &amp;amp; 2 &amp;amp; 1 \newline
2 &amp;amp; 1 &amp;amp; 1 \newline
1 &amp;amp; 1 &amp;amp; 2
\end{array}
\right)=\left(\begin{array}{c}
x_{11} &amp;amp; x_{12} &amp;amp; x_{13} \newline
x_{21} &amp;amp; x_{22} &amp;amp; x_{23} \newline
x_{31} &amp;amp; x_{32} &amp;amp; x_{33}
\end{array}\right)$$
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;元素 $x_{ij}$ 的餘因子 $X_{ij}(i,j=1,2,3)$ 爲：&lt;/p&gt;
&lt;p&gt;$$X_{11}=(-1)^{1+1}\left|
\begin{array}{c}
1 &amp;amp; 1 \newline
1 &amp;amp; 2
\end{array}\right|=1$$&lt;/p&gt;
&lt;p&gt;$$X_{12}=(-1)^{1+2}\left|
\begin{array}{c}
2 &amp;amp; 1 \newline
1 &amp;amp; 2
\end{array}\right|=-3$$&lt;/p&gt;
&lt;p&gt;$$X_{13}=(-1)^{1+3}\left|
\begin{array}{c}
2 &amp;amp; 1 \newline
1 &amp;amp; 1
\end{array}\right|=1$$&lt;/p&gt;
&lt;p&gt;$$X_{21}=(-1)^{2+1}\left|
\begin{array}{c}
2 &amp;amp; 1 \newline
1 &amp;amp; 2
\end{array}\right|=-3$$&lt;/p&gt;
&lt;p&gt;$$X_{22}=(-1)^{2+2}\left|
\begin{array}{c}
1 &amp;amp; 1 \newline
1 &amp;amp; 2
\end{array}\right|=1$$&lt;/p&gt;
&lt;p&gt;$$X_{23}=(-1)^{2+3}\left|
\begin{array}{c}
1 &amp;amp; 2 \newline
1 &amp;amp; 1
\end{array}\right|=1$$&lt;/p&gt;
&lt;p&gt;$$X_{31}=(-1)^{3+1}\left|
\begin{array}{c}
2 &amp;amp; 1 \newline
1 &amp;amp; 1
\end{array}\right|=1$$&lt;/p&gt;
&lt;p&gt;$$X_{32}=(-1)^{3+2}\left|
\begin{array}{c}
1 &amp;amp; 1 \newline
2 &amp;amp; 1
\end{array}\right|=1$$&lt;/p&gt;
&lt;p&gt;$$X_{33}=(-1)^{3+3}\left|
\begin{array}{c}
1 &amp;amp; 2 \newline
2 &amp;amp; 1
\end{array}\right|=-3$$&lt;/p&gt;
&lt;p&gt;因此餘因子矩陣爲：$adj(X)=\left(
\begin{array}{c}
1 &amp;amp; -3 &amp;amp; 1 \newline
-3 &amp;amp; 1 &amp;amp; 1 \newline
1 &amp;amp; 1 &amp;amp; -3
\end{array}
\right)^t=\left(
\begin{array}{c}
1 &amp;amp; -3 &amp;amp; 1 \newline
-3 &amp;amp; 1 &amp;amp; 1 \newline
1 &amp;amp; 1 &amp;amp; -3
\end{array}
\right)$&lt;/p&gt;
&lt;p&gt;我們看見這個餘因子矩陣是一個對稱矩陣，這是由於原矩陣 $X$ 本身就是一個對稱矩陣。另外，行列式爲：&lt;/p&gt;
&lt;p&gt;$$\begin{align}|X|&amp;amp;=1\times X_{11}+2\times X_{12}+1\times X_{13}\newline&amp;amp;=1\times1+2\times(-3)+1\times1\newline&amp;amp;=-4\end{align}$$&lt;/p&gt;
&lt;p&gt;因此所求的逆矩陣爲：&lt;/p&gt;
&lt;p&gt;$$\begin{align}X^{-1}&amp;amp;=\frac{1}{|X|}adj(X)\newline
&amp;amp;=\frac{1}{-4}\left(
\begin{array}{c}
1 &amp;amp; -3 &amp;amp; 1 \newline
-3 &amp;amp; 1 &amp;amp; 1 \newline
1 &amp;amp; 1 &amp;amp; -3
\end{array}
\right)\newline
&amp;amp;=\left(
\begin{array}{c}
-\frac{1}{4} &amp;amp; \frac{3}{4} &amp;amp; -\frac{1}{4} \newline
\frac{3}{4} &amp;amp; -\frac{1}{4} &amp;amp; -\frac{1}{4} \newline
-\frac{1}{4} &amp;amp; -\frac{1}{4} &amp;amp; \frac{3}{4}
\end{array}
\right)\end{align}$$&lt;/p&gt;
&lt;p&gt;(2) 試求矩陣 $A=\left(
\begin{array}{c}
1 &amp;amp; 2 &amp;amp; 1 \newline
2 &amp;amp; 3 &amp;amp; 1 \newline
1 &amp;amp; 2 &amp;amp; 2
\end{array}
\right)=\left(
\begin{array}{c}
a_{11} &amp;amp; a_{12}  &amp;amp; a_{13} \newline
a_{21} &amp;amp; a_{22}  &amp;amp; a_{23} \newline
a_{31} &amp;amp; a_{32}  &amp;amp; a_{33}
\end{array}
\right)$ 的逆矩陣 $A^{-1}$:&lt;/p&gt;
&lt;p&gt;$$\begin{array}
=A_{11}=6-2=4, &amp;amp; A_{12}=-(4-1)=-3, &amp;amp; A_{13}=4-3=1 \newline
A_{21}=-(4-2)=-2, &amp;amp; A_{22}=2-1=1, &amp;amp; A_{23}=-(2-2)=0 \newline
A_{31}=2-3=-1, &amp;amp; A_{32}=-(1-2)=1, &amp;amp; A_{33}=3-4=-1
\end{array}$$&lt;/p&gt;
&lt;p&gt;$$adj(A)=\left(
\begin{array}{c}
4 &amp;amp; -3 &amp;amp; 1 \newline
-2 &amp;amp; 1 &amp;amp; 0 \newline
-1 &amp;amp; 1 &amp;amp; -1
\end{array}
\right)^t=\left(
\begin{array}{c}
4 &amp;amp; -2 &amp;amp; -1 \newline
-3 &amp;amp; 1 &amp;amp; 1 \newline
1 &amp;amp; 0 &amp;amp; -1
\end{array}
\right)$$&lt;/p&gt;
&lt;p&gt;$$\begin{align}
|A| &amp;amp;=1\times A_{11}+2\times A_{12}+1\times A_{13} \newline
&amp;amp;=1\times4+2\times(-3)+1\times1 \newline
&amp;amp;=4-6+1 \newline
&amp;amp;=-1
\end{align}$$&lt;/p&gt;
&lt;p&gt;$$
\therefore
\begin{align}
A^{-1} &amp;amp;= \frac{1}{(-1)}\left(
\begin{array}{c}
4 &amp;amp; -2 &amp;amp; -1 \newline
-3 &amp;amp; 1 &amp;amp; 1 \newline
1 &amp;amp; 0 &amp;amp; -1
\end{array}
\right) \newline
&amp;amp;=\left(
\begin{array}{c}
-4 &amp;amp; 2 &amp;amp; 1 \newline
3 &amp;amp; -1 &amp;amp; -1 \newline
-1 &amp;amp; 0 &amp;amp; 1
\end{array}
\right)
\end{align}$$&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>大英帝國簽證申請</title>
      <link>https://wangcc.me/post/visa-application/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/visa-application/</guid>
      <description>&lt;p&gt;來說說7月31日去大阪交簽證材料的事情。&lt;/p&gt;
&lt;p&gt;那叫一個鬱悶。
總之，我在日本還是第一次遇見如此糟糕的接待。另外，大阪的簽證辦理中心，非常不好找，建議第一次去的人挑一個不那麼熱的日子去。這樣也不會像我一樣在馬路上被曬成狗。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;當然我才不會告訴你我早上起晚了差點趕不上我訂的火車票（9：00）。而且近鐵列車的城市快線 &lt;a href=&#34;http://www.kintetsu.co.jp/gyoumu/meihan/culture/timetable/timetable_weekday.html&#34;&gt;(urban liner)&lt;/a&gt; 開得不是很平穩，我半路感覺暈車不適還跑去洗手間把早飯吐了以後才能舒服一點得繼續坐到大阪難波車站。從難波車站再換乘御堂筋線到心斎橋，之後就出車站步行差不多10個被暴曬的街區到VFS簽證代理處。不過並非領事館或者大使館，所以我想應該不會像美國領事館那樣戒備森嚴。結果上到10樓VFS辦公室的地方，有提示語告訴我先按門鈴讓保安檢查攜帶行李。按了門鈴，出來一個身材矮小的保安問我預約的時間和簽證申請種類。我把我的預約郵件在手機上打開給他看確認以後才肯帶我進門。&lt;/p&gt;
&lt;p&gt;進去之後就能看到一個還沒有我辦公室大的房間被隔板隔開成幾個部分。保安同學說不能用手機拍照，攜帶的筆記本拿出來給他確認關機。然後材料拿出來先交給保安。他又煞有介事地讓我把揹包每一層都打開給他看確認我沒帶炸彈。這些都搞定了以後又像機場安檢一樣全身掃描一遍確認我身上沒有綁着炸彈。。。&lt;/p&gt;
&lt;p&gt;此時已經比我預約的時間晚了10分鐘。當然我不怪他。他只是認真完成任務。之後讓我在等待區域等待。不久之後來了一個接待員用機器人一樣的語調和口吻告訴我說：“把所有的材料按照不同類別分好類，一定要使用牆壁上掛着的那些分類用的不同顏色的紙張。” 我擡頭一看牆壁上掛着的文件架子上有紅色藍色黃色等不同顏色的A4紙。她又接着機械地說：“如果你發現自己不知道怎麼歸類整理這些文檔的話，我也可以幫你，但是要收取1920日元的服務費。” 我艹，連看文件整理都要收費，我心想。接待員小姐估計聽見我的心裏話了，漫不經心地又說，“你當然可以自己整理，不過責任自負喲。”&lt;/p&gt;
&lt;p&gt;你這是在威脅我嗎？我心裏又想。後來才在他們的&lt;a href=&#34;http://www.vfsglobal.co.uk/japan/user_pay_services.html#15&#34;&gt;網站&lt;/a&gt;上看到這樣的收費提示：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Application and Document Checks&lt;!-- raw HTML omitted --&gt;
The Application and Document Checks service is for applicants who have already applied and have printed out their application form to check that an application is complete before sending it to the UK Visas and Immigration in Manila.&lt;!-- raw HTML omitted --&gt;
The service will be charged an additional fee of JPY 1,920 per applicant. The fee can only be paid at Visa Application Centre in person by cash.&lt;!-- raw HTML omitted --&gt;
VFS staff will check mandatory required documents have been submitted, but not the actual content of the documents.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我想省這點錢來着，看着他們的分類文件，毫無提示，簡直就像在嘲諷我“你真的是個PhD嗎？”。隨便分類了以後我想就試試看算了去交材料時，她才說，你這個沒有清單表格不行，你這裏有一張是絕對不能使用的。我心裏十萬頭草泥馬奔騰而過，這些事你們爲啥不能寫在通知預約的郵件裏面呢？爲啥不能算在網上交的簽證費用裏面呢？&lt;/p&gt;
&lt;p&gt;然後那小妞又告訴我說，“反正你要用郵寄服務收護照的話，你可以付錢我幫你整理阿，這兩個服務可以合算起來給你打九折！”。她是不是還期待我感激一下有折扣這件事呢？ “W！T！F！”三個字明確的寫在我的臉上，我想在日本這麼多年了，我TM還是第一次感覺回到了中國大陸。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/gif/wtf.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;強忍不爽的我無奈極了，說，那好吧你幫我整理材料吧。&lt;/p&gt;
&lt;p&gt;總之，什麼都是我自己負責，什麼都要從我身上掏錢，出錯了什麼都該自認倒楣的這種噁心頭頂的感覺從一開始進門一直到錄完指紋，拍好照片準備要離開的時刻。下午1點多，十幾張材料才遞交完。&lt;/p&gt;
&lt;p&gt;不知道是不是因爲接觸太多日本的無微不至的服務突然覺得有心理落差。但願以後去了英國不是這樣的服務。&lt;/p&gt;
&lt;p&gt;兩週以後能否安全收到簽證呢？ 拭目以待。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>無條件 offer, CAS, 和宿舍抽籤結果</title>
      <link>https://wangcc.me/post/unconditional/</link>
      <pubDate>Sat, 29 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/unconditional/</guid>
      <description>&lt;p&gt;言而總之，總而言之，我的4月5月6月7月在無盡的等待中度過。期間投稿了一篇論文。和西山一起進行了磕磕絆絆的GWAS數據分析。&lt;/p&gt;
&lt;p&gt;本來以爲我的 offer 條件僅僅衹是把我原先名古屋大學的博士學位證書，中英文的原本郵寄給 LSHTM 負責確認就可以了。&lt;/p&gt;
&lt;p&gt;結果6月8日那天收到郵件催促我快點滿足 offer 條件：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/fig/meetingcondition.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看到資金證明是我必須提供的條件。所以，我立刻開始著手資金的準備，存款全部移到一個賬戶中去，然後開了一個存款證明。結果就是這個新開的存款證明，後來拖了我一個多月的腿。差點害我以爲可能這次留學計劃就要泡湯了。我原本告訴 LSHTM 的簽證詢問小組（visa-enquiries）說，我的生活費由我的大學支付的工資來做擔保，然後大學還有資助我的一部分旅費和住宿費。因此我還要求我工作的大學給我速速給我開具了上述證明。結果後來被證明這些都不如一張自己賬戶上有錢的證明來得簡單。&lt;/p&gt;
&lt;p&gt;因爲英國留學簽證(Tier 4 student)對 sponsor (資金贊助者)極爲嚴格：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For visa purposes, an Official Financial Sponsor is only one of the following: Her Majesty’s Government, your home government, the British Council or any international organisation, international company, university or an Independent School&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我原以爲我開的三個證明完全足夠了吧。結果過了一個月告訴我說：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Your documents didn’t meet the requirements because: &lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;The salary expectancy is not admissible &lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;li&gt;The statement you have provided only shows the balance on a single day and we therefore recommend a bank letter to show funds held for 28 days. Please find attached an example bank letter. &lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;li&gt;The bank statements did not include the bank name and logo.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;不知道爲什麽，未來的工資單證明不被接受，然後資金證明必須證明說我擁有足夠的資金并且保持了4周時間。而且還要求資金證明上面有銀行的logo。WTF!&lt;/p&gt;
&lt;p&gt;這些都好說。可是日本的銀行，&lt;strong&gt;沒有&lt;/strong&gt;這種類型的證明書（我也是第一次知道日本銀行不給開這樣子的證明）。所以許多人的解決辦法是讓銀行開一個月的流水賬單，要命的是這個證明不能開英文的，然後再去找翻譯公司翻譯流水。當然我也可以這麽辦。衹是，當我知道我的三個證明書都不能作爲有效的資金證明的時候，我離7月31日祗剩下不到2周時間了。在此奉勸后來者，一定要先準備好自己的資金證明書。最好能按照下面的樣本，讓銀行開具類似的證明書：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/fig/bankstatement.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我在接到證明書不滿足條件的郵件的第二天，立刻去了銀行，接待我的銀行經理先是打報告給總部請示。毫無意外被擋回來。說如果是客人自己要求的樣式的證明書，無法給加銀行logo，也不能蓋章，衹能簽字。在我一個多小時的軟磨硬泡以後，經理鬆動了。竟然主動想辦法，她提議說，可以辦理bank statement，不過我看了他們給的bank statement樣本也是一個時間點的賬戶存款而已，無法滿足28天的資金維持證明。看我面有難色，日本人經理還是挺善解人意的，說，我可以把日期改成，從xx月xx日-xx月xx日（28天）的最低資金證明。這樣就能解決問題了。而且bank statement本身自帶銀行logo。謝天謝地，一項死板不能變通的日本人讓我從此刮目相看。解決了我的燃眉之急。也不必再去找翻譯公司翻譯賬戶流水了。有驚無險。第二天我拿到開好的證明，立刻掃描PDF郵件發給LSHTM，期待他們能馬上給開來 CAS (Confirmation of Acceptance of Studies)。等了一周，還是左等不來右等不來，距離7月31日還剩下不到10天了。終於無法忍耐等待的我，打電話去倫敦詢問我的情況。對方接電話的是個年輕女聲，優雅的倫敦音告訴我，不要着急，先無視學校的提醒滿足條件的郵件吧。我們會儘快看你的檔案。無奈我衹好作罷，挂了電話繼續等待。&lt;/p&gt;
&lt;p&gt;結果第二天晚上就收到了確認函，說你的CAS很快就能發給你了。oh yeah！半夜裏我就收到了發來的新鮮剛出爐的CAS號碼以及新的無條件錄取證明：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/fig/InkedCAS_LI.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/fig/uncon.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我很早以前就在&lt;a href=&#34;https://www.visa4uk.fco.gov.uk/home/welcome&#34;&gt;visa4uk&lt;/a&gt;上註冊好了全部的信息，就等着學校發來 CAS 的文件了。於是我再花了半個小時把 CAS 上的內容填寫到簽證申請的網站上去。在申請的網站上，會中途跳出來讓你支付一年醫療保險的頁面（£150），付完保險費以後會收到自己的保險號碼。估計以後在英國如果需要看病的話報自己的保險號碼就OK了。於是乎我以迅雷不及掩耳之勢立刻預約了7月31日去大阪的簽證申請中心遞交簽證材料。&lt;/p&gt;
&lt;p&gt;等待去辦簽證的過程中，又收到好消息，宿舍抽籤中了。於是我就成了倫敦準市民之一拉。哈哈哈哈。今兒真高興阿，今兒真高興。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/gif/shuang.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我抽中的是&lt;a href=&#34;http://halls.london.ac.uk/international-hall&#34;&gt;International Hall&lt;/a&gt;的單人間。仔細閱讀了條款後發現，每週2百鎊的房租確實有點小貴，但是呢，確是包了早餐晚餐和週末的四餐的。我想這將會大大減輕時間和金錢的成本。畢竟只有一年的留學時間。將就將就吧，每天都是炸魚和薯條估計吃一週就會讓人瘋了誒。。。先做好心理準備。對伙食不應有太高期待。&lt;/p&gt;
&lt;p&gt;萬事具備，&lt;del&gt;只差簽證了。&lt;/del&gt; 於是就到了預約機票的時候，查了半天各種中介的網站，結果都是什麼中轉三四次的，要不就是繞地球一大圈的，才能有價格比較便宜的。索性打電話去日本航空詢問有沒有給留學生準備的往返一年，時間靈活的機票。果然不問不知道，一問嚇一跳阿，電話接線員小哥樂呵呵:-)說，哎呀你這電話打的太是時候了，我們日本航空正好最近上線了歐洲航線的特價機票，而且專門針對你這樣要待三個月以上的客戶。一問價格，我的媽呀，出發行程已定，歸程未定的叫做半靈活機票 (semi-flexi)，日本航空的這個折扣價爲12萬日元。比全日空便宜了一半，比其他的可疑航空減少了飛行時間，還有什麼好說的，果斷就訂了。結果呢，準備付錢了小哥告訴我說，您現在先別付定金，我這裏已經幫你把機票預留好了，您等8月1日以後再上網站上打開訂單支付，因爲8月1日後的燃油稅機場時用費等雜費由於匯率等變化會再便宜一萬日元左右。&lt;strong&gt;W!T!F!&lt;/strong&gt; 感動得熱淚盈眶有沒有，簡直就想穿過電話線去擁抱這位小哥了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/jal.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;這一週簡直了，從前幾個月的無盡等待到讓人懷疑人生，懷疑自己還能不能去英國，瞬間轉到材料全備齊，訂了飛機票，而且還額外中了一個獎學金（日本的財團）。快要樂不攏嘴了。。。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記21</title>
      <link>https://wangcc.me/post/2017-07-07/</link>
      <pubDate>Fri, 07 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-07-07/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;行的基本變形&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;行的基本變形&lt;/h2&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;p&gt;&lt;span id=&#34;thm:line&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 1  (行的基本變形)  &lt;/strong&gt;&lt;/span&gt;對矩陣進行下列操作的過程，被稱爲是行的基本變形（行的基本操作, elementary row operations）。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;給任意一行乘以/除以一個非零的數。&lt;/li&gt;
&lt;li&gt;給任意一行加上/減去另外任意行的倍數。&lt;/li&gt;
&lt;li&gt;將任意兩行的對應元素互換。
&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;練習基本變形&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;練習基本變形：&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;用行的基本變形求矩陣 &lt;span class=&#34;math inline&#34;&gt;\(X=\left(\begin{array}{c} 1&amp;amp; 2&amp;amp; 1\\ 2&amp;amp; 1&amp;amp; 1\\ 1&amp;amp; 1&amp;amp; 2\\ \end{array}\right)\)&lt;/span&gt; 的逆矩陣 &lt;span class=&#34;math inline&#34;&gt;\(X^{-1}\)&lt;/span&gt; &lt;br&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;首先，將矩陣 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 和同次單位矩陣 &lt;span class=&#34;math inline&#34;&gt;\(E_3\)&lt;/span&gt; 的元素寫成如下的左右並列的形式（用點隔開）&lt;span class=&#34;math inline&#34;&gt;\((X, E)\)&lt;/span&gt;。數字 (1) (2) (3) 表示行數：&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left(\begin{array}{c}
1&amp;amp; 2&amp;amp; 1 &amp;amp; \vdots &amp;amp; 1 &amp;amp; 0 &amp;amp; 0\\
2&amp;amp; 1&amp;amp; 1 &amp;amp; \vdots &amp;amp; 0 &amp;amp; 1 &amp;amp; 0\\
1&amp;amp; 1&amp;amp; 2 &amp;amp; \vdots &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\
\end{array}\right) \begin{align}
\left\{
\begin{array}{rr}
(1)\\
(2)\\
(3)
\end{array}
\right.
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;可以變形成爲下面的形式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left(\begin{array}{c}
1&amp;amp; 2&amp;amp; 1 &amp;amp; \vdots &amp;amp; 1 &amp;amp; 0 &amp;amp; 0\\
0&amp;amp; -3&amp;amp; -1 &amp;amp; \vdots &amp;amp; -2 &amp;amp; 1 &amp;amp; 0\\
0&amp;amp; -1&amp;amp; 1 &amp;amp; \vdots &amp;amp; -1 &amp;amp; 0 &amp;amp; 1\\
\end{array}\right) \begin{align}
\left\{
\begin{array}{l}
(1)\\
(2)=(2)-2\times(1)\\
(3)=(3)-(1)
\end{array}
\right.
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;繼續變形成如下的形式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left(\begin{array}{c}
1&amp;amp; 0&amp;amp; 3 &amp;amp; \vdots &amp;amp; -1 &amp;amp; 0 &amp;amp; 2\\
0&amp;amp; -4&amp;amp; 0 &amp;amp; \vdots &amp;amp; -3 &amp;amp; 1 &amp;amp; 1\\
0&amp;amp; 1&amp;amp; -1 &amp;amp; \vdots &amp;amp; 1 &amp;amp; 0 &amp;amp; -1\\
\end{array}\right) \begin{align}
\left\{
\begin{array}{l}
(1)=(1)+2\times(3)\\
(2)=(2)+(3)\\
(3)=-1\times(3)
\end{array}
\right.
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Next:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left(\begin{array}{c}
1&amp;amp; 0&amp;amp; 3 &amp;amp; \vdots &amp;amp; -1 &amp;amp; 0 &amp;amp; 2\\
0&amp;amp; 1&amp;amp; 0 &amp;amp; \vdots &amp;amp; 3/4 &amp;amp; -1/4 &amp;amp; -1/4\\
0&amp;amp; 1&amp;amp; -1 &amp;amp; \vdots &amp;amp; 1 &amp;amp; 0 &amp;amp; -1\\
\end{array}\right) \begin{align}
\left\{
\begin{array}{l}
(1)=(1)\\
(2)=(2)\div(-4)\\
(3)=(3)
\end{array}
\right.
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Next:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left(\begin{array}{c}
1&amp;amp; 0&amp;amp; 3 &amp;amp; \vdots &amp;amp; -1 &amp;amp; 0 &amp;amp; 2\\
0&amp;amp; 1&amp;amp; 0 &amp;amp; \vdots &amp;amp; 3/4 &amp;amp; -1/4 &amp;amp; -1/4\\
0&amp;amp; 0&amp;amp; -1 &amp;amp; \vdots &amp;amp; 1/4 &amp;amp; 1/4 &amp;amp; -3/4\\
\end{array}\right) \begin{align}
\left\{
\begin{array}{l}
(1)=(1)\\
(2)=(2)\\
(3)=(3)-(2)
\end{array}
\right.
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Next:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left(\begin{array}{c}
1&amp;amp; 0&amp;amp; 0 &amp;amp; \vdots &amp;amp; -1/4 &amp;amp; 3/4 &amp;amp; -1/4\\
0&amp;amp; 1&amp;amp; 0 &amp;amp; \vdots &amp;amp; 3/4 &amp;amp; -1/4 &amp;amp; -1/4\\
0&amp;amp; 0&amp;amp; 1 &amp;amp; \vdots &amp;amp; -1/4 &amp;amp; -1/4 &amp;amp; -3/4\\
\end{array}\right) \begin{align}
\left\{
\begin{array}{l}
(1)=(1)+3\times(3)\\
(2)=(2)\\
(3)=-1\times(3)
\end{array}
\right.
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;點 “&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;” 的左側變形成爲單位矩陣時，行變形結束。右側便是所求的逆矩陣 &lt;span class=&#34;math inline&#34;&gt;\(X^{-1}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X^{-1}=\left(\begin{array}{c}
-1/4 &amp;amp; 3/4 &amp;amp; -1/4\\
3/4 &amp;amp; -1/4 &amp;amp; -1/4\\
-1/4 &amp;amp; -1/4 &amp;amp; 3/4\\
\end{array}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;q-如果有行的基本變形請問有沒有列的基本變形-elementary-column-operations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Q: 如果有行的基本變形，請問有沒有列的基本變形 (elementary column operations)？&lt;/h3&gt;
&lt;/div&gt;
&lt;div id=&#34;a-有把行的基本變形中的定義-refthmline-的行改成列既是列的基本變形的定義&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A: 有。把行的基本變形中的定義 (&lt;a href=&#34;#thm:line&#34;&gt;1&lt;/a&gt;) 的行改成列，既是列的基本變形的定義。&lt;/h3&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記20</title>
      <link>https://wangcc.me/post/2017-07-06/</link>
      <pubDate>Thu, 06 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-07-06/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;逆矩陣&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;逆矩陣&lt;/h2&gt;
&lt;div id=&#34;逆矩陣定義&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;逆矩陣定義&lt;/h3&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-1&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 1  &lt;/strong&gt;&lt;/span&gt;如果對於正方形矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;，存在一個&lt;strong&gt;正方形矩陣&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 滿足 &lt;span class=&#34;math inline&#34;&gt;\(AX=XA=E\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(E\)&lt;/span&gt; 爲單位矩陣) 時，這個正方形矩陣 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 被叫做 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的&lt;strong&gt;逆矩陣&lt;/strong&gt;，寫作 &lt;span class=&#34;math inline&#34;&gt;\(A^{-1}\)&lt;/span&gt;。&lt;br&gt;
存在逆矩陣 &lt;span class=&#34;math inline&#34;&gt;\((A^{-1})\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; ，被叫做&lt;strong&gt;正則矩陣&lt;/strong&gt; (regular matrix, nonsingular matrix)。&lt;br&gt;
不存在逆矩陣的 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;，被叫做&lt;strong&gt;奇異矩陣&lt;/strong&gt; (singular matrix)。&lt;br&gt;
滿足 &lt;span class=&#34;math inline&#34;&gt;\(|A|\neq 0\)&lt;/span&gt; 的矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 被叫做正則矩陣。滿足 &lt;span class=&#34;math inline&#34;&gt;\(|A|=0\)&lt;/span&gt; 的矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 被叫做奇異矩陣。&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 爲正則矩陣時，滿足：&lt;span class=&#34;math inline&#34;&gt;\(A^{-1}A=AA^{-1}=E\)&lt;/span&gt; 。&lt;br&gt;
顯然，單位矩陣的逆矩陣也是一個單位矩陣: &lt;br&gt;
&lt;span class=&#34;math display&#34;&gt;\[E^{-1}E=EE^{-1}=E, E^{-1}=E\]&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;逆矩陣的性質&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;逆矩陣的性質&lt;/h3&gt;
&lt;p&gt;對於正則矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A, B\)&lt;/span&gt; 有以下性質：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((AB)^{-1}=B^{-1}A^{-1}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;注意此處矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A，B\)&lt;/span&gt; 的順序對調了。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((A^{-1})^{-1}=A\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((A^{t})^{-1}=(A^{-1})^t\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((\lambda A)^{-1}=\frac{1}{\lambda}A^{-1} (\lambda \ne 0)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;對角矩陣 &lt;span class=&#34;math inline&#34;&gt;\(D_n=diag(a_{11},a_{22},\dotsm,a_{nn})\)&lt;/span&gt; 的逆矩陣寫作： &lt;span class=&#34;math inline&#34;&gt;\(D_n^{-1}=diag(1/a_{11}, 1/a_{22},\dotsm,1/a_{nn})\)&lt;/span&gt;；&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;注意此處的條件爲所有對角成分均非零: &lt;span class=&#34;math inline&#34;&gt;\(a_{11}a_{22}\dotsm a_{nn}\neq 0\)&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;證明&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;證明&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\((AB)(AB)^{-1}=E\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;等式兩邊從左往右乘以 &lt;span class=&#34;math inline&#34;&gt;\(A^{-1}\)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\((A^{-1}A)B(AB)^{-1}=A^{-1}E\\ B(AB)^{-1}=A^{-1}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;等式兩邊從左往右乘以 &lt;span class=&#34;math inline&#34;&gt;\(B^{-1}\)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\((B^{-1}B)(AB)^{-1}=B^{-1}A^{-1}\\ E(AB)^{-1}=B^{-1}A^{-1}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;&lt;a href=&#34;https://winterwang.github.io/post/2017-03-08/&#34;&gt;根據單位矩陣的性質：&lt;/a&gt;&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\therefore (AB)^{-1}=B^{-1}A^{-1}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(E=E^{-1}=(A^{-1}A)^{-1}=A^{-1}(A^{-1})^{-1}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;等式兩邊從左往右乘以 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(AE=AA^{-1}(A^{-1})^{-1}\\ \therefore A=(A^{-1})^{-1}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(E=E^t=(A^{-1}A)^t=A^t(A^{-1})^t\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;等式兩邊從左往右乘以 &lt;span class=&#34;math inline&#34;&gt;\((A^t)^{-1}\)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\((A^t)^{-1}E=(A^t)^{-1}A^t(A^{-1})^t\\ \therefore (A^t)^{-1}=(A^{-1})^t\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>溫度，污染，和電費</title>
      <link>https://wangcc.me/post/2017-06-12/</link>
      <pubDate>Mon, 12 Jun 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-06-12/</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2017-6-12 16:6	用时：23:04
正确率：93%	错词：19个
提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;cranking: 摇动, 起动, 开动&lt;/li&gt;
&lt;li&gt;atmospheric: adj. 大气的，大气层的；有情调的，有魅力的&lt;/li&gt;
&lt;li&gt;thermostat: n. 恒温（调节）器&lt;/li&gt;
&lt;li&gt;hog: n. 猪；贪婪者，象猪般的人 v. （使）拱起&lt;/li&gt;
&lt;li&gt;belch: n. 打嗝；喷吐；喷出物 v. 打嗝；喷出&lt;/li&gt;
&lt;li&gt;offset: n. 抵销，支派，旁支，平版印刷 v. 弥补，抵销&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;或许你已经注意到夏季家里的电费情况，当你开启空调后，电费要比冬季更多些了。这是因为，空调属于耗电大户。而当一整座城市或者地区都调低恒温器的时候，功耗就不得不超过了需求。 这常见于当我们打开最古老的设备或者已经比较脏的发电设备时。这是Tracey Holloway，麦迪逊市Wisconsin 大学的一位研究大气的科学家。 这些古老的发电装备中有些只能依靠燃烧燃油或者煤炭，只在最热的日子里才会开启它们。 利用EPA 的数据， Holloway和她的研究团队对当温度升高时，空气污染物如何反应的问题进行了研究。 他们发现，贯穿美国东部， 温度每升高1摄氏度，发电厂可喷射出140，000吨额外的二氧化碳。而且，整个地区平均，热量每增加一度，污染物硫氧化物和氮氧化物的排放量就上升3.5 了个百分点。 这特别糟糕，因为炎热的夏季是泵出更多污染的最差的日子。 这些炎热的日子， 当美国人开启空调，或者一个州的居民开启空调， 这些日子也是化学反应最激烈的日子 。 每单位空气污染物进入空气很有可能就形成了臭氧。而臭氧本身是一种潜在的空气污染物。该研究已发表在《环境科学与技术》杂志上了。 Holloway说，应对夏季污染高峰的对策或许可以采用一种在炎热的阳光充足的日子里也很充足的能源。 如果我们可以在高峰时间得到 太阳能发电，这或许能抵消炎热的天气中午高峰时段的污染物排放，并且这还是一种避免不得不开启那些用电高峰时候才需要开启的发电厂的好办法。换句话说：为什么不用太阳提供的能量，保持凉爽呢。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>男人的魅力來自女人</title>
      <link>https://wangcc.me/post/2017-05-31/</link>
      <pubDate>Wed, 31 May 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-05-31/</guid>
      <description>&lt;p&gt;昨日說到&lt;a href=&#34;https://winterwang.github.io/post/2017-05-30/&#34;&gt;BBC新聞聽寫在滬江外語學習之死&lt;/a&gt;。於是去跟他們客服詢問了一下。得到如下答覆：
&lt;img src=&#34;https://wangcc.me/img/bbcdownagain.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;好吧，內容優化，就是潔淨咱們的大天朝局域網唄，正準備學習外語的小朋友們怎麼能看到BBC，VOA上面對偉大祖國的描述嘛。曾經一直認爲，學習外語是爲了增進與他國的交流，互通有無，如今卻深刻體會到學習外語的真實作用是瞭解真實的中國，瞭解那個我來自的地方。&lt;/p&gt;
&lt;p&gt;最近&lt;a href=&#34;http://wasai.org/&#34;&gt;新聞酸菜館&lt;/a&gt;也變成了只賣酸菜的館，内容優化那叫一個好！&lt;/p&gt;
&lt;p&gt;今天的聽寫講的是刊登在進化心理學雜誌上的一篇&lt;a href=&#34;https://wangcc.me/files/menwomen.pdf&#34;&gt;論文&lt;/a&gt;。說有伴的男人更受歡迎。科學家認爲女生更青睞有伴的男人，特別是伴侶如果美豔如花魅力四射，即使他們本身長相一般。也許是因爲這些男人如果不能用外表吸引人，那一定是富有內涵，或者是富可敵國的。總之一句話，男人被另一個女人證明了自己的價值，那女性便可省去自己去試錯的時間和精力成本。&lt;/p&gt;
&lt;p&gt;听写于：2017-5-31 11:24	用时：19:27
正确率：93%	错词：14个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;partnered-up: 结为舞伴，有伴的。&lt;/li&gt;
&lt;li&gt;gals: n. 女孩儿们（gal的复数，等于girls）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;据说能否成为有吸引力的男人取决另外一个有吸引力的女人。&lt;/p&gt;
&lt;p&gt;据研究报道，女性看到一个身旁有另外一个具有吸引力的女人的男人时会觉得这个男人更具有吸引力。这是跟据发表在进化心理学杂志上的一个研究得出的结论。&lt;/p&gt;
&lt;p&gt;研究人员招募了两组女性大学生对一些男性的照片进行评分——所有那些单身照开始都被评价为具有一般水平的吸引力。第一组有148名女士，给她们出示的照片里的那些男士们身旁都有一位有吸引力的女士陪伴。 这些大学生们被告知，照片中的那些女人可能是照片中男士的女朋友，前女友，堂/表兄妹或者养女。而这些女大学生们对这些有女朋友陪伴的男士的评价是比那些被告知说他们身旁是前任或者亲属的男士更令人满意。&lt;/p&gt;
&lt;p&gt;第二项研究招募的是97名学生，他们被出示的照片中的男性外貌一般，但身旁都有一位十分有吸引力的被告知是女朋友的女伴。结果这些女学生再次对有女朋友陪伴的男士的评价高于对单身男士的评价。而且，附加描述是这些男士被认为很有可能更聪明，可靠，幽默，富有以及细心。&lt;/p&gt;
&lt;p&gt;研究人员的推论是，女性或许对有同伴的男性的评价都是认为他们具有聪明的特质以及适合匹配高颜值伴侣的品格。&lt;/p&gt;
&lt;p&gt;所以，貌似我们中很多人总是怀疑的事也许还真不假——被验证过的男人最有吸引力。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>遺傳物質的橫向傳遞</title>
      <link>https://wangcc.me/post/2017-05-30/</link>
      <pubDate>Tue, 30 May 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-05-30/</guid>
      <description>&lt;p&gt;今日要祭奠BBC新聞聽寫在滬江外語學習之死。
幾周未見，今日登錄滬江準備聽聽久違的BBC。結果發現節目已經被下架：
&lt;img src=&#34;https://wangcc.me/img/bbcdown.png&#34; alt=&#34;&#34;&gt;
然後我點擊其他訂閱的節目，結果一大半都**“被下架”**。細看過去全是外語新聞類，政治類的節目。現在連外語學習也已經進入了莫談國是的狀態了嗎？ 可憐的孩子們今後還有什麼資源可以學習英語呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/newsdown.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;悲哀。&lt;/p&gt;
&lt;p&gt;連馬里蘭的空氣新鮮不新鮮都已經被上升到乳滑不乳滑了。我等草民還是閉嘴爲上策。親愛的朋友們，你們今天都健身了嗎？&lt;strong&gt;一切都只是剛剛開始。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;听写于：2017-5-30 11:34	用时：19:08
正确率：93%	错词：10个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;beetles: n. 甲壳虫；大槌 v. 用槌打；急忙来回，快速移动；突出；逼近，威胁&lt;/li&gt;
&lt;li&gt;quadruples: adj. 四重的；四倍的 n. 四倍 v. （使）成四倍&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;你能感谢你的父母给你DNA.因为人类通过~youxing~ 有性繁殖分享基因，把基因从父母传到孩子。 这就是众所周知的DNA 的纵向传递。&lt;/p&gt;
&lt;p&gt;现在想象一下如果你可以分享一两个你的ＤＮＡ片段给一个无关的陌生人，就通过握手或者其它偶然的接触——并且这个陌生人就把你的ＤＮＡ片段整合到它们的基因组里去了。无性的。也没有后代。这就是被称为DNA 的水平转移。人类是怎样做到的这件事还不很明确。 但是这确是细菌等单细胞有机物的主要遗传信息活动， 比如说利用这个过程分享它们各自的抵抗抗生素基因。&lt;/p&gt;
&lt;p&gt;现在法国科学家已经发现水平ＤＮＡ转移现象可能比我们认为的在多细胞有机物中存在的还要更常见，也包括——昆虫，在这种情况下。因为通过分析了１９５个昆虫的基因组，它们发现在没有亲缘关系的蝇类与蝴蝶、甲壳虫和黄蜂各物种之间出现的２２００多个水平ＤＮＡ转移现象。&lt;/p&gt;
&lt;p&gt;**总数上，是之前发现的在全部动物、植物和真菌之间出现的水平ＤＮＡ转移现象数目的四倍。**该研究已发表在《国家科学研究进展》杂志上。&lt;/p&gt;
&lt;p&gt;这些遗传物质的转移是如何发现的至今人类还不十分清楚。或许是靠病毒或寄生物，进行的ＤＮＡ传递。但是，无论是什么原因，这件事提示我们，昆虫的进化，至少在分子水平上，或许不只是已知公认的进化历史那么简单。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記19</title>
      <link>https://wangcc.me/post/2017-04-02/</link>
      <pubDate>Sun, 02 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-04-02/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;行列式的性質&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;行列式的性質&lt;/h2&gt;
&lt;p&gt;具體的行列式的值，可以通過以下介紹的行列式性質，儘量簡潔地求解。本節也是爲了簡易示範，僅僅使用3次行列式作例子。4次以上的行列式性質依然相同，依此類推即可。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;轉置矩陣的行列式，與轉置前的行列式一致。即：&lt;span class=&#34;math inline&#34;&gt;\(|A^t|=|A|\)&lt;/span&gt;。 &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(|A|=\begin{vmatrix}  1 &amp;amp; 2 &amp;amp; 3 \\  4 &amp;amp; 5 &amp;amp; 6 \\  7 &amp;amp; 8 &amp;amp; 9 \\ \end{vmatrix}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;任意一列（或者任意一行）若乘以 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 倍，那麼這個矩陣的行列式結果也將是乘以 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 倍。&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(|A|=\begin{vmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ \lambda a_{21} &amp;amp;\lambda a_{22} &amp;amp; \lambda a_{23}\\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\ \end{vmatrix}\\ \;\;\;\;=|A|=\lambda \begin{vmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\ \end{vmatrix}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(|A|=\begin{vmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \lambda a_{13}\\ a_{21} &amp;amp; a_{22} &amp;amp; \lambda a_{23}\\ a_{31} &amp;amp; a_{32} &amp;amp; \lambda a_{33}\\ \end{vmatrix}\\ \;\;\;\;=|A|=\lambda \begin{vmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\ \end{vmatrix}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;任意一列（或者任意一行）的各成分乘以 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 倍，與其他任意一列（或者任意一行）的各成分進行加運算（或者減運算）獲得的矩陣的行列式與原矩陣的行列式相同。&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{vmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{21}\pm \lambda a_{11} &amp;amp; a_{22}\pm \lambda a_{12} &amp;amp; a_{23}\pm \lambda a_{13}\\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\ \end{vmatrix}，\\ \begin{vmatrix} a_{11} &amp;amp; a_{12}\pm \lambda a_{11} &amp;amp; a_{13}\\ a_{21} &amp;amp; a_{22}\pm \lambda a_{21} &amp;amp; a_{23}\\ a_{31} &amp;amp; a_{32}\pm \lambda a_{31} &amp;amp; a_{33}\\ \end{vmatrix},\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{vmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{21} \pm \frac{a_{11}}{\lambda} &amp;amp; a_{22}\pm \frac{a_{12}}{\lambda} &amp;amp; a_{23}\pm \frac{a_{13}}{\lambda}\\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\ \end{vmatrix}, \\ \begin{vmatrix} a_{11} &amp;amp; a_{12}\pm \frac{a_{11}}{\lambda} &amp;amp; a_{13}\\ a_{21} &amp;amp; a_{22}\pm \frac{a_{21}}{\lambda} &amp;amp; a_{23}\\ a_{31} &amp;amp; a_{32}\pm \frac{a_{31}}{\lambda} &amp;amp; a_{33}\\ \end{vmatrix}\)&lt;/span&gt;&lt;br&gt;
上述行列式與行列式 &lt;span class=&#34;math inline&#34;&gt;\(\begin{vmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\ \end{vmatrix}\)&lt;/span&gt; 結果相同。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;符合下列條件時，行列式的值爲 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;任意一行（或者列）的全部成分均爲 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; 時。&lt;/li&gt;
&lt;li&gt;矩陣中若有兩行（或者兩列）的對應成分全部相同時。&lt;/li&gt;
&lt;li&gt;矩陣中若有兩行（或者兩列）的對應成分均成一定比例時。&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{vmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\ 0 &amp;amp; 0 &amp;amp; 0\\ \end{vmatrix}=0\\ \begin{vmatrix} a &amp;amp; b &amp;amp; c\\ a &amp;amp; b &amp;amp; c\\ d &amp;amp; e &amp;amp; f\\ \end{vmatrix}=0\\ \begin{vmatrix} a &amp;amp; b &amp;amp; c\\ ka &amp;amp; kb &amp;amp; kc\\ d &amp;amp; e &amp;amp; f\\ \end{vmatrix}=0\)&lt;/span&gt;&lt;br&gt;
由於上面的後兩條成立，所以當矩陣中任意兩列（或者兩行）的對應成分幾乎相等，或者比值無限接近時，行列式的值也可以說就接近爲 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;。此性質與多重線性迴歸的多重共線性有直接關係。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;一個矩陣中其中兩列（或者兩行）的成分交換以後獲得的矩陣，其行列式值爲原矩陣的行列式的值的相反數。（即符號相反）&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{vmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\ \end{vmatrix}=-\begin{vmatrix} a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\ a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\ \end{vmatrix}\)&lt;/span&gt; （第一行和第二行對調成分）&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;對角矩陣，上三角矩陣，下三角矩陣的行列式的值，等於對角成分的積&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{vmatrix} a_{11} &amp;amp; 0 &amp;amp; 0\\ 0 &amp;amp; a_{22} &amp;amp; 0\\ 0 &amp;amp; 0 &amp;amp; a_{33}\\ \end{vmatrix}=a_{11}a_{22}a_{33},\\ \begin{vmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ 0 &amp;amp; a_{22} &amp;amp; a_{23}\\ 0 &amp;amp; 0 &amp;amp; a_{33}\\ \end{vmatrix}=a_{11}a_{22}a_{33},\\ \begin{vmatrix} a_{11} &amp;amp; 0 &amp;amp; 0\\ a_{21} &amp;amp; a_{22} &amp;amp; 0\\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\ \end{vmatrix}=a_{11}a_{22}a_{33}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;矩陣中如果有任意一行（或列），衹有一個成分為非零成分，可以將該矩陣的行列式降次：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{vmatrix} a_{11} &amp;amp; 0 &amp;amp; 0\\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\ \end{vmatrix}=a_{11}(-1)^{1+1}\begin{vmatrix} a_{22} &amp;amp; a_{23} \\ a_{32} &amp;amp; a_{33} \end{vmatrix}\)&lt;/span&gt; &lt;br&gt;
&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{vmatrix} a_{11} &amp;amp; a_{12} &amp;amp; 0\\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\ a_{31} &amp;amp; a_{32} &amp;amp; 0\\ \end{vmatrix}=a_{23}(-1)^{1+1}\begin{vmatrix} a_{11} &amp;amp; a_{12} \\ a_{31} &amp;amp; a_{32} \end{vmatrix}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A, B\)&lt;/span&gt; 同時都是正方形矩陣時，&lt;span class=&#34;math inline&#34;&gt;\(|AB|=|A|·|B|\)&lt;/span&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;div id=&#34;證明&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;strong&gt;證明&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A=\left(\begin{array}{c} 0 &amp;amp; 4 &amp;amp; 2\\ -1 &amp;amp; 3 &amp;amp; 7\\ 6 &amp;amp; 5 &amp;amp; 9\\  \end{array}\right)\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(B=\left(\begin{array}{c} 2 &amp;amp; 3 &amp;amp; 4\\ -2 &amp;amp; 7 &amp;amp; 1\\ 4 &amp;amp; 6 &amp;amp; 0\\  \end{array}\right)\)&lt;/span&gt; 時， &lt;span class=&#34;math inline&#34;&gt;\(|AB|=|A|·|B|\)&lt;/span&gt; 成立&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;解&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;解&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\because AB=\left(\begin{array}{c}  0 &amp;amp; 40 &amp;amp; 4\\  20 &amp;amp; 60 &amp;amp; -1\\  38 &amp;amp; 107 &amp;amp; 29\\  \end{array}\right)\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\therefore |AB|=\begin{vmatrix}  0 &amp;amp; 40 &amp;amp; 4\\  20 &amp;amp; 60 &amp;amp; -1\\  38 &amp;amp; 107 &amp;amp; 29\\  \end{vmatrix}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;利用性質3： 第2列 - 第3列 &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; 10 作新的第2列&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(=\begin{vmatrix} 0 &amp;amp; 0 &amp;amp; 4\\ 20 &amp;amp; 70 &amp;amp; -1\\ 38 &amp;amp; -183 &amp;amp; 29\\ \end{vmatrix}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;利用性質7： 第一行衹有第三個元素非零，可以降次。&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(=4(-1)^{1+3}\begin{vmatrix}  20 &amp;amp; 70 \\  38 &amp;amp; -183\end{vmatrix}\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;利用性質2: 第一行所有元素除以10, 將 10 提前。&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(=4\times10\begin{vmatrix}  2 &amp;amp; 7 \\  38 &amp;amp; -183\end{vmatrix}\\  =40(-366-266)\\=-25280\)&lt;/span&gt;&lt;br&gt;
&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(|A|=\begin{vmatrix}  0 &amp;amp; 4 &amp;amp; 2\\  -1 &amp;amp; 3 &amp;amp; 7\\  6 &amp;amp; 5 &amp;amp; 9\\  \end{vmatrix}\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;利用性質3: 第2列 - 第3列 &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; 2 作爲新的第二列元素&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(=\begin{vmatrix} 0 &amp;amp; 0 &amp;amp; 2\\ -1 &amp;amp; -11 &amp;amp; 7\\ 6 &amp;amp; -13 &amp;amp; 9\\ \end{vmatrix}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;利用性質7: 第一行衹有第三個元素非零，降次。&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(=2(-1)^{1+3}\begin{vmatrix} -1 &amp;amp; -11 \\ 6 &amp;amp; -13\end{vmatrix}\\=2(13+66)=158\)&lt;/span&gt; &lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(|B|=\begin{vmatrix} 2 &amp;amp; 3 &amp;amp; 4\\ -2 &amp;amp; 7 &amp;amp; 1\\ 4 &amp;amp; 6 &amp;amp; 0\\ \end{vmatrix}\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;利用性質3: 第1行 &lt;span class=&#34;math inline&#34;&gt;\(+\)&lt;/span&gt; 第2行作新的第1行； 第3行 - 第1行 &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; 2 作新的第三行&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(=\begin{vmatrix} 0 &amp;amp; 10 &amp;amp; 5\\ -2 &amp;amp; 7 &amp;amp; 1\\ 0 &amp;amp; 0 &amp;amp; -8\\ \end{vmatrix}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;利用性質7: 第三行衹有第三個元素非零，降次。&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(=-8(-1)^{3+3}\begin{vmatrix} 0 &amp;amp; 10 \\ -2 &amp;amp; 7\end{vmatrix}\\=-8\times20=-160\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;綜上可得&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;綜上可得&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(|A|·|B|=158\times(-160)=-25280=|AB|\)&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;試用這一節介紹的行列式性質求解前一節例3的行列式值&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;試用這一節介紹的行列式性質，求解前一節&lt;a href=&#34;https://winterwang.github.io/post/2017-03-15/&#34;&gt;例(3)&lt;/a&gt;的行列式值。&lt;/h3&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;解-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;解&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{vmatrix}  -2 &amp;amp; 3 &amp;amp;4 &amp;amp; 1\\  4 &amp;amp; 2&amp;amp; 0&amp;amp; 5\\  2 &amp;amp;-3&amp;amp; -4&amp;amp; 2\\  2 &amp;amp; 1&amp;amp; 2&amp;amp; -3 \end{vmatrix}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;利用性質3&lt;br&gt;
1. 第1行 &lt;span class=&#34;math inline&#34;&gt;\(+\)&lt;/span&gt; 第3行，作新的第一行；
2. 第2行 &lt;span class=&#34;math inline&#34;&gt;\(-\)&lt;/span&gt; 第3行 &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; 2，作新的第2行；
3. 第4行 &lt;span class=&#34;math inline&#34;&gt;\(-\)&lt;/span&gt; 第3行 作新的第4行&lt;/span&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(=\begin{vmatrix}  0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 3\\  0 &amp;amp; 8 &amp;amp; 8 &amp;amp; 1\\  2 &amp;amp; -3 &amp;amp; -4 &amp;amp; 2\\  0 &amp;amp; 4 &amp;amp; 6 &amp;amp; -5 \end{vmatrix}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;利用性質7: 第1行衹有第4個元素非零，降次。&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(=3(-1)^{1+4}\begin{vmatrix} 0 &amp;amp; 8 &amp;amp; 8 \\ 2 &amp;amp; -3 &amp;amp; -4 \\ 0 &amp;amp; 4 &amp;amp; 6 \end{vmatrix}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;利用性質7: 第1列衹有第2個元素非零，降次。&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(=-3 \times 2(-1)^{1+2}\begin{vmatrix} 8 &amp;amp; 8 \\ 4 &amp;amp; 6 \end{vmatrix}\\ =6 \times (8 \times 6 - 4\times 8)\\ =96\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>留學筆記</title>
      <link>https://wangcc.me/post/2017-03-16/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-03-16/</guid>
      <description>&lt;h2 id=&#34;尋找並確定合適自己的大學合適的課程&#34;&gt;尋找並確定合適自己的大學，合適的課程&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;英國，還是美國？ 這是一個問題
&lt;ul&gt;
&lt;li&gt;我能獲得現在工作的大學的經費（其實就是保留職位，工資照發）支持的條件是，最長的出差/留學不能超過一年。&lt;/li&gt;
&lt;li&gt;上面這個條件是最硬的了，沒有銀子，啥都辦不成是吧。美國的碩士基本都是兩年，而且每年的學費都是英國的兩倍左右。真是羨慕嫉妒自費去英美讀書的大陸籍學生們，你們都是行走的美金符號 $。&lt;/li&gt;
&lt;li&gt;加上美國目前爲止去了3-4次了，對北美大陸除了加拿大(溫哥華)印象非常好以外，美帝給人的感覺就是一個自由化了的中國大陸。沒有任何親切感，或者吸引我個人再去長久居住的地方。當然去美國的機會以後可能還有。故覺得去正在經歷激盪變幻莫測歷史的英國也是不錯的選擇。脫歐愈演愈烈，不知道英國會不會有什麼波瀾壯闊的變化，如果能碰巧做個見證人，也是不錯的。將來可以跟我兒子說，看當年大英帝國被踢出歐萌的時候，爸爸在那親眼看着呢。&lt;/li&gt;
&lt;li&gt;另外就是大學的選擇了。當然可選擇的大學有很多，奈何我之前跟大學申請這個例外項目的時候說的是倫敦大學。因此什麼劍橋牛津都是浮雲了。還好我沒明確說，其實倫敦大學底下一大堆大學，UCL和LSHTM是我的申請重點。因爲論醫學統計學課程，大家可以參考這篇&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/7754267&#34;&gt;文章&lt;/a&gt;^[Pocock, S. J. Life as an academic medical statistician and how to survive it. Statist. Med. 14, 209–222 (1995).] 。儘管時間有點久遠，但是英國國內大學有開設醫學統計課程的大概就那麼幾個，估計沒什麼太大變化，摘錄Pro. Pocock總結的各家特色如下：&lt;!-- raw HTML omitted --&gt;我們可以看到，從最上面的劍橋大學，到最下面的LSHTM(有人翻譯成倫敦衛校😅)按照教學內容偏重理論還是實際進行了排序。所以，LSHTM最偏重實際應用的名氣，是由來已久的。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Theory&lt;!-- raw HTML omitted --&gt; (偏重理論)&lt;/td&gt;
&lt;td&gt;Cambridge&lt;/td&gt;
&lt;td&gt;Mathematical Statistics&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;Sheffield&lt;/td&gt;
&lt;td&gt;Statistics&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;University College London&lt;/td&gt;
&lt;td&gt;Applied Stochastic Systems&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;Oxford&lt;/td&gt;
&lt;td&gt;Applied Statistics&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;Kent&lt;/td&gt;
&lt;td&gt;Statistics&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;Reading&lt;/td&gt;
&lt;td&gt;Biometry&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;Southampton&lt;/td&gt;
&lt;td&gt;Statistics with Application in Medicine&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$\downdownarrows$&lt;/td&gt;
&lt;td&gt;Leicester&lt;/td&gt;
&lt;td&gt;Medical Statistics &amp;amp; Information Technology&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Applications (偏重實踐)&lt;/td&gt;
&lt;td&gt;London School of Hygiene &amp;amp; Tropical Medicine&lt;/td&gt;
&lt;td&gt;Medical Statitics&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;確認申請時間申請要點雅思成績要求是否有面試推薦信&#34;&gt;確認申請時間，申請要點（雅思成績要求，是否有面試，推薦信）&lt;/h2&gt;
&lt;p&gt;決定了申請 LSHTM 以後，便要開始準備材料，確定截止時間，以及雅思成績的要求等。&lt;/p&gt;
&lt;p&gt;我之前並無申請歐美大學的經驗，許多都是這次申請過程中自己摸索的。總結一下就是，留學申請這種事，自己來就可以搞定了。經過仔細鑽研LSHTM的醫學統計碩士課程&lt;a href=&#34;http://www.lshtm.ac.uk/study/masters/msms.html&#34;&gt;網站&lt;/a&gt;，確認雅思成績要求總分不低於7，聽說讀單項最低不低於5.5，寫作不低於6.5以後，便着手開始集中複習英語的計劃。&lt;/p&gt;
&lt;p&gt;至於申請截止時間，&lt;a href=&#34;http://www.lshtm.ac.uk/study/applications/index.html&#34;&gt;網站&lt;/a&gt;說的8月1日，沃天。。。9月底開學8月還能申請。不過，6月1日以後的申請要交£100的過遲申請費用。不管怎麼說，越早越好。我是2016年10月開始計劃申請的，那時候自己給自己定下目標，1月7日雅思成績如果達標，1月份之內就完成所有申請步驟。&lt;/p&gt;
&lt;p&gt;面試的情況後面會再多說一些，其他課程不太瞭解，醫學統計學的碩士課程是對有可能成爲學生的人進行面試的 (potential students will be invited to join an interview)。所以估計材料交了以後很久都沒有面試的通知的話，那就可以安心在家當作自己沒有申請過，該幹嘛幹嘛了。儘量保持低調嘛。我還跟他們負責招生的人發郵件確認了，材料遞交6周左右會給面試通知。估計不錄取也是在這個時間點給通知的。&lt;/p&gt;
&lt;p&gt;最後一個就是最重要的推薦人的選擇了。我邀請之前博士階段的導師，以及現在的同事。聽說美國大學要三個推薦人。英國是只要兩人的。關於如何選擇推薦人，LSHTM的網站上說的是，如果申請人正在就學，那就需要兩個都是對你的學業/學術十分瞭解的人。如果申請人已經就業，那就填最高學歷時期的導師一名，及現在的同事一名或者老闆/上司。當然，在把自己要寫的推薦人姓名信息等填入申請表格之前，要跟他們打個招呼才是。&lt;/p&gt;
&lt;p&gt;至於推薦信的內容。我的博士導師收到我的邀請郵件以後欣然同意，然而那之後我並沒有收到他給我的個人評價或者推薦信內容/稿件。我想，大概(有些)認真的日本人認爲這個推薦信對申請人本人來說也應該保密的。不過我對我的導師有充分的信任，不至於在推薦信裏寫我不愛讀書行爲不端之類害我的話。他一直都是實事求是認真做事的人。另外一封推薦信來自我的同事，他對自己英文不太有自信，而且他每天就坐在我隔壁，寫了稿子就讓我看，我又請native speaker幫忙校對了以後提交的。所以我對這個第二封推薦信的內容是掌握的。&lt;/p&gt;
&lt;h2 id=&#34;3個月突擊雅思8分&#34;&gt;3個月突擊，雅思8分&lt;/h2&gt;
&lt;p&gt;我以前考過兩次託福。都是裸考。一次是大學期間跟風考的，大夥兒都忙忙碌碌，準備考研啦，準備託福GRE出國拉，所以我也想說考一個，看看這些英語考試都考什麼內容。如果您來我這裏想瞭解託福雅思考試的祕籍，抱歉出門左轉去&lt;a href=&#34;https://www.hujiang.com/&#34;&gt;滬江外語&lt;/a&gt;吧。我每日也都是用的他家的APP和資源（主要是聽寫BBC新聞）。另外推薦一個背單詞的軟件：&lt;a href=&#34;https://www.baicizhan.com/&#34;&gt;百詞斬&lt;/a&gt;。&lt;a href=&#34;https://www.shanbay.com/&#34;&gt;扇貝單詞&lt;/a&gt;也不錯。不過個人還是對百詞斬比較偏愛。也許是先入爲主吧。第一次打開時，設置自己的背誦單詞表（雅思詞彙）然後設定好時間，和背詞計劃。我是設定了每日100個單詞。每天堅持一百個，直到考試前一天。百詞斬的app會再每天第一次打開app的時候提醒，並且複習昨天或者最近背誦過的生詞。感覺他們應該是用了一些算法的，大約是根據個人背誦單詞的記錄（傳說中的記憶曲線？），以及錯誤次數來選出每天複習的詞彙的，這一點百詞斬很厲害。&lt;/p&gt;
&lt;p&gt;除了背單詞，就是尋找合適的老師練習寫作和口語了。在此我就不去給某寶作廣告了。我找了兩個雅思作文老師練習，每天都有寫作的作業，一天 task 1 第二天 task 2 這樣。有的老師只提供作文修改和點評，有的還會給你上課，當然費用就比前一種稍微貴一些。能提供授課服務的老師基本上就是具有新東方，環球雅思等授課經驗的作文老師。作文老師推薦的教材可以在此介紹一下:
&lt;a href=&#34;https://book.douban.com/subject/11596223/&#34;&gt;&lt;img src=&#34;https://wangcc.me/img/ieltswriting.jpg&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;至於口語，某寶上的口語外教中介等類似商品就更多了。基本上應該都是菲律賓的口語老師。一開始我也抱着忐忑的心情預約試聽了以下，擔心菲律賓的口語老師可能會有類似印度人的難懂口音。後來的事實證明自己完全是多慮了。至少在我聽課的那幾位菲律賓的外教的口音都較爲純正。況且每個人的口音（應該）都是天生的/後天跟父母學的，不必擔心自己上了幾天口語可就變成怪怪的阿三口音。另外記得以前看過文章說英語母語者能辨別很多不同的口音，所以關鍵不是口音影響一個人的表達，而是你到底真的會不會表達。而且如果你的有點異國口音的英語常常還會被認爲很有趣，很性感，或者很有特點。個人認爲典型的中國人的口音其實多數情況下不太性感，但是你也可以變得像下面這個人一樣風趣幽默（點擊圖片可以看到他講的中式腔調的英語笑話，老外一樣被逗得一樂一樂的）:
&lt;a href=&#34;https://www.youtube.com/watch?v=JTE0-UY9_T0&#34;&gt;&lt;img src=&#34;https://wangcc.me/img/joewong.jpg&#34; alt=&#34;&#34;&gt;&lt;/a&gt;
於是我的口語課就固定爲每天早晨9點鐘開始一個小時，和老師練習過去口語考過的題目。各種常見/不常見話題的切磋和準備。許多話題是根本想不到的。比如，“請描述一次你參加過的婚禮”，或者“請用英語講一個中國歷史上的有趣的故事”這樣的題目，讓我用中文來講述我還要愣上個1分鐘，更不要說在分秒必爭的口語考試中被問道這樣的題目，基本就等於告訴你回去準備再交錢考試了。&lt;/p&gt;
&lt;p&gt;備考雅思是一段辛苦的過程。堅持每日練習才能保持良好的考試/競技狀態，口語和作文是中國人的短板。聽力和寫作常常有不少人（包括我）可以拿到接近滿分。我一開始備考時也是覺得要把過去劍橋雅思的4-11套&lt;a href=&#34;https://book.douban.com/subject/1479127/&#34;&gt;全真練習題&lt;/a&gt;全部過一邊，題海戰術嘛。後來被寫作的老師敲了警鐘。他說：「聽力和閱讀如果每天都花過多的時間去做的話，對於你來說提高很有限，因爲你都只有錯很少的題目，只是自己刷高分滿足自己的虛榮心而已。到頭來短板的作文和口語都沒有時間練習的話，總分還是上不去。」於是我聽從了寫作老師的話，改爲三四天做一套聽力和閱讀。當然每次都是用考試時的標準來。所以其實一直到了考前，我也沒有把4-11的所有過去試題都練習完。只是挑着做了一些。關於考場的真實感受和我的考分。可以看我之前的&lt;a href=&#34;https://winterwang.github.io/post/2017-01-07-ielts-test/&#34;&gt;文章&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;1個月集中文件準備&#34;&gt;1個月集中，文件準備&lt;/h2&gt;
&lt;p&gt;考完雅思考試以後等待考試成績公佈的這段時間，我便開始着手準備申請所需要的各種文件。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;最近的大學院（就是我的博士課程）成績單，英文版。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;博士學位證書，和名古屋大學的畢業證書的英文版。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1和2由於是要開英文版的，聯繫名古屋大學的留學生辦公室，申請郵寄辦理（無手續費），然後附上回信的信封和郵票就可以了。&lt;/li&gt;
&lt;li&gt;另外，爲了以防萬一，我又拜託之前本科階段上海交大的指導老師幫忙開具了本科階段的學位證書，畢業證書的英文版，以及當年的成績單。（看了當時的成績單，不禁回想當年在上海求學的日子。曾經有段時間，在中國訪問facebook是不需要任何技巧的。那個時候，我們還有google reader，還有google.cn。。。）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;個人簡歷&lt;a href=&#34;https://github.com/winterwang/markdown_cv/raw/master/Rmarkdown/rap-2pg-cv.pdf&#34;&gt;cv&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;查找了許多模板，后来选择了(&lt;a href=&#34;http://svmiller.com/blog/2016/03/svm-r-markdown-cv/&#34;&gt;这一款&lt;/a&gt;)。&lt;code&gt;Fork&lt;/code&gt;过来以后打开&lt;code&gt;Rmd&lt;/code&gt;文件，写上自己的内容，&lt;code&gt;knit&lt;/code&gt;，pdf就生成了。生活从未如此简单与快乐。告别Micro$oft，你会更轻松。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;個人陳述(Personal Statement)寫作，修改，寫作，修改。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;格式依然是用&lt;a href=&#34;https://github.com/rohanarora/SoP&#34;&gt;模板&lt;/a&gt;，然后内容的写作和修改，确实费了一番脑筋和功夫。先是寫了初稿，然後給了曾經上过LSHTM醫學統計課程的日本人前輩看，然後修改，又給寫推薦信的兩位導師看，然後再修改，之後再給曾經在UCL留學的高中同學，以及他認識的 native speaker 看，之後再修改。此後又给目前在UCL任教的曾經的高中同學看。最后又花錢送去潤色和校對一遍，才決定最後作爲申請文書遞交給LSHTM。六個不同的人給的意見自然會有不同，最終還是要自己作決斷和取捨的。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;跟以前的導師，現在的上司請求推薦信&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上面提到個人陳述的時候也說到把稿子給了兩位寫推薦信的導師看。我覺得這一點十分重要。畢竟寫推薦信的導師，他要知道你自己在個人陳述中自我推薦了什麼，才能再在推薦信裏加以強調。深以爲然。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;備齊材料終於可以申請了&#34;&gt;備齊材料，終於可以申請了！&lt;/h2&gt;
&lt;p&gt;上面的各種文件備齊了以後，就是直接在線填寫申請表格了。表格中仍有部分內容需要自己填寫的。在此不再贅述。 按下申請按鈕之後，LSHTM發來確認信。估計是系統自動發送的。之後便是等待兩位推薦人在線遞交推薦信了。兩位推薦人交齊了推薦信，已經是我申請提交之後一個月左右的事了。之後該是進入和文書審查階段。&lt;/p&gt;
&lt;h2 id=&#34;面試來了面試真的來了&#34;&gt;面試來了！面試真的來了！&lt;/h2&gt;
&lt;p&gt;過了兩到三週。課程的聯絡人(Admissions Administrator)發來郵件說安排一下Skype面試的時間。&lt;/p&gt;
&lt;h2 id=&#34;我被錄取了&#34;&gt;我被錄取了！&lt;/h2&gt;
&lt;h2 id=&#34;補交畢業證書的原件&#34;&gt;補交畢業證書的原件&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記18</title>
      <link>https://wangcc.me/post/2017-03-15/</link>
      <pubDate>Wed, 15 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-03-15/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;行列式的定義與計算&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;行列式的定義與計算&lt;/h2&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-1&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 1  (determinant)  &lt;/strong&gt;&lt;/span&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 次正方形矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A= (a_{ij})=\left( \begin{array}{c} a_{11}&amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21}&amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots&amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{n1}&amp;amp; a_{n2} &amp;amp; \cdots &amp;amp; a_{nn} \end{array} \right)\)&lt;/span&gt; 的&lt;strong&gt;行列式(determinant)&lt;/strong&gt;被定義爲是，&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的全部成分 &lt;span class=&#34;math inline&#34;&gt;\(a_{11},a_{12},\cdots,a_{nn}\)&lt;/span&gt; 的函數，這個函數是一個&lt;strong&gt;標量(scalar)&lt;/strong&gt;。
&lt;/div&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;次正方形矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的行列式(&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;次行列式)，被記作：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(|A|, |a_{ij}|, \det(A), \det(a_{ij})， \begin{vmatrix} a_{11}&amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21}&amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots&amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{n1}&amp;amp; a_{n2} &amp;amp; \cdots &amp;amp; a_{nn} \notag \end{vmatrix}\)&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;1次行列式：
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
A=(a_{11}), |A|=a_{11}
(\#eq:determinant1)
\end{equation}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2次行列式：
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
A=\left(
\begin{array}{}
a_{11} &amp;amp; a_{12}\\
a_{21} &amp;amp; a_{22}\\
\end{array}
\right), |A|=a_{11}a_{12}-a_{12}a_{21}
(\#eq:determinant2)
\end{equation}\]&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(n-1\)&lt;/span&gt; 次行列式
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
A_{(n-1)\times(n-1)}, 假設行列式 |A| 有被定義
(\#eq:determinant3)
\end{equation}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 次行列式&lt;br&gt;
假如&lt;a href=&#34;#eq:determinant3&#34;&gt;(&lt;strong&gt;??&lt;/strong&gt;)&lt;/a&gt;成立：&lt;br&gt;
對於：&lt;span class=&#34;math inline&#34;&gt;\(A_{n\times n}=\left( \begin{array}{c} a_{11}&amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21}&amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots&amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{n1}&amp;amp; a_{n2} &amp;amp; \cdots &amp;amp; a_{nn} \end{array} \right)\\ |A|=\begin{vmatrix} a_{11}&amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21}&amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots&amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{n1}&amp;amp; a_{n2} &amp;amp; \cdots &amp;amp; a_{nn} \notag \end{vmatrix}\\ \left\{ \begin{array}{} (4)\;=a_{i1}A_{i1}+a_{i2}A_{i2}+\cdots+a_{ij}A_{ij}+\cdots+a_{in}A_{in}\\ (5)\;=a_{1j}A_{i1}+a_{2j}A_{2j}+\cdots+a_{ij}A_{ij}+\cdots+a_{nj}A_{nj}\\  \end{array} \right.\)&lt;/span&gt;&lt;br&gt;
式子 &lt;span class=&#34;math inline&#34;&gt;\((4)\)&lt;/span&gt; 被稱爲行列式 &lt;span class=&#34;math inline&#34;&gt;\(|A|\)&lt;/span&gt; 的第 &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; 行&lt;strong&gt;展開式(expansion of &lt;span class=&#34;math inline&#34;&gt;\(|A|\)&lt;/span&gt; according to elements of row &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;)&lt;/strong&gt;。同樣的，式子 &lt;span class=&#34;math inline&#34;&gt;\((5)\)&lt;/span&gt; 被稱爲行列式 &lt;span class=&#34;math inline&#34;&gt;\(|A|\)&lt;/span&gt; 的第 &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; 列展開式。&lt;span class=&#34;math inline&#34;&gt;\(|A_{ij}|(i=1,2,\cdots,n;j=1,2,\cdots,n)\)&lt;/span&gt; 被稱爲 成分 &lt;span class=&#34;math inline&#34;&gt;\(a_{ij}\)&lt;/span&gt; 的&lt;strong&gt;餘因子(cofactor)&lt;/strong&gt;，定義如下：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(A_{ij}=(-1)^{i+j}D_{ij}\\ \;\;\;\;=(-1)^{i+j}\begin{vmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1,j-1} &amp;amp; a_{1,j+1} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2,j-1} &amp;amp; a_{2,j+1} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots\\ a_{i-1,1} &amp;amp; a_{i-1,2} &amp;amp; \cdots &amp;amp; a_{i-1,j-1} &amp;amp; a_{i-1,j+1} &amp;amp; \cdots &amp;amp; a_{i-1,n}\\ a_{i+1,1} &amp;amp; a_{i+1,2} &amp;amp; \cdots &amp;amp; a_{i+1,j-1} &amp;amp; a_{i+1,,j+1} &amp;amp; \cdots &amp;amp; a_{i+1,n}\\ \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots\\ a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1,j-1} &amp;amp; a_{1,j+1} &amp;amp; \cdots &amp;amp; a_{1n}\\ \end{vmatrix}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(D_{ij}\)&lt;/span&gt; 正如上面等式最右端所寫，其實是行列式 &lt;span class=&#34;math inline&#34;&gt;\(A_{n\times n}\)&lt;/span&gt; 剔除了第 &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; 行和第 &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; 列的 &lt;span class=&#34;math inline&#34;&gt;\((n-1)\)&lt;/span&gt; 次行列式，又被叫做行列式 &lt;span class=&#34;math inline&#34;&gt;\(A_{n\times n}\)&lt;/span&gt; 的&lt;strong&gt;小行列式(minor)&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;餘因子矩陣&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;餘因子矩陣&lt;/h2&gt;
&lt;p&gt;以 &lt;span class=&#34;math inline&#34;&gt;\(A_{n\times n}\)&lt;/span&gt; 的成分 &lt;span class=&#34;math inline&#34;&gt;\(a_{ij}\)&lt;/span&gt; 的餘因子 &lt;span class=&#34;math inline&#34;&gt;\(A_{ij}\)&lt;/span&gt; 作成分&lt;strong&gt;的矩陣&lt;/strong&gt;&lt;span class=&#34;diff_alert&#34;&gt;的轉置矩陣&lt;/span&gt;作被稱爲 &lt;span class=&#34;math inline&#34;&gt;\(A_{n\times n}\)&lt;/span&gt; 的&lt;strong&gt;餘因子矩陣(adjoint matrix, adjugate matrix)&lt;/strong&gt;。標記爲 &lt;span class=&#34;math inline&#34;&gt;\(adj(A)\)&lt;/span&gt;。也就是說：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(adj(A)=\left( \begin{array}{c} A_{11}&amp;amp; A_{12} &amp;amp; \cdots &amp;amp; A_{1n}\\ A_{21}&amp;amp; A_{22} &amp;amp; \cdots &amp;amp; A_{2n}\\ \vdots&amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ A_{n1}&amp;amp; A_{n2} &amp;amp; \cdots &amp;amp; A_{nn} \end{array} \right)^t=\left( \begin{array}{c} A_{11}&amp;amp; A_{21} &amp;amp; \cdots &amp;amp; A_{n1}\\ A_{12}&amp;amp; A_{22} &amp;amp; \cdots &amp;amp; A_{n2}\\ \vdots&amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ A_{1n}&amp;amp; A_{2n} &amp;amp; \cdots &amp;amp; A_{nn} \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;我們來試着計算行列式：&lt;br&gt;
1. &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; 次行列式&lt;br&gt;
以方程&lt;a href=&#34;#eq:determinant2&#34;&gt;(&lt;strong&gt;??&lt;/strong&gt;)&lt;/a&gt;的定義計算：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{vmatrix}  a_{11} &amp;amp; a_{12}\\  a_{21} &amp;amp; a_{22}\\  \end{vmatrix}=a_{11}a_{22}-a_{12}a_{21}\)&lt;/span&gt;&lt;br&gt;
此公式可以用下列 &lt;strong&gt;示意圖(薩呂法則, Sarrus’ rule)&lt;/strong&gt; 來記憶:
　&lt;img src=&#34;https://wangcc.me/img/sarrus.png&#34; /&gt;&lt;br&gt;
也就是，沿着右下方向將所有成分相乘以後用加號 &lt;span class=&#34;math inline&#34;&gt;\(+\)&lt;/span&gt; 號連接起來，沿着左下的方向的所有成分則相乘以後用減號 &lt;span class=&#34;math inline&#34;&gt;\(-\)&lt;/span&gt; 號連接起來。最後將這兩者相加獲得行列式的值。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;練習： 求 &lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{} 4 &amp;amp; 2\\ 1 &amp;amp; 3\\ \end{array} \right)\)&lt;/span&gt; 的行列式和餘因子矩陣。&lt;/p&gt;
&lt;p&gt;解： &lt;span class=&#34;math inline&#34;&gt;\(|A|=\begin{vmatrix} 4 &amp;amp; 2\\ 1 &amp;amp; 3\\ \end{vmatrix}=4\times3-2\times1=10\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(adj(A)=\left( \begin{array}{} A_{11} &amp;amp; A_{21}\\ A_{12} &amp;amp; A_{22}\\ \end{array} \right)\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\because A_{11}=(-1)^{(1+1)}\times3\\ A_{21}=(-1)^{(2+1)}\times2\\ A_{12}=(-1)^{(1+2)}\times1\\ A_{22}=(-1)^{2+2}\times4\\ \therefore adj(A)=\left( \begin{array}{r} 3 &amp;amp; -2\\ -1 &amp;amp; 4\\ \end{array} \right)\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt; 注意：餘因子&lt;strong&gt;矩陣&lt;/strong&gt;，終究是一個矩陣而非行列式。&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;三次矩陣&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c}  a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\  a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\  a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\ \end{array} \right)\)&lt;/span&gt; 的行列式 &lt;span class=&#34;math inline&#34;&gt;\(|A|\)&lt;/span&gt; 要如何用 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的成分來表示呢？ &lt;br&gt;
我們發現，代入上面第 &lt;span class=&#34;math inline&#34;&gt;\((4)\)&lt;/span&gt; 個式子 &lt;span class=&#34;math inline&#34;&gt;\(n=3\)&lt;/span&gt; 的情況來計算。&lt;br&gt;
在這裏，我們就按照 &lt;span class=&#34;math inline&#34;&gt;\(i=1\)&lt;/span&gt; 的情況來展開。&lt;span class=&#34;diff_alert&#34;&gt; (注意：&lt;span class=&#34;math inline&#34;&gt;\(i=2, i=3\)&lt;/span&gt; 的情況展開，結果也是一樣的。)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
 |A| &amp;amp;= a_{11}A_{11}+a_{12}A_{12}+a_{13}A_{13}\\
     &amp;amp;= a_{11}(-1)^{1+1}D_{11}+a_{12}(-1)^{1+2}D_{12}\\
     &amp;amp;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+a_{13}(-1)^{1+3}D_{13}\\
     &amp;amp;= a_{11}\begin{vmatrix}a_{22} &amp;amp; a_{23}\\ a_{32} &amp;amp; a_{33}\\\end{vmatrix}-a_{12}\begin{vmatrix}a_{21} &amp;amp; a_{23}\\ a_{31} &amp;amp; a_{33}\\\end{vmatrix}\\
     &amp;amp;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+a_{13}\begin{vmatrix}a_{21} &amp;amp; a_{22}\\ a_{31} &amp;amp; a_{32}\\\end{vmatrix}\\
     &amp;amp;= a_{11}(a_{22}a_{23}-a_{23}a_{32})-a_{12}(a_{21}a_{33}-a_{31}a_{23})\\
     &amp;amp;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+a_{13}(a_{21}a_{32}-a_{22}a_{31})\\
     &amp;amp;=a_{11}a_{22}a_{33}+a_{12}a_{23}a_{31}+a_{13}a_{21}a_{32}-a_{11}a_{23}a_{32}\\
     &amp;amp;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;-a_{12}a_{21}a_{33}-a_{13}a_{22}a_{31}
\end{align}\]&lt;/span&gt;&lt;br&gt;
我們也可以利用薩呂法則（下圖）來記住計算過程：&lt;br&gt;
&lt;img src=&#34;https://wangcc.me/img/sarrus33.png&#34; /&gt;&lt;br&gt;
另外，可以得到如下的餘因子：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(A_{11}=\begin{vmatrix}a_{22} &amp;amp; a_{23}\\ a_{32} &amp;amp; a_{33}\\\end{vmatrix}, A_{12}=-\begin{vmatrix}a_{21} &amp;amp; a_{23}\\ a_{31} &amp;amp; a_{33}\\\end{vmatrix}, A_{13}=\begin{vmatrix}a_{21} &amp;amp; a_{22}\\ a_{31} &amp;amp; a_{32}\\\end{vmatrix}\\ A_{21}=-\begin{vmatrix}a_{12} &amp;amp; a_{13}\\ a_{32} &amp;amp; a_{33}\\\end{vmatrix}, A_{22}=\begin{vmatrix}a_{11} &amp;amp; a_{13}\\ a_{31} &amp;amp; a_{33}\\\end{vmatrix}, A_{23}=-\begin{vmatrix}a_{11} &amp;amp; a_{12}\\ a_{31} &amp;amp; a_{32}\\\end{vmatrix}\\ A_{31}=\begin{vmatrix}a_{12} &amp;amp; a_{13}\\ a_{22} &amp;amp; a_{23}\\\end{vmatrix}, A_{32}=-\begin{vmatrix}a_{11} &amp;amp; a_{13}\\ a_{21} &amp;amp; a_{23}\\\end{vmatrix}, A_{33}=\begin{vmatrix}a_{11} &amp;amp; a_{12}\\ a_{21} &amp;amp; a_{22}\\\end{vmatrix}\)&lt;/span&gt;&lt;br&gt;
因此餘因子矩陣爲：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(adj(A)=\left( \begin{array}{c}  A_{11} &amp;amp; A_{12} &amp;amp; A_{13}\\  A_{21} &amp;amp; A_{22} &amp;amp; A_{23}\\  A_{31} &amp;amp; A_{32} &amp;amp; A_{33}\\ \end{array} \right)^t=\left( \begin{array}{c}  A_{11} &amp;amp; A_{21} &amp;amp; A_{23}\\  A_{12} &amp;amp; A_{22} &amp;amp; A_{32}\\  A_{13} &amp;amp; A_{23} &amp;amp; A_{33}\\ \end{array} \right)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;table style=&#34;width:7%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;6%&#34; /&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;練習：試求矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{r} 6 &amp;amp; 1 &amp;amp; -3\\ 3 &amp;amp; 5 &amp;amp; 7\\ 2 &amp;amp; -1 &amp;amp; 3\\ \end{array} \right)\)&lt;/span&gt; 的行列式和餘因子矩陣&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;解： &lt;span class=&#34;math inline&#34;&gt;\(|A|= \begin{vmatrix} 6 &amp;amp; 1 &amp;amp; -3\\ 3 &amp;amp; 5 &amp;amp; 7\\ 2 &amp;amp; -1 &amp;amp; 3\\ \end{vmatrix}\\ \;\;\;\;\:=6\times5\times3+1\times7\times2+(-3)\times3\times(-1)\\ \;\;\;\;\;\:\;\;\;\;\:-\{6\times7\times(-1)+1\times3\times3+(-3)\times5\times2\}\\ \;\;\;\;\:=113-(-63)=176\\ \\ A_{11}=\begin{vmatrix}5 &amp;amp; 7\\ -1 &amp;amp; 3\\\end{vmatrix}=15-(-7)=22\\ A_{12}=\begin{vmatrix}3 &amp;amp; 7\\ 2&amp;amp; 3\\\end{vmatrix}=9-14=-5\\ A_{13}=\begin{vmatrix}3 &amp;amp; 5\\ 2 &amp;amp; -1\\\end{vmatrix}=-3-10=-13\\ A_{21}=\begin{vmatrix}1 &amp;amp; -3\\ -1 &amp;amp; 3\\\end{vmatrix}=3-3=0\\ A_{22}=\begin{vmatrix}6 &amp;amp; -3\\ 2 &amp;amp; 3\\\end{vmatrix}=18-(-6)=24\\ A_{23}=\begin{vmatrix}6 &amp;amp; 1\\ 2 &amp;amp; -1\\\end{vmatrix}=-6-2=-8\\ A_{31}=\begin{vmatrix}1 &amp;amp; -3\\5 &amp;amp; 7\\\end{vmatrix}=7-(-15)=22\\ A_{32}=\begin{vmatrix}6 &amp;amp; -3\\3 &amp;amp; 7\\\end{vmatrix}=42-(-9)=51\\ A_{33}=\begin{vmatrix}6 &amp;amp; 1\\ 3 &amp;amp; 5\\\end{vmatrix}=30-3=27\\ \Longrightarrow adj(A)=\left( \begin{array}{r} 22 &amp;amp; 5 &amp;amp; -13 \\ 0 &amp;amp; 24&amp;amp; -8 \\ 22 &amp;amp; 51&amp;amp; 27 \\ \end{array} \right)^t=\left( \begin{array}{r} 22 &amp;amp; 0 &amp;amp; 22\\ 5 &amp;amp; 24 &amp;amp; 51\\ -13 &amp;amp; -8 &amp;amp; 27\\ \end{array} \right)\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table style=&#34;width:7%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;6%&#34; /&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;練習： 求3次矩陣的固有值時(將來敘述)需要的行列式&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{vmatrix} a-\lambda &amp;amp; b &amp;amp; c\\ d &amp;amp; e-\lambda &amp;amp; f\\ g &amp;amp; h &amp;amp; i-\lambda \end{vmatrix}\)&lt;/span&gt;&lt;br&gt;
展開以後，整理爲關於 &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; 的式子：&lt;br&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;解： &lt;span class=&#34;math inline&#34;&gt;\(\begin{vmatrix} a-\lambda &amp;amp; b &amp;amp; c\\ d &amp;amp; e-\lambda &amp;amp; f\\ g &amp;amp; h &amp;amp; i-\lambda \end{vmatrix}\\ =(a-\lambda)(e-\lambda)(i-\lambda)+bfg+dhc\\ \;\;\;\;\;-\{g(e-\lambda)c+bd(i-\lambda)+(a-\lambda)fh\}\\ =-\lambda^3+(a+e+i)\lambda^2+(bd+cg+fh-ae-ei-ai)\lambda\\ \;\;\;\;\;+(aei+bfg+cdh-afh-bdi-ecg)\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;4次行列式：&lt;br&gt;
試求&lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{}  a_{11}&amp;amp; a_{12}&amp;amp; a_{13}&amp;amp; a_{14}\\  a_{21}&amp;amp; a_{22}&amp;amp; a_{23}&amp;amp; a_{24}\\  a_{31}&amp;amp; a_{32}&amp;amp; a_{33}&amp;amp; a_{34}\\  a_{41}&amp;amp; a_{42}&amp;amp; a_{43}&amp;amp; a_{44} \end{array} \right)\\ \;\;=\left( \begin{array}{r}  -2 &amp;amp; 3 &amp;amp;4 &amp;amp; 1\\  4 &amp;amp; 2&amp;amp; 0&amp;amp; 5\\  2 &amp;amp;-3&amp;amp; -4&amp;amp; 2\\  2 &amp;amp; 1&amp;amp; 2&amp;amp; -3 \end{array} \right)\)&lt;/span&gt; &lt;br&gt;的行列式 &lt;span class=&#34;math inline&#34;&gt;\(|A|\)&lt;/span&gt;：&lt;br&gt;
由於第2行有成分 &lt;span class=&#34;math inline&#34;&gt;\(a_{23}=0\)&lt;/span&gt; 我們以第二行展開行列式，因爲 &lt;span class=&#34;math inline&#34;&gt;\(a_{23}=0\)&lt;/span&gt;，所以 &lt;span class=&#34;math inline&#34;&gt;\(a_{23}A_{23}=0\)&lt;/span&gt; 可以省略：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(|A|=a_{21}A_{21}+a_{22}A_{22}+a_{24}A_{24}\\ \;\;\;\;\:=a_{21}(-1)^{2+1}D_{21}+a_{22}(-1)^{2+2}D_{22}+a_{24}(-1)^{2+4}D_{24}\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\because A_{21}=(-1)^{2+1}\begin{vmatrix}  a_{12} &amp;amp; a_{13} &amp;amp; a_{14}\\  a_{32} &amp;amp; a_{33} &amp;amp; a_{34}\\  a_{42} &amp;amp; a_{43} &amp;amp; a_{44}\\ \end{vmatrix}\\ \;\;\;\;\;\;\;\;\;=-\begin{vmatrix}  3 &amp;amp; 4 &amp;amp; 1\\  -3 &amp;amp; -4 &amp;amp; 2\\  1 &amp;amp; 2&amp;amp; -3\\ \end{vmatrix}=6\\ A_{22}=(-1)^{2+2}\begin{vmatrix}  a_{11} &amp;amp; a_{13} &amp;amp; a_{14}\\  a_{31} &amp;amp; a_{33} &amp;amp; a_{34}\\  a_{41} &amp;amp; a_{43} &amp;amp; a_{44}\\ \end{vmatrix}\\ \;\;\;\;\;\;\;\;\;=\begin{vmatrix}  -2 &amp;amp; 4 &amp;amp;1\\  2 &amp;amp; -4 &amp;amp;2\\  2 &amp;amp; 2 &amp;amp;-3\\ \end{vmatrix}=36\\ A_{24}=(-1)^{2+4}\begin{vmatrix}  a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\  a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\  a_{41} &amp;amp; a_{42} &amp;amp; a_{43}\\ \end{vmatrix}\\ \;\;\;\;\;\;\;\;\;=-\begin{vmatrix}  -2 &amp;amp; 3 &amp;amp;4\\  2 &amp;amp; -3 &amp;amp;-4\\  2 &amp;amp; 1 &amp;amp;2\\ \end{vmatrix}=0\\ \therefore |A|=4\times6+2\times36+5\times0=96\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;然而，&lt;strong&gt;4次以上的矩陣的行列式計算，沒有類似薩呂法則的計算方法。&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>绝知此事要躬行</title>
      <link>https://wangcc.me/post/dictation2017-03-13/</link>
      <pubDate>Tue, 14 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/dictation2017-03-13/</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2017-3-13 18:20	用时：24:46
正确率：94%	错词：14个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;speculation &lt;code&gt;[,spekjʊ&#39;leɪʃn]: n. 推测；eg:Every induction is a speculation. 所有归纳推理都是一种猜测。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;florid &lt;code&gt;[&#39;flɒrɪd] adj. 绚丽的 eg: The senator gave a florid speech.议员作了一番词藻华美的演说。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;dune &lt;code&gt;[djuːn] n. （由风吹积而成的）沙丘 eg: Large dunes make access to the beach difficult in places. 在有些地方大沙丘使得靠近海滩很难。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;上个世纪初期，对于火星上存在生命这样的猜测有点言过其词，尤其是美国天文学家帕西瓦尔·罗威尔的猜测。通过他在亚利桑那州的望远镜，他确信自己看到了植物随着季节的变化而变化。显然，他并没有看到什么植物。他真正看到的其实是随风移动的沙丘。但是他相信自己找到了火星上存在先进文明的证据。&lt;/p&gt;
&lt;p&gt;“火星上有不同长度的运河。有些绵延2500英里。我们把这看作是火星世界里存在某种智慧生命才有的结果。”&lt;/p&gt;
&lt;p&gt;罗威尔所说的运河只不过是视觉幻影，因为望远镜里的影像并不完整，还有他的过度兴奋导致了空想。&lt;/p&gt;
&lt;p&gt;在20世纪60年代到70年代，当第一批太空探测器着陆火星，对于火星能否适合生存我们有了更好的了解。它的大气层很薄，因此几乎不能屏蔽来自太空的辐射。它的地表没有水，是一片荒漠，更不要说有运河了。&lt;/p&gt;
&lt;p&gt;但是有证据显示在遥远的过去，火星上有过水的存在，有过大量水的流动，也许这些水还以冰的形式存在地下。所以甚至在1972年，像NASA的杰拉德索芬这样的科学家们都认为如今在火星表面还有相当奇特的生命体存在的可能。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記17</title>
      <link>https://wangcc.me/post/2017-03-13/</link>
      <pubDate>Mon, 13 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-03-13/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;正定半正定-正值半正值&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;正定，半正定 (正值，半正值)&lt;/h2&gt;
&lt;p&gt;對於任意的非零向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}(\neq\underline{0})\)&lt;/span&gt; ，如果2次型 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x}\)&lt;/span&gt; 始終滿足 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x} &amp;gt; 0\)&lt;/span&gt; &lt;strong&gt;注意此處無等號&lt;/strong&gt;。我們稱這個2次型爲&lt;strong&gt;正定(positive definite)&lt;/strong&gt;，&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;爲&lt;strong&gt;正定矩陣(positive definite matrix)&lt;/strong&gt;。另外，如果任意非零向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}(\neq\underline{0})\)&lt;/span&gt; 始終滿足2次型 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x} \geqslant 0\)&lt;/span&gt;， 這個2次型被叫做&lt;strong&gt;半正定(positive semi-definite)&lt;/strong&gt;，&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;爲&lt;strong&gt;半正定矩陣(positive semi-definite matrix)&lt;/strong&gt;。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(x=\left( \begin{array}{} x_1\\ x_2\\ x_3 \end{array} \right), \ A=\left( \begin{array}{} 5 &amp;amp; 2 &amp;amp; 4\\ 2 &amp;amp; 2 &amp;amp; 3\\ 4 &amp;amp; 3 &amp;amp; 25 \end{array} \right)\)&lt;/span&gt;，2次型 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x}\)&lt;/span&gt; 是正定。因爲：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x}=5x_1^2+2x_2^2+25x_3^2\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+4x_1x_2+8x_1x_3+6x_2x_3\\\;\;\;\;\;\;\;\;\;\:=(2x_1+x_2)^2+(x_2+3x_3)^2+(x_1+4x_3)^2\\ \because \underline{x}\neq\underline{0}=\left( \begin{array}{} 0\\ 0\\ 0 \end{array} \right)\\ \therefore \underline{x}^tA\underline{x}&amp;gt;0\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(x=\left( \begin{array}{} x_1\\ x_2\\ x_3 \end{array} \right), \ A=\left( \begin{array}{} 5 &amp;amp; -6 &amp;amp; 3\\ -6 &amp;amp; 25 &amp;amp; 32\\ 3 &amp;amp; 32 &amp;amp; 73 \end{array} \right)\)&lt;/span&gt;，2次型 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x}\)&lt;/span&gt; 是半正定。因爲：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x}=5x_1^2+25x_2^2+73x_3^2\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;-12x_1x_2+6x_2x_3+64x_1x_3\\ \;\;\;\;\;\;\;\;\;\:=(2x_1-3x_3)^2+(x_1+3x_3)^2+(4x_2+8x_3)^2\\\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\because \underline{x}=\left( \begin{array}{c} 3\\ 2\\ -1 \end{array} \right)\)&lt;/span&gt; 時 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x}=0\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\therefore \underline{x}^tA\underline{x} \geqslant0\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}=\left( \begin{array}{c} x_1\\ x_2\\ \vdots\\ x_n \end{array} \right)(\neq\underline{0})\)&lt;/span&gt; 與單位矩陣 &lt;span class=&#34;math inline&#34;&gt;\(E_n\)&lt;/span&gt; 構成的2次型 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tE_n\underline{x}=\underline{x}^t\underline{x}=\sum\limits_{i=1}^nx_i^2&amp;gt;0\)&lt;/span&gt; 是爲正定。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}=\left( \begin{array}{c} x_1\\ x_2\\ \vdots\\ x_n \end{array} \right), \underline{\frac{1}{n}}=\left( \begin{array}{c} \frac{1}{n}\\ \frac{1}{n}\\ \vdots \\ \frac{1}{n} \end{array} \right)\)&lt;/span&gt; 已知，&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\underline{1/n}=\sum\limits_{i=1}^nx_i\cdot \frac{1}{n}=\bar{x}\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 的平均值)，包含了 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個 &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; 的橫向量： &lt;span class=&#34;math inline&#34;&gt;\((\bar{x}，\bar{x},\cdots,\bar{x})\)&lt;/span&gt; 展開以後成爲：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\((\bar{x}，\bar{x},\cdots,\bar{x})\\ \;\;\;\;\;\;\;\;\;\:=(x_1, x_2, \cdots, x_n)\left( \begin{array}{c} \frac{1}{n} &amp;amp; \frac{1}{n} &amp;amp; \cdots &amp;amp; \frac{1}{n}\\ \frac{1}{n} &amp;amp; \frac{1}{n} &amp;amp; \cdots &amp;amp; \frac{1}{n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ \frac{1}{n} &amp;amp; \frac{1}{n} &amp;amp; \cdots &amp;amp; \frac{1}{n} \end{array} \right)\\ \;\;\;\;\;\;\;\;\;\:=\underline{x}U\)&lt;/span&gt;&lt;br&gt;
令 &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; 代表上面第二個等式中有半部分的矩陣。那麼將之從右往左乘以 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 我們可以得到：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tU\underline{x}=(\bar{x},\bar{x},\cdots,\bar{x})\underline{x}=(\bar{x},\bar{x},\cdots,\bar{x})\left( \begin{array}{c} x_1\\ x_2\\ \vdots\\ x_n \end{array} \right)\\ =\sum\limits_{i=1}^n\bar{x}x_i=\bar{x}\sum\limits_{i=1}^nx_i=n\bar{x}^2\)&lt;/span&gt;&lt;br&gt;
利用上面的式子，我們可以得到，&lt;strong&gt;偏差平方和(sum of squared deviation, SS)&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(E_n\)&lt;/span&gt; 爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 次單位矩陣。&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(SS=\sum\limits_{i=1}^n(x_i-\bar{x})^2\\ \;\;\;\;\:=\sum\limits_{i=1}^n(x_i^2-2x_i\bar{x}+\bar{x}^2)\\ \;\;\;\;\:=\sum\limits_{i=1}^nx_i^2-2\bar{x}\sum\limits_{i=1}^nx_i+n\bar{x}^2\\ \;\;\;\;\:=\sum\limits_{i=1}^nx_i^2-2n\bar{x}^2+n\bar{x}^2\\ \;\;\;\;\:=\sum\limits_{i=1}^nx_i^2-n\bar{x}^2\\ \;\;\;\;\:=\sum\limits_{i=1}^nx_i^2-\underline{x}^tU\underline{x}\\ \;\;\;\;\:=\underline{x}^t\underline{x}-\underline{x}^tU\underline{x}\\ \;\;\;\;\:=\underline{x}^tE_n\underline{x}-\underline{x}^tU\underline{x}\\ \;\;\;\;\:=\underline{x}^t(E_n-U)\underline{x}\\ \because when \underline{x}=\left( \begin{array}{c} x_1\\ x_2\\ \vdots\\ x_n \end{array} \right)=\left( \begin{array}{c} \bar{x}\\ \bar{x}\\ \vdots\\ \bar{x} \end{array} \right), \&amp;amp; (\bar{x}\neq0), SS=0\\ \therefore \underline{x}^t(E_n-U)\underline{x}\;是半正定2次型。\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;雙一次型&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;雙一次型&lt;/h2&gt;
&lt;p&gt;對於 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}=\left( \begin{array}{c} x_1\\ x_2\\ \vdots\\ x_m \end{array} \right), A=\left( \begin{array}{c} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots\\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn} \end{array} \right), \underline{y}=\left( \begin{array}{c} y_1\\ y_2\\ \vdots\\ y_n \end{array} \right)\)&lt;/span&gt; 來說，&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{y}=\sum\limits_{i=1}^m\sum\limits_{j=1}^na_{ij}x_iy_j\)&lt;/span&gt; 既是 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 的1次型，也是 &lt;span class=&#34;math inline&#34;&gt;\(\underline{y}\)&lt;/span&gt; 的1次型，所以又叫做 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\underline{y}\)&lt;/span&gt; 的&lt;strong&gt;雙1次型(bilinear form)&lt;/strong&gt;。雙1次型是一個標量(scalar)。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;對於 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}=\left( \begin{array}{c} x_1\\ x_2\\ x_3 \end{array} \right), B=(b_{ij})=\left( \begin{array}{c} 1 &amp;amp; 0 &amp;amp; 0\\ 0 &amp;amp; 1 &amp;amp; 1\\ 1 &amp;amp; 0 &amp;amp; 1 \end{array} \right), \underline{y}=\left( \begin{array}{c} y_1\\ y_2\\ y_3 \end{array} \right)\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tB\underline{y}=\sum\limits_{i=1}^3\sum\limits_{j=1}^3b_{ij}x_iy_j=(x_1+x_3, x_2, x_2+x_3)\left( \begin{array}{c} y_1\\ y_2\\ y_3 \end{array} \right)\\ \;\;\;\;\:=x_1y_1+x_2y_2+x_2y_3+x_3y_1+x_3y_3\\ \;\;\;\;\:=x_1y_1+x_2(y_2+y_3)+x_3(y_1+y_3) \; \bf (\underline{x} 的1次型)\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\;\;\;\;\;\:=y_1(x_1+x_3)+x_2y_2+(x_2+x_3)y_3 \;\bf (\underline{y} 的1次型)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;對於 &lt;span class=&#34;math inline&#34;&gt;\(\underline{l}=\left( \begin{array}{c} l_1\\ l_2\\ \end{array} \right), T=\left( \begin{array}{c} t_{11} &amp;amp; t_{12} &amp;amp; t_{13}\\ t_{21} &amp;amp; t_{22} &amp;amp; t_{23}\\ \end{array} \right), \underline{m}=\left( \begin{array}{c} m_1\\ m_2\\ m_3 \end{array} \right)\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{l}^tT\underline{m}=\sum\limits_{i=1}^2\sum\limits_{j=1}^3t_{ij}l_im_j\\ \;\;\;\;\;\;\;\;\;\;=l_1t_{11}m_1+l_1t_{12}m_2+l_1t_{13}m_3\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+l_2t_{21}m_1+l_2t_{22}m_2+l_3t_{23}m_3\\ \;\;\;\;\;\;\;\;\;\;=l_1(t_{11}m_1+t_{12}m_2+t_{13}m_3)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+l_2(t_{21}m_1+t_{22}m_2+t_{23}m_3) \;\;(\underline{l} \textbf{的1次型})\\ \;\;\;\;\;\;\;\;\;\;=(t_{11}l_1+t_{21}l_2)m_1+(t_{12}l_1+t_{22}l_2)m_2\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+(t_{13}l_1+t_{23}l_2)m_3\;\;(\underline{m} \textbf{的1次型})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記16</title>
      <link>https://wangcc.me/post/2017-03-11/</link>
      <pubDate>Sat, 11 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-03-11/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;二次型形式&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;二次型(形式)&lt;/h2&gt;
&lt;p&gt;對於 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}=\left( \begin{array}{c} x_{1}\\ x_{2}\\ \vdots\\ x_{n} \end{array} \right), A=\left( \begin{array}{c} a_{11}&amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21}&amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots&amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots\\ a_{n1}&amp;amp; a_{n2} &amp;amp; \cdots &amp;amp; a_{nn} \end{array} \right)\)&lt;/span&gt; 那麼：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x}=\sum\limits_{i=1}^n\sum\limits_{j=1}^na_{ij}x_ix_j\\ \;\;\;\;\;\;\;\;\:\:=\sum\limits_{i=1}^na_{ii}x_i^2+\mathop{\sum\limits^n\sum\limits^n}_{i \neq j}a_{ij}x_ix_j\\ \;\;\;\;\;\;\;\;\:\:=\sum\limits_{i=1}^na_{ii}x_i^2+\mathop{\sum\limits^n\sum\limits^n}_{i\ &amp;lt;\ j}(a_{ij}+a_{ji})x_ix_j\)&lt;/span&gt;&lt;br&gt;
被稱爲 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 的同次2次式。又被叫做關於 &lt;span class=&#34;math inline&#34;&gt;\(x_1,x_2,\cdots,x_n\)&lt;/span&gt; 的&lt;strong&gt;2次型(quadratic form)&lt;/strong&gt;。特別的，當 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 爲對稱矩陣時的2次型：&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x}=\sum\limits_{i=1}^na_{ii}x_i^2+2\mathop{\sum\limits^n\sum\limits^n}_{i\ &amp;lt;\ j}a_{ij}x_ix_j\)&lt;/span&gt; 在多元變量分析中十分重要。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(x=\left( \begin{array}{} x_1\\ x_2 \end{array} \right),\ A=\left( \begin{array}{} a_{11} &amp;amp; a_{12}\\ a_{12} &amp;amp; a_{22} \end{array} \right)\)&lt;/span&gt;, 那麼： &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x}=a_{11}x_1^2+a_{22}x_2^2+2a_{12}x_1x_2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(x=\left( \begin{array}{} x_1\\ x_2\\ x_3 \end{array} \right),\ A=\left( \begin{array}{} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{12} &amp;amp; a_{22} &amp;amp; a_{23}\\ a_{13} &amp;amp; a_{23} &amp;amp; a_{33} \end{array} \right)\)&lt;/span&gt;，那麼： &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x}=a_{11}x_1^2+a_{22}x_2^2+a_{33}x_3^2+2a_{12}x_1x_2\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+2a_{13}x_1x_3+2a_{23}x_2x_3\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(x=\left( \begin{array}{} x_1\\ x_2\\ x_3 \end{array} \right), \ A=\left( \begin{array}{} 3 &amp;amp; 2 &amp;amp; 4\\ 6 &amp;amp; 5 &amp;amp; 1\\ -2 &amp;amp; 5 &amp;amp; 8 \end{array} \right)非對稱矩陣\)&lt;/span&gt;，那麼：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x}=3x_1^2+5x_2^2+8x_3^2\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+2x_1x_2+4x_1x_3+6x_2x_1\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+x_2x_3-2x_3x_1+5x_3x_2\\ \;\;\;\;\;\;\;\;\;\:=3x_1^2+5x_2^2+8x_3^2\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+(2+6)x_1x_2+(4-2)x_1x_3\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+(5+1)x_2x_3\\ \;\;\;\;\;\;\;\;\;\:=3x_1^2+5x_2^2+8x_3^2\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+8x_1x_2+2x_1x_3+6z_2x_3\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;有式子 &lt;span class=&#34;math inline&#34;&gt;\(3x_1^2-5x_2^2+7x_3^2+8x_1x_2+4x_1x_3-12x_2x_3\)&lt;/span&gt; 如果要將它改寫成 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^tA\underline{x}\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;是對稱矩陣) 的話，試求 &lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{22} &amp;amp; a_{22} &amp;amp; a_{23}\\ a_{33} &amp;amp; a_{32} &amp;amp; a_{33} \end{array} \right)=\left( \begin{array}{} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{12} &amp;amp; a_{22} &amp;amp; a_{23}\\ a_{13} &amp;amp; a_{23} &amp;amp; a_{33} \end{array} \right)\)&lt;/span&gt; 的各個成分。&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的對角成分：&lt;span class=&#34;math inline&#34;&gt;\(a_{11},a_{22},a_{33}\)&lt;/span&gt; 分別是 &lt;span class=&#34;math inline&#34;&gt;\(x_1^2,x_2^2,x_3^2\)&lt;/span&gt; 的系數： &lt;span class=&#34;math inline&#34;&gt;\(3,-5,7\)&lt;/span&gt;。非對角成分 &lt;span class=&#34;math inline&#34;&gt;\(a_{12}(=a_{21})\)&lt;/span&gt; 等於 &lt;span class=&#34;math inline&#34;&gt;\(x_1x_2\)&lt;/span&gt; 系數的一半：&lt;span class=&#34;math inline&#34;&gt;\(4\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(a_{13}(=a_{31})\)&lt;/span&gt; 等於 &lt;span class=&#34;math inline&#34;&gt;\(x_1x_3\)&lt;/span&gt; 系數的一半:&lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt;,
&lt;span class=&#34;math inline&#34;&gt;\(a_23(=a_{32})\)&lt;/span&gt; 等於 &lt;span class=&#34;math inline&#34;&gt;\(x_2x_3\)&lt;/span&gt; 系數的一半：&lt;span class=&#34;math inline&#34;&gt;\(-6\)&lt;/span&gt;。&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\therefore A=\left( \begin{array}{} 3 &amp;amp; 4 &amp;amp; 2\\ 4 &amp;amp; -5 &amp;amp; -6\\ 2 &amp;amp; -6 &amp;amp; 7 \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記15</title>
      <link>https://wangcc.me/post/2017-03-08/</link>
      <pubDate>Wed, 08 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-03-08/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;單位矩陣&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;單位矩陣&lt;/h2&gt;
&lt;p&gt;對角成分全部都是 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (此時我們假定有 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個)，的對角矩陣被叫做&lt;strong&gt;單位矩陣(identity matrix, unit matrix)&lt;/strong&gt;。寫作：
&lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \ddots &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 &amp;amp; 1 \end{array} \right)=E_n=I_n\)&lt;/span&gt; 下標 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 常被省略。一般的，將 &lt;span class=&#34;math inline&#34;&gt;\(E_n\)&lt;/span&gt; 從左往右乘以 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 次正方形矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;，的結果和從右往左相乘的結果是相等的： &lt;span class=&#34;math inline&#34;&gt;\(E_nA=AE_n=A\)&lt;/span&gt;。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;單位矩陣 &lt;span class=&#34;math inline&#34;&gt;\(E=\left( \begin{array}{c} 1 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 \\ \end{array} \right)\)&lt;/span&gt; 和矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} a_1 &amp;amp; a_2 &amp;amp; a_3 \\ b_1 &amp;amp; b_2 &amp;amp; b_3 \\ c_1 &amp;amp; c_2 &amp;amp; c_3 \\ \end{array} \right)\)&lt;/span&gt; 的積爲：&lt;span class=&#34;math inline&#34;&gt;\(EA=\left( \begin{array}{c} a_1 &amp;amp; a_2 &amp;amp; a_3 \\ b_1 &amp;amp; b_2 &amp;amp; b_3 \\ c_1 &amp;amp; c_2 &amp;amp; c_3 \\ \end{array} \right)=AE=A\)&lt;/span&gt;，矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的&lt;strong&gt;所有成分均不變。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(E_nE_n=E_n\)&lt;/span&gt;。像這樣，自己與自己相乘，結果等於自己的矩陣，被叫做&lt;strong&gt;冪等矩陣(idempotent matrix, 冪等行列「べきとうぎょうれつ」)&lt;/strong&gt;。即，&lt;span class=&#34;math inline&#34;&gt;\(HH(=H^2)=H\)&lt;/span&gt; 成立時，&lt;span class=&#34;math inline&#34;&gt;\(H\)&lt;/span&gt; 是冪等矩陣。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}=E\underline{x}, \lambda\underline{x}=\lambda E\underline{x}\)&lt;/span&gt; 此等式會在後面&lt;strong&gt;特徵值(eigenvalue, 固有値問題)&lt;/strong&gt;時使用。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://winterwang.github.io/post/2017-03-01/&#34;&gt;前一個小節&lt;/a&gt;中的對角矩陣(diagonal matrix) &lt;span class=&#34;math inline&#34;&gt;\(D^{\frac{1}{2}}\)&lt;/span&gt; 則具有這樣的性質： &lt;span class=&#34;math inline&#34;&gt;\(D^{\frac{1}{2}}D^{-\frac{1}{2}}=D^{-\frac{1}{2}}D^{\frac{1}{2}}=E_n\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;逆矩陣-inverse-matrix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;逆矩陣 inverse matrix&lt;/h2&gt;
&lt;p&gt;如果正方形矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 存在另一個正放心矩陣 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 使得他們滿足 &lt;span class=&#34;math inline&#34;&gt;\(AX=XA=E\)&lt;/span&gt;，即乘積爲一個單位矩陣，那麼我們說 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的&lt;strong&gt;逆矩陣(inverse matrix)&lt;/strong&gt;，寫作：&lt;span class=&#34;math inline&#34;&gt;\(A^{-1}\)&lt;/span&gt;。可以將上面的連等式改成：&lt;span class=&#34;math inline&#34;&gt;\(AA^{-1}=A^{-1}A=E\)&lt;/span&gt;。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;如果矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} a &amp;amp; b \\ c &amp;amp; d \\ \end{array} \right)\)&lt;/span&gt; 的成分滿足： &lt;span class=&#34;math inline&#34;&gt;\(ad -bc \neq 0\)&lt;/span&gt;，那麼有 &lt;span class=&#34;math inline&#34;&gt;\(A^{-1}=\frac{1}{ad-bc}\left( \begin{array}{c} d &amp;amp; -b \\ -c &amp;amp; a \\ \end{array} \right)\)&lt;/span&gt;。&lt;strong&gt;如果， &lt;span class=&#34;math inline&#34;&gt;\(ad-bc=0\)&lt;/span&gt; 那麼我們認爲 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的逆矩陣不存在。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;矩陣 &lt;span class=&#34;math inline&#34;&gt;\(P=\left( \begin{array}{c} \cos \theta &amp;amp; -\sin \theta \\ \sin \theta &amp;amp; \cos \theta \\ \end{array} \right)\)&lt;/span&gt; 的逆矩陣 &lt;span class=&#34;math inline&#34;&gt;\(P^{-1}=\left( \begin{array}{c} \cos \theta &amp;amp; \sin \theta \\ -\sin \theta &amp;amp; \cos \theta \\ \end{array} \right)\)&lt;/span&gt; &lt;span class=&#34;diff_alert&#34;&gt;注意此處出現了逆矩陣的逆矩陣爲元矩陣的例子。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;對稱矩陣(symmetric matrix)&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} 1 &amp;amp; 2 &amp;amp; 3 \\ 2 &amp;amp; 4 &amp;amp; 5 \\ 3 &amp;amp; 5 &amp;amp; 6 \\ \end{array} \right)\)&lt;/span&gt; 的逆矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A^{-1}=\left( \begin{array}{c} 1 &amp;amp; -3 &amp;amp; 2 \\ -3 &amp;amp; 3 &amp;amp; -1 \\ 2 &amp;amp; -1 &amp;amp; 0 \\ \end{array} \right)\)&lt;/span&gt; &lt;span class=&#34;diff_alert&#34;&gt;注意此處出現了對稱矩陣的逆矩陣還是對稱矩陣的例子。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} -11 &amp;amp; 2 &amp;amp; 2 \\ -4 &amp;amp; 0 &amp;amp; 1 \\ 6 &amp;amp; -1 &amp;amp; -1 \\ \end{array} \right)\)&lt;/span&gt; 的逆矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A^{-1}=\left( \begin{array}{c} 1 &amp;amp; 0 &amp;amp; 2 \\ 2 &amp;amp; -1 &amp;amp; 3 \\ 4 &amp;amp; 1 &amp;amp; 8 \\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;正交矩陣-orthogonal-matrix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;正交矩陣 orthogonal matrix&lt;/h2&gt;
&lt;p&gt;如果正方形矩陣 &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt; 滿足： &lt;span class=&#34;math inline&#34;&gt;\(PP^t=P^tP=E\)&lt;/span&gt; (單位矩陣)；或者滿足 &lt;span class=&#34;math inline&#34;&gt;\(P^t=P^{-1}\)&lt;/span&gt; 時，我們說這個正方形矩陣 &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt; 爲&lt;strong&gt;正交矩陣(orthogonal matrix，直交行列「ちょっこうぎょうれつ」)&lt;/strong&gt;。正交矩陣如果用列向量來表示，那麼這些組成正交矩陣的列向量被稱爲&lt;strong&gt;規範正交系(orthonomal system，正規直交系)&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;矩陣 &lt;span class=&#34;math inline&#34;&gt;\(P=\left( \begin{array}{c} \cos \theta &amp;amp; -\sin \theta \\ \sin \theta &amp;amp; \cos \theta \\ \end{array} \right)\)&lt;/span&gt; 是2次的正交矩陣。如果 &lt;span class=&#34;math inline&#34;&gt;\(\underline{p}_1=\left( \begin{array}{c} \cos \theta \\ \sin \theta \\ \end{array} \right), \; \underline{p}_2=\left( \begin{array}{c} -\sin \theta \\ \cos \theta \\ \end{array} \right)\)&lt;/span&gt;，那麼列向量的長度有：&lt;span class=&#34;math inline&#34;&gt;\(\| \underline{p}_1 \|=\| \underline{p}_2 \|=1\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(\underline{p}_1\cdot\underline{p}_2=0\)&lt;/span&gt;。因此組成矩陣 &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt; 的兩個列向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{p}_1,\underline{p}_2\)&lt;/span&gt; 構成了一個規範正交系。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;矩陣 &lt;span class=&#34;math inline&#34;&gt;\(P=\left( \begin{array}{c} \frac{1}{\sqrt{3}} &amp;amp; \frac{1}{\sqrt{2}} &amp;amp; \frac{1}{\sqrt{6}} \\ \frac{1}{\sqrt{3}} &amp;amp; -\frac{1}{\sqrt{2}} &amp;amp; \frac{1}{\sqrt{6}} \\ \frac{1}{\sqrt{3}} &amp;amp; 0 &amp;amp; -\frac{2}{\sqrt{6}} \\ \end{array} \right)\)&lt;/span&gt; 是個3次正交矩陣。如果 &lt;span class=&#34;math inline&#34;&gt;\(\underline{p}_1=\left( \begin{array}{c} \frac{1}{\sqrt{3}}\\ \frac{1}{\sqrt{3}}\\ \frac{1}{\sqrt{3}}\\ \end{array} \right), \underline{p}_2=\left( \begin{array}{c} \frac{1}{\sqrt{2}} \\ -\frac{1}{\sqrt{2}} \\ 0 \\ \end{array} \right), \underline{p}_3=\left( \begin{array}{c} \frac{1}{\sqrt{6}}\\ \frac{1}{\sqrt{6}}\\ -\frac{2}{\sqrt{6}}\\ \end{array} \right)\)&lt;/span&gt; 這三個列向量構成了一個規範正交系。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;三角矩陣-triangular-matrix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;三角矩陣 triangular matrix&lt;/h2&gt;
&lt;p&gt;主對角線的左下部分全部爲 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; 的正方形矩陣被叫做：&lt;strong&gt;上三角矩陣(upper triangular matrix)&lt;/strong&gt;，右上部分的成分全部爲 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; 的正方形矩陣被叫做： &lt;strong&gt;下三角矩陣(lower triangular matrix)&lt;/strong&gt;。上三角矩陣，下三角矩陣，統稱爲&lt;strong&gt;三角矩陣&lt;/strong&gt;。有時候左下部分或者右上部分就簡略的只寫一個大的 &lt;span class=&#34;math inline&#34;&gt;\(O\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;類型相同的兩個上三角矩陣的積依然是一個上三角矩陣。兩個類型相同的下三角矩陣的積也依然是一個下三角矩陣。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
上三角矩陣： \left(
\begin{array}{c}
a_{11}&amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\
0     &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\
\vdots&amp;amp; \ddots &amp;amp; \ddots &amp;amp; \vdots\\
0     &amp;amp; \cdots &amp;amp; 0      &amp;amp; a_{nn}
\end{array}
\right)
=\left(
\begin{array}{c}
a_{11}&amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\
      &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\
      &amp;amp;        &amp;amp; \ddots &amp;amp; \vdots\\
\Huge{0}  &amp;amp;        &amp;amp;        &amp;amp; a_{nn}
\end{array}
\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
下三角矩陣：\left(
\begin{array}{c}
a_{11}&amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\
a_{21}&amp;amp; a_{22} &amp;amp; \ddots &amp;amp; \vdots \\
\vdots&amp;amp; \cdots &amp;amp; \ddots &amp;amp; 0\\
a_{n1}&amp;amp; a_{n2} &amp;amp; \cdots   &amp;amp; a_{nn}
\end{array}
\right)=\left(
\begin{array}{c}
a_{11}&amp;amp; &amp;amp;&amp;amp;\Huge{0}  \\
a_{21}&amp;amp; a_{22} &amp;amp;  \\
\vdots&amp;amp; \cdots &amp;amp; \ddots &amp;amp;\\
a_{n1}&amp;amp; a_{n2} &amp;amp; \cdots   &amp;amp; a_{nn}
\end{array}
\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} 2 &amp;amp; 1 \\ 0 &amp;amp; 8 \\ \end{array} \right), \left( \begin{array}{c} -3 &amp;amp; 0 &amp;amp; 6 \\ 0 &amp;amp; 5 &amp;amp; 2 \\ 0 &amp;amp; 0 &amp;amp; 4 \\ \end{array} \right), \left( \begin{array}{c} 5 &amp;amp; -6 &amp;amp; 3 &amp;amp; 2 \\ 0 &amp;amp; 9 &amp;amp;-2 &amp;amp; 4 \\ 0 &amp;amp; 0 &amp;amp; 3 &amp;amp; 7 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{array} \right)\)&lt;/span&gt; 這些都是上三角矩陣。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} 2 &amp;amp; 0 \\ 5 &amp;amp; 8 \\ \end{array} \right), \left( \begin{array}{c} -3 &amp;amp; 0 &amp;amp; 0 \\ 8 &amp;amp; 5 &amp;amp; 0 \\ 7 &amp;amp; 2 &amp;amp; 4 \\ \end{array} \right), \left( \begin{array}{c} 5 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 2 &amp;amp; 9 &amp;amp; 0 &amp;amp; 0 \\ 3 &amp;amp; 10 &amp;amp; 3 &amp;amp; 0 \\ 5 &amp;amp; 1 &amp;amp; 34 &amp;amp; 0 \end{array} \right)\)&lt;/span&gt; 這些都是下三角矩陣。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;階梯形矩陣-echelon-matrix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;階梯形矩陣 echelon matrix&lt;/h2&gt;
&lt;p&gt;如下所示，第1行，第2行，第3行，行數增加的同時，左側的成分中 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; 的個數跟着增加的矩陣被叫做&lt;strong&gt;階梯形矩陣(echelon matrix)&lt;/strong&gt;。 &lt;span class=&#34;math inline&#34;&gt;\(\#\)&lt;/span&gt; 表示非 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; 的數， &lt;span class=&#34;math inline&#34;&gt;\(*\)&lt;/span&gt; 表示任意數。&lt;span class=&#34;math inline&#34;&gt;\(\#\)&lt;/span&gt; 的個數，或者說此矩陣的非零向量的個數被定義爲這個矩陣的&lt;strong&gt;階數 (rank)&lt;/strong&gt;。階梯形矩陣的階數記爲： &lt;span class=&#34;math inline&#34;&gt;\(rank(A)\)&lt;/span&gt;。零矩陣 &lt;span class=&#34;math inline&#34;&gt;\(O\)&lt;/span&gt; 的階數： &lt;span class=&#34;math inline&#34;&gt;\(rank(O)=0\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left(
\begin{array}{c}
\# &amp;amp; * &amp;amp; * &amp;amp; * &amp;amp; * &amp;amp; * &amp;amp; * &amp;amp; *  &amp;amp; *\\
0 &amp;amp; \# &amp;amp; * &amp;amp; * &amp;amp; * &amp;amp; * &amp;amp; * &amp;amp; *  &amp;amp; * \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \# &amp;amp; * &amp;amp; * &amp;amp; * &amp;amp; *  &amp;amp; * \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0  &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \# &amp;amp; *  \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0  &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0  &amp;amp; 0
\end{array}
\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} 2 &amp;amp; 5 &amp;amp; 6 &amp;amp; 9\\ 0 &amp;amp; 5 &amp;amp; -1 &amp;amp; 4\\ 0 &amp;amp; 0 &amp;amp; 5 &amp;amp; 0\\ \end{array} \right)， rank(A)=3\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(B=\left( \begin{array}{c} 4 &amp;amp; 0 &amp;amp; 6 &amp;amp; 0\\ 0 &amp;amp; 5 &amp;amp; 0 &amp;amp; 4\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 5\\ \end{array} \right)， rank(B)=3\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(C=\left( \begin{array}{c} 2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\ 0 &amp;amp; 0 &amp;amp; -7 &amp;amp; 4\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -1\\ \end{array} \right)， rank(C)=3\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(D=\left( \begin{array}{c} 4 &amp;amp; 0 &amp;amp; 6 &amp;amp; 0\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 4\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\ \end{array} \right), rank(D)=2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(F=\left( \begin{array}{c} 0 &amp;amp; 2 &amp;amp; 0 &amp;amp; 0\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\ \end{array} \right), rank(F)=1\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(O=\left( \begin{array}{c} 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\ \end{array} \right), rank(O)=0\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記14</title>
      <link>https://wangcc.me/post/2017-03-01/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-03-01/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;updated: 2017-03-07&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;對稱矩陣&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;對稱矩陣&lt;/h2&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-1&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 1  (symmetric matrix)  &lt;/strong&gt;&lt;/span&gt;矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 如果完全和它的轉置矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A^t\)&lt;/span&gt; 相同，即：&lt;span class=&#34;math inline&#34;&gt;\(A=A^t\)&lt;/span&gt; 成立時，這樣的正方形矩陣被稱爲&lt;strong&gt;對稱矩陣(symmetric matrix)&lt;/strong&gt;。對稱矩陣的成分是以主對角線(main diagonal)對稱的。
&lt;/div&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} 4 &amp;amp; 3 &amp;amp; 2 &amp;amp; 1 \\ 3 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 \\ 2 &amp;amp; 6 &amp;amp; 8 &amp;amp; 9 \\ 1 &amp;amp; 7 &amp;amp; 9 &amp;amp; 0 \end{array} \right)\)&lt;/span&gt; 是典型的4次對稱矩陣。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;數學&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;物理&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;化學&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;數學&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(0.72\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(0.62\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;物理&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(0.72\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(-0.55\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;化學&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(0.62\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(-0.55\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;上表是幾名學生的數學，物理，化學成績得分的相關系數。&lt;br&gt;
如果提取出數字的部分，左右用圓括號括起來，會得到這樣一個矩陣：&lt;span class=&#34;math inline&#34;&gt;\(R=\left( \begin{array}{c} 1 &amp;amp; 0.72 &amp;amp; 0.62 \\ 0.72 &amp;amp; 1 &amp;amp; -0.55 \\ 0.62 &amp;amp; -0.55 &amp;amp; 1 \\ \end{array} \right)\)&lt;/span&gt; 這樣類型的矩陣被特別的稱爲&lt;strong&gt;相關矩陣(correlation matrix)&lt;/strong&gt;。類似相關矩陣這樣的明確爲對稱矩陣的情況下，常常像下面這樣簡略的記左下或者右上部分：
&lt;span class=&#34;math display&#34;&gt;\[\left(
\begin{array}{c}
1 &amp;amp;  &amp;amp;  \\
0.72 &amp;amp; 1 &amp;amp;  \\
0.62 &amp;amp; -0.55 &amp;amp; 1 \\
\end{array}
\right)， \left(
\begin{array}{c}
1 &amp;amp; 0.72 &amp;amp; 0.62 \\
 &amp;amp; 1 &amp;amp; -0.55 \\
 &amp;amp;  &amp;amp; 1 \\
\end{array}
\right)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;下面的對稱矩陣，對角成分是&lt;strong&gt;方差(variance, 分散)&lt;/strong&gt;，非對角成分是&lt;strong&gt;協方差(covariance, 共分散)&lt;/strong&gt;，被稱爲&lt;strong&gt;方差協方差矩陣(variance-covariance matrix, 分散共分散行列)&lt;/strong&gt;。&lt;br&gt;
&lt;span class=&#34;math display&#34;&gt;\[\sum=\left(
\begin{array}{c}
\sigma_{1}^2 &amp;amp; \sigma_{2}   &amp;amp; \cdots &amp;amp; \sigma_{1n} \\
\sigma_{12}  &amp;amp; \sigma_{2}^2 &amp;amp; \cdots &amp;amp; \sigma_{2n} \\
\vdots       &amp;amp; \vdots       &amp;amp; \ddots &amp;amp; \vdots      \\
\sigma_{1n}  &amp;amp; \sigma_{2}   &amp;amp; \cdots &amp;amp; \sigma_{n}^2
\end{array}
\right), S=\left(
\begin{array}{c}
s_{1}^2 &amp;amp; s_{2}   &amp;amp; \cdots &amp;amp; s_{1n} \\
s_{12}  &amp;amp; s_{2}^2 &amp;amp; \cdots &amp;amp; s_{2n} \\
\vdots  &amp;amp; \vdots  &amp;amp; \ddots &amp;amp; \vdots  \\
s_{1n}  &amp;amp; s_{2}   &amp;amp; \cdots &amp;amp; s_{n}^2
\end{array}
\right)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;矩陣&lt;span class=&#34;math inline&#34;&gt;\(X=\left( \begin{array}{c} x_{11} &amp;amp; x_{12} &amp;amp; x_{13} \\ x_{21} &amp;amp; x_{22} &amp;amp; x_{23} \\ \end{array} \right)\)&lt;/span&gt; ，那麼，&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(XX^t=\left( \begin{array}{c} x_{11} &amp;amp; x_{12} &amp;amp; x_{13} \\ x_{21} &amp;amp; x_{22} &amp;amp; x_{23} \\ \end{array} \right)\left( \begin{array}{c} x_{11} &amp;amp; x_{12} \\ x_{12} &amp;amp; x_{22} \\ x_{13} &amp;amp; x_{13} \end{array} \right)\\ \;\;\;\;\;\;\;=\left( \begin{array}{c} x_{11}^2+x_{12}^2+x_{13}^2 &amp;amp; x_{11}x_{21}+x_{12}x_{22}+x_{13}x_{23} \\ x_{21}x_{11}+x_{22}x_{12}+x_{23}x_{13} &amp;amp; x_{21}^2+x_{22}^2+x_{23}^2 \\ \end{array} \right)\)&lt;/span&gt; 是一個對稱矩陣。&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(X^tX=\left( \begin{array}{c} x_{11}^2+x_{21}^2 &amp;amp; x_{11}x_{12}+x_{21}x_{22} &amp;amp; x_{11}x_{13}+x_{21}x_{23} \\ x_{12}x_{11}+x_{22}x_{21} &amp;amp; x_{12}^2+x_{22}^2 &amp;amp; x_{12}x_{13}+x_{22}x_{23} \\ x_{13}x_{11}+x_{23}x_{21} &amp;amp; x_{13}x_{12}+x_{23}x_{22} &amp;amp; x_{13}^2+x_{23}^2 \end{array} \right)\)&lt;/span&gt; 也是一個對稱矩陣。 &lt;br&gt;
且，他們的&lt;strong&gt;跡(trace)&lt;/strong&gt;也是一樣的，均爲 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 各個成分的平方和：
&lt;span class=&#34;math display&#34;&gt;\[tr(XX^t)=tr(X^tX)=x_{11}^2+x_{12}^2+x_{13}^2+x_{21}^2+x_{22}^2+x_{23}^2\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;對角矩陣&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;對角矩陣&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;非對角成分(off-diagonal element)&lt;/strong&gt;均爲零 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; 的正方形矩陣被稱爲&lt;strong&gt;對角矩陣(diagonal matrix)&lt;/strong&gt;。寫成如下形式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left(
\begin{array}{c}
a_{11} &amp;amp; 0  &amp;amp; 0 &amp;amp; \cdots  &amp;amp; 0\\
0 &amp;amp; a_{22}  &amp;amp; 0 &amp;amp; \cdots  &amp;amp; 0\\
0 &amp;amp; 0  &amp;amp; a_{33} &amp;amp; \cdots  &amp;amp; 0\\
0 &amp;amp; \cdots  &amp;amp; 0 &amp;amp; \ddots  &amp;amp; 0\\
0 &amp;amp; 0  &amp;amp; \cdots &amp;amp; 0       &amp;amp;  a_{nn}
\end{array}
\right)=D_n=\Delta_n\\=diag(a_{11},a_{22},a_{33},\cdots,a_{nn})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;這樣的矩陣也常把左下部分右上部分的非對角成分用一個大的 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; 來表示：
&lt;span class=&#34;math display&#34;&gt;\[
\left(
    \begin{array}{ccccc}
    a_{11}                         \\
      &amp;amp; a_{22}            &amp;amp;   &amp;amp; \Huge0 \\
      &amp;amp;               &amp;amp; a_{33}          \\
      &amp;amp; \Huge 0       &amp;amp;   &amp;amp; \ddots           \\
      &amp;amp;               &amp;amp;   &amp;amp;      &amp;amp; a_{nn}
    \end{array}
    \right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;下面也是一個對角矩陣的例子：
&lt;span class=&#34;math display&#34;&gt;\[\left(
\begin{array}{c}
\sqrt{a_{11}} &amp;amp; 0  &amp;amp; 0 &amp;amp; \cdots  &amp;amp; 0\\
0 &amp;amp; \sqrt{a_{22}}  &amp;amp; 0 &amp;amp; \cdots  &amp;amp; 0\\
0 &amp;amp; 0  &amp;amp; \sqrt{a_{33}} &amp;amp; \cdots  &amp;amp; 0\\
0 &amp;amp; \cdots  &amp;amp; 0 &amp;amp; \ddots  &amp;amp; 0\\
0 &amp;amp; 0  &amp;amp; \cdots &amp;amp; 0       &amp;amp;  \sqrt{a_{nn}}
\end{array}
\right)=D_n^{\frac{1}{2}}=\Delta_n^{\frac{1}{2}}\\=diag(\sqrt{a_{11}},\sqrt{a_{22}},\sqrt{a_{33}},\cdots,\sqrt{a_{nn}})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;對角成分也可以是分母非零的分數：
&lt;span class=&#34;math display&#34;&gt;\[\left(
\begin{array}{c}
1/a_{11} &amp;amp; 0  &amp;amp; 0 &amp;amp; \cdots  &amp;amp; 0\\
0 &amp;amp; 1/a_{22}  &amp;amp; 0 &amp;amp; \cdots  &amp;amp; 0\\
0 &amp;amp; 0  &amp;amp; 1/a_{33} &amp;amp; \cdots  &amp;amp; 0\\
0 &amp;amp; \cdots  &amp;amp; 0 &amp;amp; \ddots  &amp;amp; 0\\
0 &amp;amp; 0  &amp;amp; \cdots &amp;amp; 0       &amp;amp;  1/a_{nn}
\end{array}
\right)=D_n^{-1}=\Delta_n^{-1}\\=diag(a_{11}^{-1},a_{22}^{-1},a_{33}^{-1},\cdots,a_{nn}^{-1})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;當然如下的例子也是對角矩陣，默認根號內爲正：
&lt;span class=&#34;math display&#34;&gt;\[\left(
\begin{array}{c}
\frac{1}{\sqrt{a_{11}}} &amp;amp; 0  &amp;amp; 0 &amp;amp; \cdots  &amp;amp; 0\\
0 &amp;amp; \frac{1}{\sqrt{a_{22}}}  &amp;amp; 0 &amp;amp; \cdots  &amp;amp; 0\\
0 &amp;amp; 0  &amp;amp; \frac{1}{\sqrt{a_{33}}} &amp;amp; \cdots  &amp;amp; 0\\
0 &amp;amp; \cdots  &amp;amp; 0 &amp;amp; \ddots  &amp;amp; 0\\
0 &amp;amp; 0  &amp;amp; \cdots &amp;amp; 0       &amp;amp;  \frac{1}{\sqrt{a_{nn}}}
\end{array}
\right)=D_n^{-\frac{1}{2}}=\Delta_n^{-\frac{1}{2}}\\=diag(\frac{1}{\sqrt{a_{11}}},\frac{1}{\sqrt{a_{22}}},\frac{1}{\sqrt{a_{33}}},\cdots,\frac{1}{\sqrt{a_{nn}}})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;當然，上述對角矩陣之間具有這樣的關系：&lt;span class=&#34;math inline&#34;&gt;\(D_n^{\frac{1}{2}}D_n^{\frac{1}{2}}=D_n\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(D_n^{-\frac{1}{2}}D_n^{-\frac{1}{2}}=D_n^{-1}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 或者向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 與對角矩陣 &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; 從左向右乘時，&lt;span class=&#34;math inline&#34;&gt;\(DA, D\underline{x}\)&lt;/span&gt; 的第 &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; 行成分是：&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 或 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 的第 &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; 行乘以 &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; 的第 &lt;span class=&#34;math inline&#34;&gt;\((i,i)\)&lt;/span&gt; 成分。例如：
&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(D=\left( \begin{array}{c} \lambda_1 &amp;amp; 0 &amp;amp; 0\\ 0 &amp;amp; \lambda_2 &amp;amp; 0\\ 0 &amp;amp; 0 &amp;amp; \lambda_3\\ \end{array} \right), A=\left( \begin{array}{c} a_1 &amp;amp; a_2 &amp;amp; a_3 \\ b_1 &amp;amp; b_2 &amp;amp; b_3 \\ c_1 &amp;amp; c_2 &amp;amp; c_3 \\ \end{array} \right),\\ \underline{x}=\left( \begin{array}{c} x_1\\ x_2\\ x_3\\ \end{array} \right)\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(DA=\left( \begin{array}{c} \lambda_1a_1 &amp;amp; \lambda_1a_2 &amp;amp; \lambda_1a_3 \\ \lambda_2b_1 &amp;amp; \lambda_2b_2 &amp;amp; \lambda_2b_3 \\ \lambda_3c_1 &amp;amp; \lambda_3c_2 &amp;amp; \lambda_3c_3 \\ \end{array} \right) \\ D\underline{x}=\left( \begin{array}{c} \lambda_1x_1\\ \lambda_2x_2\\ \lambda_3x_3\\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記13</title>
      <link>https://wangcc.me/post/2017-02-28/</link>
      <pubDate>Tue, 28 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-28/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;連立一次方程式與矩陣向量的積&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;連立一次方程式與矩陣向量的積&lt;/h2&gt;
&lt;p&gt;連立一次方程式可以改寫爲&lt;strong&gt;矩陣與向量的積形成的向量&lt;/strong&gt;的形式。特別的，以連立方程式的系數作成分的矩陣被叫做&lt;strong&gt;系數矩陣(coefficient matrix)&lt;/strong&gt;。當我們看到連立方程式，應該能立刻條件反射地聯想到其對應的&lt;strong&gt;矩陣和向量的積&lt;/strong&gt;。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} \left\{ \begin{array}{rr}  a_1+2a_2+3a_3 = 3\\ 2a_1+4a_2+5a_3 = 5\\ 3a_1+5a_2+6a_3 = 7 \end{array} \right. \end{align}\)&lt;/span&gt; 可以改寫成 &lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} 1 &amp;amp; 2 &amp;amp; 3 \\ 2 &amp;amp; 4 &amp;amp; 5 \\ 3 &amp;amp; 5 &amp;amp; 6 \end{array} \right)\left( \begin{array}{c} a_1\\ a_2\\ a_3 \end{array} \right)=\left( \begin{array}{c} 3\\ 5\\ 7 \end{array} \right)\)&lt;/span&gt; 的形式。&lt;br&gt;
如果把等號右邊的列向量寫到&lt;strong&gt;系數矩陣&lt;/strong&gt;的右側，形成的矩陣被叫做&lt;strong&gt;擴大系數矩陣(augmented coefficient)&lt;/strong&gt;：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 3 \\ 2 &amp;amp; 4 &amp;amp; 5 &amp;amp; 5 \\ 3 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} \left\{ \begin{array}{rr} a_{11}x_1+a_{12}x_2+a_{13}x_3=0\\ a_{21}x_1+a_{22}x_2+a_{23}x_3=0\\ \end{array} \right. \end{align}\)&lt;/span&gt; 可以改寫成 &lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} \\ \end{array} \right)\left( \begin{array}{c} x_1\\ x_2\\ x_3 \end{array} \right)=\left( \begin{array}{c} 0\\ 0\\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} \left\{ \begin{array}{rr} (5-\lambda)x_1+ x_2+ x_3 = 0\\  x_1+(3-\lambda)x_2+ x_3 = 0\\  x_1+ x_2+(3-\lambda)x_3 = 0 \end{array} \right. \end{align}\)&lt;/span&gt; 可以改寫爲 &lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} 5-\lambda &amp;amp; 1 &amp;amp; 1 \\ 1 &amp;amp; 3-\lambda &amp;amp; 1 \\ 1 &amp;amp; 1 &amp;amp; 3-\lambda \end{array} \right)\left( \begin{array}{c} x_1\\ x_2\\ x_3 \end{array} \right)=\left( \begin{array}{c} 0\\ 0\\ 0 \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;矩形矩陣&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;矩形矩陣&lt;/h2&gt;
&lt;p&gt;列數行數不相等的矩陣，被稱爲&lt;strong&gt;矩形矩陣(rectangular matrix)&lt;/strong&gt;。特別的行數 &lt;span class=&#34;math inline&#34;&gt;\(&amp;gt;\)&lt;/span&gt; 列數的矩陣被叫做&lt;strong&gt;垂直型矩形矩陣&lt;/strong&gt;。行數 &lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;\)&lt;/span&gt; 列數的矩陣被叫做&lt;strong&gt;水平型矩形矩陣&lt;/strong&gt;。多元變量分析時，數據常常被加工稱爲垂直型矩形矩陣的形式。&lt;/p&gt;
&lt;hr /&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;個体&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;体重 &lt;span class=&#34;math inline&#34;&gt;\((kg)\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;身長 &lt;span class=&#34;math inline&#34;&gt;\((cm)\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;安倍さん&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(53\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(157\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;伊藤さん&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(67\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(172\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;植村さん&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(49\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(163\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;江川さん&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(80\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(178\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;小野さん&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(74\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(181\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;ul&gt;
&lt;li&gt;5人的體重和身高數據被表示爲上面的表格： &lt;br&gt;
如果只提取出表格中的數字寫成垂直型矩形矩陣： &lt;span class=&#34;math inline&#34;&gt;\(\left(  \begin{array}{c} 53 &amp;amp; 157 \\ 67 &amp;amp; 172 \\ 49 &amp;amp; 163 \\ 80 &amp;amp; 178 \\ 74 &amp;amp; 181 \\  \end{array}  \right)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;正方形矩陣&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;正方形矩陣&lt;/h2&gt;
&lt;p&gt;行數和列數相等的矩陣被稱爲&lt;strong&gt;正方形矩陣(sqare matrix)&lt;/strong&gt;。一個正方形的矩陣如果類型爲 &lt;span class=&#34;math inline&#34;&gt;\((n,n)\)&lt;/span&gt;，又被叫做是 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 次正方矩陣或者 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 次矩陣。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[A_{n\times n}= \left(
\begin{array}{c}
a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\
a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
a_{n1} &amp;amp; a_{n2} &amp;amp; \cdots &amp;amp; a_{nn}
\end{array}
\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;從左上角往右下角方向劃一條對角線，這條對角線的名稱爲&lt;strong&gt;主對角線(main diagonal)&lt;/strong&gt;。主對角線上有的成分 &lt;span class=&#34;math inline&#34;&gt;\(a_{11},a_{22},\cdots, a_{nn}\)&lt;/span&gt;，被叫做&lt;strong&gt;對角成分(diagonal element)&lt;/strong&gt;。其餘的成分被叫做&lt;strong&gt;非對角成分(off-diagonal element)&lt;/strong&gt;。對角成分的和被叫做是該矩陣的跡(trace/spur)，寫作 &lt;span class=&#34;math inline&#34;&gt;\(tr(A)=\sum\limits_{i=1}^na_{ii}\)&lt;/span&gt;
。
&lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} 1 &amp;amp; 2 &amp;amp; 3 \\ 4 &amp;amp; 5 &amp;amp; 6 \\ 7 &amp;amp; 8 &amp;amp; 9 \end{array} \right)\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; 次正方形矩陣， &lt;span class=&#34;math inline&#34;&gt;\(tr(A)=1+5+9=15\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;矩陣轉置&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;矩陣轉置&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\((m,n)\)&lt;/span&gt; 型矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A_{m\times n}=(a_{ij})\)&lt;/span&gt; 的行與列互相對調，被叫做&lt;strong&gt;轉置(transpose)&lt;/strong&gt;，形成的新 &lt;span class=&#34;math inline&#34;&gt;\((n,m)\)&lt;/span&gt; 型矩陣，被叫做 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的&lt;strong&gt;轉置矩陣 (transposed matrix)&lt;/strong&gt; ： &lt;span class=&#34;math inline&#34;&gt;\((a_{ji})\)&lt;/span&gt; 有多種標記方式：&lt;span class=&#34;math inline&#34;&gt;\(A^t, A^\prime, A^T, ^TA\)&lt;/span&gt; 等，我們今後統一使用 &lt;span class=&#34;math inline&#34;&gt;\(A^t\)&lt;/span&gt;。轉置矩陣具有如下的性質：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((A^t)^t=A\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((AB)^t=B^tA^t\)&lt;/span&gt; &lt;span class=&#34;diff_alert&#34;&gt;注意： 不是&lt;span class=&#34;math inline&#34;&gt;\(A^tB^t\)&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((A+B)^t=A^t+B^t\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((kA)^t=kA^t\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;爲標量 scalar)&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;練習&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;練習&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} 1 &amp;amp; 2 &amp;amp; 3 \\ 4 &amp;amp; 5 &amp;amp; 6 \\ 7 &amp;amp; 8 &amp;amp; 9 \end{array} \right)\)&lt;/span&gt; 的轉置矩陣爲：&lt;span class=&#34;math inline&#34;&gt;\(A^t=\left( \begin{array}{c} 1 &amp;amp; 4 &amp;amp; 7 \\ 2 &amp;amp; 5 &amp;amp; 8 \\ 3 &amp;amp; 6 &amp;amp; 9 \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(B=\left( \begin{array}{c} 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4\\ 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8\\ \end{array} \right)\)&lt;/span&gt; 的轉置矩陣爲：&lt;span class=&#34;math inline&#34;&gt;\(B^t=\left( \begin{array}{c} 1 &amp;amp; 5 \\ 2 &amp;amp; 6 \\ 3 &amp;amp; 7 \\ 4 &amp;amp; 8 \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記12</title>
      <link>https://wangcc.me/post/2017-02-22/</link>
      <pubDate>Wed, 22 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-22/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;矩陣乘法運算&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;矩陣乘法運算&lt;/h2&gt;
&lt;div id=&#34;矩陣乘法定義&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;矩陣乘法定義&lt;/h4&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-1&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 1  (matrix multiplication)  &lt;/strong&gt;&lt;/span&gt;兩個矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A, B\)&lt;/span&gt; ，只有 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的列數和 &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; 的行數相等(這種特徵又被稱爲：矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A,B\)&lt;/span&gt; &lt;strong&gt;可整合的&lt;/strong&gt;，conformable)時，才有定義：&lt;span class=&#34;math inline&#34;&gt;\(AB\)&lt;/span&gt;。&lt;span class=&#34;math inline&#34;&gt;\(AB\)&lt;/span&gt; 則爲新的矩陣，類型爲 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的行數， &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;的列數。即：&lt;span class=&#34;math inline&#34;&gt;\(A_{k\times l}, \; B_{m\times n}\)&lt;/span&gt; 且 &lt;span class=&#34;math inline&#34;&gt;\(l=m\)&lt;/span&gt; 時才能計算乘積: &lt;span class=&#34;math inline&#34;&gt;\(AB_{k\times n}\)&lt;/span&gt;。
&lt;/div&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A_{2\times3}=\left( \begin{array}{c} 4 &amp;amp; 6 &amp;amp; 8\\ 2 &amp;amp; 1 &amp;amp; 3\\ \end{array} \right),\; B_{3\times2}=\left( \begin{array}{c} 0 &amp;amp; 8\\ 2 &amp;amp; -1\\ 9 &amp;amp; 4 \\ \end{array} \right)\)&lt;/span&gt; 時，&lt;br&gt;
“&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;的列數” &lt;span class=&#34;math inline&#34;&gt;\(=\)&lt;/span&gt; “&lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; 的行數” &lt;span class=&#34;math inline&#34;&gt;\(= 3\)&lt;/span&gt;，因此積 &lt;span class=&#34;math inline&#34;&gt;\(AB\)&lt;/span&gt; 被定義，類型是 &lt;span class=&#34;math inline&#34;&gt;\((2,2)\)&lt;/span&gt; &lt;br&gt;
“&lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;的列數” &lt;span class=&#34;math inline&#34;&gt;\(=\)&lt;/span&gt; “&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的行數” &lt;span class=&#34;math inline&#34;&gt;\(= 2\)&lt;/span&gt;，因此積 &lt;span class=&#34;math inline&#34;&gt;\(BA\)&lt;/span&gt; 被定義，類型是 &lt;span class=&#34;math inline&#34;&gt;\((3,3)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(C_{3\times2}=\left( \begin{array}{c} 4 &amp;amp; 2 \\ 5 &amp;amp; 6 \\ 7 &amp;amp; 3 \end{array} \right),\; D_{2\times4}=\left( \begin{array}{c} 2 &amp;amp; 0 &amp;amp; 9 &amp;amp; -1 \\ 4 &amp;amp; 7 &amp;amp; 6 &amp;amp; 5 \\ \end{array} \right)\)&lt;/span&gt; 時， &lt;br&gt;
“&lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt;的列數” &lt;span class=&#34;math inline&#34;&gt;\(=\)&lt;/span&gt; “&lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; 的行數” &lt;span class=&#34;math inline&#34;&gt;\(= 2\)&lt;/span&gt;，因此積 &lt;span class=&#34;math inline&#34;&gt;\(CD\)&lt;/span&gt; 被定義，類型是 &lt;span class=&#34;math inline&#34;&gt;\((3,4)\)&lt;/span&gt; &lt;br&gt;
“&lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;的列數”&lt;span class=&#34;math inline&#34;&gt;\(= 4\)&lt;/span&gt;，“&lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; 的行數” &lt;span class=&#34;math inline&#34;&gt;\(= 3\)&lt;/span&gt;，因此積 &lt;span class=&#34;math inline&#34;&gt;\(DC\)&lt;/span&gt; 不被定義，&lt;span class=&#34;math inline&#34;&gt;\(DC\)&lt;/span&gt; 不可整合。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;矩陣的積的向量表達形式&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;矩陣的積的向量表達形式&lt;/h4&gt;
&lt;p&gt;矩陣也可以被看做是一個個相同類型（大小，方向）的向量組成。那麼當，下面&lt;span class=&#34;math inline&#34;&gt;\(A, B\)&lt;/span&gt;兩個矩陣滿足：&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的行向量的維度，和&lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;的列向量的維度相等時，&lt;span class=&#34;math inline&#34;&gt;\(AB\)&lt;/span&gt;被定義。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} \underline{a}_1^t\\ \underline{a}_2^t\\ \vdots\\ \underline{a}_k^t \end{array} \right), \; B=(\underline{b}_1,\underline{b}_2,\cdots,\underline{b}_n)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(AB=A(\underline{b}_1,\underline{b}_2,\cdots,\underline{b}_n)=(A\underline{b}_1,A\underline{b}_2,\cdots,A\underline{b}_n)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;或者：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(AB=\left( \begin{array}{c} \underline{a}_1^t\\ \underline{a}_2^t\\ \vdots\\ \underline{a}_k^t \end{array} \right)B=\left( \begin{array}{c} \underline{a}_1^tB\\ \underline{a}_2^tB\\ \vdots\\ \underline{a}_k^tB \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;特殊情況當&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;僅有一個行向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}^t\)&lt;/span&gt; 時，&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(AB=\underline{a}^tB=\underline{a}^t(\underline{b}_1,\underline{b}_2,\cdots,\underline{b}_n)=(\underline{a}^t\underline{b}_1,\underline{a}^t\underline{b}_2,\cdots,\underline{a}^t\underline{b}_n)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;矩陣的積的成分&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;矩陣的積的成分&lt;/h4&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-2&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 2  (matrix multiplication component)  &lt;/strong&gt;&lt;/span&gt;兩個矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A_{k\times l}, \; B_{m\times n}\)&lt;/span&gt; 的積有被定義時，矩陣 &lt;span class=&#34;math inline&#34;&gt;\(AB_{k\times n}\)&lt;/span&gt; 的任意成分&lt;span class=&#34;math inline&#34;&gt;\((i,j)\)&lt;/span&gt;，被定義爲：&lt;strong&gt;“&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的第 &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; 行向量與 &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;的第 &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; 列向量的內積”&lt;/strong&gt;。
&lt;/div&gt;
&lt;p&gt;故：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(AB\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\((1,1)\)&lt;/span&gt; 成分是，“&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的第 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; 行向量與 &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;的第 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; 列向量的內積”&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(AB\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\((1,2)\)&lt;/span&gt; 成分是，“&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的第 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; 行向量與 &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;的第 &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; 列向量的內積”&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(AB\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\((k,n)\)&lt;/span&gt; 成分是，“&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的第 &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; 行向量與 &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;的第 &lt;span class=&#34;math inline&#34;&gt;\(ns\)&lt;/span&gt; 列向量的內積”&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;練習&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;練習&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} 1 &amp;amp; 2 \\ 3 &amp;amp; 4 \\ \end{array} \right), B=\left( \begin{array}{c} 4 &amp;amp; 1 \\ 5 &amp;amp; 2 \\ \end{array} \right)\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(AB=\left( \begin{array}{c} 1\times4+2\times5 &amp;amp; 1\times1+2\times2 \\ 3\times4+4\times5 &amp;amp; 3\times1+4\times2 \\ \end{array} \right)\\ \;\;\;\;\;=\left( \begin{array}{c} 14 &amp;amp; 5 \\ 32 &amp;amp; 11 \\ \end{array} \right)\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(BA=\left( \begin{array}{c} 4\times1+1\times3 &amp;amp; 4\times2+1\times4 \\ 5\times1+2\times3 &amp;amp; 5\times2+2\times4 \\ \end{array} \right)\\ \;\;\;\;\;=\left( \begin{array}{c} 7 &amp;amp; 12 \\ 11 &amp;amp; 18 \\ \end{array} \right)\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;注意： &lt;span class=&#34;math inline&#34;&gt;\(AB\neq BA\)&lt;/span&gt;&lt;/span&gt;
&lt;br&gt;
另外：&lt;span class=&#34;math inline&#34;&gt;\(AA=\left( \begin{array}{c} 1\times1+2\times3 &amp;amp; 1\times2+2\times4 \\ 3\times1+4\times3 &amp;amp; 3\times2+4\times4 \\ \end{array} \right)\\ \;\;\;\;=\left( \begin{array}{c} 7 &amp;amp; 10 \\ 15 &amp;amp; 22 \\ \end{array} \right)=AA^2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} 1 &amp;amp; 2 \\ -2 &amp;amp; -4 \\ \end{array} \right), B=\left( \begin{array}{c} 6 &amp;amp; -2 \\ -3 &amp;amp; 1 \\ \end{array} \right)\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(AB=\left( \begin{array}{c} 1\times6+2\times(-3) &amp;amp; 1\times(-2)+2\times1 \\ (-2)\times6+(-4)\times(-3) &amp;amp; (-2)\times(-2)+(-4)\times1 \\ \end{array} \right)\\ \;\;\;\;=\left( \begin{array}{c} 0 &amp;amp; 0 \\ 0 &amp;amp; 0 \\ \end{array} \right)=\Large 0\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;這裏出現了非零矩陣相乘爲&lt;strong&gt;零矩陣 &lt;span class=&#34;math inline&#34;&gt;\(\large 0\)&lt;/span&gt;&lt;/strong&gt;的例子。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A_{2\times3}=\left( \begin{array}{c} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\ \end{array} \right)=\left( \begin{array}{c} \underline{a}_1^t\\ \underline{a}_2^t\\ \end{array} \right)=(\underline{c}_1,\underline{c}_2,\underline{c}_3); \\ B_{3\times2}=\left( \begin{array}{c} b_{11} &amp;amp; b_{12}\\ b_{21} &amp;amp; b_{22}\\ b_{31} &amp;amp; b_{32}\\ \end{array} \right)=(\underline{b}_1,\underline{b}_2)=\left( \begin{array}{c} \underline{d}^t_1\\ \underline{d}^t_2\\ \underline{d}^t_3\\ \end{array} \right)\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(AB_{2\times2}\)&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;math inline&#34;&gt;\(=\left( \begin{array}{c} \sum\limits_{k=1}^3a_{1k}b_{k1} &amp;amp;\sum\limits_{k=1}^3a_{1k}b_{k2} \\ \sum\limits_{k=1}^3a_{2k}b_{k1} &amp;amp;\sum\limits_{k=1}^3a_{2k}b_{k2} \\ \end{array} \right)\\=\left( \begin{array}{c} \underline{a}^t_1\underline{b}_1 &amp;amp; \underline{a}^t_1\underline{b}_2 \\ \underline{a}^t_2\underline{b}_1 &amp;amp; \underline{a}^t_2\underline{b}_2 \\ \end{array} \right)\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;diff_alert&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(BA_{3\times3}\)&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;math inline&#34;&gt;\(=\left( \begin{array}{c} \sum\limits_{k=1}^2b_{1k}a_{k1} &amp;amp; \sum\limits_{k=1}^2b_{1k}a_{k2} &amp;amp; \sum\limits_{k=1}^2b_{1k}a_{k3} \\ \sum\limits_{k=1}^2b_{2k}a_{k1} &amp;amp; \sum\limits_{k=1}^2b_{2k}a_{k2} &amp;amp; \sum\limits_{k=1}^2b_{2k}a_{k3} \\ \sum\limits_{k=1}^2b_{3k}a_{k1} &amp;amp; \sum\limits_{k=1}^2b_{3k}a_{k2} &amp;amp; \sum\limits_{k=1}^2b_{3k}a_{k3} \end{array} \right)\\ =\left( \begin{array}{c} \underline{d}^t_1\underline{c}_1 &amp;amp; \underline{d}^t_1\underline{c}_2 &amp;amp; \underline{d}^t_1\underline{c}_3 \\ \underline{d}^t_2\underline{c}_1 &amp;amp; \underline{d}^t_2\underline{c}_2 &amp;amp; \underline{d}^t_2\underline{c}_3 \\ \underline{d}^t_3\underline{c}_1 &amp;amp; \underline{d}^t_3\underline{c}_2 &amp;amp; \underline{d}^t_3\underline{c}_3 \\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}=\left( \begin{array}{c} x_1\\ x_2\\ \vdots\\ x_n\\ \end{array} \right)\)&lt;/span&gt; 時， &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\underline{x}^t=\left( \begin{array}{c} x_1^2 &amp;amp; x_1x_2 &amp;amp; \cdots &amp;amp; x_1x_n \\ x_2x_1 &amp;amp; x_2^2 &amp;amp; \cdots &amp;amp; x_2x_n \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ x_nx_1 &amp;amp; x_nx_2 &amp;amp; \cdots &amp;amp; x_n^2 \\ \end{array} \right)\)&lt;/span&gt;，&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^t\underline{x}=\sum\limits_{i=1}^nx_i^2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} a_1\\ a_2\\ a_3\\ \end{array} \right), \underline{b}=\left( \begin{array}{c} b_1\\ b_2\\ b_3\\ \end{array} \right), \underline{c}=\left( \begin{array}{c} c_1\\ c_2\\ c_3\\ \end{array} \right)\\ A=\left( \begin{array}{c} a_1 &amp;amp; b_1 &amp;amp; c_1 \\ a_2 &amp;amp; b_2 &amp;amp; c_2 \\ a_3 &amp;amp; b_3 &amp;amp; c_3 \\ \end{array} \right)\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\underline{a}^t+\underline{b}\underline{b}^t+\underline{c}\underline{c}^t\\ \;\;=\left( \begin{array}{c} a_1^2 &amp;amp; a_1a_2 &amp;amp; a_1a_3 \\ a_2a_1 &amp;amp; a_2^2 &amp;amp; a_2a_3 \\ a_3a_1 &amp;amp; a_3a_2 &amp;amp; a_3^2 \\ \end{array} \right)\\ \;\;\;\;\;\;+\left( \begin{array}{c} b_1^2 &amp;amp; b_1b_2 &amp;amp; b_1b_3 \\ b_2b_1 &amp;amp; b_2^2 &amp;amp; b_2b_3 \\ b_3b_1 &amp;amp; b_3b_2 &amp;amp; b_3^2 \\ \end{array} \right)\\ \;\;\;\;\;\;+\left( \begin{array}{c} c_1^2 &amp;amp; c_1c_2 &amp;amp; c_1c_3 \\ c_2c_1 &amp;amp; c_2^2 &amp;amp; c_2c_3 \\ c_3c_1 &amp;amp; c_3c_2 &amp;amp; c_3^2 \\ \end{array} \right)\\ =\left( \begin{array}{c} a_1 &amp;amp; b_1 &amp;amp; c_1 \\ a_2 &amp;amp; b_2 &amp;amp; c_2 \\ a_3 &amp;amp; b_3 &amp;amp; c_3 \\ \end{array} \right)\left( \begin{array}{c} a_1 &amp;amp; a_2 &amp;amp; a_3 \\ b_1 &amp;amp; b_2 &amp;amp; b_3 \\ c_1 &amp;amp; c_2 &amp;amp; c_3 \\ \end{array} \right)=AA^t\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}=\left( \begin{array}{c} x_1\\ x_2\\ \vdots\\ x_n\\ \end{array} \right), \; \underline{\frac{1}{n}}=\left( \begin{array}{c} \frac{1}{n}\\ \frac{1}{n}\\ \cdots\\ \frac{1}{n}\\ \end{array} \right)\)&lt;/span&gt; 時， &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^t\underline{\frac{1}{n}}=\sum\limits_{i=1}^nx_i\cdot\frac{1}{n}=\bar{x}\)&lt;/span&gt; &lt;span class=&#34;diff_alert&#34;&gt;(&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}\)&lt;/span&gt; 的&lt;strong&gt;平均值&lt;/strong&gt;)&lt;/span&gt;
&lt;br&gt;
將這樣的 &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; 寫成 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個的橫向量：&lt;span class=&#34;math inline&#34;&gt;\((\bar{x},\bar{x},\cdots,\bar{x})\)&lt;/span&gt; &lt;br&gt;
這個向量如果寫成展開的形式就是：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\((\bar{x},\bar{x},\cdots,\bar{x})=(\underline{x}^t\underline{\frac{1}{n}}, \underline{x}^t\underline{\frac{1}{n}}, \cdots,\underline{x}^t\underline{\frac{1}{n}})\\ \;\;\;\;\;\;=\underline{x}^t(\underline{\frac{1}{n}},\underline{\frac{1}{n}},\cdots,\underline{\frac{1}{n}})\\ \;\;\;\;\;\;=(x_1,x_2,\cdots,x_n)\left( \begin{array}{c} \frac{1}{n} &amp;amp; \frac{1}{n} &amp;amp; \cdots &amp;amp; \frac{1}{n} \\ \frac{1}{n} &amp;amp; \frac{1}{n} &amp;amp; \cdots &amp;amp; \frac{1}{n} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ \frac{1}{n} &amp;amp; \frac{1}{n} &amp;amp; \cdots &amp;amp; \frac{1}{n} \\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;矩陣積的性質&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;矩陣積的性質&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;矩陣 &lt;span class=&#34;math inline&#34;&gt;\(AB\)&lt;/span&gt; 有定義時， &lt;span class=&#34;math inline&#34;&gt;\(BA\)&lt;/span&gt; 並不一定就有定義。無法整合時就沒有定義。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(AB=BA\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(A, B\)&lt;/span&gt; 被稱爲&lt;strong&gt;可交換 commutative&lt;/strong&gt;，&lt;strong&gt;交換可能矩陣&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(AB, BA\)&lt;/span&gt; 都有定義時，也不一定就滿足 &lt;span class=&#34;math inline&#34;&gt;\(AB=BA\)&lt;/span&gt;。也就是說，多數情況下， &lt;span class=&#34;math inline&#34;&gt;\(AB\neq BA\)&lt;/span&gt;。爲了區分二者，&lt;span class=&#34;math inline&#34;&gt;\(AB\)&lt;/span&gt; 被稱爲 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 從右往左乘 &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; &lt;strong&gt;(postmultiplication of &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; by &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;)&lt;/strong&gt;，&lt;span class=&#34;math inline&#34;&gt;\(BA\)&lt;/span&gt; 被稱爲 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 從左往右乘 &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; &lt;strong&gt;(postmultiplication of &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; by &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;)&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;相似的， &lt;span class=&#34;math inline&#34;&gt;\(AC=BC\)&lt;/span&gt; 時，應該理解爲： 等式&lt;span class=&#34;math inline&#34;&gt;\(A=B\)&lt;/span&gt;兩邊同時從右往左乘 &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(CA=CB\)&lt;/span&gt; 就是：等式&lt;span class=&#34;math inline&#34;&gt;\(A=B\)&lt;/span&gt;兩邊同時從左往右乘&lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;即使 &lt;span class=&#34;math inline&#34;&gt;\(A\neq\Large 0\)&lt;/span&gt; 且 &lt;span class=&#34;math inline&#34;&gt;\(B\neq\Large 0\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(AB\)&lt;/span&gt; 也有可能等於 &lt;span class=&#34;math inline&#34;&gt;\(\Large 0\)&lt;/span&gt; (零矩陣)，此時我們說， &lt;span class=&#34;math inline&#34;&gt;\(A, B\)&lt;/span&gt; 是&lt;strong&gt;零因子 (zero divisor)&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記11</title>
      <link>https://wangcc.me/post/2017-02-21/</link>
      <pubDate>Tue, 21 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-21/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;矩陣的定義&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;矩陣的定義&lt;/h2&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;p&gt;&lt;span id=&#34;thm:unnamed-chunk-1&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 1  (matrix)  &lt;/strong&gt;&lt;/span&gt;將&lt;span class=&#34;math inline&#34;&gt;\(m\times n\)&lt;/span&gt; 個數 &lt;span class=&#34;math inline&#34;&gt;\(a_{ij} (i=1,2,\cdots,m; j=1,2,\cdots,n)\)&lt;/span&gt;, 寫成縱 &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; 行， 橫 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 列的長方形或者正方形，左右用圓括號或者方括號包含在內。我們稱之爲 &lt;span class=&#34;math inline&#34;&gt;\(m\times n\)&lt;/span&gt; &lt;strong&gt;矩陣(matrix)&lt;/strong&gt;，或者 &lt;span class=&#34;math inline&#34;&gt;\((m, n)\)&lt;/span&gt; 矩陣。 &lt;span class=&#34;math inline&#34;&gt;\(m\times n\)&lt;/span&gt; 或者 &lt;span class=&#34;math inline&#34;&gt;\((m,n)\)&lt;/span&gt; 被稱爲是這個矩陣的類型。我們常用大寫字母來標記一個矩陣，如下面的矩陣我們標記爲 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;。 如果要特別明示矩陣的類型，可以寫作 &lt;span class=&#34;math inline&#34;&gt;\(\mathop{A}_{m\times n}, \mathop{A}_{(m, n)}, \; A(m\times n)\)&lt;/span&gt;。兩個矩陣如果行數相等，列數也相等，我們稱他們爲類型相同的矩陣。構成矩陣的一個個數 &lt;span class=&#34;math inline&#34;&gt;\(a_{11},a_{12},\cdots,a_{mn}\)&lt;/span&gt; 被叫做矩陣的成分(component, element, entry)。&lt;/p&gt;
第&lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;行，第&lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;列交叉的地方的成分，&lt;span class=&#34;math inline&#34;&gt;\(a_{ij}\)&lt;/span&gt; 被叫做 &lt;span class=&#34;math inline&#34;&gt;\((i,j)\)&lt;/span&gt; 成分。矩陣有時候也會寫成 &lt;span class=&#34;math inline&#34;&gt;\(A=(a_{ij})\)&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1j} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2j} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{i1} &amp;amp; a_{i2} &amp;amp; \cdots &amp;amp; a_{ij} &amp;amp; \cdots &amp;amp; a_{in}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mj} &amp;amp; \cdots &amp;amp; a_{mn}\\ \end{array} \right), \\ \left[ \begin{array}{c} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1j} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2j} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{i1} &amp;amp; a_{i2} &amp;amp; \cdots &amp;amp; a_{ij} &amp;amp; \cdots &amp;amp; a_{in}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mj} &amp;amp; \cdots &amp;amp; a_{mn}\\ \end{array} \right]\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;矩陣 &lt;span class=&#34;math inline&#34;&gt;\(\mathop{A}_{m\times n}\)&lt;/span&gt; 可以被看做是：&lt;br&gt;
以第&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;行爲成分的行向量 &lt;span class=&#34;math inline&#34;&gt;\((a_{11},a_{12},\cdots,a_{1n})=\underline{b}_1^t\)&lt;/span&gt;；&lt;br&gt;
以第&lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt;行爲成分的行向量 &lt;span class=&#34;math inline&#34;&gt;\((a_{21},a_{22},\cdots,a_{2n})=\underline{b}_2^t\)&lt;/span&gt;；&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;br&gt;
以第 &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; 行爲成分的行向量 &lt;span class=&#34;math inline&#34;&gt;\((a_{m1},a_{m2},\cdots,a_{mn})=\underline{b}_m^t\)&lt;/span&gt;；&lt;br&gt;
爲成分組成的列向量：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} \underline{b}_1^t\\ \underline{b}_2^t\\ \vdots\\ \underline{b}_m^t\\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;類似的，矩陣 &lt;span class=&#34;math inline&#34;&gt;\(\mathop{A}_{m\times n}\)&lt;/span&gt; 可以被看做是：&lt;br&gt;
以第&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;列爲成分的列向量： &lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} a_{11}\\ a_{21}\\ \vdots\\ a_{m1}\\ \end{array} \right)=\underline{c}_1\)&lt;/span&gt; &lt;br&gt;
以第&lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt;列爲成分的列向量：&lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} a_{12}\\ a_{22}\\ \vdots\\ a_{m2}\\ \end{array} \right)=\underline{c}_2\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;br&gt;
以第&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;列爲成分的列向量：&lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} a_{1n}\\ a_{2n}\\ \vdots\\ a_{mn}\\ \end{array} \right)=\underline{c}_n\)&lt;/span&gt; &lt;br&gt;
爲成分組成的行向量：&lt;span class=&#34;math inline&#34;&gt;\((\underline{c}_1,\underline{c}_2,\cdots,\underline{c}_n)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;矩陣的運算和零矩陣&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;矩陣的運算，和零矩陣&lt;/h2&gt;
&lt;div id=&#34;矩陣的和與差&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;矩陣的和與差&lt;/h3&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-2&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 2  (matrix plus or minus)  &lt;/strong&gt;&lt;/span&gt;類型(type)相同的矩陣之間的加減法運算，被定義爲各個對應成分的加減法結果作成分的矩陣。
&lt;/div&gt;
&lt;p&gt;對於&lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn}\\ \end{array} \right),\\ B=\left( \begin{array}{c} b_{11} &amp;amp; b_{12} &amp;amp; \cdots &amp;amp; b_{1n}\\ b_{21} &amp;amp; b_{22} &amp;amp; \cdots &amp;amp; b_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ b_{m1} &amp;amp; b_{m2} &amp;amp; \cdots &amp;amp; b_{mn}\\ \end{array} \right)\)&lt;/span&gt; &lt;br&gt;
有：&lt;span class=&#34;math inline&#34;&gt;\(A\pm B=\left( \begin{array}{c} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn}\\ \end{array} \right)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\pm \left( \begin{array}{c} b_{11} &amp;amp; b_{12} &amp;amp; \cdots &amp;amp; b_{1n}\\ b_{21} &amp;amp; b_{22} &amp;amp; \cdots &amp;amp; b_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ b_{m1} &amp;amp; b_{m2} &amp;amp; \cdots &amp;amp; b_{mn}\\ \end{array} \right)\\ \;\;\;\;\;\;\;\;\;\;=\left( \begin{array}{c} a_{11}\pm b_{11} &amp;amp; a_{12}\pm b_{12} &amp;amp; \cdots &amp;amp; a_{1n}\pm b_{1n}\\ a_{21}\pm b_{21} &amp;amp; a_{22}\pm b_{22} &amp;amp; \cdots &amp;amp; a_{2n}\pm b_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{m1}\pm b_{m1} &amp;amp; a_{m2}\pm b_{m2} &amp;amp; \cdots &amp;amp; a_{mn}\pm b_{mn}\\ \end{array} \right)(復号同順)\)&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A=\left(  \begin{array}{c}  9 &amp;amp; 3 &amp;amp; 1\\  -2 &amp;amp; 5 &amp;amp; 8\\  \end{array}  \right)， B=\left(  \begin{array}{c}  4 &amp;amp; 2 &amp;amp; 1\\  3 &amp;amp; -3 &amp;amp; 5\\  \end{array}  \right)\)&lt;/span&gt; 那麼&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(A+B = \left(  \begin{array}{c}  9+4 &amp;amp; 3+2 &amp;amp; 1+1\\  -2+3 &amp;amp; 5+(-3) &amp;amp; 8+5\\  \end{array}  \right)=\left(  \begin{array}{c}  13 &amp;amp; 5 &amp;amp; 2\\  1 &amp;amp; 2 &amp;amp; 13\\  \end{array}  \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;用1.中的矩陣運算：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(A-B=\left(  \begin{array}{c}  9-4 &amp;amp; 3-2 &amp;amp; 1-1\\  -2-3 &amp;amp; 5-(-3) &amp;amp; 8-5\\  \end{array}  \right)=\left(  \begin{array}{c}  5 &amp;amp; 1 &amp;amp; 0\\  -5 &amp;amp; 8 &amp;amp; 3\\  \end{array}  \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;矩陣的相等&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;矩陣的相等&lt;/h3&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-3&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 3  (matrix equal)  &lt;/strong&gt;&lt;/span&gt;類型相同的兩個矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A,B\)&lt;/span&gt;，如果他們對應的所有成分，一一相等，我們說這兩個矩陣是相等的。即：&lt;span class=&#34;math inline&#34;&gt;\(A=B\)&lt;/span&gt;。
&lt;/div&gt;
&lt;p&gt;對於&lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn}\\ \end{array} \right),\\ B=\left( \begin{array}{c} b_{11} &amp;amp; b_{12} &amp;amp; \cdots &amp;amp; b_{1n}\\ b_{21} &amp;amp; b_{22} &amp;amp; \cdots &amp;amp; b_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ b_{m1} &amp;amp; b_{m2} &amp;amp; \cdots &amp;amp; b_{mn}\\ \end{array} \right)\)&lt;/span&gt;&lt;br&gt;
如果有：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(a_{11}=b_{11},a_{12}=b_{12},\cdots,a_{mn}=b_{mn}\)&lt;/span&gt;&lt;br&gt;
那麼 &lt;span class=&#34;math inline&#34;&gt;\(A=B\)&lt;/span&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;零矩陣&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;零矩陣&lt;/h3&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-4&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 4  (zero matrix)  &lt;/strong&gt;&lt;/span&gt;所有的成分均爲數字 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(m\times n\)&lt;/span&gt; 矩陣，&lt;br&gt;
(共有　&lt;span class=&#34;math inline&#34;&gt;\(m\times n\)&lt;/span&gt; 個零。)&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0\\ 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0\\ \end{array} \right)\)&lt;/span&gt;&lt;br&gt;
被稱爲&lt;strong&gt;零矩陣(zero matrix, null matrix)&lt;/strong&gt;。寫作：&lt;span class=&#34;math inline&#34;&gt;\(\large 0, \mathop{\large 0}_{m\times n}, \mathop{\large 0}_{(m,n)}\)&lt;/span&gt;。要注意與標量的 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; 區分。
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;矩陣的標量倍數運算&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;矩陣的標量倍數運算&lt;/h3&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-5&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 5  (scalar times)  &lt;/strong&gt;&lt;/span&gt;矩陣 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 的所有的成分，均乘以一個標量 &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;，獲得新的矩陣的過程被稱爲矩陣的標量倍數運算。 寫作 &lt;span class=&#34;math inline&#34;&gt;\(kA\)&lt;/span&gt;。
&lt;/div&gt;
&lt;p&gt;對於 &lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn}\\ \end{array} \right)\)&lt;/span&gt;，&lt;br&gt;
有：&lt;span class=&#34;math inline&#34;&gt;\(kA = k\left( \begin{array}{c} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n}\\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn}\\ \end{array} \right)\\ =\left( \begin{array}{c} ka_{11} &amp;amp; ka_{12} &amp;amp; \cdots &amp;amp; ka_{1n}\\ ka_{21} &amp;amp; ka_{22} &amp;amp; \cdots &amp;amp; ka_{2n}\\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\ ka_{m1} &amp;amp; ka_{m2} &amp;amp; \cdots &amp;amp; ka_{mn}\\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;特別的，當 &lt;span class=&#34;math inline&#34;&gt;\(k=-1\)&lt;/span&gt; 時， &lt;span class=&#34;math inline&#34;&gt;\((-1)A=-A\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(k=0\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(0A=\Large 0\)&lt;/span&gt;。注意 &lt;span class=&#34;math inline&#34;&gt;\(\Large 0\)&lt;/span&gt; 是與 &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; 類型相同的零矩陣，而非標量 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;對 &lt;span class=&#34;math inline&#34;&gt;\(A=\left( \begin{array}{c} a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\ \end{array} \right)\)&lt;/span&gt;， &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(kA=\left( \begin{array}{c} ka_{11} &amp;amp; ka_{12} &amp;amp; ka_{13}\\ ka_{21} &amp;amp; ka_{22} &amp;amp; ka_{23}\\ ka_{31} &amp;amp; ka_{32} &amp;amp; ka_{33}\\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;對 &lt;span class=&#34;math inline&#34;&gt;\(B=\left( \begin{array}{c} 1 &amp;amp; -2 &amp;amp; 3\\ -4 &amp;amp; 5 &amp;amp; -6\\ \end{array} \right)\)&lt;/span&gt;，&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(7B=\left( \begin{array}{c} 7\times1 &amp;amp; 7\times(-2) &amp;amp; 7\times3\\ 7\times(-4) &amp;amp; 7\times5 &amp;amp; 7\times(-6)\\ \end{array} \right)\\ \;\;\;\;=\left( \begin{array}{c} 7 &amp;amp; -14 &amp;amp; 21\\ -28 &amp;amp; 35 &amp;amp; -42\\ \end{array} \right)\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(-B=\left( \begin{array}{c} -1 &amp;amp; 2 &amp;amp; -3\\ 4 &amp;amp; -5 &amp;amp; 6\\ \end{array} \right)\)&lt;/span&gt;；&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(0B=\left( \begin{array}{c} 0 &amp;amp; 0 &amp;amp; 0\\ 0 &amp;amp; 0 &amp;amp; 0\\ \end{array} \right)=\mathop{\large 0}_{2\times3}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記10</title>
      <link>https://wangcc.me/post/2017-02-19/</link>
      <pubDate>Mon, 20 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-19/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;向量的內積-inner-product&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;向量的內積 (inner product)&lt;/h2&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-1&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 1  (vectors inner product)  &lt;/strong&gt;&lt;/span&gt;向量的&lt;strong&gt;內積&lt;/strong&gt;運算，僅限定於維度相同的兩個向量之間。一個向量爲橫向量寫在左側，一個向量爲列向量寫在右側，兩個向量的相對應成分一一相乘，然後將各成分乘積相加的過程，我們稱之爲內積(inner product, scalar product)運算。內積運算結果通常不會是向量，而是標量(scalar)，或正或負，或爲零。向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\)&lt;/span&gt; 與向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{b}\)&lt;/span&gt; 的內積寫作：&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}^t\underline{b}, \underline{b}^t\underline{a}\)&lt;/span&gt; 或者寫作： &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\cdot\underline{b}, (\underline{a},\underline{b}), &amp;lt;\underline{a},\underline{b}&amp;gt;\)&lt;/span&gt;。內積爲 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; 的向量我們稱他們爲正交向量(orthogonal)，寫作：&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\perp\underline{b}\)&lt;/span&gt;。
內積，與和記號: &lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt; 有緊密聯系。我們常常會把 &lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt; 式子/量寫成向量的內積形式。
&lt;/div&gt;
&lt;div id=&#34;練習&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;練習&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;列向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} a_1\\ a_2\\ a_3 \end{array} \right), \underline{b}=\left( \begin{array}{c} b_1\\ b_2\\ b_3 \end{array} \right)\)&lt;/span&gt; 的內積：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}^t\underline{b}=(a_1,a_2,a_3)\left( \begin{array}{c} b_1\\ b_2\\ b_3 \end{array} \right)=a_1b_1+a_2b_2+a_3b_3\\=\sum\limits_{i=1}^3a_ib_i=\sum\limits_{i=1}^3b_ia_i=\underline{b}^t\underline{a}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;橫向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=(a_1,a_2,a_3), \underline{b}=(b_1,b_2,b_3)\)&lt;/span&gt; 的內積：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\underline{b}^t=(a_1,a_2,a_3)\left( \begin{array}{c} b_1\\ b_2\\ b_3 \end{array} \right)=a_1b_1+a_2b_2+a_3b_3\\=\sum\limits_{i=1}^3a_ib_i=\sum\limits_{i=1}^3b_ia_i=\underline{b}\underline{a}^t\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;完全相同的兩個列向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{x}=\left( \begin{array}{c} x_1\\ x_2\\ x_3 \end{array} \right),\;\underline{x}=\left( \begin{array}{c} x_1\\ x_2\\ x_3 \end{array} \right)\)&lt;/span&gt; 的內積：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^t\underline{x}=(x_1,x_2,x_3)\left( \begin{array}{c} x_1\\ x_2\\ x_3 \end{array} \right)\\=x_1^2+x_2^2+x_3^2=\sum\limits_{i=1}^3x_i\cdot x_i=\sum\limits_{i=1}^3x_i^2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;完全相同的兩個橫向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{y}=(y_1,y_2,y_3), \underline{y}=(y_1,y_2,y_3)\)&lt;/span&gt; 的內積：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{y}\underline{y}^t=(y_1,y_2,y_3)\left( \begin{array}{c} y_1\\ y_2\\ y_3 \end{array} \right)\\=y_1^2+y_2^2+y_3^2=\sum\limits_{i=1}^3y_i\cdot y_i=\sum\limits_{i=1}^3y_i^2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=(2,0,-1), \underline{b}=(4,-2,8)\)&lt;/span&gt; 的內積：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\underline{b}^t=(2,0,-1)\left( \begin{array}{c} 4\\ -2\\ 8 \end{array} \right)=2\times4+0\times(-2)+(-1)\times8=0\)&lt;/span&gt; &lt;br&gt;
因此我們稱這兩個向量正交。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{1}=\left( \begin{array}{c} 1\\ 1\\ 1 \end{array} \right), \underline{x}=\left( \begin{array}{c} x_1\\ x_2\\ x_3 \end{array} \right)\)&lt;/span&gt; 時：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{1}^t\underline{x}=1\cdot x_1+1\cdot x_2+1\cdot x_3 =\sum\limits_{i=1}^3x_i=\underline{x}^t\underline{1}\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{1}^t\underline{1}=\sum\limits_{i=1}^31\cdot 1=3\)&lt;/span&gt; &lt;br&gt;
前者的內積與後者內積的商： &lt;span class=&#34;math inline&#34;&gt;\(\frac{\underline{1}^t\underline{x}}{\underline{1}^t\underline{1}}=\frac{x_1+x_2+x_3}{3}\)&lt;/span&gt; 我們在統計學中用 &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; (平均值) 來標記。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;問題-如果向量-underlinea-underlineb-有內積-請問有沒有所謂的外積-outer-product&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;問題： 如果，向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}, \underline{b}\)&lt;/span&gt; 有內積， 請問有沒有所謂的外積 (outer product) ？&lt;/h5&gt;
&lt;/div&gt;
&lt;div id=&#34;回答-有不過僅限於3維度的向量&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;回答： 有。不過，僅限於3維度的向量：&lt;/h5&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} a_1\\ a_2\\ a_3 \end{array} \right), \underline{b}=\left( \begin{array}{c} b_1\\ b_2\\ b_3 \end{array} \right)\)&lt;/span&gt; 的外積，我們用 &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; 來表示，寫作： &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\times\underline{b}\)&lt;/span&gt;。 其運算被定義爲：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\times\underline{b}=\left( \begin{array}{c} a_2b_3-a_3b_2\\ a_3b_1-a_1b_3\\ a_1b_2-a_2b_1 \end{array}\right)\)&lt;/span&gt;。與內積不同的是，外積運算的結果仍然是&lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt;維度的向量。外積有如下的性質：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\times\underline{b}=-\underline{b}\times\underline{a}\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;向量的長度-length&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;向量的長度 (length)&lt;/h2&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;p&gt;&lt;span id=&#34;thm:unnamed-chunk-2&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 2  (vector length)  &lt;/strong&gt;&lt;/span&gt;向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\)&lt;/span&gt; 的內積 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}^t\underline{a}\)&lt;/span&gt; 的平方根中，非負的量，我們稱之爲向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\)&lt;/span&gt; 的&lt;strong&gt;長度&lt;/strong&gt;或者&lt;strong&gt;大小&lt;/strong&gt;。也就是：&lt;span class=&#34;math inline&#34;&gt;\(\sqrt{\underline{a}^t\underline{a}}\)&lt;/span&gt;。記作：&lt;span class=&#34;math inline&#34;&gt;\(\| \underline{a} \|\)&lt;/span&gt;。&lt;/p&gt;
兩個向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}, \underline{b}\)&lt;/span&gt; 類型(type：大小，維度)相同時，他們的差 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}-\underline{b}\)&lt;/span&gt; 依然是向量，這個新向量的長度爲：&lt;span class=&#34;math inline&#34;&gt;\(\| \underline{a}-\underline{b} \| = \sqrt{(\underline{a}-\underline{b})^t(\underline{a}-\underline{b})}\)&lt;/span&gt;
&lt;/div&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}=\left( \begin{array}{c} x_1\\ x_2\\ x_3 \end{array} \right)\)&lt;/span&gt; 的長度爲： &lt;span class=&#34;math inline&#34;&gt;\(\| \underline{x} \| =\sqrt{\underline{x}^t\underline{x}}=\sqrt{x_1^2+x_2^2+x_3^2}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=(a_1,a_2,a_3)\)&lt;/span&gt; 的長度爲： &lt;span class=&#34;math inline&#34;&gt;\(\| \underline{a} \| =\sqrt{\underline{a}\underline{a}^t}=\sqrt{a_1^2+a_2^2+a_3^2}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;兩個向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}, \underline{b}\)&lt;/span&gt; 的長度和內積有這樣的關系：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(-\| \underline{a} \|\| \underline{b} \|\leqslant \underline{a}^t\underline{b}\leqslant\| \underline{a} \|\| \underline{b} \|\)&lt;/span&gt;&lt;br&gt;
&lt;strong&gt;證明&lt;/strong&gt;: 以維度爲 &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; 的向量爲例進行證明，其他維度的向量，證明思路類似：&lt;br&gt;
令 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} a_1\\ a_2\\ a_3 \end{array} \right), \underline{b}=\left( \begin{array}{c} b_1\\ b_2\\ b_3 \end{array} \right)\)&lt;/span&gt;， &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; 爲任意實數。平方和：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\sum\limits_{i=1}^3(a_it+b_i)^2 =(a_1t+b_1)^2+(a_2t+b_2)^2+(a_3t+b_3)^2\\ \;\;\;\;\;\;\;=(a_1^2+a_2^2+a_3^2)t^2+2(a_1b_1+a_2b_2+a_3b_3)t\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;+(b_1^2+b_2^2+b_3^2)\\ \;\;\;\;\;\;\;=\| \underline{a} \|^2t^2+2\underline{a}^t\underline{b}t+\| \underline{b} \|^2\geqslant0\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\therefore \| \underline{a} \|^2(t+\frac{\| \underline{b} \|^2}{2\| \underline{a} \|^2})^2+\| \underline{b} \|^2-\frac{(2\underline{a}^t\underline{b})^2}{4\| \underline{a} \|^2}\geqslant0\)&lt;/span&gt;&lt;br&gt;
可見這是一個&lt;strong&gt;關於 &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; 的絕對不等式&lt;/strong&gt;。因此，&lt;strong&gt;判別式&lt;/strong&gt;：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\((2\underline{a}^t\underline{b})^2-4\times\| \underline{a} \|^2\| \underline{b} \|^2\leqslant0\\ \therefore (\underline{a}^t\underline{b})^2\leqslant\| \underline{a} \|^2\| \underline{b} \|^2\\ \therefore -\| \underline{a} \|\| \underline{b} \|\leqslant \underline{a}^t\underline{b}\leqslant \| \underline{a} \|\| \underline{b} \|\)&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\divideontimes\)&lt;/span&gt; 兩向量內積，除以兩向量各自的長度(正)，在統計學中被成爲是&lt;strong&gt;相關系數&lt;/strong&gt;，寫作 &lt;span class=&#34;math inline&#34;&gt;\(r=\frac{\underline{a}^t\underline{b}}{\| \underline{a} \|\| \underline{b} \|}\)&lt;/span&gt;，我們從上面的不等式也可以得出， &lt;span class=&#34;math inline&#34;&gt;\(-1 \leqslant r \leqslant 1\)&lt;/span&gt; 另外，兩個向量又可以表示爲兩條射線，這兩條射線構成的角度如果爲 &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(\cos\theta=r =\frac{\underline{a}^t\underline{b}}{\| \underline{a} \|\| \underline{b} \|}\)&lt;/span&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;兩個向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}, \underline{b}\)&lt;/span&gt; 的和 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}+\underline{b}\)&lt;/span&gt; 也是一個新的向量。這三個向量之間有：&lt;span class=&#34;math inline&#34;&gt;\(\| \underline{a}+\underline{b} \|\leqslant\| \underline{a} \|+\| \underline{b} \|\)&lt;/span&gt;。這個關系被稱爲&lt;strong&gt;三角不等式&lt;/strong&gt;，或者&lt;strong&gt;三角關系&lt;/strong&gt;(triangular inequality)。&lt;br&gt;
&lt;strong&gt;證明&lt;/strong&gt;：此處亦爲了簡便起見使用維度爲 &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; 的向量，即，前述3.的 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}, \underline{b}\)&lt;/span&gt;：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\| \underline{a}+\underline{b}\|^2=(a_1+b_1)^2+(a_2+b_2)^2+(a_3+b_3)^2\\ \;\;\;\;\;\;\;=(a_1^2+a_2^2+a_3^3)+2(a_1b_1+a_2b_2+a_3b_3)+(b_1^2+b_2^2+b_3^2)\\ \;\;\;\;\;\;\;=\| \underline{a} \|^2+2\underline{a}^t\underline{b}+\| \underline{b} \|^2\)&lt;/span&gt;&lt;br&gt;
如果我們把前面問題3.中的不等式代入：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\| \underline{a} \|^2+2\underline{a}^t\underline{b}+\| \underline{b} \|^2\leqslant \| \underline{a} \|^2+2\| \underline{a} \|\| \underline{b} \|+\| \underline{b} \|^2\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;=(\| \underline{a} \|+\| \underline{b} \|)^2\\ \therefore \| \underline{a}+\underline{b}\|^2 \leqslant (\| \underline{a} \|+\| \underline{b} \|)^2\\ \therefore \| \underline{a}+\underline{b}\|\leqslant\| \underline{a} \|+\| \underline{b} \|\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;向量正規化-normalize&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;向量正規化 normalize&lt;/h2&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;p&gt;&lt;span id=&#34;thm:unnamed-chunk-3&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 3  (normalize)  &lt;/strong&gt;&lt;/span&gt;長度不爲 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; 的任意向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}(\neq\underline{0})\)&lt;/span&gt;，如果將它轉變成長度爲 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; 的向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{e}_{\underline{a}}\)&lt;/span&gt;。這個過程被叫做向量的正規化(normalize)。通常只要將向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\)&lt;/span&gt; 除以他的長度 &lt;span class=&#34;math inline&#34;&gt;\(\| \underline{a} \|\)&lt;/span&gt; 即可。&lt;/p&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{e}_{\underline{a}}=\frac{\underline{a}}{\| \underline{a} \|}=\frac{1}{\| \underline{a} \|}\underline{a}\)&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} a_1\\ a_2\\ a_3 \end{array} \right)\)&lt;/span&gt;， 則有 &lt;span class=&#34;math inline&#34;&gt;\(\underline{e}_{\underline{a}}=\frac{1}{\sqrt{a_1^2+a_2^2+a_3^2}}\left( \begin{array}{c} a_1\\ a_2\\ a_3 \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{b}=\left( \begin{array}{c} -2\\ 1\\ 2 \end{array} \right)\)&lt;/span&gt;，則有 &lt;span class=&#34;math inline&#34;&gt;\(\underline{e}_{\underline{a}}=\frac{1}{\sqrt{(-2)^2+1^2+2^2}}\left( \begin{array}{c} -2\\ 1\\ 2 \end{array} \right)=\left( \begin{array}{c} -\frac{2}{3}\\ \frac{1}{3}\\ \frac{2}{3} \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記9</title>
      <link>https://wangcc.me/post/2017-02-18/</link>
      <pubDate>Sat, 18 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-18/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;特殊向量&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;特殊向量&lt;/h2&gt;
&lt;div id=&#34;零向量-zero-vector-null-vector&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;零向量 (zero vector, null vector)&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;全部的成分均爲&lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;的向量，我們稱之爲&lt;strong&gt;零向量(zero vector, null vector)&lt;/strong&gt;, 寫作： &lt;span class=&#34;math inline&#34;&gt;\(\underline{0}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;注意與&lt;strong&gt;標量(scalar)&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; 相區分。&lt;/li&gt;
&lt;li&gt;如果想要加注零向量的維度，我們可以在右下角加上 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;：&lt;span class=&#34;math inline&#34;&gt;\(\underline{0}_n\)&lt;/span&gt; ，意爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 維度的零向量。&lt;/li&gt;
&lt;li&gt;不是零向量的向量又被叫做，&lt;strong&gt;非零向量(non-zero vector, non-null vector)&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;例如： 列向量：&lt;span class=&#34;math inline&#34;&gt;\(\underline{0}_3=\left( \begin{array}{c} 0\\ 0\\ 0\\ \end{array} \right)\)&lt;/span&gt;， 行向量：&lt;span class=&#34;math inline&#34;&gt;\(\underline{0}_3^t=(0,0,0)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;向量-vector-with-all-elements-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; 向量 (vector with all elements 1)&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;當一個向量的全部成分都是數字 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;，我們稱這個向量爲 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; 向量。 &lt;span class=&#34;math inline&#34;&gt;\(\underline{1}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;這裏也需要注意與&lt;strong&gt;標量&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; 相區分。&lt;/li&gt;
&lt;li&gt;如果想要加注&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;向量的維度，我們可以在右下角加上 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;：&lt;span class=&#34;math inline&#34;&gt;\(\underline{1}_n\)&lt;/span&gt; ，意爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 維度的&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;向量。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;例如：列向量：&lt;span class=&#34;math inline&#34;&gt;\(\underline{1}_4=\left( \begin{array}{c} 1\\ 1\\ 1\\ 1 \end{array} \right)\)&lt;/span&gt;， 行向量：&lt;span class=&#34;math inline&#34;&gt;\(\underline{1}_4^t=(1,1,1,1)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;第-i-基本向量&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;第 &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; 基本向量&lt;/h4&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-1&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 1  (fundamental vector)  &lt;/strong&gt;&lt;/span&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 維度的向量，假如它的第 &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; 個成分是自然數 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;，其他的成分全部都是 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;， 我們稱這樣的向量爲&lt;strong&gt;第&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(\textbf{i}\)&lt;/span&gt; &lt;strong&gt;基本向量 (fundamental vector)&lt;/strong&gt;。寫作 &lt;span class=&#34;math inline&#34;&gt;\(\underline{\smash{e}}_i\)&lt;/span&gt;。
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;平時我們較少用到一個單獨的基本向量。大多情況下我們用的是由 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個單獨向量組成的一組向量。這個類型的向量與坐標軸的關系緊密。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如：維度爲4的第 &lt;span class=&#34;math inline&#34;&gt;\(1\sim4\)&lt;/span&gt; 基本向量：&lt;span class=&#34;math inline&#34;&gt;\(\underline{e}_1=\left( \begin{array}{c} 1\\ 0\\ 0\\ 0 \end{array} \right), \; \underline{e}_2=\left( \begin{array}{c} 0\\ 1\\ 0\\ 0 \end{array} \right), \; \underline{e}_3=\left( \begin{array}{c} 0\\ 0\\ 1\\ 0 \end{array} \right), \; \underline{e}_4=\left( \begin{array}{c} 0\\ 0\\ 0\\ 1 \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;單位向量-unit-vector&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;單位向量 (unit vector)&lt;/h4&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-2&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 2  (unit vector)  &lt;/strong&gt;&lt;/span&gt;求向量的各個成分平方和的正平方根，當結果爲 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; 時，這個向量被稱作&lt;strong&gt;單位向量(unit vector)&lt;/strong&gt;。寫作： &lt;span class=&#34;math inline&#34;&gt;\(\underline{e}\)&lt;/span&gt;。
&lt;/div&gt;
&lt;p&gt;例如： 因爲 &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{(\frac{2}{3})^2+(-\frac{1}{3})^2+(\frac{2}{3})^2}=1\)&lt;/span&gt;，所以我們稱向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{e}=\left( \begin{array}{c} \frac{2}{3}\\ -\frac{1}{3}\\ \frac{2}{3}\\ \end{array} \right)\)&lt;/span&gt; 爲&lt;strong&gt;單位向量&lt;/strong&gt;。另外，&lt;span class=&#34;math inline&#34;&gt;\((\frac{1}{\sqrt{2}},-\frac{1}{\sqrt{2}},0)^t, \; (\frac{2}{\sqrt{6}},\frac{1}{\sqrt{6}},-\frac{1}{\sqrt{6}})^t\)&lt;/span&gt;，以及前一項的&lt;strong&gt;第 &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; 基本向量&lt;/strong&gt;，都是單位向量。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;向量的計算與相等&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;向量的計算，與相等&lt;/h2&gt;
&lt;div id=&#34;向量的和與差&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;向量的和與差&lt;/h4&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-3&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 3  (vectorplus)  &lt;/strong&gt;&lt;/span&gt;類型(type)/成分，維度相同的向量之間的加減運算定義爲：相對應的成分之間的和或差。
&lt;/div&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} a_1\\ a_2\\ \vdots\\ a_n \end{array} \right), \; \underline{b}=\left( \begin{array}{c} b_1\\ b_2\\ \vdots\\ b_n \end{array} \right)\)&lt;/span&gt;，則有： &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\pm\underline{b}=\left( \begin{array}{c} a_1\\ a_2\\ \vdots\\ a_n \end{array} \right)\pm\left( \begin{array}{c} b_1\\ b_2\\ \vdots\\ b_n \end{array} \right)=\left( \begin{array}{c} a_1 \pm b_1\\ a_2 \pm b_2\\ \vdots\\ a_n \pm b_n \end{array} \right)\)&lt;/span&gt; &lt;strong&gt;複号同順&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}= (a_1,a_2,\cdots,a_n), \; \underline{b} = (b_1,b_2,\cdots,b_n)\)&lt;/span&gt;，則有： &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\pm\underline{b}=(a_1,a_2,\cdots,a_n)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+(b_1,b_2,\cdots,b_n)\\ \;\;\;\;\;\;\;\;\;\;=(a_1 \pm b_1, a_2 \pm b_2, \cdots, a_n \pm b_n)\)&lt;/span&gt; &lt;br&gt;&lt;strong&gt;複号同順&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;練習&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;練習&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} 6\\ 7\\ 8\\ \end{array} \right),\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\underline{b}=\left( \begin{array}{c} 1\\ 3\\ 5\\ \end{array} \right)\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}+\underline{b} =\left( \begin{array}{c} 6+1\\ 7+3\\ 8+5\\ \end{array} \right)=\left( \begin{array}{c} 7\\ 10\\ 13\\ \end{array} \right)\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}-\underline{b}=\left( \begin{array}{c} 6-1\\ 7-3\\ 8-5\\ \end{array} \right)=\left( \begin{array}{c} 5\\ 4\\ 3\\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{c}=(6,0,9), \underline{d}=(7,-3,2)\)&lt;/span&gt; 時，&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{c}+\underline{d}=(6+7,0-3,9+2)=(13,-3,11)\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{c}-\underline{d}=(6-7,0-(-3),9-2)=(-1,3,7)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;向量的標量乘法scalar-multiplication&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;向量的標量乘法(scalar multiplication)&lt;/h4&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-4&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 4  (scalar multiplication)  &lt;/strong&gt;&lt;/span&gt;向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\)&lt;/span&gt; 的所有成分同時乘以標量 &lt;span class=&#34;math inline&#34;&gt;\((k)\)&lt;/span&gt; 以後的向量，我們稱爲 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\)&lt;/span&gt; 的標量 &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; 倍。寫作： &lt;span class=&#34;math inline&#34;&gt;\(k\underline{a}\)&lt;/span&gt;。特別地，當 &lt;span class=&#34;math inline&#34;&gt;\(k=1\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(1\underline{a}=\underline{a}\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(k=-1\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\((-1)\underline{a}=-\underline{a}\)&lt;/span&gt;。另外 &lt;span class=&#34;math inline&#34;&gt;\(k=0\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(0\underline{a}=\underline{0}\)&lt;/span&gt;。注意此時&lt;span class=&#34;math inline&#34;&gt;\(\underline{0}\)&lt;/span&gt;是與&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\)&lt;/span&gt;同維度的零向量。不可寫作標量的 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;。
&lt;span class=&#34;math display&#34;&gt;\[k\underline{a}=k\left(
\begin{array}{c}
a_1\\
a_2\\
\vdots\\
a_n
\end{array}
\right)=\left(
\begin{array}{c}
ka_1\\
ka_2\\
\vdots\\
ka_n
\end{array}
\right), \\k\underline{a}=k(a_1,a_2,\cdots,a_n)=(ka_1,ka_2,\cdots,ka_n)\]&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;練習-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;練習&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(k=5, l=\frac{1}{9}, \underline{a}=\left( \begin{array}{c} 3\\ 2\\ -7\\ \end{array} \right)\)&lt;/span&gt; 時，&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(k\underline{a}=5\left( \begin{array}{c} 3\\ 2\\ -7\\ \end{array} \right)=\left( \begin{array}{c} 5\times3\\ 5\times2\\ 5\times(-7)\\ \end{array} \right)=\left( \begin{array}{c} 15\\ 10\\ -35\\ \end{array} \right)\)&lt;/span&gt;, &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(l\underline{a}=\frac{1}{9}\left( \begin{array}{c} 3\\ 2\\ -7\\ \end{array} \right)=\left( \begin{array}{c} \frac{1}{9}\times3\\ \frac{1}{9}\times2\\ \frac{1}{9}\times(-7)\\ \end{array} \right)=\left( \begin{array}{c} \frac{1}{3}\\ \frac{2}{9}\\ -\frac{7}{9}\\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} 3\\ -2\\ 4\\ \end{array} \right), \underline{b}=\left( \begin{array}{c} 1\\ 1\\ -3\\ \end{array} \right), \underline{c}=\left( \begin{array}{c} 0\\ 5\\ 2\\ \end{array} \right)\)&lt;/span&gt; 時，&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(2\underline{a}-\underline{b}+3\underline{c}=\left( \begin{array}{c} 2\times3\\ 2\times(-2)\\ 2\times4\\ \end{array} \right)-\left( \begin{array}{c} 1\\ 1\\ -3\\ \end{array} \right)\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+\left( \begin{array}{c} 3\times0\\ 3\times5\\ 3\times2\\ \end{array} \right)=\left( \begin{array}{c} 6-1+0\\ -4-1+15\\ 8-(-3)+6\\ \end{array} \right)=\left( \begin{array}{c} 5\\ 10\\ 17\\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;向量相等-equal&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;向量相等 equal&lt;/h4&gt;

&lt;div class=&#34;theorem&#34;&gt;
&lt;span id=&#34;thm:unnamed-chunk-5&#34; class=&#34;theorem&#34;&gt;&lt;strong&gt;Theorem 5  (vectors equal)  &lt;/strong&gt;&lt;/span&gt;類型(type)/成分，維度相同的向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}, \underline{b}\)&lt;/span&gt;，其對應成分完全一致，我們就稱 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\underline{b}\)&lt;/span&gt;，此時有 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}-\underline{b}=\underline{0}\)&lt;/span&gt; &lt;strong&gt;零向量&lt;/strong&gt;。
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;練習-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;練習：&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} a_1\\ a_2\\ a_3\\ \end{array} \right), \underline{b}=\left( \begin{array}{c} b_1\\ b_2\\ b_3\\ \end{array} \right)\)&lt;/span&gt; 如果相等，那麼 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\underline{b}\)&lt;/span&gt;，&lt;br&gt;即：&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} \left\{ \begin{array}{ll} a_1 = b_1 \\ a_2 = b_2 \\ a_3 = b_3 \end{array} \right. \end{align}\)&lt;/span&gt; 等價於：&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}-\underline{b}=0\)&lt;/span&gt;，或者&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} \left\{ \begin{array}{ll} a_1 - b_1 =0\\ a_2 - b_2 =0\\ a_3 - b_3 =0 \end{array} \right. \end{align}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;向量等式：&lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} a_{11}x_1+a_{12}x_2+a_{13}x_3\\ a_{21}x_1+a_{22}x_2+a_{23}x_3\\ a_{31}x_1+a_{32}x_2+a_{33}x_3\\ \end{array} \right)=\left( \begin{array}{c} b_1\\ b_2\\ b_3\\ \end{array} \right)\)&lt;/span&gt; 等價於三個等式的連立方程：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} \left\{ \begin{array}{ll} a_{11}x_1+a_{12}x_2+a_{13}x_3= b_1\\ a_{21}x_1+a_{22}x_2+a_{23}x_3= b_2\\ a_{31}x_1+a_{32}x_2+a_{33}x_3= b_3 \end{array} \right. \end{align}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;求滿足 &lt;span class=&#34;math inline&#34;&gt;\(5\left( \begin{array}{c} a_1\\ a_2\\ a_3\\ \end{array} \right)+\left( \begin{array}{c} 2\\ 5\\ -1\\ \end{array} \right)=\left( \begin{array}{c} 12\\ 25\\ 29\\ \end{array} \right)\)&lt;/span&gt; 的向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} a_1\\ a_2\\ a_3\\ \end{array} \right)\)&lt;/span&gt;。&lt;br&gt;
解：&lt;span class=&#34;math inline&#34;&gt;\(5\left( \begin{array}{c} a_1\\ a_2\\ a_3\\ \end{array} \right)=\left( \begin{array}{c} 12\\ 25\\ 29\\ \end{array} \right)-\left( \begin{array}{c} 2\\ 5\\ -1\\ \end{array} \right)=\left( \begin{array}{c} 10\\ 20\\ 30\\ \end{array} \right)\)&lt;/span&gt;&lt;br&gt;
因此，&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} a_1\\ a_2\\ a_3\\ \end{array} \right)=\left( \begin{array}{c} 2\\ 4\\ 6\\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記8</title>
      <link>https://wangcc.me/post/2017-02-17/</link>
      <pubDate>Fri, 17 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-17/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;向量-vector&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;向量 vector&lt;/h2&gt;
&lt;div id=&#34;列向量-column-vector&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;列向量 column vector&lt;/h3&gt;
&lt;p&gt;在等號的右側，將數字寫成一列，左右用圓括號或者方括號包含在內的形式，被叫做列向量(column vector)：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} a_1\\ a_2\\ \vdots\\ a_i\\ \vdots\\ a_n \end{array} \right), \;\; \textbf{a}=\left[ \begin{array}{c} a_1\\ a_2\\ \vdots\\ a_i\\ \vdots\\ a_n \end{array} \right]\)&lt;/span&gt;&lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;我們接下來將會繼續定義，向量的加減法，標量乘法(scalar multiplication)。把上述的向量用一個文字表示的時候，通常會記爲下劃線 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\)&lt;/span&gt;，或者是加粗的小寫字母： &lt;span class=&#34;math inline&#34;&gt;\(\bf{a}\)&lt;/span&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;構成向量的各個數字，被命名爲&lt;strong&gt;成分(component, element, entry)&lt;/strong&gt;，從上往下第 &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; 個成分稱爲第 &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; 成分。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;成分的個數爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;，就被稱爲這個向量具有 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個&lt;strong&gt;維度(次元，dimension)&lt;/strong&gt;，或者說這個向量的維度爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;。成分可以是數字，也可以是函數，或者式子。如果兩個列向量的維度一致，我們稱這兩個列向量的&lt;strong&gt;型(size, order)&lt;/strong&gt;,或者 &lt;strong&gt;類型(type)&lt;/strong&gt; 一致。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;成分只有一個的向量，被特別稱爲&lt;strong&gt;標量(scalar)&lt;/strong&gt;，原則上不加括號。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;將向量成分全部羅列出來，寫成上面的形式的過程，被稱爲&lt;strong&gt;成分表示&lt;/strong&gt;。在多元變量分析中，我們說到向量，多默認指的就是列向量。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{b}=\left( \begin{array}{c} 16\\ 59\\ 80\\ \end{array} \right)=\left[ \begin{array}{c} 16\\ 59\\ 80\\ \end{array} \right]=\textbf{b}\)&lt;/span&gt;&lt;br&gt;今後我們都用字母帶下劃線，圓括號包含數字的方式表示向量。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{c}=\left( \begin{array}{c} \sin t+\cos t\\ \cos t+\tan t-2\\ \tan t + \sin t\\ \end{array} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;當 &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; 爲 &lt;span class=&#34;math inline&#34;&gt;\(a_1,a_2,a_3\)&lt;/span&gt; 的函數時，寫作 &lt;span class=&#34;math inline&#34;&gt;\(F(a_1,a_2,a_3)\)&lt;/span&gt;。 以&lt;strong&gt;三個未知數的偏微分&lt;/strong&gt;爲成分的向量(梯度向量，gradient vector)，寫成下面等式左邊的形式。可以簡略寫作: &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} a_1\\ a_2\\ a_3\\ \end{array} \right)\)&lt;/span&gt;。&lt;span class=&#34;math inline&#34;&gt;\(\nabla\)&lt;/span&gt;讀作&lt;code&gt;nabla&lt;/code&gt;。&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\left( \begin{array}{c} \frac{\partial F}{\partial a_1}\\ \frac{\partial F}{\partial a_2}\\ \frac{\partial F}{\partial a_3}\\ \end{array} \right)=\frac{\partial F}{\partial \underline{a}}=\nabla_{\underline{a}}F\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;橫向量行向量-row-vector&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;橫向量(行向量) row vector&lt;/h2&gt;
&lt;p&gt;在等號的右側，將數字寫成一行，左右用圓括號或者方括號包含在內的形式，被叫做橫向量(row vector):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=(a_1,a_2,\cdots,a_j,\cdots,a_n), \; \textbf{a}=[a_1,a_2,\cdots,a_j,\cdots,a_n]\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;成分，維度，類型等的定義與列向量相同。另外注意，維度相同，但是一個是橫向量，一個是列向量的話，這兩個向量是不同類型的。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}=(x_1,x_2,x_3)\)&lt;/span&gt;&lt;br&gt;
有時也可以不用逗號分隔成分。 寫作 &lt;span class=&#34;math inline&#34;&gt;\((x_1 \; x_2 \;x_3)\)&lt;/span&gt;。下同。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((\frac{\partial F}{\partial x_1},\frac{\partial F}{\partial x_2},\frac{\partial F}{\partial x_3})=\frac{\partial F}{\partial \underline{x}}=\nabla_{\underline{x}F}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{u}=(\sin\theta\cos\phi, \sin\theta\cos\theta, \cos\theta)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;向量的轉置-vector-transpose&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;向量的轉置 (vector transpose)&lt;/h2&gt;
&lt;p&gt;將列向量的每個成分，按照從上到下的順序，一字橫着排開寫成橫向量。這個向量稱爲原來列向量的轉置向量(transposed vector)。反之亦然。&lt;/p&gt;
&lt;p&gt;向量 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}\)&lt;/span&gt; 的轉置向量，可以標記爲 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}^t,\;\underline{a}^\prime,\;^t\underline{a},\;\underline{a}^T, \;^T\underline{a}\)&lt;/span&gt; 各種形式。今後統一用 &lt;span class=&#34;math inline&#34;&gt;\(\underline{a}^t\)&lt;/span&gt;。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}=\left( \begin{array}{c} a_1\\ a_2\\ a_3\\ \end{array} \right)\)&lt;/span&gt; 的轉置向量我們會記爲：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{a}^t=\left( \begin{array}{c} a_1\\ a_2\\ a_3\\ \end{array} \right)^t=(a_1,a_2,a_3)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}=(x_1.x_2,x_3)\)&lt;/span&gt; 的轉置向量我們會記爲：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\underline{x}^t=(x_1.x_2,x_3)^t=\left( \begin{array}{c} x_1\\ x_2\\ x_3\\ \end{array} \right)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記7</title>
      <link>https://wangcc.me/post/2017-02-16/</link>
      <pubDate>Thu, 16 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-16/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;分解平方和-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;分解平方和 1&lt;/h2&gt;
&lt;p&gt;樣本量均爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 的兩變量 &lt;span class=&#34;math inline&#34;&gt;\(z, \hat{z}\)&lt;/span&gt; 如下表，已知這兩個變量滿足條件：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\bar{z}=\frac{1}{n}\sum\limits_{i=1}^nz_i=\frac{1}{n}\sum\limits_{i=1}^n\hat{z}_i=\bar{\hat{z}},\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\sum\limits_{i=1}^n(z_i-\hat{z_i})(\hat{z_i}-\bar{z})=0\)&lt;/span&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;個体の番号&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;変量 &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;変量 &lt;span class=&#34;math inline&#34;&gt;\(\hat{z}\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(z_1\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat{z}_1\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(z_2\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat{z}_2\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(z_i\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat{z}_i\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(z_n\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat{z}_n\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;此時我們有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;全平方和&lt;/strong&gt;(全変動，總平方和，總變動， &lt;strong&gt;Total sum of Squares&lt;/strong&gt;)：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(S_T=(z_i-\bar{z})^2+(z_2-\bar{z})^2+\cdots+(z_n-\bar{z})^2\\ \;\;\;\;=\sum\limits_{i=1}^n(z_i-\bar{z})^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;回歸平方和&lt;/strong&gt;(回歸變動，&lt;strong&gt;Regression sum of Squares&lt;/strong&gt;)&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(S_R=(\hat{z_1}-\bar{\hat{z}})^2+(\hat{z_2}-\bar{\hat{z}})^2+\cdots+(\hat{z_n}-\bar{\hat{z}})^2\\ \;\;\;\;=\sum\limits_{i=1}^n(\hat{z_i}-\bar{\hat{z}})^2=\sum\limits_{i=1}^n(\hat{z_i}-\bar{z})^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;殘差平方和&lt;/strong&gt;(誤差平方和，殘差變動，誤差變動，&lt;strong&gt;residual sum of Squares&lt;/strong&gt;)&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(S_e=(z_1-\hat{z_1})^2+(z_2-\hat{z_2})^2+\cdots+(z_n-\hat{z_n})^2\\ \;\;\;\;=\sum\limits_{i=1}^n(z_i-\hat{z_i})^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;上面三個平方和之間，有如下的關系：
&lt;span class=&#34;math display&#34; id=&#34;eq:Sumofsquares&#34;&gt;\[\begin{equation}
  S_T=S_R+S_e
  \tag{1}
  \end{equation}\]&lt;/span&gt;
&lt;br&gt;
既：全平方和等於殘差平方和與回歸平方和之和。&lt;a href=&#34;#eq:Sumofsquares&#34;&gt;(1)&lt;/a&gt;式被稱爲&lt;strong&gt;平方和的分解(decomposition of sum of squares)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;證明refeqsumofsquares式&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;證明&lt;a href=&#34;#eq:Sumofsquares&#34;&gt;(1)&lt;/a&gt;式&lt;/h5&gt;
&lt;/div&gt;
&lt;div id=&#34;解&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;解：&lt;/h5&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{equation}
\begin{split}
S_T &amp;amp; = \sum\limits_{i=1}^n(z_i-\bar{z})^2 \\
&amp;amp; = \sum\limits_{i=1}^n\left\{(z_i-\hat{z_i})+(\hat{z_i}-\bar{z})\right\}^2\\
&amp;amp; = \sum\limits_{i=1}^n\left\{(z_i-\hat{z_i})^2+(\hat{z_i}-\bar{z})^2+2(z_i-\hat{z_i})(\hat{z_i}-\bar{z})\right\}\\
&amp;amp; = \sum\limits_{i=1}^n(z_i-\hat{z_i})^2+\sum\limits_{i=1}^n(\hat{z_i}-\bar{z})^2 + 0\\
&amp;amp; = S_e + S_R
\end{split}
\end{equation}
\]&lt;/span&gt;
最後一步等式，利用了一開始給出的條件 &lt;span class=&#34;math inline&#34;&gt;\(\sum\limits_{i=1}^n(z_i-\hat{z_i})(\hat{z_i}-\bar{z})=0\)&lt;/span&gt;&lt;br&gt;
這裏的平方和分解與&lt;strong&gt;回歸分析&lt;/strong&gt;有着緊密的聯系。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;分解平方和-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;分解平方和 2&lt;/h2&gt;
&lt;p&gt;有樣本量爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 的變量 &lt;span class=&#34;math inline&#34;&gt;\(z_1\)&lt;/span&gt; 與樣本量爲 &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; 的變量 &lt;span class=&#34;math inline&#34;&gt;\(z_2\)&lt;/span&gt; 的數據如下表：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;変量 &lt;span class=&#34;math inline&#34;&gt;\(z_1\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;変量 &lt;span class=&#34;math inline&#34;&gt;\(z_2\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(z_{11}\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(z_{12}\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(z_{21}\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(z_{22}\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(z_{i1}\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(z_{i2}\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(z_{n1}\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(z_{m2}\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;此時我們有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;樣本&lt;strong&gt;平均值&lt;/strong&gt;： &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\bar{z_1}=\frac{1}{n}\sum\limits_{i=1}^nz_{i1}, \;\bar{z_2}=\frac{1}{m}\sum\limits_{i=1}^mz_{i2}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;樣本&lt;strong&gt;總平均值&lt;/strong&gt;： &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\bar{z}=\frac{1}{n+m}(\sum\limits_{i=1}^nz_{i1}+\sum\limits_{i=1}^mz_{i2})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;全&lt;strong&gt;平方和&lt;/strong&gt; (全変動，總平方和，總變動, &lt;strong&gt;Total sum of Squares&lt;/strong&gt;)：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(S_T=\left\{(z_{11}-\bar{z})^2+(z_{21}-\bar{z})^2+\cdots+(z_{n1}-\bar{z})^2\right\}\\ \;\;\;\;\;\;\;\;+\left\{(z_{12}-\bar{z})^2+(z_{22}-\bar{z})^2+\cdots+(z_{m2}-\bar{z})^2\right\}\\ \;\;\;\;=\sum\limits_{i=1}^n(z_{i1}-\bar{z})^2+\sum\limits_{i=1}^m(z_{i2}-\bar{z})^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;羣內平方和&lt;/strong&gt;(組內平方和，級內平方和，羣內變動，級內變動，變量內平方和，變量內變動，&lt;strong&gt;Within-groups sum of Squares&lt;/strong&gt;)：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(S_W=\left\{(z_{11}-\bar{z_1})^2+(z_{21}-\bar{z_1})^2+\cdots+(z_{n1}-\bar{z_1})^2\right\}\\ \;\;\;\;\;\;\;\;+\left\{(z_{12}-\bar{z_2})^2+(z_{22}-\bar{z_2})^2+\cdots+(z_{m2}-\bar{z_2})^2\right\}\\ \;\;\;\;=\sum\limits_{i=1}^n(z_{i1}-\bar{z_1})^2+\sum\limits_{i=1}^m(z_{i2}-\bar{z_2})^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;羣間平方和&lt;/strong&gt;(組間平方和，級間平方和，羣間變動，級間變動，變量間平方和，變量間變動，&lt;strong&gt;Between-groups sum of Squares&lt;/strong&gt;)：&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(S_B=\left\{(\bar{z_1}-\bar{z})^2+(\bar{z_1}-\bar{z})^2+\cdots+(\bar{z_1}-\bar{z})^2\right\}\\ \;\;\;\;\;\;\;\;+\left\{(\bar{z_2}-\bar{z})^2+(\bar{z_2}-\bar{z})^2+\cdots+(\bar{z_2}-\bar{z})^2\right\}\\ \;\;\;\;=\sum\limits_{i=1}^n(\bar{z_1}-\bar{z})^2+\sum\limits_{i=1}^m(\bar{z_2}-\bar{z})^2\\ \;\;\;\;=n(\bar{z_1}-\bar{z})^2+m(\bar{z_2}-\bar{z})^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;上面三個平方和之間有如下的關系：
&lt;span class=&#34;math display&#34; id=&#34;eq:Sumofsqua&#34;&gt;\[\begin{equation}
S_T=S_W+S_B
\tag{2}
\end{equation}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;證明refeqsumofsqua式&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;證明&lt;a href=&#34;#eq:Sumofsqua&#34;&gt;(2)&lt;/a&gt;式&lt;/h5&gt;
&lt;/div&gt;
&lt;div id=&#34;解-1&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;解：&lt;/h5&gt;
&lt;p&gt;注意利用：&lt;span class=&#34;math inline&#34;&gt;\(\sum\limits_{i=1}^n(z_{i1}-\bar{z_1})(\bar{z_1}-\bar{z})=(\bar{z_1}-\bar{z})\sum\limits_{i=1}^n(z_{i1}-\bar{z_1})\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\:=(\bar{z_1}-\bar{z})(\sum\limits_{i=1}^nz_{i1}-n\bar{z_1})\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\:=(\bar{z_1}-\bar{z})(n\bar{z_1}-n\bar{z_1})=0\)&lt;/span&gt;&lt;br&gt;因此&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{equation}
\begin{split}
S_T &amp;amp; = \sum_{i=1}^n(z_{i1}-\bar{z})^2+\sum_{i=1}^m(z_{i2}-\bar{z})^2\\
&amp;amp; = \sum_{i=1}^n\left\{(z_{i1}-\bar{z_1})+(\bar{z_1}-\bar{z})\right\}^2\\
&amp;amp;\;\;\;\;\; + \sum_{i=1}^m\left\{(z_{i2}-\bar{z_2})+(\bar{z_2}-\bar{z})\right\}^2\\
&amp;amp; = \sum_{i=1}^n\left\{(z_{i1}-\bar{z_1})^2+2(z_{i1}-\bar{z_1})(\bar{z_1}-\bar{z})+(\bar{z_1}-\bar{z})^2\right\}\\
&amp;amp;\;\;\;\;\; +\sum_{i=1}^m\left\{(z_{i2}-\bar{z_2})^2+2(z_{i2}-\bar{z_2})(\bar{z_2}-\bar{z})+(\bar{z_2}-\bar{z})^2\right\}\\
&amp;amp; = \sum_{i=1}^n(z_{i1}-\bar{z_1})^2 + n(\bar{z_1}-\bar{z})^2\\
&amp;amp;\;\;\;\;\; + \sum_{i=1}^m(z_{i2}-\bar{z_2})^2 + m(\bar{z_2}-\bar{z})^2\\
&amp;amp; = S_W+S_B
\end{split}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;變量的合成與加權&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;變量的合成與加權&lt;/h2&gt;
&lt;p&gt;我們說，將 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 個變量 &lt;span class=&#34;math inline&#34;&gt;\(x_1,x_2,\cdots,x_p\)&lt;/span&gt; 轉變成一次式：&lt;span class=&#34;math inline&#34;&gt;\(w_1x_1+w_2x_2+\cdots+w_px_p (=\hat{y})\)&lt;/span&gt; 的過程稱爲變量的合成 &lt;strong&gt;(linear combination of variables)&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}\)&lt;/span&gt; 被叫做&lt;strong&gt;合成變量&lt;/strong&gt;。系數 &lt;span class=&#34;math inline&#34;&gt;\(w_1,w_2,\cdots,w_p\)&lt;/span&gt; 被叫做&lt;strong&gt;權重 (weight)&lt;/strong&gt;。假如 &lt;span class=&#34;math inline&#34;&gt;\(x_1,x_2,\cdots,x_p\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 個科目的考試得分，那麼:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(w_1=w_2=\cdots=w_p=1\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(\hat{y}\)&lt;/span&gt; 意思就是 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 個科目的總分&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(w_1=w_2=\cdots=w_p=\frac{1}{p}\)&lt;/span&gt; 時，&lt;span class=&#34;math inline&#34;&gt;\(\hat{y}\)&lt;/span&gt; 意思就是 &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; 個科目的平均分&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;多元變量分析中，我們實質上做的許多事就是思考如何合理的決定這個&lt;strong&gt;權重&lt;/strong&gt;。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記6</title>
      <link>https://wangcc.me/post/2017-02-15/</link>
      <pubDate>Wed, 15 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-15/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;數據的變換&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;數據的變換&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;平均值附近的偏差:
&lt;ul&gt;
&lt;li&gt;各個數值 &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; 與樣本平均值 &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; 的差 &lt;span class=&#34;math display&#34;&gt;\[x_i^\prime=x_i-\bar{x} (i = 1,2,\cdots,n)\]&lt;/span&gt; &lt;br&gt;
稱爲數據 &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; 在它的平均值 &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; 附近的&lt;strong&gt;偏差(deviation)&lt;/strong&gt;。通常我們說&lt;strong&gt;求偏差&lt;/strong&gt;，指的是，對數據 &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; 進行&lt;strong&gt;偏差轉換&lt;/strong&gt;。這個過程又被稱作是&lt;strong&gt;中心變換(centering)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;關於偏差，我們列舉如下兩個有特徵的的&lt;strong&gt;概括統計&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;樣本平均值：
&lt;span class=&#34;math display&#34; id=&#34;eq:samplemean&#34;&gt;\[\begin{equation}
   \bar{x}^\prime=\frac{1}{n}\sum_{i=1}^nx_i^\prime=0
   \tag{1}
   \end{equation}\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;樣本偏差平方和：
&lt;span class=&#34;math display&#34; id=&#34;eq:SSprime&#34;&gt;\[\begin{equation}
  SS^\prime=\sum_{i=1}^n(x^\prime)^2=SS
  \tag{2}
  \end{equation}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;練習證明refeqsamplemean&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;練習：證明&lt;a href=&#34;#eq:samplemean&#34;&gt;(1)&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;div id=&#34;解&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解：&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;證明&lt;a href=&#34;#eq:samplemean&#34;&gt;(1)&lt;/a&gt;&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\bar{x}^\prime=\frac{\sum\limits_{i=1}^n(x_i-\bar{x})}{n}\\
\;\;\;=\frac{\sum\limits_{i=1}^nx_i-n\bar{x}}{n}\\
\;\;\;=\frac{\sum\limits_{i=1}^nx_i}{n}-\bar{x}\\
\;\;\;=\bar{x}-\bar{x}=0\]&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;數據的標準化：
&lt;ul&gt;
&lt;li&gt;將數據 &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; 的平均值 &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; 附近的偏差除以樣本標準偏差 &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt; 從而獲得下面式子所表示的數據 &lt;span class=&#34;math inline&#34;&gt;\(z_i\)&lt;/span&gt; 的過程，被叫做&lt;strong&gt;數據的標準化 (standardization)&lt;/strong&gt;：
&lt;span class=&#34;math display&#34; id=&#34;eq:standardization&#34;&gt;\[\begin{equation}
 z_i=\frac{x_i-\bar{x}}{s}
 \tag{3}
 \end{equation}\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;標準化後的數據 &lt;span class=&#34;math inline&#34;&gt;\(z_i\)&lt;/span&gt; 的&lt;strong&gt;概括統計&lt;/strong&gt;有下列特徵：
&lt;ul&gt;
&lt;li&gt;樣本平均值：
&lt;span class=&#34;math display&#34; id=&#34;eq:samplemeans&#34;&gt;\[\begin{equation}
  \bar{z}=\frac{1}{n}\sum_{i=1}^nz_i=0
  \tag{4}
  \end{equation}\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;樣本方差:
&lt;span class=&#34;math display&#34; id=&#34;eq:Ssquare&#34;&gt;\[\begin{equation}
  s_{z}^2=\frac{1}{n}\sum_{i=1}^nz_i^2=1
  \tag{5}
  \end{equation}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;由於標準化數據具有上述兩個非常顯著的特徵，均值爲 &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;，方差爲 &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;，因此我們實際分析數據過程中常常對數據進行標準化。標準化以後的數據，單位消失，變成了一組&lt;strong&gt;無名數&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\divideontimes\)&lt;/span&gt; 數據的標準化，有時你會看到被定義爲:
&lt;span class=&#34;math display&#34; id=&#34;eq:newstandardization&#34;&gt;\[\begin{equation}
 z_i=\frac{x_i-\bar{x}}{u}
 \tag{6}
 \end{equation}\]&lt;/span&gt; &lt;br&gt;
此時的不偏樣本方差爲：
&lt;span class=&#34;math display&#34; id=&#34;eq:unbsamplevar&#34;&gt;\[\begin{equation}
 u_z^2=\frac{1}{n-1}\sum_{i=1}{n}z_i^2=1
 \tag{7}
 \end{equation}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;變量數據的概括統計&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2變量數據的概括統計：&lt;/h2&gt;
&lt;div id=&#34;樣本量同爲-n-的-2-變量-x_1x_2-的數據表示爲如下表格&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;樣本量同爲 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; 變量 &lt;span class=&#34;math inline&#34;&gt;\(x_1,x_2\)&lt;/span&gt; 的數據，表示爲如下表格：&lt;/h5&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;個体の番号&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;変量 &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;変量 &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(x_{11}\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(x_{12}\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(x_{21}\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(x_{22}\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(x_{i1}\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(x_{i2}\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(x_{n1}\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(x_{n2}\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;按照變量-x_1x_2-各自的定義&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;按照變量 &lt;span class=&#34;math inline&#34;&gt;\(x_1,x_2\)&lt;/span&gt; 各自的定義：&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;樣本&lt;strong&gt;平均值&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(\bar{x_1}=\frac{1}{n}\sum\limits_{i=1}^nx_{i1}, \; \bar{x_2}=\frac{1}{n}\sum\limits_{i=1}^nx_{i2}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;樣本&lt;strong&gt;偏差平方和&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(SS_1=\sum\limits_{i=1}^n(x_{i1}-\bar{x_1})^2, \; SS_2=\sum\limits_{i=1}^n(x_{i2}-\bar{x_2})^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;樣本&lt;strong&gt;方差&lt;/strong&gt;： &lt;span class=&#34;math inline&#34;&gt;\(s_1^2=\frac{SS_1}{n}, \; s_2^2=\frac{SS_2}{n}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;樣本&lt;strong&gt;標準偏差&lt;/strong&gt;： &lt;span class=&#34;math inline&#34;&gt;\(s_1=\sqrt{s_1^2}, \; s_2=\sqrt{s_2^2}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;不偏樣本方差&lt;/strong&gt;： &lt;span class=&#34;math inline&#34;&gt;\(u_1^2=\frac{SS}{n-1}, \; u_2^2=\frac{SS_2}{n-1}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;不偏樣本方差平方根&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(u_1=\sqrt{u_1^2}, \; u_2=\sqrt{u_2^2}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;對於這樣一對變量-x_1x_2-來說我們又可以追加如下的概括統計&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;對於這樣一對變量 &lt;span class=&#34;math inline&#34;&gt;\(x_1,x_2\)&lt;/span&gt; 來說，我們又可以追加如下的概括統計：&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;樣本&lt;strong&gt;總體平均值&lt;/strong&gt;： &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}=\frac{1}{n+n}(\sum\limits_{i-1}^nx_{i1}+\sum\limits_{i-1}^nx_{i2})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;樣本&lt;strong&gt;方差積和(cross-product)&lt;/strong&gt;：
&lt;span class=&#34;math display&#34; id=&#34;eq:crossproduct&#34;&gt;\[\begin{equation}
\begin{split}
S_{12} &amp;amp; = \sum_{i=1}^n(x_{i1}-\bar{x_1})\cdot(x_{i2}-\bar{x_2})\\
&amp;amp; = \sum_{i=1}^n(x_{i1}x_{i2}-\bar{x_1}x_{i2}-x_{i1}\bar{x_2}+\bar{x_1}\bar{x_2})\\
&amp;amp; = \sum_{i=1}^nx_{i1}x_{i2}-\bar{x_1}\sum_{i=1}^nx_{i2}-{\sum_{i=1}^nx_{i1}}\bar{x_2}+n\bar{x_1}\bar{x_2}\\
&amp;amp; = \sum_{i=1}^nx_{i1}x_{i2}-\bar{x_1}\cdot n\bar{x_2}-n\bar{x_1}\cdot\bar{x_2}+n\bar{x_1}\bar{x_2}\\
&amp;amp; = \sum_{i=1}^nx_{i1}x_{i2}-n\cdot\bar{x_1}\cdot\bar{x_2}\\
&amp;amp; = \sum_{i=1}^nx_{i1}x_{i2}-n\cdot\frac{\sum\limits_{i=1}^nx_{i1}}{n}\cdot\frac{\sum\limits_{i=1}^nx_{i2}}{n}\\
&amp;amp; = \sum_{i=1}^nx_{i1}x_{i2}-\frac{1}{n}(\sum_{i=1}^nx_{i1})(\sum_{i=1}^nx_{i2}) = S_{21}
\end{split}
\tag{8}
\end{equation}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;樣本&lt;strong&gt;協方差(covariance，共分散)&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(s_{12}=\frac{S_{12}}{n}=\frac{S_{21}}{n}=s_{21}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;樣本&lt;strong&gt;相關系數 (correlation coefficient)&lt;/strong&gt;： &lt;span class=&#34;math inline&#34;&gt;\(r_{11}=r_{22}=1\)&lt;/span&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:correlation&#34;&gt;\[\begin{equation}
\begin{split}
r_{12} &amp;amp; = \frac{S_{12}}{\sqrt{SS_1\cdot SS_2}}\\
&amp;amp; = \frac{\frac{S_{12}}{n}}{\sqrt{\frac{SS_1}{n}}\cdot\sqrt{\frac{SS_2}{n}}}\\
&amp;amp; = \frac{s_{12}}{s_1s_2}=r_{21}\\
\end{split}
\tag{9}
\end{equation}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;此處我們再來證明一下標準化以後的數據的樣本協方差covariance和標準化以前原來的數據的樣本相關系數correlation-coefficient是相等的&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;此處我們再來證明一下，標準化以後的數據的樣本協方差(covariance)，和標準化以前原來的數據的樣本相關系數(correlation coefficient)是相等的：&lt;/h5&gt;
&lt;p&gt;假設，&lt;span class=&#34;math inline&#34;&gt;\(x_{i1}\)&lt;/span&gt; 標準化以後爲 &lt;span class=&#34;math inline&#34;&gt;\(z_{i1}=\frac{x_{i1}-\bar{x_1}}{s_1}\)&lt;/span&gt;； &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x_{i2}\)&lt;/span&gt; 標準化以後爲 &lt;span class=&#34;math inline&#34;&gt;\(z_{i2}=\frac{x_{i2}-\bar{x_2}}{s_1}\)&lt;/span&gt;。 &lt;br&gt;
此時，&lt;span class=&#34;math inline&#34;&gt;\(z_{i1}, z_{i2}\)&lt;/span&gt; 的樣本協方差可以計算如下:
&lt;span class=&#34;math display&#34; id=&#34;eq:stcorrelation&#34;&gt;\[\begin{equation}
\begin{split}
s_{z_{12}} &amp;amp; = \frac{S_{z_{12}}}{n} \\
&amp;amp; = \frac{1}{n}\cdot\sum_{i=1}^n(z_{i1}-\bar{z_1})(z_{i2}-\bar{z_2})\\
&amp;amp; = \frac{1}{n}\sum_{i=1}^nz_{i1}z_{i2}\\
&amp;amp; = \frac{1}{n}\sum_{i=1}^n(\frac{x_{i1}-\bar{x_1}}{s_1})(\frac{x_{i2}-\bar{x_2}}{s_2})\\
&amp;amp; = \frac{S_{12}}{n}\cdot\frac{1}{s_1s_2} = \frac{s_{12}}{s_1s_2}=r_{12}
\end{split}
\tag{10}
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記5</title>
      <link>https://wangcc.me/post/2017-02-13/</link>
      <pubDate>Tue, 14 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-13/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;ul&gt;
&lt;li&gt;2017-02-15 &lt;strong&gt;updated.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;數據的種類和尺度&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;數據的種類和尺度&lt;/h2&gt;
&lt;table class=&#34;gmisc_table&#34; style=&#34;border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;td colspan=&#34;14&#34; style=&#34;text-align: left;&#34;&gt;
表1. 20歳の若者9名のデータ
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th colspan=&#34;1&#34; style=&#34;font-weight: 900; border-top: 2px solid grey; text-align: center;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-top: 2px solid grey;; border-bottom: hidden;&#34;&gt;
 
&lt;/th&gt;
&lt;th colspan=&#34;2&#34; style=&#34;font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;&#34;&gt;
性別
&lt;/th&gt;
&lt;th style=&#34;border-top: 2px solid grey;; border-bottom: hidden;&#34;&gt;
 
&lt;/th&gt;
&lt;th colspan=&#34;5&#34; style=&#34;font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;&#34;&gt;
健康状態
&lt;/th&gt;
&lt;th style=&#34;border-top: 2px solid grey;; border-bottom: hidden;&#34;&gt;
 
&lt;/th&gt;
&lt;th colspan=&#34;1&#34; style=&#34;font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;&#34;&gt;
体温
&lt;/th&gt;
&lt;th style=&#34;border-top: 2px solid grey;; border-bottom: hidden;&#34;&gt;
 
&lt;/th&gt;
&lt;th colspan=&#34;1&#34; style=&#34;font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;&#34;&gt;
身長
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;border-bottom: 1px solid grey; text-align: center;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey;&#34; colspan=&#34;1&#34;&gt;
 
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey; text-align: center;&#34;&gt;
男
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey; text-align: center;&#34;&gt;
女
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey;&#34; colspan=&#34;1&#34;&gt;
 
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey; text-align: center;&#34;&gt;
極良
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey; text-align: center;&#34;&gt;
良好
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey; text-align: center;&#34;&gt;
普通
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey; text-align: center;&#34;&gt;
不良
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey; text-align: center;&#34;&gt;
極悪
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey;&#34; colspan=&#34;1&#34;&gt;
 
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey; text-align: center;&#34;&gt;
°C
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey;&#34; colspan=&#34;1&#34;&gt;
 
&lt;/th&gt;
&lt;th style=&#34;border-bottom: 1px solid grey; text-align: center;&#34;&gt;
cm
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
36.9
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
155
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
36.5
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
190
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
36.7
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
165
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
39
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
155
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
5
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
38.1
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
167
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
6
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
36.2
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
180
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
7
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
36.6
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
178
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
8
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
36.7
&lt;/td&gt;
&lt;td style colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;text-align: center;&#34;&gt;
170
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom: 2px solid grey; text-align: center;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey;&#34; colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey; text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey; text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey;&#34; colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey; text-align: center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey; text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey; text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey; text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey; text-align: center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey;&#34; colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey; text-align: center;&#34;&gt;
36.5
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey;&#34; colspan=&#34;1&#34;&gt;
 
&lt;/td&gt;
&lt;td style=&#34;border-bottom: 2px solid grey; text-align: center;&#34;&gt;
166
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;數據按照尺度類型分4種：
&lt;ul&gt;
&lt;li&gt;定性數據：(qualitative data/categorical data)
&lt;ul&gt;
&lt;li&gt;名義尺度 (nominal scale):
&lt;br&gt;如番號，性別等，僅用於識別或者區分對象。&lt;/li&gt;
&lt;li&gt;順序尺度 (ordinal scale):
&lt;br&gt;如表1中的健康狀態，既具有名義尺度的性質，也具有順序(順位，前後，程度等)意義。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;定量數據：(quantitative data)
&lt;ul&gt;
&lt;li&gt;間隔尺度 (interval scale):
&lt;br&gt;又稱區間尺度，距離尺度。如體溫等數值之間的差具有意義，可以設定原點（零）的尺度。&lt;/li&gt;
&lt;li&gt;比例尺度 (ratio scale)
&lt;br&gt;如身高(身長)，不同人的身高差有意義，同時原點（零）又無意義。（身高爲零的人是不存在的）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;樣本與總體(標本/サンプルと母集団)：
&lt;ul&gt;
&lt;li&gt;表格1 中，
&lt;br&gt;(1) 全國20歲的年輕人全體的性別，健康狀態，體溫，身高的數據
&lt;br&gt;(2) 任意抽選數名(此處爲9名)年輕人的性別，健康狀態，體溫，身高的數據。
&lt;br&gt;(1) 稱爲&lt;strong&gt;總體(population)&lt;/strong&gt;, (2) 稱爲&lt;strong&gt;樣本(sample)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;一般的，我們稱問卷調查的對象個人爲&lt;strong&gt;個體(subject, individual)&lt;/strong&gt;，人數爲&lt;strong&gt;樣本量(size)&lt;/strong&gt;，我們也常常假設總體有無窮大。在多元變量分析中，如果我們稱&lt;strong&gt;數據&lt;/strong&gt;，通常只能是指&lt;strong&gt;樣本數據&lt;/strong&gt;。我們在統計分析中，一般是通過樣本去推測總體的狀況或者利用一些樣本的&lt;strong&gt;參數(parameter)&lt;/strong&gt;來描述總體，去進行檢驗等。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;變量(variable)：
&lt;ul&gt;
&lt;li&gt;表1 中變量有“性別”，“健康狀態”，“體溫”，“身長”四個。&lt;/li&gt;
&lt;li&gt;進一步的，性別又細分了“男”，“女”，健康狀態又分爲“極好”，“良好”，“普通”，“不良”，“極差”五個小項目，這些小項目整個可以視爲一個變量，也可以視爲單獨的變量，如果視爲單獨變量，表1 中就共有9個變量。&lt;/li&gt;
&lt;li&gt;性別，健康狀態的各個變量中，我們看到表1 中的數據只有1或者0，這樣的變量稱爲&lt;strong&gt;啞變量(dummy variable，ダミー変量)&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;特別地，我們可以稱性別和健康狀態的變量爲&lt;strong&gt;項目(item)&lt;/strong&gt;，稱底下的小項目爲&lt;strong&gt;分類(category)&lt;/strong&gt;。我們又稱以這樣有項目，下面有分類的變量爲&lt;strong&gt;項目分類型數據(item-categorical data)&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;多元變量分析，顧名思義，指的是對一個具有一個以上變量的數據進行統計學分析的過程。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;單變量數據
&lt;ul&gt;
&lt;li&gt;將數據進行總結，分析提取特徵的過程，稱爲&lt;strong&gt;概括統計(summary statistics)&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;下表中爲樣本量-n-的單變量數據我們看看該數據可以有哪些概括統計&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;下表中爲樣本量 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 的單變量數據，我們看看該數據可以有哪些概括統計&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;個体の番号&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;変量 &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\vdots\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;樣本&lt;strong&gt;平均值(mean)&lt;/strong&gt;： &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}=\frac{x_1+x_2+\cdots+x_n}{n}=\frac{1}{n}\sum\limits_{i=1}^nx_i\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;樣本&lt;strong&gt;範圍(range)&lt;/strong&gt;： &lt;span class=&#34;math inline&#34;&gt;\(R=\max(x_i) - \min(x_i)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;樣本&lt;strong&gt;平方和(偏差平方和，Sum of Squares)&lt;/strong&gt;:&lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(SS=(x_1-\bar{x})^2+(x_2-\bar{x})^2+\cdots+(x_n-\bar{x})^2\\ \;\;\;\;\:=\sum\limits_{i=1}^{n}(x_i-\bar{x})^2\\ \;\;\;\;\:=\sum\limits_{i=1}^n(x_i^2-2\bar{x}x_i+\bar{x}^2)\\ \;\;\;\;\:=\sum\limits_{i=1}^nx_i^2-2\bar{x}\sum\limits_{i=1}^nx_i+\sum\limits_{i=1}^{n}\bar{x}^2\\ \;\;\;\;\:=\sum\limits_{i=1}^nx_i^2-2\cdot\frac{\sum\limits_{i=1}^nx_i}{n}\cdot\sum\limits_{i=1}^nx_i+n\cdot(\frac{\sum\limits_{i=1}^nx_i}{n})^2\\ \;\;\;\;\:=\sum\limits_{i=1}^nx_i^2-\frac{1}{n}(\sum\limits_{i=1}^nx_i)^2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;樣本&lt;strong&gt;方差(variance, 分散)&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(s^2=\frac{SS}{n}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;樣本&lt;strong&gt;標準差(standard deviation, S.D., 標準偏差)&lt;/strong&gt;： &lt;span class=&#34;math inline&#34;&gt;\(s=\sqrt{s^2}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;無偏樣本方差(unbiased sample variance, 不偏標本分散)&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(u^2=\frac{SS}{n-1}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;無偏樣本標準差平方根(不偏標本分散平方根)&lt;/strong&gt;： &lt;span class=&#34;math inline&#34;&gt;\(u=\sqrt{u^2}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;通在多元變量分析中，常常利用的思想是將&lt;strong&gt;變動(variability)&lt;/strong&gt;或者是&lt;strong&gt;波動(dispersion)&lt;/strong&gt;最大化，最小化。此處說的變動和波動是指上面提到的無偏樣本方差。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記4</title>
      <link>https://wangcc.me/post/2017-02-12-t/</link>
      <pubDate>Sun, 12 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-12-t/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;連立方程式-simultaneous-equations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;連立方程式 (simultaneous equations)&lt;/h2&gt;
&lt;p&gt;連立方程式，將與第六章談的特徵值問題(固有値問題)有緊密聯系，此處我們一起觀察幾種不同的組合：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;解同次連立1次方程式 &lt;span class=&#34;math inline&#34;&gt;\(\left\{ \begin{array}{ll}  (1)\;a_1+2a_2+3a_3 = 0 \\  (2)\;2a_1+4a_2+5a_3 = 0 \;\\  (3)\;3a_1+5a_2+6a_3 = 0 \\  \end{array} \right.\)&lt;/span&gt; &lt;br&gt;
由 &lt;span class=&#34;math inline&#34;&gt;\(2\times(1)-(2)\)&lt;/span&gt; 可得 &lt;span class=&#34;math inline&#34;&gt;\(a_3=0\)&lt;/span&gt; 。 代入 &lt;span class=&#34;math inline&#34;&gt;\((1),(2),(3)\)&lt;/span&gt; 式後，&lt;span class=&#34;math inline&#34;&gt;\((3)-(2)\)&lt;/span&gt; 可得 &lt;span class=&#34;math inline&#34;&gt;\(a_1=-a_2\)&lt;/span&gt; 。 代入 &lt;span class=&#34;math inline&#34;&gt;\((1)\)&lt;/span&gt; 式可得 &lt;span class=&#34;math inline&#34;&gt;\(a_2=0\)&lt;/span&gt; 。 再代入 &lt;span class=&#34;math inline&#34;&gt;\((4)\)&lt;/span&gt; 式可知 &lt;span class=&#34;math inline&#34;&gt;\(a_1=0\)&lt;/span&gt; 。最終可得 &lt;span class=&#34;math inline&#34;&gt;\(a_1=a_2=a_3=0\)&lt;/span&gt; &lt;br&gt;
其實上述問題不解自明 (trivial solution)。 那麼同次1次連立方程式 (homogeneous system) 除了自明解之外，還有別的解嗎? 我們再看下面一例。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;解 &lt;span class=&#34;math inline&#34;&gt;\(\left\{ \begin{array}{ll}  (1)\;4a_1+3a_2+6a_3 = 0 \\  (2)\;2a_1+a_2+4a_3 = 0 \;\\  (3)\;a_1+a_2+a_3 = 0 \\  \end{array} \right.\)&lt;/span&gt; &lt;br&gt;
上述方程表面上看有三個式子，實際上由於 &lt;span class=&#34;math inline&#34;&gt;\((3)=\left\{(1)-(2)\right\}\div2\)&lt;/span&gt; 只有2個有意義的方程式。如此這般，有3個未知數，卻只有兩個連立方程組，是無法求解的。如果將三個未知數中的一個例如 &lt;span class=&#34;math inline&#34;&gt;\(a_3\)&lt;/span&gt; 視爲常數(定数) (寫作：&lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt; ) 即： &lt;br&gt;&lt;span class=&#34;math inline&#34;&gt;\((4)\;a_3=s\)&lt;/span&gt; &lt;br&gt;
整理方程組得到新的連立方程 &lt;span class=&#34;math inline&#34;&gt;\(\left\{ \begin{array}{ll}  (1^\prime)\;4a_1+3a_2 = -6s \\  (2^\prime)\;2a_1+a_2 = -4s \;\\  \end{array} \right.\)&lt;/span&gt; &lt;br&gt;
由 &lt;span class=&#34;math inline&#34;&gt;\((1^\prime)-2\times(2^\prime)\)&lt;/span&gt; 可得 &lt;span class=&#34;math inline&#34;&gt;\(a_2=2s\)&lt;/span&gt; 。代入 &lt;span class=&#34;math inline&#34;&gt;\((2^\prime)\)&lt;/span&gt; 可得 &lt;span class=&#34;math inline&#34;&gt;\(a_1=-3s\)&lt;/span&gt;。因此我們得到 &lt;span class=&#34;math inline&#34;&gt;\(a_1=-3s,a_2=2s,a_3=s\)&lt;/span&gt; 且 &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt; 爲任意常數，故此連立方程組的解有無數組。當且僅當 &lt;span class=&#34;math inline&#34;&gt;\(s=0\)&lt;/span&gt; 時方程組有自明解， &lt;span class=&#34;math inline&#34;&gt;\(s\neq0\)&lt;/span&gt; 時此連立方程組的解爲非自明解 (non-trivial solution)。如果將其他未知數視爲常數(定数)時，求得的解會有變化嗎？&lt;br&gt;
若視 &lt;span class=&#34;math inline&#34;&gt;\(a_2=s\)&lt;/span&gt; 求解連立方程的解時，我們會獲得 &lt;span class=&#34;math inline&#34;&gt;\(a_1=-\frac{3}{2}s, a_2=s, a_3=-\frac{1}{2}s\)&lt;/span&gt;。若視 &lt;span class=&#34;math inline&#34;&gt;\(a_1=s\)&lt;/span&gt; 時，計算可得 &lt;span class=&#34;math inline&#34;&gt;\(a_1=s, a_2=-\frac{2}{3}s,a_3=-\frac{1}{3}s\)&lt;/span&gt;。&lt;br&gt;
由此可見，非自明解表面看去各不相同，但是都滿足了 &lt;span class=&#34;math inline&#34;&gt;\(a_1:a_2:a_3=-3:2:1\)&lt;/span&gt; 的本質條件。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;解 &lt;span class=&#34;math inline&#34;&gt;\(\left\{ \begin{array}{ll}  (1)\;4a_1+3a_2+6a_3 = 0 \\  (2)\;2a_1+a_2+4a_3 = 0 \;\\  (3)\;a_1^2+a_2^2+a_3^2 = 0 \\  \end{array} \right.\)&lt;/span&gt; &lt;br&gt;
上述方程組其實是將例題2.中的方程 &lt;span class=&#34;math inline&#34;&gt;\((3)\)&lt;/span&gt; 替換成了2次方程。&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(3\times(2)-(1)\)&lt;/span&gt; 可得 &lt;span class=&#34;math inline&#34;&gt;\(a_1=-3a_3\)&lt;/span&gt; &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\((1)-2\times(2)\)&lt;/span&gt; 可得 &lt;span class=&#34;math inline&#34;&gt;\(a_2=2a_3\)&lt;/span&gt; &lt;br&gt;
以上代入 &lt;span class=&#34;math inline&#34;&gt;\((3)\)&lt;/span&gt; 可得， &lt;span class=&#34;math inline&#34;&gt;\(a_3 = \pm \frac{1}{\sqrt{14}}\)&lt;/span&gt;。&lt;br&gt;
總結一下：　&lt;span class=&#34;math inline&#34;&gt;\(a_1=\mp \frac{3}{\sqrt{14}}, a_2=\pm \frac{2}{\sqrt{14}}, a_3=\pm\frac{1}{\sqrt{14}}\)&lt;/span&gt; (複号同順 double-sign corresponds)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;解 &lt;span class=&#34;math inline&#34;&gt;\(a_1+2a_2-3a_3=0\)&lt;/span&gt; &lt;br&gt;
上面的方程只有一個，並不是連立方程組，將其中兩個未知數視爲常數時就變成了只有一個未知數的方程。例如視，&lt;span class=&#34;math inline&#34;&gt;\(a_2=s, a_3=t\)&lt;/span&gt; 代入上述方程則可以得到: &lt;span class=&#34;math inline&#34;&gt;\(a_1=-2s+3t\)&lt;/span&gt;，因此，此方程的解爲： &lt;span class=&#34;math inline&#34;&gt;\(a_1=-2s+3t, a_2=s, a_3=t\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(s,t\)&lt;/span&gt; 爲任意常數，有無數組解。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;練習-解下列連立方程組&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;練習: 解下列連立方程組&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\left\{ \begin{array}{ll}  (1)\;2a_1-3a_2 = 0 \\  (2)\;-4a_1+6a_2 = 0 \;\\  \end{array} \right.\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\left\{ \begin{array}{ll}  (1)\;2a_1-3a_2 = 0 \\  (2)\;-4a_1+6a_2 = 0 \;\\  (3)\;a_1^2+a_2^2 = 0 \\  \end{array} \right.\)&lt;/span&gt; &lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;解&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;解&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\because\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\((2)=-2\times(1)\)&lt;/span&gt; 實質上方程組僅有一個方程。&lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\therefore a_1=\frac{3}{2}s, a_2=s\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;只需要求解例題1 中符合方程 &lt;span class=&#34;math inline&#34;&gt;\((3)\)&lt;/span&gt; 的解即可。 &lt;br&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\therefore a_1=\pm\frac{3}{\sqrt{13}}, a_2=\pm\frac{2}{\sqrt{13}}\)&lt;/span&gt; (複号同順 double-sign corresponds)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記3</title>
      <link>https://wangcc.me/post/2017-02-10/</link>
      <pubDate>Fri, 10 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-10/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;函數的最大值最小值問題&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;函數的最大值最小值問題&lt;/h2&gt;
&lt;div id=&#34;沒有制約條件的情況&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;沒有制約條件的情況&lt;/h3&gt;
&lt;p&gt;函數 &lt;span class=&#34;math inline&#34;&gt;\(F(a_1,a_2,\dots,a_i,\dots,a_n)\)&lt;/span&gt; 取最大值或者最小值時，以下的連立方程
&lt;span class=&#34;math display&#34;&gt;\[\frac{\partial F}{\partial a_1}=0,\frac{\partial F}{\partial a_2}=0，\frac{\partial F}{\partial a_3}=0, \dots,\frac{\partial F}{\partial a_i}=0, \dots, \frac{\partial F}{\partial a_n}=0\]&lt;/span&gt;
要成立&lt;strong&gt;(必要條件)&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;1.已知下列方程有最小值，求當該方程取最小值時&lt;span class=&#34;math inline&#34;&gt;\(a_1,a_2\)&lt;/span&gt;的值 &lt;span class=&#34;math display&#34;&gt;\[F(a_1,a_2)=\left\{y_1-(a_1+a_2x_1)\right\}^2+\left\{y_2-(a_1+a_2x_2)\right\}^2+\cdots+\left\{y_n-(a_1+a_2x_n)\right\}^2\\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;=\sum\limits_{i=1}^n\left\{y_i-(a_1+a_2x_i)\right\}^2\\\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
\frac{\partial F}{\partial a_1}&amp;amp;=-2\left\{y_1-(a_1+a_2x_1)\right\}-2\left\{y_2-(a_1+a_2x_2)\right\}-\cdots-2\left\{y_n-(a_1+a_2x_n)\right\}\\
&amp;amp;= -2\sum_{i=1}^n\left\{y_i-(a_1+a_2x_i)\right\}=0 \Leftrightarrow  \sum_{i=1}^n\left\{y_i-(a_1+a_2x_i)\right\}=0\\
\Leftrightarrow \sum_{i=1}^ny_i &amp;amp;= a_1\cdot n+a_2\sum_{i=1}^nx_i (1)\\
\\
\frac{\partial F}{\partial a_2}&amp;amp;=-2x_1\left\{y_1-(a_1+a_2x_1)\right\}-2x_2\left\{y_2-(a_1+a_2x_2)\right\}-\cdots-2x_3\left\{y_n-(a_1+a_2x_n)\right\}\\
&amp;amp;= -2\sum_{i=1}^nx_i\left\{y_i-(a_1+a_2x_i)\right\}=0\\
\Leftrightarrow \sum_{i=1}^nx_iy_i &amp;amp;=a_1\sum_{i=1}^nx_i+a_2\sum_{i=1}^nx_i^2 (2)\\

&amp;amp;將(1)(2)連立方程求解即可。在回歸分析中，\\
&amp;amp;這個連立方程組被稱作正規方程組(Normal \;equation)
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;求下列方程取最大或者最小值時的&lt;span class=&#34;math inline&#34;&gt;\(a_1,a_2,a_3\)&lt;/span&gt;的大小：
&lt;span class=&#34;math display&#34;&gt;\[F(a_1,a_2,a_3)=a_1^2+a_1a_2+a_1a_3+a_2^2+a_2a_3+a_3^2-6a_1-3a_2-7a_3\]&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
解連立方程：\\
\frac{\partial F}{\partial a_1} &amp;amp; = 2a_1+a_2+a_3-6=0\\
\frac{\partial F}{\partial a_2} &amp;amp; = a_1+2a_2+a_3-3=0\\
\frac{\partial F}{\partial a_3} &amp;amp; = a_1+a_2+2a_3-7=0\\
答：&amp;amp; a_1=2, a_2=-1,a_3=3
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記2</title>
      <link>https://wangcc.me/post/2017-02-08/</link>
      <pubDate>Wed, 08 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-08/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;偏微分&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;偏微分&lt;/h2&gt;
&lt;div id=&#34;個變量的函數的微分&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;1個變量的函數的微分&lt;/h3&gt;
&lt;div id=&#34;公式&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;公式：&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;函數 &lt;span class=&#34;math inline&#34;&gt;\(f(a)\)&lt;/span&gt; 關於變量 &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; 的微分，被定義爲： &lt;span class=&#34;math inline&#34;&gt;\(\lim\limits_{h \to 0} \frac{f(a+h)-f(a)}{h}\)&lt;/span&gt; , 寫作 &lt;span class=&#34;math inline&#34;&gt;\(\frac{df}{da}\)&lt;/span&gt;, 具有下列性質：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(f(a) = a^n\)&lt;/span&gt; 時， &lt;span class=&#34;math inline&#34;&gt;\(\frac{df}{da} = na^{n-1}\)&lt;/span&gt; &lt;strong&gt;重要&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\frac{d}{da}\left\{kf(a)+lg(a)\right\}=k\frac{df}{da}+l\frac{dg}{da}\)&lt;/span&gt; &lt;strong&gt;(&lt;span class=&#34;math inline&#34;&gt;\(k,l\)&lt;/span&gt; 是常數)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\frac{d}{da}\left\{f(a) \cdot g(a)\right\}=\frac{df}{da}g(a)+f{a}\frac{dg}{da}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\frac{d}{da}\left\{\frac{f(a)}{g(a)}\right\}=\frac{\frac{df}{da}g(a)-f(a)\frac{dg}{da}}{\left\{g(a)\right\}^2}\)&lt;/span&gt;, 特別的有，&lt;span class=&#34;math inline&#34;&gt;\(\frac{d}{da}\left\{\frac{1}{g(a)}\right\}=-\frac{\frac{dg}{da}}{\left\{g(a)\right\}^2}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(y=f(b), b=g(a)\)&lt;/span&gt; 時， &lt;span class=&#34;math inline&#34;&gt;\(\frac{dy}{da}=\frac{dy}{db}\frac{db}{da}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2次（2階）微分 【二階導數】:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(f(a)\)&lt;/span&gt; 關於常數 &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; 的微分 &lt;span class=&#34;math inline&#34;&gt;\(\frac{df}{da}\)&lt;/span&gt; 的二次微分表示爲： &lt;span class=&#34;math inline&#34;&gt;\(\frac{d^2f}{da^2}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;多個變量的函數的微分&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;多個變量的函數的微分&lt;/h3&gt;
&lt;div id=&#34;偏微分-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;偏微分&lt;/h4&gt;
&lt;p&gt;包含了 &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; 個獨立變量 &lt;span class=&#34;math inline&#34;&gt;\(a_1, a_2,a_3,\cdots,a_i,\cdots,a_n\)&lt;/span&gt;的函數，即多變量函數 &lt;span class=&#34;math inline&#34;&gt;\(F(a_1, a_2,a_3,\cdots,a_i,\cdots,a_n)\)&lt;/span&gt; 關於 &lt;span class=&#34;math inline&#34;&gt;\(a_i (i=1,2,\cdots,n)\)&lt;/span&gt; 的偏微分 &lt;em&gt;(partial differentiation)&lt;/em&gt; 的定義是，把 &lt;span class=&#34;math inline&#34;&gt;\(a_i\)&lt;/span&gt; 以外的獨立變量當做常數（定数），將函數 &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; 對變量 &lt;span class=&#34;math inline&#34;&gt;\(a_i\)&lt;/span&gt; 求微分，寫作： &lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial F}{\partial a_i}\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;以下爲了便於說明，以三個變量爲例。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;函數 &lt;span class=&#34;math inline&#34;&gt;\(F(a_1,a_2,a_3)=a_1+a_2+a_3=\sum\limits_{i=1}^3a_i\)&lt;/span&gt; 對於三個獨立變量分別求偏微分：
&lt;span class=&#34;math display&#34;&gt;\[\frac{\partial F}{\partial a_1}=1，\frac{\partial F}{\partial a_2}=1， \frac{\partial F}{\partial a_3}=1\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;函數 &lt;span class=&#34;math inline&#34;&gt;\(F(a_1,a_2,a_3)=a_1b_1+a_2b_2+a_3b_3=\sum\limits_{i=1}^3a_ib_i\)&lt;/span&gt; 對於三個獨立變量分別求偏微分：
&lt;span class=&#34;math display&#34;&gt;\[\frac{\partial F}{\partial a_1}=b_1，\frac{\partial F}{\partial a_2}=b_2， \frac{\partial F}{\partial a_3}=b_3\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;函數 &lt;span class=&#34;math inline&#34;&gt;\(F(a_1,a_2,a_3)=a_1^2+a_2^2+a_3^2=a_1\cdot a_1+a_2\cdot a_2+a_3\cdot a_3\\=\sum\limits_{i=1}^3a_i^2=\sum\limits_{i=1}^3a_i\cdot a_i \;對三個變量分別求偏微分：\)&lt;/span&gt;　
&lt;span class=&#34;math display&#34;&gt;\[\frac{\partial F}{\partial a_1}=2a_1，\frac{\partial F}{\partial a_2}=2a_2， \frac{\partial F}{\partial a_3}=2a_3\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;函數 &lt;span class=&#34;math inline&#34;&gt;\(F(a_1,a_2,a_3)=\lambda_1a_1^2+\lambda_2a_2^2+\lambda_3a_3^2=a_1\cdot\lambda_1\cdot a_1+a_2\cdot\lambda_2\cdot a_2+a_3\cdot\lambda_3\cdot a_3\\=\sum\limits_{i=1}^3\lambda_ia_i^2=\sum\limits_{i=1}^3a_i\cdot\lambda_i\cdot a_i \; 對三個變量分別求偏微分：\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\frac{\partial F}{\partial a_1}=2\lambda_1a_1，\frac{\partial F}{\partial a_2}=2\lambda_2a_2， \frac{\partial F}{\partial a_3}=2\lambda_3a_3\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;函數 &lt;span class=&#34;math inline&#34;&gt;\(F(a_1,a_2,a_3)=(b_1-\lambda a_1)^2+(b_2-\lambda a_2)^2+(b_3-\lambda a_3)^2\\=\sum\limits_{i=1}^3(b_i-\lambda a_i)^2=\sum\limits_{i=1}^3(b_i-\lambda a_i)(b_i-\lambda a_i)\;對三個變量求偏微分：\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\frac{\partial F}{\partial a_1}=-2\lambda(b_1-\lambda a_1)，\frac{\partial F}{\partial a_2}=-2\lambda(b_2-\lambda a_2)， \frac{\partial F}{\partial a_3}=-2\lambda(b_3-\lambda a_3)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;函數 &lt;span class=&#34;math inline&#34;&gt;\(F = a_{11}x_1y_1 + a_{12}x_1y_2 + a_{13}x_1y_3 \\ \;\;\;\;\;\;+a_{21}x_2y_1+a_{22}x_2y_2+a_{23}x_2y_3\\ \;\;\;\;\;\;+a_{31}x_3y_1+a_{32}x_3y_2+a_{33}x_3y_3\\ \;\;\;=\sum\limits_{i=1}^3\sum\limits_{i=1}^3a_{ij}x_iy_j\;對三個變量求偏微分：\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(F(x_1,x_2,x_3)\)&lt;/span&gt;, 即視爲 &lt;span class=&#34;math inline&#34;&gt;\(x_1,x_2,x_3\)&lt;/span&gt; 的函數的時候：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
 \frac{\partial F}{\partial x_1}=a_{11}y_1+a_{12}y_2+a_{13}y_3=\sum_{j=1}^3a_{1j}y_j \\
 \frac{\partial F}{\partial x_2}=a_{21}y_1+a_{22}y_2+a_{23}y_3=\sum_{j=1}^3a_{2j}y_j \\
 \frac{\partial F}{\partial x_3}=a_{31}y_1+a_{32}y_2+a_{33}y_3=\sum_{j=1}^3a_{3j}y_j \\
 將上面三個式子總結一下就是: \\
 \frac{\partial F}{\partial x_i}=\sum_{j=1}^3a_{ij}y_j (i=1,2,3)
 \]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(F(y_1,y_2,y_3)\)&lt;/span&gt;, 即視爲 &lt;span class=&#34;math inline&#34;&gt;\(y_1,y_2,y_3\)&lt;/span&gt; 的函數的時候：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
 \frac{\partial F}{\partial y_1}=a_{11}x_1+a_{21}x_2+a_{31}x_3=\sum_{i=1}^3a_{i1}x_i \\
 \frac{\partial F}{\partial y_2}=a_{12}x_1+a_{22}x_2+a_{32}x_3=\sum_{i=1}^3a_{i2}x_i \\
 \frac{\partial F}{\partial y_3}=a_{13}x_1+a_{32}x_2+a_{33}x_3=\sum_{i=1}^3a_{i3}x_i \\
 將上面三個式子總結一下就是: \\
 \frac{\partial F}{\partial x_i}=\sum_{i=1}^3a_{ij}x_i (j=1,2,3)
 \]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;函數 &lt;span class=&#34;math inline&#34;&gt;\(F(x_1,x_2,x_3)=a_{11}x_1x_1+a_{12}x_1x_2+a_{13}x_1x_3 \\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+a_{12}x_2x_1+a_{12}x_2x_2+a_{23}x_2x_3\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+a_{13}x_3x_1+a_{23}x_3x_2+a_{33}x_3x_3\\ \;\;\;\;\;\;\;\;\;\;\;\;=a_{11}x_1^2+2a_{12}x_1x_2+2a_{13}x_1x_3+a_{22}x_2^2+2a_{23}x_2x_3+a_{33}x_3^2\\ \;\;\;\;\;\;\;\;\;\;\;\;=\sum\limits_{i=1}^3a_{ii}x_i^2+2\mathop{\sum\limits^3\sum\limits^3}\limits_{i&amp;lt;j}a_{ij}x_ix_j\\ \;\;\;\;\;\;\;\;\;\;\;\;==\sum\limits_{i=1}^3x_ia_{ii}x_i+2\mathop{\sum\limits^3\sum\limits^3}\limits_{i&amp;lt;j}x_ia_{ij}x_j\;對三個變量求偏微分：\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\frac{\partial F}{\partial x_1}=2(a_{11}x_1+a_{12}x_2+a_{13}x_3)\\
\frac{\partial F}{\partial x_2}=2(a_{12}x_1+a_{22}x_2+a_{23}x_3)\\
\frac{\partial F}{\partial x_3}=2(a_{13}x_1+a_{23}x_2+a_{33}x_3)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;函數 &lt;span class=&#34;math inline&#34;&gt;\(F(x_1,x_2,x_3)=a_{11}x_1x_1+a_{12}x_1x_2+a_{13}x_1x_3 \\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+a_{12}x_2x_1+a_{12}x_2x_2+a_{23}x_2x_3\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+a_{13}x_3x_1+a_{23}x_3x_2+a_{33}x_3x_3\\ G(x_1,x_2,x_3)=b_{11}x_1x_1+b_{12}x_1x_2+b_{13}x_1x_3 \\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+b_{12}x_2x_1+b_{12}x_2x_2+b_{23}x_2x_3\\ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+b_{13}x_3x_1+b_{23}x_3x_2+b_{33}x_3x_3\\\;對三個變量求偏微分：\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial}{\partial x_1}(\frac{F}{G})=\frac{\frac{\partial F}{\partial x_1}G(x_1,x_2,x_3)-F(x_1,x_2,x_3)\frac{\partial G}{\partial x_1}}{\left\{G(x_1,x_2,x_3)\right\}^2}\\
=2\cdot \frac{(a_{11}x_1+a_{12}x_2+a_{13}x_3)\cdot G(x_1,x_2,x_3)-F(x_1,x_2,x_3)\cdot (b_{11}x_1+b_{12}x_2+b_{13}x_3)}{\left\{G(x_1,x_2,x_3)\right\}^2}\\
\\
\frac{\partial}{\partial x_2}(\frac{F}{G})=\frac{\frac{\partial F}{\partial x_2}G(x_1,x_2,x_3)-F(x_1,x_2,x_3)\frac{\partial G}{\partial x_2}}{\left\{G(x_1,x_2,x_3)\right\}^2}\\
=2\cdot \frac{(a_{12}x_1+a_{22}x_2+a_{23}x_3)\cdot G(x_1,x_2,x_3)-F(x_1,x_2,x_3)\cdot (b_{12}x_1+b_{22}x_2+b_{23}x_3)}{\left\{G(x_1,x_2,x_3)\right\}^2}\\
\frac{\partial}{\partial x_3}(\frac{F}{G})=\frac{\frac{\partial F}{\partial x_3}G(x_1,x_2,x_3)-F(x_1,x_2,x_3)\frac{\partial G}{\partial x_3}}{\left\{G(x_1,x_2,x_3)\right\}^2}\\
=2\cdot \frac{(a_{13}x_1+a_{23}x_2+a_{33}x_3)\cdot G(x_1,x_2,x_3)-F(x_1,x_2,x_3)\cdot (b_{13}x_1+b_{23}x_2+b_{33}x_3)}{\left\{G(x_1,x_2,x_3)\right\}^2}\\
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;次2階偏微分-二階導數&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;2次（2階）偏微分 【二階導數】:&lt;/h4&gt;
&lt;p&gt;函數 &lt;span class=&#34;math inline&#34;&gt;\(F(a_1,a_2,\cdots,a_n)\)&lt;/span&gt; 對 &lt;span class=&#34;math inline&#34;&gt;\(a_i\)&lt;/span&gt; 取偏微分 &lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial F}{\partial a_i}\)&lt;/span&gt; 時，記作 &lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial^2 F}{\partial a_i^2}\)&lt;/span&gt; ; 取變量 &lt;span class=&#34;math inline&#34;&gt;\(a_j\)&lt;/span&gt; 的偏微分時記作 &lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial^2 F}{\partial a_i\partial a_j}\)&lt;/span&gt; 或者 &lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial^2 F}{\partial a_j\partial a_i}\)&lt;/span&gt;。 這些都被稱爲是函數 &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; 的2次（2階）偏微分。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>「統計解析のための線形代数」復習筆記1</title>
      <link>https://wangcc.me/post/2017-02-06/</link>
      <pubDate>Mon, 06 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-02-06/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;和記號sum&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;和記號&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt; 的性質 (1)
&lt;strong&gt;下標(添字)&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(x_1 + x_2 + x_3 + \dots + x_n\)&lt;/span&gt; 記作如下:&lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^{n}x_i\]&lt;/span&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^{n}x_i\)&lt;/span&gt; 中的&lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; 稱爲&lt;code&gt;dummy index&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;可以簡略寫爲：&lt;span class=&#34;math inline&#34;&gt;\(\sum x\)&lt;/span&gt; 或者 &lt;span class=&#34;math inline&#34;&gt;\(\sum_1 x_i\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\sum x_i\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt; 的性質 (2)
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:1&#34;&gt;\[\begin{equation}
\sum_{i=1}^{n}(ax_i + by_i)= a\sum_{i=1}^{n}x_i + b\sum_{i=1}^{n}y_i \tag{1}
\end{equation}\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^{n}ax_i = a\sum_{i=1}^{n}x_i\)&lt;/span&gt; &lt;code&gt;常數(定数)可以提前&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^{n}a = na\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^{n}1 = n\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^{n}(ax_i+b) = a\sum_{i=1}^{n}x_i + nb\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;公式&lt;a href=&#34;#eq:1&#34;&gt;(1)&lt;/a&gt;的應用:
&lt;span class=&#34;math display&#34;&gt;\[
  \begin{aligned}
  \sum_{i=1}^{n}(ax_i -by_i)^2 &amp;amp;= \sum_{i=1}^{n}(a^2x_i^2 - 2abx_iy_i + b^2y_i^2) \\
   &amp;amp;= \sum_{i=1}^{n}a^2x_i^2 -\sum_{i=1}^{n}2abx_iy_i + \sum_{i=1}^{n}b^2y_i^2 \\
   &amp;amp;= a^2\sum_{i=1}^{n}x_i^2 - 2ab\sum_{i=1}^{n}x_iy_i + b^2\sum_{i=1}^{n}y_i^2
  \end{aligned}
  \]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;但是，乘法或平方有如下性質，計算方差(分散)或者相關系數時需要注意：&lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^{n}x_i^2 \neq (\sum_{i=1}^{n}x_i)^2\]&lt;/span&gt; 以及 &lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^{n}x_iy_i \neq (\sum_{i=1}^{n}x_i)(\sum_{i=1}^{n}y_i)\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;自然數的冪運算之和(冪[べき]乗の和)的公式:
&lt;span class=&#34;math display&#34;&gt;\[
  \begin{aligned}
  1+2+3+\dots+n &amp;amp;= \sum_{t=1}^{n}t = \frac{n(n+1)}{2}\\
  1^2+2^2+3^2+\dots+n^2 &amp;amp;= \sum_{t=1}^{n}t^2 = \frac{n(n+1)(2n+1)}{6} \\
  1^3+2^3+3^3+\dots+n^3 &amp;amp;= \sum_{t=1}^{n}t^3 = {\frac{n(n+1)}{2}}^2 \\
  1^4+2^4+3^4+\dots+n^4 &amp;amp;= \sum_{t=1}^{n}t^4 = \frac{n(n+1)(2n+1)(3n^2+3n-1)}{30}
  \end{aligned}
  \]&lt;/span&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    上面的公式將會應用在時間序列分析，斯皮尔曼等级相关系数(スピアマンの順位相関係数)的定義公式的推導。
  &lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;sum式子變形成普通計算式&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt;式子變形成普通計算式：&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^{n}f_{ij} = f_{i1} + f_{i2} + f_{i3} + \dots + f_{in}\]&lt;/span&gt; 此式子也常寫作&lt;span class=&#34;math inline&#34;&gt;\(f_{i+}\)&lt;/span&gt;, 或者&lt;span class=&#34;math inline&#34;&gt;\(f_{i\cdot}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^{m}f_{ij} = f_{1i} + f_{2i} + f_{3i} + \dots + f_{mj}\]&lt;/span&gt; 此式子也常寫作&lt;span class=&#34;math inline&#34;&gt;\(f_{+j}\)&lt;/span&gt;, 或者&lt;span class=&#34;math inline&#34;&gt;\(f_{\cdot j}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math display&#34;&gt;\[\sum_{i=1}^{2}\sum_{j=1}^{3}x_{ij} = \sum_{i=1}^{2}(\sum_{i=j}^{3}x_{ij}) = \sum_{i=1}^{2}(x_{i1} + x_{i2} + x_{i3}) = (x_{11} + x_{12} + x_{13}) + (x_{21} + x_{22} + x_{23})\]&lt;/span&gt; 此式子也可以寫作&lt;span class=&#34;math inline&#34;&gt;\(x_{++}\)&lt;/span&gt;, 或者&lt;span class=&#34;math inline&#34;&gt;\(x_{\cdot\cdot}\)&lt;/span&gt;。另外，中間的式子如果是&lt;span class=&#34;math inline&#34;&gt;\(\sum_{j=1}^{3}(\sum_{i=1}^{2}x_{ij})\)&lt;/span&gt;也可以成立，過程如下：&lt;span class=&#34;math display&#34;&gt;\[\sum_{j=1}^{3}(\sum_{i=1}^{2}x_{ij})=\sum_{j=1}^{3}(x_{1j} + x_{2j}) = (x_{11} + x_{21}) + (x_{12} + x_{22}) + (x_{13} + x_{23})\]&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math display&#34;&gt;\[
  \begin{aligned}
  \sum_{i=1}^2\sum_{j=1}^2a_{ij}x_ix_j &amp;amp;= \sum_{i=1}^2(\sum_{j=1}^2a_{ij}x_ix_j) \\
  &amp;amp;= \sum_{i=1}^2({\sum_{j=1}^2a_{ij}x_j)x_i} \\
  &amp;amp;= \sum_{i=1}^2(a_{i1}x_1 + a_{i2}x_2)x_i \\
  &amp;amp;= (a_{11}x_1 + a_{12}x_2)x_1 + (a_{21}x_1 + a_{22}x_2)x_2 \\
  &amp;amp;= a_{11}x_1^2 + (a_{12} + a_{21})x_1x_2 + a_{22}x_2^2
  \end{aligned}
  \]&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math display&#34;&gt;\[
  \begin{aligned}
  \sum_{k=1}^3\left\{(\sum_{i=1}^2b_ix_{ik})(\sum_{j=1}^2b_jx_{jk})\right\} &amp;amp;= \sum_{k=1}^3\left\{(b_1x_{1k} + b_2x_{2k})(b_1x_{1k} + b_2x_{2k})\right\} \\
  &amp;amp;= \sum_{k=1}^3(b_1x_{1k} + b_2x_{2k})^2 \\
  &amp;amp;= (b_1x_{11} + b_2x_{21})^2 + (b_1x_{12} + b_2x_{22})^2 + (b_1x_{13} + b_2x_{23})^2
  \end{aligned}
  \]&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathop{\sum\limits^3\sum\limits^3}\limits_{i&amp;lt;j}e_{ij}\)&lt;/span&gt; 會變成怎樣的式子呢？ 滿足 &lt;span class=&#34;math inline&#34;&gt;\(i&amp;lt;j (i = 1,2,3; j = 1,2,3)\)&lt;/span&gt; 條件的 &lt;span class=&#34;math inline&#34;&gt;\(i,j\)&lt;/span&gt;, 有且僅有 &lt;span class=&#34;math inline&#34;&gt;\((1,2),(1,3),(2,3)\)&lt;/span&gt;,故 &lt;span class=&#34;math inline&#34;&gt;\(\mathop{\sum\limits^3\sum\limits^3}\limits_{i&amp;lt;j}e_{ij} = e_{12} + e_{13} + e_{23}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;那麼&lt;span class=&#34;math inline&#34;&gt;\(\mathop{\sum\limits^3\sum\limits^3}\limits_{i\neq j}e_{ij}\)&lt;/span&gt;又會變成怎樣的式子呢？ 滿足 &lt;span class=&#34;math inline&#34;&gt;\(i\neq j (i = 1,2,3; j = 1,2,3)\)&lt;/span&gt; 的 &lt;span class=&#34;math inline&#34;&gt;\((i,j)\)&lt;/span&gt; 有6種組合:&lt;span class=&#34;math inline&#34;&gt;\((1,2),(2,1),(1,3),(3,1),(2,3),(3,2)\)&lt;/span&gt;, 故&lt;span class=&#34;math inline&#34;&gt;\(\mathop{\sum\limits^3\sum\limits^3}\limits_{i\neq j}e_{ij} = e_{12} + e_{21} + e_{13} + e_{31} + e_{23} + e_{32}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;加法算式變形爲sum&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;加法算式變形爲&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;在多元變量分析(多変量解析)中，與前項相比，加法算式變形成爲&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt;式子更加重要。也就是說，以前項計算爲例的話，作爲答案的計算式如果放在題幹，反向求解&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt;式的過程更加常用。簡單練習一下吧：&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;將計算式&lt;span class=&#34;math inline&#34;&gt;\(a_1x_1^2 + a_2x_2^2 + a_3x_3^2 + a_4x_4^2 + a_5x_5^2\)&lt;/span&gt;改寫成&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt;式：
&lt;ul&gt;
&lt;li&gt;先寫下：&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;再寫各個單元的共通部分&lt;span class=&#34;math inline&#34;&gt;\((a,x^2)\)&lt;/span&gt;： &lt;span class=&#34;math inline&#34;&gt;\(\sum ax^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;各單元不同的僅爲下標： &lt;span class=&#34;math inline&#34;&gt;\(\sum a_ix_i^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;注意到下標的變化規律爲&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;到&lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;之間的整數，故在&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt;符號的上部寫上&lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;，下部寫上&lt;span class=&#34;math inline&#34;&gt;\(i=1\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\sum\limits_{i=1}^5a_ix_i^2\)&lt;/span&gt; (答)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;將計算式&lt;span class=&#34;math inline&#34;&gt;\(f_2(x_2 - \bar{x})^2 + f_3(x_3 - \bar{x})^2 + f_4(x_4 - \bar{x})^2 + f_5(x_5 - \bar{x})^2\)&lt;/span&gt;改寫成&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt;式：
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sum f(x-\bar{x})^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sum f_i(x_i - \bar{x})^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sum\limits_{i=2}^5f_i(x_i - \bar{x})^2\)&lt;/span&gt; (答)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;提問&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;提問：&lt;/h2&gt;
&lt;div id=&#34;我們現在了解了可以使用簡單的sum符號來表達復雜有規律的加法算式請問有沒有相應的記號來代表乘法&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;我們現在了解了可以使用簡單的&lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt;符號來表達復雜有規律的加法算式。請問有沒有相應的記號來代表乘法？&lt;/h3&gt;
&lt;/div&gt;
&lt;div id=&#34;當然有用希臘字母pi的大寫pi來表示例如-x_1x_2x_3x_4x_5-prod_i15x_i-x_1x_2x_3dots-x_n-prod_i1nx_i&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;當然有。用希臘字母&lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;的大寫&lt;span class=&#34;math inline&#34;&gt;\(\Pi\)&lt;/span&gt;來表示。例如： &lt;span class=&#34;math display&#34;&gt;\[x_1x_2x_3x_4x_5 = \prod_{i=1}^5x_i\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[x_1x_2x_3\dots x_n = \prod_{i=1}^nx_i\]&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div id=&#34;乘法記號可以證明下面的等式成立-prod_i1nx_i2-prod_i1nx_i2-logprod_i1nx_i-prod_i1nlog-x_i&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;乘法記號可以證明下面的等式成立： &lt;span class=&#34;math display&#34;&gt;\[\prod_{i=1}^nx_i^2 = (\prod_{i=1}^nx_i)^2\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[\log(\prod_{i=1}^nx_i) = \prod_{i=1}^n\log x_i\]&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>IELTs test 雅思考試感受與我的成績</title>
      <link>https://wangcc.me/post/2017-01-07-ielts-test/</link>
      <pubDate>Sat, 04 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-01-07-ielts-test/</guid>
      <description>&lt;p&gt;今年1月7日周六，我在日本名古屋市參加了人生第一次，但願是唯一一次的雅思考試。
就是如下圖的這個叫做TKP名古屋駅前カンファレンスセンター，這建築物名字翻譯成人話其實就是“名古屋車站前TKP會議中心”，之前接待臺灣友人時被問道：“爲什麼日本人有時候用漢字，有時候又用片假名或者平假名。”答曰：“任性。”&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IELTS.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;回到雅思考試話題上來。爲什麼一把年紀了還要考雅思？其實說實話，我肯定不是那日考雅思中最老的，看到一個大叔估計50+，我也才快30而已。不老不老。回想當年剛畢業時好多人吭哧吭哧考雅思或者託福，我也跟風（裸）考了一次託福（好像不到80分，iBT，慘不忍睹），當然我自己精心準備的考試是日本語能力測試的2級與1級。如今已經在日本獲得博士學位，留校工作快2年了，爲啥又要去靠雅思捏？答案很簡單，&lt;strong&gt;又想出國了&lt;/strong&gt;。記得之前有一次有點小尷尬的經歷，好像是去愛知縣政府的時候，坐八谷老師的車，一邊聊天，他問道：“哎呀，小王，你沒有考慮以後留學去嗎？” 我楞了一下，過了十幾秒，他好似也意識到了什麼，又說道：“對哦，現在已經在留學了。” 此事後來常被我拿來在酒桌上開玩笑，看我的日語還是很地道的嘛，老師都忘記我是留學生了。&lt;/p&gt;
&lt;p&gt;所以上文我說又想&lt;strong&gt;出國&lt;/strong&gt;，出的是&lt;strong&gt;日本國&lt;/strong&gt;，有點終於要“衝出亞洲，走向世界”的豪情萬丈了。其實我這次追求的是，從一個島國，去另一個島國。試問東瀛到英吉利的距離有多遠？答曰：相隔一次雅思考試的時間，需要一份個人陳述的鋪墊，還要有兩封推薦信的含情脈脈，最終也還不一定能夠買到這張出發的船票。所以我的第一件事就是，花1個月的時間，從早到晚幾乎每日10個小時以上的精力投入，1小時菲律賓外教的口語模考課，3篇劍橋閱讀，1次真題聽力，大小作文每周各練習2-3篇，然後重頭戲我覺得是堅持每天一片聽寫，目標是雅思成績overall大於等於7。終於等到1月7日這天，檢驗我的魔鬼訓練成果的日子。&lt;/p&gt;
&lt;p&gt;日本的雅思考點很少，聽說大陸光上海就6個考點，而且今年的考試費用是1980RMB，真是那啥人傻錢多劍橋速來，考點每年一個的增加，費用也是每年100的上漲。我在的名古屋考點，把名古屋周圍地區的考生都包括了（愛知縣，三重縣，岐阜縣，靜岡縣，說不定還有其他縣市的趕過來），我考試那天也才80個人左右，我還看到有人拖着行李箱從外地趕來考試。全日本考點不知道有沒有超過10個。考試全程感覺周圍的人都好牛逼，不知道是他們提前放棄了還是真的寫的比我還快啊。早晨考完聽力閱讀作文以後是12點半，其實1點開始就有考口語的，只是考官人數有限，口語考試我被安排在了最後一個，輪到我時已經是晚上6點。&lt;/p&gt;
&lt;p&gt;我還記得考完作文的時候長舒一口氣，因爲尿憋了好久了，結果接下來的5個小時漫長等待才是最摧殘人的。考完口語之後我把被問的話題回憶了一下:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Part 1
&lt;ul&gt;
&lt;li&gt;Work or study ?&lt;/li&gt;
&lt;li&gt;Why the work ?&lt;/li&gt;
&lt;li&gt;Future work you like to do ?&lt;/li&gt;
&lt;li&gt;Describe a celebrity you know in your country.&lt;/li&gt;
&lt;li&gt;Do you like to read about celebrities?&lt;/li&gt;
&lt;li&gt;Do you like to take photos ?&lt;/li&gt;
&lt;li&gt;What do you do with the photos?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Part 2: Describe a very busy time.&lt;/li&gt;
&lt;li&gt;Part 3:
&lt;ul&gt;
&lt;li&gt;Do you think children in your country, I mean China, are under great stress?&lt;/li&gt;
&lt;li&gt;Do you think stress in the future will be more or less?&lt;/li&gt;
&lt;li&gt;Give me some examples about modern ways to deal with stress.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;考口語的時候，我的感覺十分緊張，而且在Part3有部分語無倫次。不過結束以後我還跟考官握了握手說我很享受跟你的對話。(I really enjoyed our talk, have a good night!)&lt;/p&gt;
&lt;p&gt;2周以後的1月21日是出分的日子，從中午開始我就不停的上網站刷新，結果一直都提示沒有可顯示的成績。後來到了晚上7點半，刷出了成績：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/IELTSresults.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Overall 8分的成績還是挺滿意的，1個多月非人的生活終於可以結束了。結果信心滿滿的去登錄London School of Hygiene and Tropical Medicine的報名網站的時候，悲催的是人家關於英文能力的問題只有一個：&lt;strong&gt;你的雅思成績總分是否大於7，請回答是或者否。。。。。。。。。。。。。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以其實語言考試這玩意兒根本不能說明任何問題。它只提供了本人可以進行英文交流的能力證明，沒有哪個大學會因爲你的英語成績雅思或者託福滿分，就錄取你的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>布克獎</title>
      <link>https://wangcc.me/post/2017-1-5/</link>
      <pubDate>Thu, 05 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-1-5/</guid>
      <description>&lt;p&gt;听写于：2017-1-5 9:35	用时：26:08
正确率：88%	错词：26个&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/booker.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;covet:&lt;code&gt;v. 贪求，觊觎&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;satire:&lt;code&gt;n. 讽刺；讽刺文学，讽刺作品&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;mercantilism:&lt;code&gt;n. 重商主义；商人本性；商业主义&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;burgle:&lt;code&gt;vt. 偷窃，破门盗窃 vi. 偷窃，破门盗窃&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;cavernous:&lt;code&gt;adj. 似巨穴的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;chamber:&lt;code&gt;n. 会客室，议事厅；议院；房间；卧室；腔 v. 限制，把…关在室内；装填&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;waive:&lt;code&gt;vt. 放弃；搁置&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;padded:&lt;code&gt;adj. 有装填垫料的；脚底有厚肉的 v. 填补（pad的过去分词形式）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;land sb in： &lt;code&gt;使某人陷入 Revealing confidential information to a rival company could land you in serious trouble with your boss. 给竞争公司泄露机密信息很可能会让老板使你陷入麻烦&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;My rights remain silent 米兰达权利： &lt;a href=&#34;https://en.wikipedia.org/wiki/Miranda_warning&#34;&gt;美国刑事诉讼中的miranda rights——米兰达权利，也就是犯罪嫌疑人保持沉默的权利，是个具有特殊意义的法律制度。“你有权保持沉默。如果你不保持沉默，那么你所说的一切都能够用作为你的呈堂证供。你有权在受审时请一位律师。如果你付不起律师费的话，我们可以给你请一位。你是否完全了解你的上述权利？”这句话就是著名的“米兰达警告”，也称“米兰达告诫”，即犯罪嫌疑人、被告人在被讯问时，有保持沉默和拒绝回答的权利。&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;先来介绍的是文学明星保罗·比蒂（Paul Beatty）。他是今年布克文学奖的获得者，也是第一位获此殊奖的美国作家。除了能获得5万英镑奖金外，他的获奖作品也会在畅销书榜占据一席之地。《出卖》（The Sellout，又译《背叛》）是一本幽默小说，这在布克奖获奖历史中并不常见。这本书常使我捧腹大笑。而它以讽刺当代美国的种族关系为题材，我觉得这非常适合2016年这个年份——特朗普赢得大选胜利，及“黑人的命也是命”（Black Lives Matter）的抗议运动都在2016年发生。 在经历了父亲被警察击毙，家乡城市在地图上消失的事件后，小说的叙述者决定通过雇佣奴隶及施行种族隔离制度来纠正这个错误。这些行为最终使他被送上最高法院的法庭。 “这些话从一个黑人口中说出可能难以让人信服。但是我从来没有偷过东西，从来没有偷税漏税，没有在玩牌时出老千，没有偷偷溜进电影院看电影。我每次都把多找的零钱还给药店收银员。我对重商主义的手段并不在意，对最低薪资标准也没有什么期许。我从未入室盗窃，或是抢劫卖酒的商店。我从没在拥挤的公车或地铁上占用老人专用座位。但我还是落得如此下场，在大而“幽深”的美国最高法庭接受审判。我的车非法地、有些讽刺地停在了宪法大道。我的手被手铐铐住，反剪在背后。当我来到法庭，我不再拥有“保持缄默”的权利。我坐的椅子上垫着厚厚的坐垫，但它跟这个国家一样，都只是看着舒服罢了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>企業的社會責任</title>
      <link>https://wangcc.me/post/2017-1-4/</link>
      <pubDate>Wed, 04 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-1-4/</guid>
      <description>&lt;p&gt;听写于：2017-1-4 10:8	用时：19:19
正确率：91%	错词：17个&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/amazon.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered
&lt;ul&gt;
&lt;li&gt;bruising /ˈbruːzɪŋ/: &lt;code&gt;a.十分激烈的 例： The administration hopes to avoid another bruising battle over civil rights. 政府希望避免因民权问题再次发生激烈冲突。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;back-stabbing: &lt;code&gt;n.伤人暗箭  例句： We weren&#39;t really trying to tell anyone that this was Shakespeare, but it is about back-stabbing.  我们真的没打算做一出莎士比亚戏剧，但这确实是关于背后一刀的故事。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;portrayal:&lt;code&gt;n. 描绘，描写；画像&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;如果浏览任何一家公司的年报，你都很有可能看到一些关于企业社会责任的内容。这是因为我们不仅仅要求我们所投资的公司盈利能力出众，我们还希望他们是优秀的企业公民。这也可能解释了近期的新闻报道有关亚马逊暗自任命了新高管来负责社会责任。这起任命源于之前这家网络零售商所遭遇的大量有关公司行为的负面批评。纽约时报近期文章批判了该公司对待员工的方式。文章讲道亚马逊的冲突文化和内部中伤，但亚马逊老板坚称这些描述都不确凿。无论真相如何，Christine Bader已经成为现任亚马逊社会责任的负责人，她也是一位企业社会责任支持者，曾任联合国秘书长商业与人权特别代表的顾问。她曾在这里接受我在我们姐妹节目Business Matters的采访，那时我问她企业社会责任到底是什么含义。&lt;/p&gt;
&lt;p&gt;我想主要原因是呼吁的核心企业责任领域已经变化，现在没人能说清楚它表示什么。它可以表示CEO所赋予的任何意义。它可以意味着员工志愿项目。它也可以包括削减温室气体排放量。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>蛻變</title>
      <link>https://wangcc.me/post/2017-1-3/</link>
      <pubDate>Tue, 03 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-1-3/</guid>
      <description>&lt;p&gt;听写于：2017-1-3 11:52	用时：16:56
正确率：94%	错词：12个&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/tuibian.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;hop:&lt;code&gt;vt. 搭乘  v. 单足跳跃〔跳行〕 vi. 双足或齐足跳行 n. 蹦跳,跳跃；跳舞；一次飞行的距离&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;sparrow:&lt;code&gt;n. 麻雀&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;straggle:&lt;code&gt;vi. 迷路；落伍，掉队；四散，蔓延 n. 散乱&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;中国的城市化在过去几十年发展速度惊人。1990年，1/4的中国人居住在城市。去年，中国已经有超过一半的人是城市居民，而且其增长速度还没有放缓的趋势。为响应政策号召，中国各地纷纷建起城市，此举的目的是促使农民转为工人和消费者，以推动经济的增长。十年前，我们的中国事务主编嘉莉·格雷西走访了位于北京西南1000英里处的一个农村。她目睹白马村经历了非同寻常的转变，现在它已经是一座霓虹灯闪烁的巫溪新城，而这对一些人来说意味着“尽善尽美”。&lt;/p&gt;
&lt;p&gt;我和九岁的小佩佩一块盯着毛绒做的玩具和超级英雄，盯了很长的时间。&lt;/p&gt;
&lt;p&gt;“佩佩，”我说，“你有300元，可以买任何想要的东西。现在你想要什么？”&lt;/p&gt;
&lt;p&gt;他只是无奈地看着我笑，两条小腿交替跳跃着。今天是漫长的一天，早上五点BBC的白马村摄制组就出发，匆忙来到新城市广场，为新闻之夜的现场采访做准备。然而我们并不是最早出现在广场上的人 。来自周围山村的农民早就在主要道路的路面上铺好了他们种的蔬菜，等待着城里人的细心检验，而这些城里人自己不久前也是农民。仅仅十年前，这个山谷唯一仰赖的只有农业。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>宗教與食品</title>
      <link>https://wangcc.me/post/2017-1-2/</link>
      <pubDate>Mon, 02 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-1-2/</guid>
      <description>&lt;p&gt;听写于：2017-1-2 10:01	用时：21:24
正确率：93%	错词：14个&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/religiousfood.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;merriment:&lt;code&gt;n. 欢喜,嬉戏&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;conspicuous:&lt;code&gt;adj. 显眼的，明显的，引人注目的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;kosher:&lt;code&gt;adj. 合适的；符合犹太教教规的，干净的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;halal:&lt;code&gt;n. 伊斯兰教律法的合法食物 v. 按伊斯兰教律法屠宰牲畜&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;savvy:&lt;code&gt;adj. 有见识的；具有实际知识的  n. 悟性；头脑 v. 理解；懂, 精明&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;rail/reɪl/: &lt;code&gt;v. 强烈抗议 例句： It also likes to rail against U.S. support for authoritarian regimes in the Islamic world.  它差点就要责骂美国在伊斯兰世界里支持独裁政体。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;take refuge:&lt;code&gt; 避难；躲避 例句： He is my loving God and my fortress, my stronghold and my deliverer, my shield, in whom I take refuge, who subdues peoples under me.  他是我慈爱的主，我的山寨，我的高台，我的救主，我的盾牌，是我所投靠的。 他使我的百姓服在我以下。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;对大多数人来讲，圣诞季意味着欢乐、大餐、畅饮，总之凡事都要多多益善。如果你信教，可能就与当下的气氛背道而驰了，当然，总不乏宗教领袖们在抵制圣诞节商业化。但这些夸张的盛宴确实有其宗教起源。稍后，我们将听到有多少宗教节日是欢庆的节日。但首先，宗教与消费的二者关系早已被食品公司和零售商们所发现。事实上，我们能看到越来越多的宗教食物，比如标注为犹太或伊斯兰食品，成为主流。在很多西方超市里，都能看到一大批食品包装上印有那些标识。那么这一切是如何演变的？犹太和伊斯兰食品是如何成为食品行业的主流素食主义的？伊丽莎白·霍森在伦敦为我们找寻答案。&lt;/p&gt;
&lt;p&gt;曾经有段时间，“如果你想吃贝果，你就去犹太面包房”或想吃清真羔羊肉就去找伊斯兰屠夫。当今，很多超市都贮存曾经那些看似专业性的或异国的商品，精明的商业从中挖掘利益。伦敦的一个阴雨天，我来到城市西边的一家巴基斯坦餐馆Gifto躲雨。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>望子成龍</title>
      <link>https://wangcc.me/post/2017-1-1/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2017-1-1/</guid>
      <description>&lt;p&gt;听写于：2017-1-1 10:23	用时：14:03
正确率：93%	错词：16个&lt;/p&gt;
&lt;p&gt;概述：许多父母都对自己的孩子寄予厚望，愿意把宝宝的小动作解读为过人的天赋，但是有多少望子女成龙凤的父母能如愿以偿呢？也要有点“舍得孩子才能套着狼”的精神吧。新年BBC第一弹，祝大家元气满满！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/dominique_moceanu.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;p&gt;In 1996, Dominique Moceanu made headlines as the &lt;!-- raw HTML omitted --&gt;youngest-ever&lt;!-- raw HTML omitted --&gt;  member of the US &lt;!-- raw HTML omitted --&gt;Women&amp;rsquo;s &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;gymnastic&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Gymnastics&lt;!-- raw HTML omitted --&gt; team to win a gold medal at the Olympic Games. Her parents were from Romania and inspired by the popular Romanian gymnast Nadia Comăneci, they had high &lt;!-- raw HTML omitted --&gt;ambition&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;ambitions&lt;!-- raw HTML omitted --&gt; for their daughter. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;My parents had it in their hearts that when they had their first child, I would be a gymnast. And when they immigrated to the United States in 1981&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;that &lt;!-- raw HTML omitted --&gt;desire stayed within their hearts &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and &lt;!-- raw HTML omitted --&gt;so after I was born about &lt;!-- raw HTML omitted --&gt;6&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;six&lt;!-- raw HTML omitted --&gt; months&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; they did a test of my strength just for fun. And my parents didn&amp;rsquo;t have a washer or dryer so they &lt;!-- raw HTML omitted --&gt;hanged&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;hung&lt;!-- raw HTML omitted --&gt; me from a &lt;!-- raw HTML omitted --&gt;cloth&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;clothes&lt;!-- raw HTML omitted --&gt; line to see how long I could hold on to the &lt;!-- raw HTML omitted --&gt;cloth&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;clothes&lt;!-- raw HTML omitted --&gt; line. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;My &lt;!-- raw HTML omitted --&gt;goodness&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;I know. And so my &lt;!-- raw HTML omitted --&gt;father&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;dad&lt;!-- raw HTML omitted --&gt; used to always say &lt;!-- raw HTML omitted --&gt;I&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;it&lt;!-- raw HTML omitted --&gt; was such enthusiasm&lt;!-- raw HTML omitted --&gt;:&lt;!-- raw HTML omitted --&gt; &amp;quot; You held on until the &lt;!-- raw HTML omitted --&gt;cloth&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;clothes&lt;!-- raw HTML omitted --&gt; line broke. &amp;quot; But of course &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; they were there to catch me&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and &lt;!-- raw HTML omitted --&gt;they said that was really a sign to them that I was gonna be a &lt;!-- raw HTML omitted --&gt;great&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;real&lt;!-- raw HTML omitted --&gt; gymnast. And &lt;!-- raw HTML omitted --&gt;then&lt;!-- raw HTML omitted --&gt; eventually &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; I &lt;!-- raw HTML omitted --&gt;would&amp;rsquo;ve&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;started&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;gymnastic&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;would&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;start&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;gymnastics&lt;!-- raw HTML omitted --&gt; by the age of &lt;!-- raw HTML omitted --&gt;3&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;three&lt;!-- raw HTML omitted --&gt; in the United States&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and &lt;!-- raw HTML omitted --&gt;I was put in a tennis class and a &lt;!-- raw HTML omitted --&gt;gymnastic&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;gymnastics&lt;!-- raw HTML omitted --&gt; class. And really tennis was great, but I didn&amp;rsquo;t have the love that I immediately had for gymnastics&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; and really the rest was history from that moment on.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;make headlines: &lt;code&gt;出现在头条新闻位置；受到宣扬。 例句： But other software, developments, and trends are sure to make headlines and seduce developers in 2010.  但是其他软件、开发和趋势等在2010年必定会成为开发人员所关注的头条新闻。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;1996年，美国女子体操队史上最年轻的运动员多米尼克·莫西阿努荣获了奥运金牌。她的父母来自罗马尼亚，受到罗马尼亚知名体操运动员纳迪亚·科马内奇的启发，他们对女儿也抱着很高的期望。&lt;/p&gt;
&lt;p&gt;我父母打从心里希望自己第一个孩子，也就是我，能成为一名体操运动员。1981年他们移民来美国时，这个愿望就扎根在他们心里。在我6个月大的时候，他们以测试我的力量为乐趣。我家没有洗衣机和烘干机，于是他们把我挂在晾衣绳上，想看看我能在上面坚持多久。&lt;/p&gt;
&lt;p&gt;我的天呐。&lt;/p&gt;
&lt;p&gt;没错。我父亲过去老说这实在是太令人惊叹了：“你居然坚持到晾衣绳都断了”。当然，他们在那里接着我呢。他们觉得这就在向他们暗示我将来肯定能成为一个真正的体操运动员。而我从三岁起就在美国进行体操训练。我同时学习网球和体操。网球运动确实很棒，但是我不像立刻爱上体操那样喜爱网球，而且从那一刻起，其余都是历史了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>蓬勃的生活 Life, Animated</title>
      <link>https://wangcc.me/post/2016-12-31/</link>
      <pubDate>Sat, 31 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-31/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.com/news/entertainment-arts-36671208&#34;&gt;Documentary follows autistic boy obsessed with Disney&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;听写于：2016-12-31 10:44	用时：19:00
正确率：95%	错词：12个&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Owen.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;概括：《蓬勃的生活》根据Ron Suskind同名小说改编，是一部穿插动画与真实影像的纪录片，体现了自闭症儿童的家庭在照顾特殊孩子上所遭遇的困难。Suskind的儿子Owen三岁时不再说话，Suskind夫妇和Owen两岁的弟弟一直在与自闭症作斗争，想要维系他们与Owen的感情，而此时Owen唯一的爱好就是迪士尼动画电影。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;burst into:&lt;code&gt;闯入；情绪的突然发作&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;carnivorous:&lt;code&gt;adj. 食肉的&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>1型糖尿病患者减肥要小心</title>
      <link>https://wangcc.me/post/2016-12-30/</link>
      <pubDate>Fri, 30 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-30/</guid>
      <description>&lt;p&gt;听写于：2016-12-30 16:37	用时：21:04
正确率：95%	错词：13个&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/diabetes.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;omit:&lt;code&gt;v. 遗漏；疏忽；省略；删除&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;umbrella term: &lt;code&gt;涵盖性术语 eg： In prior presentations, this has sometimes been referred to under the umbrella term of &#39;Semantic Web&#39;. 在先前的介绍中，它有时会在“语义网”这个术语中被提及。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;deliberately:&lt;code&gt;adv.故意地&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Diabulimia:&lt;code&gt;n. （糖尿病患者的）不规律饮食 英英解释： An eating disorder in which a diabetic person attempts to lose weight by regularly omitting insulin injections.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;简单点说，卡莉达，Diabulimia是什么？&lt;/p&gt;
&lt;p&gt;Diabulimia是一个涵盖性术语，1型糖尿病患者需要注射与他们的血糖和他们所吃的碳水化合物成一定比例的胰岛素，而为了控制或者减少体重，他们会故意减少胰岛素的注入，或者根本不注射胰岛素。&lt;/p&gt;
&lt;p&gt;你第一次注意到这个问题是在什么时候？&lt;/p&gt;
&lt;p&gt;嗯，我在国王学院附属医院当精神病医生，我的病人中就有15年糖尿病史的患者，自从那时我就不断看到这种现象。&lt;/p&gt;
&lt;p&gt;所以这不是新鲜事，糖尿病患者一直都这么做吗？&lt;/p&gt;
&lt;p&gt;可能自从胰岛素被发明出来的时候，就有一个因子在操纵着1型糖尿病患者体内的胰岛素，我觉得这种说法是正确的。我认为我们对它越来越了解了。&lt;/p&gt;
&lt;p&gt;那么，过会儿我们将讨论艾玛的亲身经历，但是莉比，作为一个组织，从你的角度，你能给我们稍微讲讲胰岛素对人体的作用吗。它是怎么作用的？&lt;/p&gt;
&lt;p&gt;胰岛素调节人体血糖含量。葡萄糖是糖的另一种说法。没有患上1型糖尿病的人们，他们的胰腺会产生与他们所吃食物相当的胰岛素。而1型糖尿病患者，他们的身体不会产生胰岛素，所以他们需要注射等剂量的胰岛素，他们需要正确计算出与他们所吃食物相当的胰岛素剂量。&lt;/p&gt;
&lt;p&gt;现在，不同人对胰岛素有不同反应，是吗？&lt;/p&gt;
&lt;p&gt;不同人对胰岛素剂量的需求不同，注射次数也不同。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>夏威夷的天堂生活</title>
      <link>https://wangcc.me/post/2016-12-29/</link>
      <pubDate>Thu, 29 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-29/</guid>
      <description>&lt;p&gt;听写于：2016-12-29 10:51	用时：24:29
正确率：90%	错词：22个&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nytimes.com/2012/01/16/movies/awardsseason/feisty-host-and-feisty-winners-on-golden-globes.html?_r=1&amp;amp;scp=2&amp;amp;sq=the%20descendants&amp;amp;st=cse&#34;&gt;影片《后裔》以度假胜地夏威夷为背景，讲述中年男子处理突如其来的家庭危机，乔治克鲁尼凭借该片获得第69届金球奖最佳男主角。&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/hawaii.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;box office:&lt;code&gt;phr. 票房，票房收入；售票处&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Glasgows:&lt;code&gt;格拉斯哥(英国苏格兰西南部港市)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;BAFTA:&lt;code&gt;abbr. （英）电影和电视艺术学院（British Academy of Film and Television Arts）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;dream-like:&lt;code&gt;adj. 梦一般的；朦胧的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;sect:&lt;code&gt;宗派; 邪教&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;rightful:&lt;code&gt;adj. 合法的；正当的；公正的；正直的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;redevelopment:&lt;code&gt;再发展,再显影,照相加厚,二次显影&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;backdrop:&lt;code&gt;n. 背景幕；背景；交流声&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Mai Tai:&lt;code&gt;迈代鸡尾酒&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;surfboard:&lt;code&gt;n. 冲浪板 v. 以冲浪板滑水&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;大家好。随着家庭类影片《後裔》在影院上映，导演亚历山大•佩恩向我们展示了穿上夏威夷花衬衫的乔治•克鲁尼的巨大魅力。哥谭镇（指代纽约）的僵尸和蝙蝠侠赫赫有名，可是为什么格拉斯哥（苏格兰西南的城市）更能吸引电影制作人的眼球？ 在各个方面都很邪典（非主流）的影片《双面玛莎》的导演和编剧肖恩•德金向我们讲述了如梦似幻的故事&amp;ndash;一个女孩躲避邪教组织魔爪的逃亡之旅。最后，获得英国电影学院杰出贡献奖的老戏骨约翰•赫特回想他最近失之交臂的角色。&lt;/p&gt;
&lt;p&gt;不过首先，我们要介绍上周末在影院强势推出的电影《後裔》。主演乔治•克鲁尼以人夫、人父的居家形象示人。虽然演员阵容不是很惊艳，不过影片中的家庭可不一般。影片的背景设在夏威夷，克鲁尼饰演的麦特•金是家庭信托基金的负责人，有大把有待重新开发的地皮。&lt;/p&gt;
&lt;p&gt;但是他却被另外一件棘手的事情弄得焦头烂额。他的妻子，也就是他17岁、10岁女儿的母亲坐船时遇到事故，至今昏迷不醒。所有这些令人揪心的事情竟然发生在这美不胜收地方—大海碧蓝澄澈和棕榈树影婆娑。&lt;/p&gt;
&lt;p&gt;“内陆的朋友们觉得因为我住在夏威夷，所以我住在天堂。我们好像永远在度假，整天喝着鸡尾酒、跳着草裙舞、去海滩冲浪。他们难道秀逗了吗？他们觉得我们百毒不侵？他们怎么可以觉得我们家的麻烦就比他们的少？我们就算得了绝症也没他们的那么要人命？我们的心就不像他们这么痛？ 苍天啊，我已经有十五年没碰过冲浪板啦。”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>跟蹤和騷擾</title>
      <link>https://wangcc.me/post/2016-12-28/</link>
      <pubDate>Wed, 28 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-28/</guid>
      <description>&lt;p&gt;听写于：2016-12-28 11:45	用时：22:35
正确率：88%	错词：31个&lt;/p&gt;
&lt;p&gt;概述：跟踪与骚扰的区别，前者对受害人的精神伤害更大&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;fixated:&lt;code&gt;adj. 念念不忘的;迷恋的 He seems to be fixated on this idea of travelling around the world. 他似乎对周游世界这一想法十分迷恋。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;incessant:&lt;code&gt;adj. 不間斷的, 連續的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;nuisance: &lt;code&gt;n.討厭的人或者事情; 非法妨害&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;“跟踪骚扰（stalking）”会剥夺人们原有的生活。它使人们无法继续从前正常的生活方式，如上班、送孩子上学、处理日常事务。跟踪骚扰者异常痴迷且迷恋某人或某事，通常会采取一切手段剥夺受害人的自由。任何人都可能受到跟踪骚扰的危险。我们认为大约每五位女性或十位男性中就有一人遭受到跟踪骚扰，而实际情况可能比这还要严重，因为很多时候人们并不知道自己被跟踪了。当人们电话联系National Stalking Advocacy Service时，他们想要知道你怎么定义那些行为（他们需要你来判断他们是否受到跟踪骚扰）。&lt;/p&gt;
&lt;p&gt;这样吧，我说些例子给你。比如说，有人不停给我打电话，有人经常出没在我上班的地方，或者是我经常收到不想要的信件、礼物。跟踪骚扰就是指这类事情吗？&lt;/p&gt;
&lt;p&gt;可能是跟踪骚扰（stalking），或是骚扰（harassment）。通常，骚扰（harassment）是持续进行的滋扰行为，会严重影响受害者的生活方式和精神健康。跟踪骚扰和骚扰的区别在于：跟踪骚扰更偏向于造成人对暴力的严重畏惧感，受害者的自由权利受到严重威胁，他们会不得不考虑搬家、换工作。受害者可能患上严重的精神疾病，如创伤后应激障碍（PTSD）或抑郁症。许多客户会告诉我们他们不断面临的问题，以及他们是如何处理的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>零是偶数还是奇数</title>
      <link>https://wangcc.me/post/2016-12-27/</link>
      <pubDate>Tue, 27 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-27/</guid>
      <description>&lt;p&gt;听写于：2016-12-27 22:40	用时：17:55
正确率：92%	错词：20个&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/zero.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;single out : &lt;code&gt;挑选出 例句： We all did well, but the teacher singled him out for praise. 我们都做得很好，但老师就表扬了他一个人。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;但是，为什么布隆伯格市长要说“偶数和零”？有必要把零单独拿出来说吗？在我们看来这有点奇怪。于是，我们询问了加入了英国剑桥大学千年数学工程的詹姆斯·格兰姆博士。他说1970年代也有过类似的事例。&lt;/p&gt;
&lt;p&gt;“1977年，巴黎弥漫着大量烟雾，空气质量十分糟糕，政府不得不采取措施限制汽车的使用。他们的方法和现在纽约市采用的方法一样，即单双号车辆隔日出行。警察不知道零是单数还是双数，也不知道该不该拦下车牌尾号为零的车辆，只好让这些车开走。”&lt;/p&gt;
&lt;p&gt;“看来并不是所有人都确定零是奇数还是偶数，不过，数学家在这个问题上意见统一吗？”&lt;/p&gt;
&lt;p&gt;“数学家的看法是一致的。”&lt;/p&gt;
&lt;p&gt;“他们认为零是偶数？”&lt;/p&gt;
&lt;p&gt;“零是偶数，它通过了所有测试，符合偶数的所有定义。”&lt;/p&gt;
&lt;p&gt;“对偶数的测试和定义都有哪些？”&lt;/p&gt;
&lt;p&gt;“把一个数乘以2可以得到一个偶数。如果你把3乘以2，结果是6。6就是一个偶数。这就是对偶数的定义。零也符合这条定义。如果你把零乘以2，结果是零。它还通过了其它测试。如果把奇数和偶数间隔排列，零位于两个奇数1和-1之间，它也通过了这项测试。”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>生物鍾</title>
      <link>https://wangcc.me/post/2016-12-26/</link>
      <pubDate>Mon, 26 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-26/</guid>
      <description>&lt;p&gt;听写于：2016-12-26 11:48	用时：20:02
正确率：91%	错词：16个&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/biologicalclock.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;circadian: &lt;code&gt;adj. 昼夜节奏的，生理节奏的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;jet lag:&lt;code&gt;phr. 飞行时差综合症；时差反应&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;makeup:&lt;code&gt;n. 化妆品，组成，体格，性格，【美】补考，【印】排版&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;fine-tuned:&lt;code&gt;v. 调整，微调；使有规则&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;我今天的嘉宾罗素·福斯特拥有牛津大学生理节律神经科学教授的头衔，这是一种科学上的说法，即指他对钟着迷——可并非滴答走时的钟，而是我们的生物钟以及生命节奏。更确切地说，他研究光对我们体内的时钟和昼夜节律的控制方式，并努力理解明暗是如何对我们的身心健康产生影响的，从时差反应到严重的心理健康疾病，无所不包。当罗素发现一种动物察觉亮光的新方式时，他不得不对抗来自眼科专家的强烈反对。他已有大量著作解释这些生物时钟是如何控制我们和动物们的日常生活的。罗素，欢迎来到生命科学节目。&lt;/p&gt;
&lt;p&gt;很高兴加入你，吉姆。&lt;/p&gt;
&lt;p&gt;我们的生物构造是否意味着要应付全天候不停运转的社会很困难？&lt;/p&gt;
&lt;p&gt;嗯，是的。我们可以说是身负35亿年的进化重担，而且已把这内部时钟的所有指令根植于我们的基因组中，这就像是我们体内有一个一天的模型。我们生理机能上的各个方面都随着不断变化的活动和休息的需要而做出微调。要与这植根体内的程序作对可不容易。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>東德情節</title>
      <link>https://wangcc.me/post/2016-12-25/</link>
      <pubDate>Sun, 25 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-25/</guid>
      <description>&lt;p&gt;听写于：2016-12-25 13:1	用时：24:53
正确率：88%	错词：23个&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/GDR.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;grip:&lt;code&gt;n. 紧握；对…的影响力；理解；把手 v. 紧握；吸引注意力；对…产生强有力的影响&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Leipzig:&lt;code&gt;莱比锡(民主德国城市)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;succint:&lt;code&gt;adj. 简洁的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;equanimity:&lt;code&gt;n. 平静，镇定&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;cobbled:&lt;code&gt;adj. 用鹅卵石砌/铺成的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;gabled:&lt;code&gt;adj. 有山形墙的,人字板制作的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;brutalist:&lt;code&gt;n. 野兽派(信奉美术、建筑或文学上野兽主义的人)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;GDR: &lt;code&gt;abbr. German Democratic Republic (East Germany) 德意志民主共和国（东德）&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;我们正舟车劳顿，准备去了解东德情结这种现象。对前东德的怀念之情仍然影响着一些现代德国人，还有我的旅伴。&lt;/p&gt;
&lt;p&gt;我们现在在火车上，基本上是直奔茨维考。我们那辆可怜的卫星牌汽车最终还是抛锚了。很遗憾的是，我们不得不略过计划中的莱比锡市。我们本来打算去参观斯塔西博物馆，去看更多关于前东德政权黑暗面的证据。斯塔西博物馆的Irmtraut Hollitzer通过一位中间人给我们发了邮件邀请。车坏了我们还因此嬉笑了一通，然后身为德国人又礼貌地道歉，还说东德情结没有胜出。说这话的是Irmtraut Hollitzer，她很关注这一点。&lt;/p&gt;
&lt;p&gt;这是对隐藏在表面之下的情感的一种简明而惊人的洞悉，德国的现代史并不像表面那样平静。&lt;/p&gt;
&lt;p&gt;我们到了，迈克。我们到茨维考了。&lt;/p&gt;
&lt;p&gt;就是在这里，茨维考，300万辆卫星汽车曾在这里被生产出来。作为一款社会主义的普及汽车，它的设计30年来都没有什么变化。然而东德人民要等10年才能买到一辆。茨维考如今仍然是个很大的汽车生产基地。鹅卵石街道两边是挺拔的三角屋顶建筑，这些野兽派风格的混凝土建筑承载了茨维考过去的东德意志。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>天注定</title>
      <link>https://wangcc.me/post/2016-12-22/</link>
      <pubDate>Thu, 22 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-22/</guid>
      <description>&lt;p&gt;听写于：2016-12-22 11:40	用时：19:38
正确率：91%	错词：17个&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/atouchofsin.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;subvert:&lt;code&gt;v. 颠覆；破坏; ...an alleged plot to subvert the state. …一个被指控颠覆国家的阴谋。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;industrial complex:&lt;code&gt;[工经] 工业联合企业；大工业中心&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;surreal:&lt;code&gt;adj. 超现实的，离奇的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;relentless:&lt;code&gt;adj. 无情的，残酷的；不间断的；坚韧的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;hollow out:&lt;code&gt;vt. 挖空（挖洞；开凿）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;skim off:&lt;code&gt;phr. 撇取，撇去；提出精华;捞取; 偷走 (钱)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;parlour:&lt;code&gt;adj. 客厅的 n. 客厅,会客室,特别室&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;graphically:&lt;code&gt;adv. 生动地；活灵活现地；用图表表示；轮廓分明地&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;setup:&lt;code&gt;n. 体制；机构；组织；调整；计划；安装，设置；陷害&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;archetypal:&lt;code&gt;adj. 原型的; ...the archetypal American middle-class family living in the suburbs. …住在郊区的典型美国中产阶级家庭。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;现在，我们来看看一部中国电影，《天注定》，它颠覆了人们的期待。首先，它主要把故事设定在远离大城市的偏远、荒凉的城镇和乡村。这些地区有时被大型工业联合企业占据。其次，电影的主题是突发性暴力事件。导演以超现实主义塔伦蒂诺式的风格讲述了在中国坚持不懈地的追求经济发展的同时，一部分的普通老百姓被恐吓、陷入困境、被剥削。例如，在一个被过度开采的采矿镇，一个男人拿起武器，像一个士兵一样去追踪在利润中捞钱的腐败领导。在别处，一个按摩院的前台用自己的实际行动表明自己不会越过底线。如果你觉得这些设定看上去很典型，其实它全取材于真实生活。去年的戛纳电影节上，导演兼编剧贾樟柯凭此片获得了最佳编剧奖，但这些故事并不是原创的，而是他通过中国的社交媒体发现的。&lt;/p&gt;
&lt;p&gt;“我在微博（中国版推特）上听说了这些事件。大约三年前我开始用微博，我通过这一渠道了解了在中国、甚至在偏远地区发生的许多事。人们在微博上议论这些事情，提出自己的见解，使这些事件流传得更广。”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>足球運動員掙多少錢?</title>
      <link>https://wangcc.me/post/2016-12-21/</link>
      <pubDate>Wed, 21 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-21/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/footballplayer.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-21 11:56	用时：18:57
正确率：92%	错词：17个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;sanctum: &lt;code&gt;n. 圣所,密室,私室&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Tottenham_Hotspur_F.C.&#34;&gt;Tottenham Hotspur: &lt;code&gt;托特纳姆热刺足球俱乐部，简称热刺，是英格兰超级联赛的球队之一。它是二十世纪首支成为联赛及英格兰足总杯双料冠军的球队。在1963年夺得欧洲优胜者杯宝座，是英国首支取得欧洲赛事锦标的队伍。&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;a word of mouth 口碑: &lt;code&gt; Few things offer better word of mouth than a rocketing stock price. 最有助于打造良好口碑的莫过于飙升的股价。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;billboard:&lt;code&gt;n. 广告牌；布告板 v. 宣传&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;但首先，球员过去的收入是怎么样的?我们是如何结束这种观念的呢? 1973年，新闻记者Hunter Davies被允许进入托特纳姆热刺足球俱乐部进行内部随访。Davies花了一个季度的时间和球队呆在一起，他和他们一起训练，一起去球员家做客，亲眼目睹更衣室里球员间的混战打闹。在当今无比谨慎的媒体管理和周密严格的安保措施之下，没有任何体育记者可以再次被准许拥有这种前所未有的近距离接触行为。 起初，在一个19人组成的团队中，没有一个球员有专门的代理人、律师和会计师，也没有球队经理来关照他们。这只是一个口碑的问题。每周他们可以拿到大概200英镑。自20世纪70年代起他们就住在20,000英镑房租的房子里，像阿森纳，在节目中也没有他的广告代言。简直令你难以置信，不是么？ billboard排行榜中都没有有关他们广告的一席之地的原因在于，他们认为自身的价值远不止于这些。他们的价值立于那些不入流的广告营销之上。抱有这种想法的球员时代已经整整结束了超过100年的时间了。 每周两百英镑放到现在就是2181英镑的价值，可以说是相当大的一笔钱，但这笔钱和现在的顶级球员所能赚的相比还够不着边儿。2004年，Hunter Davies受邀编写韦恩鲁尼的自传，那时鲁尼19岁，他的自传被认为是五个球员自传系列中的第一个，以至于其价值盖过了他剩下的的足球生涯。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>人民幣可靠麼?</title>
      <link>https://wangcc.me/post/2016-12-20/</link>
      <pubDate>Tue, 20 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-20/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/renminbi.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-20 11:55	用时：19:49
正确率：94%	错词：8个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;talking point: &lt;code&gt;话题；论据；讨论的焦点 例： It&#39;s bound to be the main talking point during discussions between the prime minister and the president. 这必定会成为首相和总统会谈的主要议题。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;hedge one&amp;rsquo;s bets:&lt;code&gt; 为防止损失两面下注，两面讨好 例句： 1861-1865: U.S. Civil War -- British hedge bets on both Union and Confederacy. 1861~1865 美国内战期间，英国佬对北部联邦和南部邦联两头下重注。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;supposedly: &lt;code&gt;adv. 据信地，可能地&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;partial: &lt;code&gt;a.偏袒的 例：  I might be accused of being partial. 我可能会被人指责是偏袒的。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;从全球股票市场来看，这又是艰难的一周——周四的又一次大跌，对美国中央银行政策的担忧，当然还有中国的经济状况。有一个问题一直被提及，中国现行的货币有多稳定？几个月来，中国所面临的各种挑战已经成为了谈论的焦点，下降的增长率，下滑的股市。但假设中国真的发生一场危机，一些人认为最初的迹象可能是国家货币的挤兑。目前还没发展到那种地步，但似乎富有些的中国公民逐渐将资本在多方下注，将价值数十亿美元的人民币运往国外，并换成更保险的外国投资产品，即便中国政府在人民币外汇交易上有各种偏袒和限制。BBC记者丹尼·文森特走出北京的办公室，到人们比较熟知的黑市交易地点进行走访。 我来到了位于北京站周围的小路上，想要从其中一个商贩手中买一些假发票，这些商贩在街上招呼着顾客。在北京站对面的路上能看到大波的旅客在新年后返回首都，还有一小撮商贩会打断他们的步伐，兜售一些商品和服务。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>總統的COI</title>
      <link>https://wangcc.me/post/2016-12-19/</link>
      <pubDate>Mon, 19 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-19/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/coitrump.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-19 12:00	用时：19:55
正确率：91%	错词：17个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;pledge:&lt;code&gt;n. 抵押；典当品；许诺；誓言；信物 v. 保证，发誓；用……抵押&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;far-flung:&lt;code&gt;adj. 广布的,广泛的,蔓延的,遥远的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;trustee:&lt;code&gt;n. 受托人；理事；信托公司 v. 移交…给受托人&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;dispose:&lt;code&gt;phr. 处理，解决；转让，卖掉；吃光；除掉&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Judgment vs. judgement&lt;/strong&gt;: In American English, &lt;strong&gt;judgement is generally considered a misspelling of judgment&lt;/strong&gt; for all uses of the word, notwithstanding individual preferences. &lt;strong&gt;In British popular usage, judgment was traditionally the preferred form&lt;/strong&gt;, but judgement has gained ground over the last couple of centuries and is now nearly as common as judgment.&lt;/li&gt;
&lt;li&gt;blind trust: &lt;code&gt;保密信托 例： Yang transferred the shares into a blind trust earlier this week. 这个星期的早些时候杨把股票转成了保密信托。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;当唐纳德·特朗普真正宣誓就职美国下任总统时，他如何避免利益冲突带来的损害？本周原定关于该主题的一次记者招待会被取消了。特朗普本人只在他的推特上发文称其在白宫期间不会达成新的交易事项。这也呼应了其前不久的誓言，即他将退出对其遍布全球的商业帝国的实时管控。但仍有很多人认为这一举措不可能持久。那么以前那些成为总统的人是如何处理他们的经济事项的呢？我们请来了奥巴马政府的白宫首席道德律师，诺尔曼·艾森。 自从1978年美国政府道德法案得以通过，美国总统可以充分利用我们所说的合乎标准的保密信托或类似手段。这意味着他们将剥离这些商业利益，并置于信托人处理，转换为现金，再背对背地进行二次投资。所以美国总统们不会知道他们投资于何处，就是为了避免冲突。只要总统们或其他人知悉这些投资，总统的判断就很有可能被左右，或者其他人将利用这些投资游说总统意图影响他。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>兩百萬</title>
      <link>https://wangcc.me/post/2016-12-18/</link>
      <pubDate>Sun, 18 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-18/</guid>
      <description>&lt;p&gt;概述：从小我们就被教育要拾金不昧，但是现实生活中有便宜可占的时候，你会怎么做呢？澳大利亚有位“lucky dog”，把银行当钱包，自称“年轻无知，糊里糊涂”透支了2百万澳元。。。做人还是要诚实啊&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/luke-moore.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.ibtimes.co.uk/australian-man-spent-1-5m-over-two-years-due-bank-glitch-somehow-got-away-it-1596081&#34;&gt;Australian man spent $1.5m over two years due to bank glitch and somehow got away with it&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-18 16:17	用时：20:03
正确率：91%	错词：25个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;administrative:&lt;code&gt;adj. 管理的；行政的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;dawn on:&lt;code&gt;渐渐为…所明白，开始为…所理解; 例句： Slowly, it begins to dawn on me: I have been having a nightmare. 渐渐地，我明白了：我一直在做噩梦。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;overdrawn:&lt;code&gt;v. 透支；夸张；拉过度&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;have access to: &lt;code&gt;使用；接近；可以利用。 例句： Plug-ins can have access to the file system and Internet once they are installed. 插件一旦安装就可以访问文件系统和Internet。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;如果你发现你能从银行不断地取钱，而且所取数目早已超出你存进账户的金额，你会怎么做？2010年3月，澳大利亚的年轻人卢克·穆尔碰巧遇到这样的事。他在圣·乔治银行分行开设了一个账户。一个管理方面的错误导致他不论何时申请贷款，都能被自动批准。接下来两年时间里，他取走了200多万澳元，约合150万美元。他告诉我他是什么时候发现他能无限制地取钱。&lt;/p&gt;
&lt;p&gt;事情就那么慢慢发生了。起初我只有一个日常的银行账户，用来支付我的房贷、医保等等这类东西。第一周左右，我正在发愁“没钱还贷款，我该怎么办？”但是居然成功受理了。于是我就想“那好吧”。接着下一个月我又成功得到了一笔400块的贷款，然后又一笔。这一状态一直持续了12个月，而这一切都是在我账户透支的情况下发生的。&lt;/p&gt;
&lt;p&gt;那么银行没找过你、而你也没觉得应该找银行问问发生了什么吗？&lt;/p&gt;
&lt;p&gt;我不知道自己怎么想的。这事困扰了我一段时间。那会儿我是个年少无知的22岁小伙子，哪懂什么银行系统之类的东西。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>澤國江山入戰圖</title>
      <link>https://wangcc.me/post/2016-12-17/</link>
      <pubDate>Sat, 17 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-17/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Taliban.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-17 12:07	用时：22:37
正确率：91%	错词：15个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;mild-mannered:&lt;code&gt;adj. 温和的，温柔的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In some ways, Afghanistan &lt;strong&gt;is an easy patch&lt;/strong&gt;. There are no &lt;strong&gt;spin doctors&lt;/strong&gt; here. Afghan men themselves are extremely &lt;strong&gt;courteous&lt;/strong&gt;. 从某些方面来说，阿富汗是&lt;strong&gt;一片安逸之地&lt;/strong&gt;，这里没有&lt;strong&gt;专家喉舌&lt;/strong&gt;，这里的男人也&lt;strong&gt;彬彬有礼&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;spin doctors: &lt;code&gt;起导向作用者，定调者；(尤指)助选的高级顾问，谋士；公关专家[亦作 spindoctor]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;courteous: &lt;code&gt;adj. 有礼貌的，谦恭的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;decency:&lt;code&gt;n. 得体，体面；正派&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;nonetheless:&lt;code&gt;adv. 尽管如此，但是&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;swaggered: &lt;code&gt;adj. 时髦的 n. 大摇大摆，趾高气扬；吹嘘，自大；威吓 v. 大摇大摆，趾高气扬；夸耀；吹牛；吓唬&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;artillery: &lt;code&gt;n. 火炮，大炮；炮队；炮术&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;bunch:&lt;code&gt;n. 群；串；突出物 vt. 使成一串；使打褶 vi. 隆起；打褶；形成一串 n. (Bunch)人名；(英)邦奇&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;chrysanthemums:&lt;code&gt;n. 菊花&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;slit:&lt;code&gt;n. 切口，裂缝；投币口 v. 切开，撕开&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;hand-to-hand:&lt;code&gt;adj. 极接近的；白刃战的；传递到手的&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;令我惊讶的是，塔利班高级官员举止非常温和。他们似乎不会生气也不会很开心，对自己所做的事情也深信不疑，但面对媒体时，却显得很天真。从某些方面来说，阿富汗是一片安逸之地，这里没有专家喉舌，这里的男人也彬彬有礼。允许带包以及大门敞开是我遇到的主要问题。但与我去过的其它任何国家不同的是，在这里我从未受到过性骚扰。&lt;/p&gt;
&lt;p&gt;我很难想象阿富汗人民经历过这么多年的残酷战争，因为在这里，我感受到的只有礼貌、热情和文明。&lt;/p&gt;
&lt;p&gt;在一次前线采访中，我对这一悖论有了深入的观察。战士们向我展示了位于废墟村庄中部的导弹发射装置。塔利班组织成员老少不一，有经验丰富的老兵，也有羽翼未丰的青年，但他们依然气宇轩昂。&lt;/p&gt;
&lt;p&gt;火炮展示完毕之后，他们给我递了一杯茶，还送我一束古铜色的菊花。花居然是他们自己在地堡里种的，那片地还残存弹片。几个月前，这些战士还在肉搏战中撕裂别人的喉咙，而他们竟然爱好在室内种植植物。我很好奇，他们在撕裂别人喉咙之前，会不会也递上一杯茶。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>輪回轉世</title>
      <link>https://wangcc.me/post/2016-12-16/</link>
      <pubDate>Fri, 16 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-16/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Buddhist.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-16 12:31	用时：28:24
正确率：90%	错词：23个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;stepping stone: &lt;code&gt;垫脚石；跳板；进身之阶 例： The next rock in your path may be a stepping stone. 也许人生路上的下一个绊脚石就是垫脚石。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;hang on to: &lt;code&gt;紧紧抓住；紧握 例： For most nations, it is a great achievement to hang on to what you already have. 对于大多数国家来说，为了已经拥有的东西而坚持不懈是伟大的成就。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;clinging:&lt;code&gt;adj. 执着的；有黏性的；紧靠着的 v. cling的现在分词；抓紧&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;grasping: &lt;code&gt;adj. 贪婪的，贪心的 v. grasp的现在分词；抓住&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;customary: &lt;code&gt;adj. 习惯的；通常的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;underlying current: &lt;code&gt;其潜在的趋势&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;altogether: &lt;code&gt;adv. 完全地；总共；总而言之&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;reincarnation: &lt;code&gt;n. 再赋与肉体，化身，再生，转世，轮回&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;merit: &lt;code&gt;n. 优点，价值；功绩；功过 vt. 值得 vi. 应受报答&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;afterlife:&lt;code&gt;n. 来世;晚年&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;joyfully:&lt;code&gt;adv. 欢喜地;高兴地;快乐地&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;in actual fact&lt;/strong&gt;: &lt;code&gt;事實上&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;对佛教徒来说，夕阳红的晚年是通向往生的进身之阶。为了深入了解这一点，我来到了伦敦北部靠近巴克汉姆斯特镇的一个宁静偏远的景点——阿玛拉瓦第佛法道场。我将拜见其住持方丈Ajahn Amaro。&lt;/p&gt;
&lt;p&gt;“从佛教的视角来看，引起最大麻烦的东西是我们依赖于附属物的习惯，无论我们是生还是死。如果你紧握住你的财富不放，或是放不下过去的悔恨，那么以传统的佛教模式思考，或者说理解我们都在经历着的前世和来世，今生只是一长串序列中的一部分。所以佛教修行的基本过程及其潜在的趋势是终止轮回转世。”&lt;/p&gt;
&lt;p&gt;“我认为这是最令人着迷的一个概念。它非常古老，起源于印度教传统，佛教继承了它，锡克教大致上也沿袭了它。然而之后发生了什么？随着理念的发展，行善所得的功德成为了投胎转世的驱动者。这种功德的理念同样推动了不存在投胎再生的犹太教、基督教、伊斯兰教世界，形成了生死、审判以及来世的世界。在西方，我们习得了轮回转世的理念，我们相当正面且愉快地接受了它。事实上，它就是你不断地经历磨难直到最后得到解脱的过程。”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>強奸不犯法 喪盡天良的摩洛哥法律</title>
      <link>https://wangcc.me/post/2016-12-15/</link>
      <pubDate>Thu, 15 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-15/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/morocco.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.bbc.com/news/world-africa-17416426&#34;&gt;摩洛哥刑法规定强奸犯与受害者结婚可免除刑责，16岁少女自杀一石激起千层浪. Morocco protest against rape-marriage law&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-15 12:8	用时：22:26
正确率：92%	错词：20个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;campainger: &lt;code&gt;n. 竞选者，活动家；从军者，出征者；老兵&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;penal code: &lt;code&gt;刑法典&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;摩洛哥的女权运动者在首都拉巴特示威，抗议该国强奸法案。该法律规定，强奸犯可与被害者结婚，以免受刑责。16岁少女阿米娜•费拉利被迫嫁给强奸犯后，于上周遭毒打后自杀身亡，此事件也点燃了抗议者的怒火。阿米娜的妈妈讲述了事情的经过。&lt;/p&gt;
&lt;p&gt;“他强奸我女儿，还虐待她。我女儿向我诉苦说他虐待她，不给她东西吃，还威胁说如果她留在家里就杀了她。我告诉她不要害怕，要忍耐，一定要忍下去。”&lt;/p&gt;
&lt;p&gt;摩洛哥刑法强迫受害者与强奸犯结婚，以保护家族名誉，抗议者则要求政府废除这项条例。我的同事朱利安•马歇尔与拉巴特记者诺拉•法基姆连线，获知了更多细节。&lt;/p&gt;
&lt;p&gt;“摩洛哥妇女联盟今天抗议，要求政府废除刑法475条，并帮助受害者恢复心理状态，因为如果政府不改变现状，对受害者来说就是浪费生命，今后也可能会发生更多类似阿米娜•费拉利的事件。”&lt;/p&gt;
&lt;p&gt;“那么这次要求废除刑法相关条例的抗议得到了多少支持？”&lt;/p&gt;
&lt;p&gt;“一般来说，妇女运动会受到很多来自摩洛哥人的压力，但我今早与他们交谈，发现他们对政府目前的反应感到失望，因为仅有两名大臣做出回应。而之前法官曾强迫15岁少女嫁给强奸犯，司法部长对此做出的支持也令他们尤为愤慨。”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>也門飢荒</title>
      <link>https://wangcc.me/post/2016-12-14/</link>
      <pubDate>Wed, 14 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-14/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/n3ct0bxp&#34;&gt;Yemen Starving&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Yemen.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-14 14:14	用时：16:00
正确率：92%	错词：16个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;stark: &lt;code&gt;adj. 荒凉的；光秃秃的；刻板的；僵硬的；朴实的；完全的 adv. 完全地；明显地&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;ally to: &lt;code&gt;与...属一类,与...相似,与...有关系, 同盟&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;vacantly:&lt;code&gt;adv. 空虚地,无表情地&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;首先，联合国发出了一则严肃的警告：也门越来越多的儿童因缺乏国际援助而面临饿死的危险。世界卫生组织称，由于长达20个月的战乱，也门境内超过半数的医院已经停止工作。胡西族的反政府武装以及和前总统阿拉布都结盟的武装力量联合起来，正在与得到国际认可、并由沙特阿拉伯支持的也门政府交锋。自从开战以来，患上营养不良的儿童数量翻了三倍。我们的特派记者 Fergo Kee 已经前往也门儿童饥饿情况最严重的地区之一。&lt;/p&gt;
&lt;p&gt;“（这哭声）也是属于我们的时代的其中一种声音。无休无止的战争，又一个深陷绝望的婴儿。在这则视频中，我左手边的是 Juda, 她四个月大；我右手边的，跟母亲躺在同一张床上的是 Allian, 他九个月大。他们两个都已经长时间营养不良。我此刻正看着 Juda, 这张小脸空洞洞地看着我，而她的手，作为一个四个月大的孩子来说也太小了。实在太小了。”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Troublemaker</title>
      <link>https://wangcc.me/post/2016-12-13/</link>
      <pubDate>Tue, 13 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-13/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/p01s60xs&#34;&gt;Ukraine&amp;rsquo;s Tiny &amp;lsquo;Troublemaker&amp;rsquo;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/troublemaker.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-13 12:04	用时：23:33
正确率：92%	错词：16个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;unrest: &lt;code&gt;n. 动乱，骚乱，不安的状态&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;stunt: &lt;code&gt;n. 特技表演；噱头 v. 阻碍，遏制；表演特技; 例句： He used to stunt-drive in acrobatic performances. 他过去常在杂技表演中表演驱车特技。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;brutally: &lt;code&gt;adv. 残忍地，野蛮地，狠狠地；直截了当地；难以忍受地&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;ramming:&lt;code&gt;舂实,捣打,打夯,抛砂,夯,压实&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;deliberatly:&lt;code&gt;adv. 故意地；从容不迫地&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;smashing:&lt;code&gt;adj. 极好的；轰动的；粉碎性的 v. smash的现在分词；粉碎&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;divide opinion: &lt;code&gt;指令（一群）人的意见产生分歧。 例句： Airport expansion plans divide opinion. 众人对机场扩建方案看法不一&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;scooter[ˈsku:tə(r)]: &lt;code&gt; n. &amp;lt;英&amp;gt;小型摩托车；（儿童）滑板车。 例句： On the scooter we laughed about the performance.  在摩托车上我们为这场表演哈哈大笑。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;whiz[wɪz]: &lt;code&gt; vi. 发出飕飕声；&amp;lt;口&amp;gt;高速移动。 例句： They heard bullets continue to whiz over their heads. 他们听到子弹不断在他们头顶上嗖嗖飞过。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;【背景资料】
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://baike.baidu.com/link?url=gcz1iRQ83_Hbf8ULWWLoNvXhuTOtvO3IJ4hCx5XZRihxunHNzP-uqKrB9lnIjhm3fzXN1eGLxNpp4G7PCS1TnlGEpalkPopoAygK8OgvttLKJgzX1vxgD8OBgVUEHKS&#34;&gt;Ukraine（乌克兰）&lt;/a&gt;
乌克兰位于欧洲东部，是欧洲除俄罗斯外领土面积最大的国家。原苏联15个加盟共和国之一，是仅次于俄罗斯和 哈萨克斯坦的第三大加盟共和国。1991年苏联解体后，乌克兰独立。乌克兰地理位置重要，是欧洲联盟与独联体特别是与俄罗斯地缘政治的交叉点。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://baike.baidu.com/link?url=3e9EmjsojGCIm2N5XPfOBb9TeAGO_haspCnwGWhQLdn-YDeitY6mPXEJYVavJxNoYLwNe5MS4rijuHLyj2kxO_&#34;&gt;Kiev（基辅）&lt;/a&gt; 基辅为乌克兰首都，经济、文化中心。位于第聂伯河中游两岸，及其最大支流普里皮亚季河与杰斯纳河汇合处附近。面积 782平方千米，人口约260万，全市分为10个行政区。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Tetiana_Chornovol&#34;&gt;Tetiana Chornovol&lt;/a&gt;
Tetiana Mykolayivna Chornovol is a Ukrainian journalist and civic activist, one of the leaders in the ongoing Euromaidan protest campaign. She is famous for investigative reports about corruption in Ukraine, as well as for her adventurous direct actions. On 25 December 2013, Chornovol was the victim of a much published and condemned severe beating.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;译文&#34;&gt;译文&lt;/h2&gt;
&lt;p&gt;我们听说过那些在欧洲引起轰动而具有争议的活动家们。今天我们将去乌克兰的基辅，那里自去年11月动乱开始，政府势力和反对派组织间的冲突已经达到暴力顶峰。34岁的塔提亚娜·车娜沃尔是一位反政府激进分子，乌克兰人对她看法不一。作为一位反对派网站的调查记者，她以工作中行事出奇冒险而闻名。但是去年12月，塔提亚娜自己成为了冒险故事的主角，她的车被逼驶离了公路，之后遭到残忍的攻击。上个月，Outlook节目的露西·阿什去基辅见到了她和她的家人。&lt;/p&gt;
&lt;p&gt;乌斯提姆得到一个带灯的小滑板车，他一圈一圈的（踩着它）走。他很像塔提亚娜。&lt;/p&gt;
&lt;p&gt;噢，是的，他们性格非常相像。&lt;/p&gt;
&lt;p&gt;我刚到达塔提亚娜在首都基辅的郊外的家。在她家客厅，车娜3岁的儿子乌斯提姆坚决地卷起了地毯，好在房间里踩着滑板车溜来溜去，奶奶纳塔丽娅紧紧盯着他看。&lt;/p&gt;
&lt;p&gt;我告诉自己：“汤娅，笔直开。别离开公路。”但撞过来的这辆车大概价值4万美元。于是我意识到，如果这么贵的一辆车故意撞我，肯定有人花了大价钱买我的命。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>人性與戰爭</title>
      <link>https://wangcc.me/post/2016-12-12/</link>
      <pubDate>Mon, 12 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-12/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.com/news/world-13687796&#34;&gt;How soldiers deal with the job of killing&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/soldiers.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-12 14:24	用时：20:19
正确率：89%	错词：22个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;Reverend: &lt;code&gt;adj. （对牧师的尊称，前面与the连用）尊敬的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;combatant: &lt;code&gt;n. 争斗者,战斗员&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;infantry: &lt;code&gt;n. 步兵；步兵团&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;de facto: &lt;code&gt;（法）实际上的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;conscientious:&lt;code&gt;adj. 认真的；尽责的；本着良心的；小心谨慎的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;objector: &lt;code&gt;n. 反对者；提出异议的人&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;musket: &lt;code&gt;n. 步枪；滑膛枪，毛瑟枪&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;Ben说他曾经想要杀戮。但也有一些人是被逼无奈才这么做的。二战期间，作为参战人员的S.L.A. Marshall观察到当时很多人都没有开枪。他做了一个名叫《反对战火的人》的研究，在这份报告里他得出的结论是人们不愿意杀戮。这些人叫做不开枪的人。Marshall说害怕杀戮而非害怕被杀其实是战斗失败的最常见的原因。Marshall研究的方法虽然一直遭到质疑，但是他得出的大结论还是被广泛接受，那就是士兵一般不愿开枪。Giles Frasers博士在英国国防部学院做了以道德为主题的演讲。&lt;/p&gt;
&lt;p&gt;“我认为人类自内心深处就对杀戮有排斥。S.L.A. Marshall发现战斗步兵队伍中，只有15%到20%的人能够朝敌人开枪。而80%的人在面临开枪那一刻实际上是会产生抵触情绪而不愿意这么做的。我认为这个发现很特别。葛底斯堡的战役也很特别。当时有27000把来复枪和步枪散落在战场上，其中90%的枪都上了膛。实际上这是因为没有人开枪。”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>亂局中的伊斯坦布爾(Istanbul)</title>
      <link>https://wangcc.me/post/2016-12-11/</link>
      <pubDate>Sun, 11 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-11/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/istanbul.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-11 17:20	用时：22:26
正确率：94%	错词：14个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;political repression: &lt;code&gt;政治壓迫,鎮壓&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;turmoil: &lt;code&gt;n. 混乱；焦虑；骚动&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;coup: &lt;code&gt;n. 成功之举；政变；妙计&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;attempted[əˈtemptɪd]: &lt;code&gt;adj. 未遂的，企图的。例句： The attempted coup took place in January. 那场未遂政变发生在1月份。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;alleged: &lt;code&gt;adj. 声称的；被断言的；可疑的 v. allege的过去式和过去分词；宣称&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;plotter: &lt;code&gt;n. 阴谋者,计划者;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;unbiased: &lt;code&gt;adj. 公正的；无偏见的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%BC%8A%E6%96%AF%E5%9D%A6%E5%B8%83%E5%B0%94%E6%B5%B7%E5%B3%A1&#34;&gt;Bosphorus&lt;/a&gt;: &lt;code&gt;伊斯坦布爾海峽&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;breezy: &lt;code&gt;adj. 有微风的；活泼的，明快的，随意的&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;我们今天的节目鲜活地反映了政治镇压时期土耳其的生活。那时，国家处于一片混乱。未遂政变发生近六个月以来，国家一直处于非常时刻。司法部官方数字表明，至少93,000人因涉嫌策划政变而接受调查，约34,000人正面临指控。土耳其最近一次政治骚乱发生在上世纪80年代，那是一场真正的军事政变。近来作为小说家而被人熟知的布尔汗·索门茨在那时还是个孩子。直到几年后这个怀揣理想主义的17岁男孩搬到伊斯坦布尔准备去攻读法律学位时，才对动乱的局面真正有所感触。&lt;/p&gt;
&lt;p&gt;当然，来这之前我就知道伊斯坦布尔。关于土耳其伊斯坦布尔的各种歌曲、电影、故事、小说和诗歌。甚至一些关于伊斯坦布尔的神话故事。&lt;/p&gt;
&lt;p&gt;嗯。你第一次来到这里就觉得它像神话吗？&lt;/p&gt;
&lt;p&gt;是的，那当然，令我惊叹。我们来到伊斯坦布尔的一个宏伟的火车站，海达尔帕夏火车站。它就坐落在海边。我敢说它是世界上最美的火车站。&lt;/p&gt;
&lt;p&gt;这评价很客观，当然。&lt;/p&gt;
&lt;p&gt;是的。一下火车就能看见博斯普鲁斯海峡，而海对面就是欧洲。景色壮美，引人入胜，那天还有些许微风感觉非常棒，我记得当时是9月。&lt;/p&gt;
&lt;p&gt;而你正打算开始成年生活。&lt;/p&gt;
&lt;p&gt;是的。我不害怕，反而非常兴奋，还有点紧张，因为你不知道这座大城市有什么在等着你，好事还是坏事。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>默片《拿破侖》</title>
      <link>https://wangcc.me/post/2016-12-10/</link>
      <pubDate>Sat, 10 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-10/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/napoleon.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-10	用时：21:39
正确率：94%	错词：5个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E6%84%9B%E6%A8%82%E7%AE%A1%E5%BC%A6%E6%A8%82%E5%9C%98&#34;&gt;爱乐乐团（The &lt;em&gt;London&lt;/em&gt; Philharmonia Orchestra&lt;/a&gt;: 是伦敦的一支管弦乐团。曾几度易名。乐团于1945年在“EMI唱片公司”制作人华尔特·莱格组织下成立，当时只是一支录音专用乐团。从1995年起，皇家节日大厅成了乐团的固定演出场所。&lt;/li&gt;
&lt;li&gt;composer: &lt;code&gt;n. 作曲家；著作者&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;gauge: &lt;code&gt;n. 标准尺寸；测量仪器；规，表，计；大小，程度；范围；容量；（枪管的）口径 v. 判断；估计；量，测&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;本周在伦敦，影院的年度重大事件，暂且不说是本世纪，将会是一部制作长达90年的五个半小时电影。那就是阿贝尔·冈斯的《拿破仑》。这部电影曾经被忽视，如今通过数字修复技术于上周日上映，上映时还配有爱乐管弦乐团的现场演出，由即将80岁并支付了电影修复费用的作曲家卡尔•戴维斯指挥。&lt;/p&gt;
&lt;p&gt;我们必须留下一些什么。这就是我们做这部电影的意义。这不是为了纪念，或是因为什么强势的力量让我们促成了这部电影，真正重要的是你做了什么，这才是重要的，你知道吗，他是拿破仑，这就够了。&lt;/p&gt;
&lt;p&gt;我们之所以能在21世纪看到《拿破仑》是因为一个追求了60年片段和轨迹的人的奉献。他就是电影侦探凯文·布朗罗。&lt;/p&gt;
&lt;p&gt;当我还是个在学校的小男孩时，我就是一个非常热衷于收藏9.5mm电影的人，在8mm占领荧屏之前，这是标准的家庭电影规格。我有一部由法国知识分子让 · 爱普斯坦指导的电影《蒙古的雄狮》，然而我不能忍受它，想要摆脱它。 所以我打电话给我当时买这部电影的图书馆，他们说“不过，不幸的是，我们只剩下一部电影了“。 它就是《法国大革命中的拿破仑·波拿巴》，当时我并不想要它，因为那听起来像一部在教室里放的电影。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>對話總統演講撰稿人</title>
      <link>https://wangcc.me/post/2016-12-9/</link>
      <pubDate>Fri, 09 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-9/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/p04h4616&#34;&gt;Speech Writer to the President&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/speechwriter.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-9 12:29	用时：21:01
正确率：91%	错词：30个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;hone in : &lt;code&gt;磨炼; Improves my ability to hone in on an idea and learn to execute it quickly as well as meticulously. 改善我迅速深入一个创意骨子里的能力，并且学习如何迅速而尽善尽美地体现它; 锁定目标，进一步查明或发现 例句：We can hone in on your problem areas and have your employees maximizing their skills again in no time. 我们会全力研究您公司的问题，让您的职员在最短的时间里再发挥出他们的最大才能。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;dear: &lt;code&gt;adj. 关切 例句： This is a subject very dear to the hearts of academics up and down the country. 这个话题举国上下的学者都非常关切。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;this idea of being true to the character of the president: &lt;code&gt;符合总统本身的特点&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;演讲写作也是一种职业，我想并不是所有人都知道还有这样的职业存在。那么，萨拉达，你能给我们讲讲演讲撰稿人是做什么的吗？&lt;/p&gt;
&lt;p&gt;当然可以。而且我也很想听听对蒂娜和科索沃来说会有什么不一样的地方。对于我们来说，演讲撰稿人的职责就是真正地帮助演讲者发现自己的心声，弄清楚自己想要表达什么、怎样去表达。我个人觉得，演讲的真正作用就是说服听众去相信某件事、去做某件事。所以在我看来，作为一名演讲撰稿人，你的工作并不是替演讲者出主意，而是帮助他们发现并且弄清楚自己的想法、确立论据，然后找到最有说服力的方法来传达这条论据。&lt;/p&gt;
&lt;p&gt;跟我的想法不谋而合。对我来说，了解亚希亚加总统所关心的问题、了解她的看法是很重要的。如果你想让演讲有影响力、令人难忘、又符合总统本身的特点、还要反应她和她的内阁成员们所关心的问题，那么在演讲里穿插她的个人经历以及她的政治立场也是很重要的。&lt;/p&gt;
&lt;p&gt;这点很有意思，“符合总统本身的特点”或者其他你为之写作的人物的特点。那么为了写出好的演讲稿，你是不是得充分了解他们才行？&lt;/p&gt;
&lt;p&gt;对我来说，能在总统的身边听她谈话、听她跟各种各样的人交谈——跟她身份相当的人交谈，或是跟科索沃的普通民众——对我是很有帮助的。当我在写演讲稿的时候，我会觉得几乎得完全摒弃自己的声音，要用她的语气、她的用词，这样演讲才会最贴近她本身的说话方式。所以，对的，演讲稿是要跟演讲者的谈吐、跟他们本身的化学效应相匹配的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>不可能的故事</title>
      <link>https://wangcc.me/post/2016-12-8/</link>
      <pubDate>Thu, 08 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-8/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/slavery.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-8 11:32	用时：14:48
正确率：95%	错词：8个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;p&gt;We start today with the unlikely story of how an American woman came to be working with truckers to combat human trafficking. Kendis Paris lives in Denver, Colorado with her Anglican priest husband and &lt;!-- raw HTML omitted --&gt;her&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;their&lt;!-- raw HTML omitted --&gt; two children. She used to spend her days making bread and cheese, home with &lt;!-- raw HTML omitted --&gt;her&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; kids. But now she travels the country&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; training drivers to &lt;!-- raw HTML omitted --&gt;recognize&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;recognise&lt;!-- raw HTML omitted --&gt; and report human trafficking. Her &lt;!-- raw HTML omitted --&gt;organization&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;organisation&lt;!-- raw HTML omitted --&gt; is called Truckers Against Trafficking, or TAT. She told me what inspired her to set it up. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;It was around 2007 and I read a book by David Batstone called Not For Sale. And before that &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; I probably could give you a working definition of human trafficking&lt;!-- raw HTML omitted --&gt;if&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;but&lt;!-- raw HTML omitted --&gt; that&amp;rsquo;s about it. And I picked that up at the direction of my mother &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and &lt;!-- raw HTML omitted --&gt;got to &lt;!-- raw HTML omitted --&gt;Chapter &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;3&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Three&lt;!-- raw HTML omitted --&gt; and &lt;!-- raw HTML omitted --&gt;I&lt;!-- raw HTML omitted --&gt; was so appalled and outraged I &lt;!-- raw HTML omitted --&gt;have&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;had&lt;!-- raw HTML omitted --&gt; to flip to the back of the book to find out how to help. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;What did that book say &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; that shocked you so much? &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;It was the level of systematic &lt;!-- raw HTML omitted --&gt;reap&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;rape&lt;!-- raw HTML omitted --&gt; for profit &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;that &lt;!-- raw HTML omitted --&gt;just floored me. I just &lt;!-- raw HTML omitted --&gt;could&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;couldn&amp;rsquo;t&lt;!-- raw HTML omitted --&gt; believe the numbers&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; I couldn&amp;rsquo;t believe that &lt;!-- raw HTML omitted --&gt;modern-day&lt;!-- raw HTML omitted --&gt;  slavery existed on this scale&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; around the world and right here in the United States.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;human trafficking: &lt;code&gt; 贩卖人口。 例句： It has deciphered secret communications about murder, drug transactions, illegal gambling and human trafficking. 那些密码涉及到了谋杀、毒品交易、非法赌博和贩卖人口之间的秘密联系&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Anglican[ˈæŋglɪkən]: &lt;code&gt; adj. 英国国教会的。 例句： It is now an Anglican church.  它现在是英国圣公会。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;appalled[əˈpɔ:ld]: &lt;code&gt; adj. 惊骇的；丧胆的。 例句: He looks appalled, as if I&#39;ve tried to assault him.  他那样子显得很惊骇，仿佛我试图袭击他。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;priest: &lt;code&gt;n. 牧师，神父，教士&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;British English&lt;/strong&gt; lists an alternate spelling as recognise, &lt;strong&gt;but the main entry is recognize&lt;/strong&gt;. &lt;strong&gt;North Americans (yes, that includes Canada) prefer the &lt;em&gt;ize&lt;/em&gt; spelling&lt;/strong&gt;, and &lt;strong&gt;this is accepted everywhere.&lt;/strong&gt; However, &lt;strong&gt;outside North America some prefer the ise spelling and it is not incorrect.&lt;/strong&gt; This spelling change goes across all derivatives including: recognizability, recognisability, recognizable, recognisable, recognizeably, recognisably, recognizer, and recogniser.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Organise and organize are different spellings of the same word&lt;/strong&gt;. Organize is the preferred spelling in the U.S. and Canada, and &lt;strong&gt;organise is more common outside North America&lt;/strong&gt;. This extends to all the word’s derivatives, including organized/organised, organizing/organising, and organization/organisation.&lt;/li&gt;
&lt;li&gt;rape for profit: &lt;code&gt;为了盈利的抢夺/强奸&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;give a working definition: &lt;code&gt;理论上/操作型/工作上的定义&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;direction: &lt;code&gt;n. 方向；指导；趋势；用法说明&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;floor: &lt;code&gt;n. 地板，地面；基底；议员席；楼层 v. 铺地板；打倒；难倒&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;modern-day: &lt;code&gt;adj. 现代的&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;今天这个故事听起来似乎不大可能：一位美国女人与卡车司机们联手合作，共同打击贩卖人口。肯蒂斯•帕里斯和她的丈夫——一名英国国教牧师——以及两个孩子生活在科罗拉多州丹佛市。她过去经常在家制作面包和奶酪，陪孩子们在一起。但是现如今，她走遍全国各地，教授司机去识别并上报贩卖人口的犯罪行为。她有一个名为“卡车司机打击贩卖人口”的组织，简称TAT。她告诉我是什么启发她建立这个组织的。&lt;/p&gt;
&lt;p&gt;大概2007年的时候，我读了大卫•巴斯顿的《非卖品》。在此之前也许我能够给出贩卖人口的定义，但仅此而已。我在母亲的推荐下阅读了这本书。在读到第三章时，书中的内容令我既惊恐又愤怒。我不得不将书翻到最后去寻找帮助他们的办法。&lt;/p&gt;
&lt;p&gt;那本书里讲了什么让你如此震惊呢？&lt;/p&gt;
&lt;p&gt;里面涉及被拐卖后强迫卖淫的问题，真的让我吃惊极了。我无法相信那些数字。我无法相信在现代社会还有如此规模的奴隶制度依然存在，而且遍及世界各地，甚至就在美国。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>撒謊</title>
      <link>https://wangcc.me/post/2016-12-7/</link>
      <pubDate>Wed, 07 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-7/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://ting.hujiang.com/bbc/163725085737/&#34;&gt;概述：对朋友撒了一个谎，需要用更多的谎言来圆它。所以，朋友之间还是坦诚一点比较好。&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-7 10:33	用时：28:09
正确率：89%	错词：33个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;row: &lt;code&gt;n. 行，排；街道；划船；吵闹 v. 划船；争吵; My parents often have rows. 我爸爸妈妈经常吵架。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Heathrow:&lt;code&gt;Airport(英国伦敦的)希思罗机场&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;overstuff: &lt;code&gt;v. 过度填塞&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;overstock: &lt;code&gt;n. 供给过多,库存过剩 vt. 供给过多,进货过多,过剩&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;hue: &lt;code&gt;n. 色彩，色调；喊叫声; Add orange paint to get a warmer hue. 加些橙色颜料使之略呈暖色.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Wandsworth: &lt;code&gt;旺兹沃思[英国英格兰东南部城市](在大伦敦郡的西南部)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;lengthen: &lt;code&gt;vt. 使延长；加长 vi. 延长；变长&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;untruthfully:&lt;code&gt;adv. 不真实地;不诚实地&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;emaciate: &lt;code&gt;v. （使）消瘦，衰弱&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;day-to-day: &lt;code&gt;日常的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;bedsit [ˈbed.sɪt]: &lt;code&gt;n. 起居卧室两用房 He was living alone in a dingy bedsit in London. 他独自一人住在伦敦一间昏暗的客卧两用出租屋里。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;1976年，我朋友格林决定放弃他的广告事业，转而去苏丹当一年英语教师。他回来后本该跟他兄弟一起住。但当飞机降落在希思罗机场后几分钟，他们吵了一架。于是格林打电话给我，询问能否和他来自新西兰的新女友弗吉尼亚在我家的空房间里小住。他们到我家时，身后拖着几个塞得满满的大箱子。俩人非常消瘦，皮肤由于感染热带寄生虫而显浅橘色。&lt;/p&gt;
&lt;p&gt;重回伦敦的头几天，他俩几乎是在我家卫生间度过的，里面时常传来可怕的声音。我和我妻子琳达担心被感染上同样的寄生虫，所以都跑到离家不远的酒吧用卫生间。酒吧在河对岸的旺兹沃思，公交车几站就到了。&lt;/p&gt;
&lt;p&gt;一周又一周过去了，这对情侣极少出门，他们整日待在公寓不断的争吵、抽烟。过了段时间，琳达和我再也无法忍受，便要求格林二人搬走。但是，我们并没有选择坦诚相告，而是骗他们说有一个老朋友克里斯汀将要来家里住段时间，她需要这间屋子，且不清楚到底要住多久。&lt;/p&gt;
&lt;p&gt;消瘦的格林二人不大情愿地同意了。不过他们想要把行李箱留在这里。因为他们唯一能租到的房子非常小，是个卧室兼起居室的两用租间，没有地方放置行李箱。我们同意了，但随之而来也有一个问题——接下来的日子，格林或是弗吉尼亚会定期回这间房里取东西。这样一来，我便不得不制造这间房被克莉斯居住的假象。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>老年性瞬間失憶</title>
      <link>https://wangcc.me/post/2016-12-6/</link>
      <pubDate>Tue, 06 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-6/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/memory.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-6 12:9	用时：20:40
正确率：94%	错词：7个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;darn: &lt;code&gt;adj. 可恶的；完全的 adv. 极其 interj. 可恶 n. 补丁 v. 织补&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Green Party: &lt;code&gt;n.绿党（关注环保的政党） 例句： There is a Green party but it only scored around about 10 percent in the vote. 虽然有一个绿党，但在选举中该党只得到了大约10%的选票。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;aphasia [əˈfeʒə]: &lt;code&gt; n.失语症（Aphasia is a mental condition in which people are often unable to remember simple words or communicate.） 例句： Unfortunately, he suffered from sudden onset of aphasia one week later.不幸的是, 他术后一星期突然出现失语症。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;gallop: &lt;code&gt;n. 疾驰，飞奔；飞快 v. （使）疾驰，飞奔；飞速发展；快速做（或说），急速进行；飞速传递&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;inability: &lt;code&gt;n. 无能，无力，不能&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;最近几个月，一些人像得老年痴呆一样忘事的行为见诸报端。二月初，埃德·鲍尔斯忘记他的商业伙伴比尔·托马斯的名字。几个星期后，绿党领袖娜塔莉·贝内特在接受伦敦广播公司尼克·法拉利采访时差点没回忆起绿党政策。嗯，我敢打赌，埃德·米利班德也希望我们早点忘记去年秋天他在工党会议上忘了提及国家经济的囧事。其实我完全能够理解这些政治家，因为我和他们一样，都一把年纪了，总是记不得东西，该死的。&lt;/p&gt;
&lt;p&gt;心不在焉的习惯我早就有了。我30多岁时经常是晚上把车停好白天就忘了停哪。我经常忘记前一天做过的事情，而且还会记不起别人的名字。&lt;/p&gt;
&lt;p&gt;不过我一直擅长多线程工作，我丰富的知识还曾经让我当上大学挑战队的队长。曾经的我也可以在政治辩论里意气风发，崭露头角。&lt;/p&gt;
&lt;p&gt;现在不行了。因为我糟糕的记忆力，儿时成为国会议员的梦想已离我远去，我记不住面孔，统计数字甚至政策，我记不清名字，好像患了失语症一般，我的认知能力也下降了很多，太可怕了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>川普閉關鎖國</title>
      <link>https://wangcc.me/post/2016-12-5/</link>
      <pubDate>Mon, 05 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-5/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/trump.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-5 11:56	用时：18:03
正确率：87%	错词：27个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;President-elect: &lt;code&gt;n. 总统当选人；已当选而尚未就职的总统&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;watcher: &lt;code&gt;n. 看守人,守望者,照顾者&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;PIMCO: &lt;code&gt;abbr. 太平洋投资管理公司（Pacific Investment Management Company）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;crushing: &lt;code&gt;adj. 决定性的；压倒的；支离破碎的 v. crush的现在分词, 毁灭性的强调; 例:...since their crushing defeat in the local elections.…自从他们在地方选举中遭到毁灭性的挫败以来。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;tariff:&lt;code&gt;n. 关税表，关税；价目表；菜单；价格，费 v. 对...征收关税；定...的税率；按税率定...的价格&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;NAFTA: &lt;code&gt;【缩写】=North American Free Trade Agreement 北美自由贸易协议&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;imminent: &lt;code&gt;adj. 即将发生的，逼近的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;dismantle: &lt;code&gt;v.逐步废除; 例：Public services of all kinds are being dismantled. 各种公共服务正被逐步废除。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;根据总统当选人唐纳德·特朗普的说法，跨太平洋伙伴关系协定将被终结。他说，一旦一月份入主白宫，首要就是了结TPP。这是否预示着特朗普观察者一直以来担心的事情已经有了苗头，即美国在其统治下将更注重自我保护主义。可能是的。但在昨天BBC的Hard Talk节目中，PIMCO前CEO，现任美国总统奥巴马的全球发展委员会主席Mohamed El-Erian认为仅这个动作对整体格局只是杯水车薪。 原因很简单，TPP还没有完全敲定。并且他也没说事先逃离市场，增加对中国和墨西哥打击性关税。我们还没听说这点。我会逐步废除北美自由贸易协定，而这一协定已经运转数十年。我们也没听说。他显然在避免提及这些。 无论事实如何，即便TPP即将终止，跨太平洋贸易整体上仍能找到出路。以中国为例，该国投资数十亿美元启动了新的丝绸之路，通过中亚的公路和铁路将其工厂与欧洲和中东市场联结。北京方面似乎仍看好由美国帮忙完成该项目。珍·奥布莱恩带来相关报道。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>命運不是天注定</title>
      <link>https://wangcc.me/post/2016-12-4/</link>
      <pubDate>Sun, 04 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-4/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.ozy.com/true-story/how-a-team-of-unclean-cleaners-fought-caste-with-cricket/65120&#34;&gt;HOW A TEAM OF &amp;lsquo;UNCLEAN CLEANERS&amp;rsquo; FOUGHT CASTE WITH CRICKET&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Bombay.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-4 17:29 	用时：23:16
正确率：92% 	错词：21个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;Mumbai: &lt;code&gt;n. 孟买(位于印度西部,原名为Bombay)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;on grounds of: &lt;code&gt; 以…为理由，以…为借口，根据。 例句： We base this call on grounds of social justice and equity. 我们基于社会正义和公平发出这一呼吁。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;castes: &lt;code&gt;n. 种姓（制度），社会等级（制度）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;pit: &lt;code&gt;n. 深洞；煤矿；麻子；修理加油站；交易场所 v. 使有麻子；使有凹陷&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;rise above: &lt;code&gt; 克服；升到…之上；超越…；沾沾自喜。 例句： It tells the story of an aspiring young man&#39;s attempt to rise above the squalor of the street.  它讲述了一位有志青年试图摆脱贫苦肮脏的街头生活。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;今天的故事发生在印度。多年来，即使因为种姓而歧视人是违法的，那里的人仍然处于极为不利的地位。维姆·库马尔就是来自最底层种姓中的一员——楚哈拉斯家族。他们时常被称为“贱民”，家族里几代人都是靠打扫厕为生。但如今维姆正在攻读博士学位。他设法摆脱了种姓制度，并帮助处于这一阶层中其他人改变命运。远在孟买的维姆在线向我讲述了他的故事，一切始于他的学生时代。&lt;/p&gt;
&lt;p&gt;那些记忆在我脑海里依旧鲜明。我的母亲也在同一所学校做清洁工。她过去经常打扫干厕，也就是没有水的厕所，而我在学校的身份就是清洁工的儿子。老师们不叫我的名字。他们都这样这么跟我说话，“清洁工的儿子，到这来”。在学校我觉得非常丢脸。&lt;/p&gt;
&lt;p&gt;那为这个你会生气吗？你生过气么？&lt;/p&gt;
&lt;p&gt;是的，全班乃至整个学校都对我说“你妈是给我们扫厕所的。你们是烂人，脏人”。他们还打我们。他们不愿意碰我们，不让我们进他们家门。因此我不喜欢去上学，通常待在家里。每天家人都极力劝我去上学。我的母亲说：“别在意那些，抛开它们，你就去上学，把精力集中在学习上”。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>《大洋之光》</title>
      <link>https://wangcc.me/post/2016-12-3/</link>
      <pubDate>Sat, 03 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-3/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/light_between_oceans.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-3 11:49	用时：23:21
正确率：91%	错词：21个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;adaptation: &lt;code&gt;n. 适应；改编，改编本&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;emotionally wrenching: &lt;code&gt;让人感到情感上痛苦的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;endorphin: &lt;code&gt;n. ［生化］内啡肽:指将麻醉传感器联结在一起的任一肽激素群，主要存在大脑中，可缓解痛感并影响情绪 a chemical produced by your body that reduces pain and can make you feel happier&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;my face was melting from tears: &lt;code&gt;我的脸上淌满了泪水&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;North Star: &lt;code&gt;北极星&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;sequence [&amp;lsquo;siːkw(ə)ns]: &lt;code&gt;n. 有关联的一组事物, 一连串  例句： At each location on the sequence, we can measure all these different attributes of chromatin. 在序列的每个位置上，我们都可以测量染色质的这些不同属性。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;我们开始吧，先让我们抑制一下呜咽，虽然这周值得在影院一哭。为什么呢？因为一部新电影《大洋之间的灯光》。这部电影改编自M·L·斯坦德曼的小说，讲述的是一对夫妻的故事，由迈克尔·法斯宾德和艾丽西亚·维坎德饰演。妻子屡遭流产，而他们这时候却发现了一个婴儿，但幸福并未就此开始。故事就发生在那片被未知海洋包围的遥远澳大利亚岛屿。最近的一项牛津大学研究表明，观看让人情感上痛苦的荧幕电影可以激活内啡肽的产生——科学认证明，痛快哭一场能让你感觉更好。对很多人来说，观看《大洋之间的灯光》将是一个非常棒的夜晚。一些观众在电影最后都哭的无法自已。剧本的改编和拍摄指导都出自国导演德里克·斯安弗朗斯，他先前的两部作品《蓝色情人节》和《松林外》都让我感动落泪。德里克也承认他之所以决定改编《大洋之间的灯光》一部分原因也是因为它让他热泪盈眶。 “我的意思是我爱这本小说。我还记得我是在纽约的城市列车上看哭的。你知道，看到书的结尾时我的脸上淌满了泪水，你知道的，最初我很尴尬，然后我心想，任何人如果正在读这本小说，他们也将有同样的反应。我只是把它当作我的北极星。”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>控制野豬新方法</title>
      <link>https://wangcc.me/post/2016-12-2/</link>
      <pubDate>Fri, 02 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-2/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/pigs.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-2 12:37	用时：26:21
正确率：91%	错词：24个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;boar: &lt;code&gt; n. 公猪，野猪；公猪肉&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;worm: &lt;code&gt;n. 虫，蠕虫；螺纹；蜗杆；小人物 v. （使）蠕动；（使）缓慢前进；给…除虫&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;dart: &lt;code&gt;n. 飞镖，标枪；猛冲，飞奔 v. 飞奔，猛冲；投射&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;piglet: &lt;code&gt;n. 小猪&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;feral: &lt;code&gt;adj. 野生的,凶猛的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;vessel: &lt;code&gt;n. 船；飞船，飞机；容器，器皿；血管&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;syringe: &lt;code&gt;n. 注射器,洗涤器 vt. 注射,洗涤&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;barb: &lt;code&gt;adj. 有倒钩刺的 n. 倒钩，倒刺&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;我一直觉得一定有什么方法可以控制野猪的数量增长。我们这里在除虫之类的时候可以从六尺以外进行注射。但是当我听说有一家公司可以远程射中野猪的时候，我很感兴趣。然后他们就过来了。结果，他们飞镖注射了我们全部的八只野猪。这是今年四月一号发生的事情，成功率100%，之后再没有小猪出生了。&lt;/p&gt;
&lt;p&gt;可是看看这些野猪，它们移动速度那么快，射中它们真的实际吗？&lt;/p&gt;
&lt;p&gt;是呢，就这么容易射中。他们用的枪很复杂，带有望远镜的。开枪的时候野猪几乎都不会注意到。&lt;/p&gt;
&lt;p&gt;那么，为了了解更多关于远距离注射的情况，我去见了动物福利研究院的菲尔约克。他专门给半野生动物注射镇静剂和疫苗。现在，他就在我旁边，手里拿着注射飞镖。我不得不说这个注射飞镖的针头看上去非常可怕。菲尔，你能跟我讲讲这个飞镖吗？&lt;/p&gt;
&lt;p&gt;这就是我们用来注射疫苗的飞镖。它是专门从美国进口的。它真的非常好用。我们使用的远程注射系统在60码以外也很精确。你可以看到这里有一个用来保持平衡的镖尾。药物是由兽医注入这个飞镖上的容器里的。药物会从飞镖的尾部流出，就像注射器那样。这儿有个蜡制的倒钩，当飞镖进入动物身体后，体温会使蜡融化。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>時間的錯覺</title>
      <link>https://wangcc.me/post/2016-12-1/</link>
      <pubDate>Thu, 01 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-12-1/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/time.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-12-1 17:9	用时：21:30
正确率：90%	错词：23个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;I wonder if any of us have really stopped to consider their full import: &lt;code&gt;但你们也许从来没有思考过它们的意义。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;speculative: &lt;code&gt;adj. 推测出的；投机的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;subjective: &lt;code&gt;adj. 主观的；个人的；自觉的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;unredeemable [&amp;lsquo;ʌnrɪ&amp;rsquo;di:məbl]&lt;code&gt;adj.不能收回的，不能赎回的 例句： They will be unredeemable for two years, and will be redeemed in eight years. 必须保存2年， 8年内偿还。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;transpire: &lt;code&gt;v. 使蒸发；蒸发；发散 : 例句： We don&#39;t know what will transpire when we have a new boss. 当我们有位新老板时,不知会发生什么。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;let alone: &lt;code&gt;更不必说；听任；不打扰&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;inclination: &lt;code&gt;n. 倾向；意愿；倾斜度&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;attribution: &lt;code&gt;n. 归属；属性；归属物；归因判断&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;preoccupy: &lt;code&gt;v. 使出神；抢先占有&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;slipperier: &lt;code&gt;adj. 滑的；狡猾的；不稳定的 (slippery的变形)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;slither: &lt;code&gt;vi. 蜿蜒地滑行 vt. 使滑动 n. 滑动；滑行&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;nauseating: &lt;code&gt;adj. 令人恶心的；厌恶的 v. 使恶心（nauseate的ing形式）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;cleave: &lt;code&gt;v. 劈开，使分开；坚守；披荆斩棘地前进；粘住&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;cleave to: &lt;code&gt;粘着；坚持 例句： The tribe cleave to their old belief even after the european arrive。即使在欧洲人到来之后,这些部落仍固守著它们古老的信仰.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;托马斯‧史特恩‧艾略特(Thomas Stearns Eliot 1888-1965) 是位出版者、剧作家、文学、社会评论者，及二十世纪最受争议的重要英语诗人，生于美国，在1914年搬至英国。他以《J.阿弗雷德•普鲁弗洛克的情歌》(The Love Song of J. Alfred Prufrock)奠定诗名，是现代主义运动的重要作品，写于1910年，在1915年发表；此诗具有很浓的讽刺意味，刻画当时社会背景下，人们对爱情及生活的复杂心理。他重要的诗作包括《Poems》(诗集1919)、《The Waste Land》(荒原1922)、《The Hollowmen》(中空的人1925)、《Ash Wednesday》(圣灰星期三1930)及《Four Quartets》(四个四重奏1945)。他写过七部剧本，其中以《Murder in the Cathedral》(教堂谋杀1935)为着。他在1948年以《Order of Merit》得诺贝尔文学奖。《焦灼的诺顿》（Burnt Norton）是 《四个四重奏》(Four Quartets)中的第一首诗；他书写时间与救赎(Time and Redemption)的特质，他的意旨在强调个人对目前状况及了解宇宙秩序的需要。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;“现在和过去的时光， 也许都存在于未来之中，且未来的时光包含于过往。假如所有时间都永恒存在，所有时间都无法履行。”这是写于20世纪30年代，艾略特《四个四重奏》中《焦灼的诺顿》的开场白。虽然你们可能很熟悉这几句，但你们也许从来没有思考过它们的意义。诚然，因为一个词“也许”，艾略特的语气听起来不是十分确定，但他的意思已经很清晰：如果时间向一条河流一样滚滚向前只是我们的主观臆测（译者注：就是时间没有先后），所有的时间和事件都已经发生，那么我们就根本无力改变未来，更别说过去了（译者注：看过interstellar的人可以联想电影中四维空间的相关镜头）。人会倾向于将艾略特的这个观点和自由意志以及道德责任联系起来，毕竟这是人作为社会动物最为关心的问题。不过，在这里我只想着眼于时间本身，探讨一下人对时间的感知。&lt;/p&gt;
&lt;p&gt;第四维比前三维费解得多，人想抓住它时，它总是能从我们的指尖溜走。想一想，如果我们不同意艾略特的想法，认为过去的已经过去且不再存在，而未来还没有发生，那么所有的现实都会与此时此刻紧密相关。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>救贖</title>
      <link>https://wangcc.me/post/2016-11-30/</link>
      <pubDate>Wed, 30 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-30/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/b07x2zcw&#34;&gt;Trevor McDonald on Redemption&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/redemption.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-30 11:49	用时：18:14
正确率：91%	错词：27个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;redemption: &lt;code&gt;n. （尤指基督教的）拯救，赎罪，救赎例句： They visited the Shrine of Our Lady to pray for redemption. 他们参观了圣母玛利亚的神龛，祈祷以期救赎。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;be subjected to sth: &lt;code&gt;有；遭受，承受 例句： Cars are subject to a high domestic tax. 买汽车要交很高的国内税。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;brutality /bruːˈtæl.ə.ti/: &lt;code&gt;n. 残酷性，残忍行径 例句： the brutalities of war 战争的残酷&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;sort: &lt;code&gt;n. 种类；方式；品质 vt. 将…分类；将…排序；挑选出某物 vi. 分类；协调；交往&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;redeem: &lt;code&gt;vt. 赎回；挽回；兑换；履行；补偿；恢复&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;whilst: &lt;code&gt;conj. 同时；时时，有时；当…的时候&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;set out: &lt;code&gt;（怀着特定目的）开始，着手 例句： She set out with the aim of becoming the youngest ever winner of the championship. 她努力的目标就是成为史上最年轻的冠军。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;lurk /lɜːk/: &lt;code&gt; v. 潜伏，潜藏 例句： It seems that old prejudices are still lurking beneath the surface. 表象背后似乎依然潜藏着旧有的偏见。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;“救赎（redemption）”一词的概念有多种解读。它通常指挽救过失、罪恶，或从过失、罪恶中得到解放的过程。我们用这一词表明某人曾犯下罪行。而今天我们的嘉宾未曾犯过罪行。事实上，她在13岁时遭到严重的暴力虐待。玛德琳·布莱克曾被强奸。而她如今认为，自己通过“原谅”得到了救赎。&lt;/p&gt;
&lt;p&gt;玛德琳，一个人要怎么寻求或者得到这样的救赎？&lt;/p&gt;
&lt;p&gt;“寻求救赎”并非我本来的打算。这是三样东西的结合。我曾以为我已经从过去的伤痛中走了出来，那些创伤已经被治愈了。但总有东西潜藏着，让我无法真正释怀。在我长女快到13岁时，我已经接受了3年的心理治疗。我的治疗师暗示我那些人可能并非生来就是强奸犯。但我一点也不想去原谅他们。我只希望他们也被绑架、被绑起来、被强奸、被折磨数小时，就像他们曾对我做的那样。然而，心理医师的话却像颗种子被植入我的脑海，并开始生长。我开始想要了解他们为什么会走上“强奸”这条路。他们并没有比我大多少，大概17、18岁。我想知道，他们怎么会对别人那么残酷、暴力，他们曾看到、听到或经历过什么事情，导致他们会做出这样的行为。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>敘利亞難民危機</title>
      <link>https://wangcc.me/post/2016-11-29/</link>
      <pubDate>Tue, 29 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-29/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://ting.hujiang.com/bbc/163721381109/&#34;&gt;Crisis in Syria&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-29 11:36	用时：20:43
正确率：92%	错词：15个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;besiegement: &lt;code&gt;n. 围攻;围绕;推进&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;subtle: &lt;code&gt;adj. 微妙的；精细的；敏感的；狡猾的；稀薄的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;submit: &lt;code&gt;vi. 提交；服从 vt. 使服从；主张；呈递&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;deliberate: &lt;code&gt;adj. 故意的；深思熟虑的；从容的 v. 仔细考虑；商讨&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;tactic: &lt;code&gt;n. 策略，战略 adj. 按顺序的，依次排列的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;compound: &lt;code&gt;n. [化学] 化合物；混合物；复合词 adj. 复合的；混合的 v. 合成；混合；恶化，加重；和解，妥协&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;仅仅在过去半年里，被困在叙利亚的难民人数达到将近一百万，已经相比之前翻了一番。在一份呈交给安理会的简报中，联合国人道主义援助事务负责人史蒂芬·奥布莱恩发出警告：阿勒颇东部的难民处境已经从“糟糕”变成了“惨不忍睹”。他声称，在叙利亚发生的大部分暴力事件都是由叙利亚政府军挑起的。&lt;/p&gt;
&lt;p&gt;“难民们被围困是个纯粹的事实，没有什么复杂和费解的地方。他们与世隔绝、忍饥挨饿、出行受限、得不到任何可以帮助他们撑过眼前难关或者是医疗措施、或者可以让他们逃离这里的人道主义援助。甚至有人出于政治、军事、在有些情况下、甚至是经济上的利益而去欺压践踏这群毫无还手之力的难民、加重他们的痛苦，这实在是人为的暴行。“&lt;/p&gt;
&lt;p&gt;他再三呼吁安理会采取强硬行动来支持他的决议，终止这场内战，疏通人道主义援助渠道、强制禁止围困。安理会的成员在如何结束这场将近长达六年的内战问题上意见产生了分歧。叙利亚政府军的盟友、俄罗斯——其背后还有中国的支持，为了保护叙利亚总统阿萨德免受联合国部分措施的制裁，而对几项决议投出了反对票。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>一春夢雨常飄瓦</title>
      <link>https://wangcc.me/post/2016-11-28/</link>
      <pubDate>Mon, 28 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-28/</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-28 12:3	用时：24:42
正确率：89%	错词：26个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Harbor vs. harbour&lt;/strong&gt;: &lt;code&gt;There is no difference in meaning between harbor and harbour. Harbor is the preferred spelling in American English, and harbour is preferred in all other main varieties of English.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;reclaimed: &lt;code&gt;v. 回收利用；改造（reclaim的过去分词）；开垦土地 adj. 回收的，再生的；翻造的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Paracel Islands: &lt;code&gt;帕拉塞尔群岛(某些外国人沿用的殖民主义者对我国西沙群岛的称呼)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;scrawled: &lt;code&gt;n. 潦草的笔迹 v. 潦草地写；乱涂乱画&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Saigon: &lt;code&gt;n. 西贡（越南一座城市，现称胡志明市）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;shabby: &lt;code&gt;adj. 破旧的；卑鄙的；吝啬的；低劣的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;dusty: &lt;code&gt;adj. 布满灰尘的，灰尘弥漫的；轻率的回绝，毫无用处的回答&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;华盛顿再次声明对北京政府在南中国海的活动表示关注。中国正在南中国海的人工岛上建造军用机场及港口，并占用了其他国家视为本国领土的领地。&lt;/p&gt;
&lt;p&gt;本周，一位美国太平洋区高级海军司令警告说，中国的做法可能令南中国海地区卷入危险的军备竞赛。两个最受争议的地区分别是临近马来西亚和菲律宾的斯普拉特利群岛（中国称为南沙群岛），以及中国在1974年从越南占领的帕拉塞尔群岛（中国称为西沙群岛）。BBC韩福瑞（Humphrey Hawksley）见过一些越南渔民，如今这些渔民发现自己正处于领土争端的风口浪尖。&lt;/p&gt;
&lt;p&gt;“嘿，亲爱的，你得过来看看这个。”说话的是一个带着绿色棒球帽的高个子美国游客，他正在河内市的一处军事历史博物馆招呼他的妻子过去看一件展品。这是一份记录于1975年4月的潦草的手写笔记，记录了越南最高指挥部命令其下所有指挥官以闪电般速度向西贡进攻，对美国所扶持的南越政权发动最后的攻势。“亲爱的，你能想象有一天我们的孩子在中东ISIL的某个博物馆里看到类似这样的么？”他问道。这间破败的布满灰尘的博物馆里陈列了1954年越南战胜法国，以及1975年击退美国人的作战计划模型，那时的越南共产党代表了西方民主社会所谴责的一切。博物馆中还展有描绘越南人抗击中国人的历史性战役的巨幅绘画，数千人在这些战役中被杀害。不过奇怪的是绘画所描述的仅为10世纪到15世纪期间的战役，而没有时间较近的一场发生于1979年的中越边境战争，越南同样也赢得了此场战役的胜利.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>身份竊賊</title>
      <link>https://wangcc.me/post/2016-11-27/</link>
      <pubDate>Sun, 27 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-27/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/p04gcck2&#34;&gt;The Secret Fraudster in my Family&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/axton.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-27 13:58	用时：25:37
正确率：88%	错词：33个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;fraudster: &lt;code&gt;n. 骗子；诈骗犯&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Realise&lt;/strong&gt; and &lt;strong&gt;realize&lt;/strong&gt; are different spellings of the same word, and both are used to varying degrees throughout the English-speaking world. &lt;strong&gt;Realize is the preferred spelling in American and Canadian English, and realise is preferred outside North America.&lt;/strong&gt; The spelling distinction extends to all derivatives of the verb, including realised/realized, realising/realizing, and realisation/realization.&lt;/li&gt;
&lt;li&gt;sophomore: &lt;code&gt;n. 大学二年级生；（美）有二年经验的人 adj. 二年级的；二年级学生的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;incur: &lt;code&gt;vt. 招致，引发；蒙受; 例句： The government had also incurred huge debts 政府也已负债累累。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;manila: &lt;code&gt;n. 马尼拉麻；马尼拉纸（等于manilla） adj. 马尼拉纸制的；马尼拉麻制的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;get hold of: &lt;code&gt;把握；抓住；得到。例句： He got hold of some money before the banks close today. 他今天在银行关门前取了些钱出来。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;rack up &lt;code&gt;击倒，获胜。 例句： Lower rates mean that firms are more likely to rack up profits in the coming months. 更低的费率意味着各公司更有可能在未来的几个月里获得大量利润。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;safe bet &lt;code&gt;准能赢的打赌（或事情）。 例句： It is a safe bet that the current owners will not sell.  十有八九现在的业主不会出售。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;fraudulent[ˈfrɔ:djələnt] &lt;code&gt;adj. 欺骗的，不诚实的；奸诈。 例句： There is no evidence that the broker was in league with the fraudulent vendor没有证据表明该经纪人与进行诈骗的卖主狼狈为奸&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;我们今天的故事发生在美国伊利诺斯州，主人公身份被盗用导致钱财尽失，而行骗者竟是她意想不到的人。近年来身份盗用事件日益猖獗。犯罪分子窃取你的姓名、身份信息并在你一无所知的情况下利用它们提取贷款、盗刷信用卡，或是掳走大捆钞票。而这一切发生在上世纪90年代的阿克斯顿·贝茨-汉密尔顿身上就极为罕见了，这对她是个不小的打击，但是和她后来发现真凶是谁相比根本算不了什么。19岁那年，她才意识到出了问题。&lt;/p&gt;
&lt;p&gt;那时我上大二，想到要离开校园我还挺兴奋的。我搬离了宿舍，拥有了自己的第一间公寓。我给电力公司打电话要求建立服务，他们寄给我一封信，上面写着：“基于您的信用评分，我们需要您支付100美元的保证金来建立服务。”&lt;/p&gt;
&lt;p&gt;贝茨，信用评分就意味着，你的财务状况都在这里了，如果你要借钱或者贷款，是否值得信任（借钱给你是不是安全）。&lt;/p&gt;
&lt;p&gt;没错。信末还附着一个电话号码，说打过去可以索要我信用报告的复印件。出于好奇，我打电话过去。6周后，我收到信用报告机构寄来的一个大马尼拉纸信封，打开后发现我的信用报告有10页那么长，里面涵盖了自1993年到当时8年内全部的收账代理商和信用卡欺诈的条目。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>一弦一柱思華年</title>
      <link>https://wangcc.me/post/2016-11-25/</link>
      <pubDate>Fri, 25 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-25/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/p041mfj1&#34;&gt;Cultural Inclusion and Exclusion&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/pokemon.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-25 16:1	用时：29:16
正确率：91%	错词：23个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;augment: &lt;code&gt;n. 增加；增大 vt. 增加；增大 vi. 增加；增大&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;augmented reality: &lt;code&gt;增强现实&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;hooked: &lt;code&gt;adj. 钩状的；吸毒成瘾的；入迷的 v. 用钩固定；捉住（hook的过去分词）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Millennial: &lt;code&gt;adj. 一千年的；千禧年的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;nostalgia: &lt;code&gt;n. 乡愁；怀旧之情; Her work is pervaded by nostalgia for a past age. 她的作品充满怀旧之情.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;designate [&amp;lsquo;dezɪgneɪt] &lt;code&gt;v. 指明; 任命; 指出 There are efforts under way to designate the bridge a historic landmark. 人们正在努力将这座桥定为历史遗迹。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;我们来说说Pokémon Go。这是一款超级流行的增强现实游戏，该游戏一经推出便掀起全球热潮。我一直按捺着没敢玩，担心会上瘾，然后就要花大把时间追逐皮卡丘和波波球。不过看起来我是少数派。&lt;/p&gt;
&lt;p&gt;Pokémon Go于7月6日在澳洲、新西兰和美国地区上线，随后登陆英国、加拿大、埃及和几个欧洲国家，一经发售便收获众多迷粉。该游戏软件的日常用户数量已超过Twitter，软件下载量也超过约会软件Tinder。政客也会跟Pokémon Go“套套近乎”。例如美总统候选人希拉里就借Pokémon Go之名拉选票，鼓励美国公民注册选民身份。不过，尽管该游戏已取得巨大成功，但也存在隐忧。我看到一些相关事故报道，如玩家过于沉迷游戏从而走下悬崖或闯入犯罪现场。安全隐忧显而易见。&lt;/p&gt;
&lt;p&gt;另外，当游戏扯上博物馆又会怎样？许多历史文化机构发现几乎一到晚上自己就被游戏标为小精灵基站或道场。Pokémon Go对我们的文化景点有什么影响？我们请来从事博物馆软件开发相关工作的纽约博主、学术研究者布莱尔·莫斯凯维茨。&lt;/p&gt;
&lt;p&gt;“布莱尔，欢迎来到我们节目。”&lt;/p&gt;
&lt;p&gt;“谢谢你们的邀请。”&lt;/p&gt;
&lt;p&gt;“我觉得你应该是玩Pokémon初代游戏的那一代人。”&lt;/p&gt;
&lt;p&gt;“是。许多千禧一代的人都记得小时候那款游戏。”&lt;/p&gt;
&lt;p&gt;“什么是千禧一代？我能问问你的年龄么？”&lt;/p&gt;
&lt;p&gt;“我今年27。千禧一代指90年代出生的人。90年代的时候，我们玩过Pokémon对战卡片，看过动画片。如今Pokémon Go这款手机游戏让我们想起了童年时光，引发千禧一代用户的怀旧情绪。”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>空城澹月華</title>
      <link>https://wangcc.me/post/2016-11-24/</link>
      <pubDate>Thu, 24 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-24/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://ting.hujiang.com/bbc/163719561871/&#34;&gt;Sir Edward Burnett Tylor&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/tylor.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-24 11:44	用时：28:56
正确率：90%	错词：22个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;dryer vs. drier: &lt;code&gt;Drier is a comparative adjective meaning more dry. A dryer is one of many types of electrical appliances used to dry things.&lt;/code&gt; The words were once &lt;strong&gt;interchangeable&lt;/strong&gt;. The distinction crept into the language through the 20th century and has only recently solidified. Some dictionaries still list the words as variants of each other, but the words are almost always kept separate in 21st-century publications.&lt;/li&gt;
&lt;li&gt;archaeology vs. archeology : &lt;strong&gt;Archaeology is the standard spelling throughout the English-speaking world&lt;/strong&gt;, even in American English, where the a is dropped from many words traditionally containing ae (or æ, as it used to be rendered). Archeology is a somewhat common variant. It is about two centuries old and is common enough to have earned its way into many of the major dictionaries, but it has hasn’t gained much traction in edited writing. The traditional spelling remains the safer choice.&lt;/li&gt;
&lt;li&gt;befriend [bɪ&amp;rsquo;frend]:&lt;code&gt;v. 待人如友, 帮助 I asked a certain comrade to befriend this fellow so that he would not interrupt our talks. 我请一位伙伴向这家伙套近乎以便能让他不来打断我们的谈话。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;pueblo [&amp;lsquo;pwebləʊ]: &lt;code&gt;n. 印第安人村庄 Early Amerindians related to the Pueblo Indians is known for skill in making baskets. 和普韦布洛印地安人有联系地早期美国印地安人;以编篮子的技术而闻名。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;tutelage: &lt;code&gt;n. 指导，指引；保护，监护，托管&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;sergeant: &lt;code&gt;n. 警官；军士，中士；高等律师&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;morph: &lt;code&gt;n. 语素；变种；变 v. 在屏幕上变换图像；改变&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;lustrous: &lt;code&gt;adj. 有光泽的,光辉的; The moon was above, lustrous and serene. 天上的月亮皎洁肃穆。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;cumulonimbus: &lt;code&gt;n. 积雨云&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;quarrel: &lt;code&gt;n. 吵架；反目；怨言；争吵的原因；方头凿 vi. 吵架；争论；挑剔&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;literay critic: &lt;code&gt;文学评论家&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;anarchy: &lt;code&gt;n. 无政府状态，混乱&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Edward_Burnett_Tylor&#34;&gt;Edward Burnett Tylor 爱德华·伯内特·泰勒（Edward Burnett Tylor，1832－1917），英国文化人类学的奠基人、古典进化论的主要代表人物。泰勒出生于伦敦一个富有的工厂主家庭，接受了良好的私人教育。&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Matthew_Arnold&#34;&gt;Matthew Arnold 英国诗人、评论家。拉格比公学校长、托马斯·阿诺德之子。他所倡导的“文化批评”理论在西方文学史及思想史上占有重要的地位。阿诺德自称为“英国文化的倡导者”,后人尊他为“文化使徒”。&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;19世纪，同众多感染肺结核的英国人一样，爱德华·伯内特·泰勒遵从医嘱离开英国，前往更温暖、更干燥的地区。泰勒出生于一个富裕的贵格会商人家庭，故而他有足够的资金进行长途旅行。1855年，二十多岁的泰勒动身前去美洲的途中结交了贵格会考古学家亨利·克里斯蒂。最后二人一同奔赴墨西哥乡下，考察阿兹特克遗址和满是灰尘的普埃布洛村落。&lt;/p&gt;
&lt;p&gt;克里斯蒂当时已是经验颇丰的考古学家。在他的指导下，泰勒学会如何在考古现场工作。而受墨西哥当地巡佐的影响，泰勒对这里的人类族群研究——不论是古代的还是近代的——产生了浓厚的热情，这份热情一直燃烧到他生命的最后一刻。1871年，泰勒的代表作《原始文化》出版，该书可以称得上是近代人类学的第一巨作。随后几十年间，当他的胡子从光亮的加里波第式变为让甘道夫都会嫉妒的银白色长髯，泰勒一直通过博物馆和图书馆学习世界人类族群方面的知识。从某些方面来讲，《原始文化》是对另一部书《文化与无政府状态》（马修·阿诺德著）的驳斥。《文化与无政府状态》系列书籍比《原始文化》早两年出版。文化之于阿诺德——这位诗人及文学评论家——是一种对完美的追求，即了解与我们关系最密切的所有事物，领略世界上最好的想法和说法。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>異口同聲</title>
      <link>https://wangcc.me/post/2016-11-23/</link>
      <pubDate>Wed, 23 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-23/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://ting.hujiang.com/bbc/163663271177/&#34;&gt;雙胞胎一起講話有點瘮人&amp;hellip;..&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/twins.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-23 11:53	用时：18:50 正确率：89%	错词：27个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;unison: &lt;code&gt;adj. 同音的 n. 调和，和谐，一致，齐唱，齐奏; in unison 齐声；一齐；一致地，和谐地。 例句: Michael and the landlady nodded in unison.  迈克尔和房东太太一起点头。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;put it on: &lt;code&gt;装腔作势；夸大；夸张。 例句： It wasn&#39;t as hard as you claimed；you were putting it on． 这并不象你说的那么难，你在夸大其词。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;anabiolic: &lt;code&gt;adj. 合成代谢的; Anabolic steroids are a synthetic version of the hormone testosterone, and promote the storage of protein and tissue growth. 合成代谢类固醇相当于人造的睾丸激素，它能促进蛋白质的积累和组织的生长。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;葆拉和布丽奇特·鲍尔斯是澳大利亚东部的同卵双胞胎，她们会做一件非常不寻常的事——能同时说话。这对双胞胎几乎天天生活在一起。目前她们40多岁，并且非常喜欢海鸟。她们在阳光海岸建立了推尼斯鹈鹕和海鸟救助站。她们来到了我们位于佩斯的演播室讲述她们的故事。接下来有请这对双胞胎。&lt;/p&gt;
&lt;p&gt;妈妈说照管我俩非常轻松，我们总能相互逗趣，她说我们有自己的双胞胎语言，其他人都无法听懂我们在说什么。&lt;/p&gt;
&lt;p&gt;你们小时候有自己双胞胎语言，但是你们现在的说话方式很不可思议，完全一致。&lt;/p&gt;
&lt;p&gt;是的，这是自然而然的，大家以为我们是装的，但其实不是，根本不可能。事实上我们同时得了感冒，而且代谢相同。&lt;/p&gt;
&lt;p&gt;真的假的？你们一直都是同时生病、生同样的病吗？&lt;/p&gt;
&lt;p&gt;是的，很不幸。&lt;/p&gt;
&lt;p&gt;真的么？你们从小就这样吗？&lt;/p&gt;
&lt;p&gt;是啊，没错。我做了阑尾切除手术，然后布丽奇特几周后也摘了她的。&lt;/p&gt;
&lt;p&gt;哇，那也就是说是葆拉先摘的阑尾。&lt;/p&gt;
&lt;p&gt;是这样。然后两周后我也不得不经历同样的遭遇。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>大草原上的農業</title>
      <link>https://wangcc.me/post/2016-11-22/</link>
      <pubDate>Tue, 22 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-22/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/cow.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-22 22:16	用时：26:49
正确率：95%	错词：12个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;It&amp;rsquo;s an old saw. &lt;code&gt;saw /sɔː/ n.格言 例句： The old saw &amp;quot;you should learn something new every day&amp;quot; is a good one. 古老的格言“每天你都应该学些新的东西”说的很好&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;centre-right: &lt;code&gt;中间偏右&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;handout/ˈhændaʊt/: &lt;code&gt;n.施舍物; 救济品; 救济金 例：Each family is being given a cash handout of six thousand rupees. 每个家庭都被给予6000卢比的救济金。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;synonymous /sɪˈnɒnɪməs/:  &lt;code&gt;a.密不可分的 例： Paris has always been synonymous with elegance, luxury and style. 巴黎与优雅、华贵和时尚一直是密不可分的。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;上个月，全球贸易谈判在日内瓦举行。你可能要拿起收音机了，但稍等，不要换台。这很重要。政府之间又在争论，焦点仍然锁定在是否要削减发给农民的补贴。这是老生常谈。尤其在贫困地区，人们对此已经有数年的争议。在贫困国家的农民所得到的补贴远低于那些欧洲、美国和日本等国超级富有的农民所得到的政府的慷慨之助，而一些人认为这样会使全球市场走向失真。但那些有钱的政府并不愿意改变这样一个数十年历史的惯例。而这，某种程度上，就是我们今天每日财经的主题。我们首先来看一个实例。阿根廷是一个主要的农业生产国。新上任的中右翼政府想方设法改变这样一项愈发奢侈的国民政策，一些人认为这在经济和环境方面看都是不可持续的。Grace Livingstone 带来报道。 我来到了位于阿根廷的潘帕斯平原，了解这里的农民如何看待新一届的政府。潘帕斯曾经是牛群和牛仔的天下，但现在这里大部分地区都种植了转基因大豆。我来到了位于罗萨里奥的大豆联盟，它能够代表所有种植或加工大豆的群体。这个建筑外表是智能玻璃的，让你一下子就能感觉到大豆产业带来了丰厚的经济利润。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>另類保鏢</title>
      <link>https://wangcc.me/post/2016-11-21/</link>
      <pubDate>Mon, 21 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-21/</guid>
      <description>&lt;p&gt;(俄國人的口音真難懂(⊙o⊙))&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/bodyguard.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-21 11:56	用时：24:03
正确率：87%	错词：27个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;queer: &lt;code&gt;n. 同性恋者；怪人；伪造的货币 adj. 奇怪的；同性恋的；不舒服的；心智不平衡的 vt. 搞糟；使陷于不利地位; gender queer  同性恋。 例句： From the start, Timothy introduced himself as masculine-of-center gender queer. 从入学一开始，提摩西在自我介绍是说自己是一位偏男性的跨性人。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;masculine pronune: &lt;code&gt;阳性代词；阳性代名词。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;right-wing: &lt;code&gt;adj. 右翼的；右派的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;natinalistic: &lt;code&gt;adj. 民族主义的；国家的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;virulent: &lt;code&gt;adj. 剧毒的,致命的,刻毒的,恶毒的,恶性的,有病毒的,充满敌意的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;constrict&lt;code&gt;vt. 收缩；压紧；阻碍；挤压。 例句： Men and women alike have been constricted by traditional sexual roles.  男性和女性同样受到传统性别角色的束缚。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;【背景介绍】National Coming Out Day“全国出柜日”是国际上LGBT（包括同性恋、双性恋和跨性别）人群的庆祝出柜和提高社会认识的节日，LGBT社群成员和他们的支持者（常被称为“同盟”）在每年10月11日庆祝这个节日，在英国则是在10月12日来庆祝。（资料来源：http://tieba.baidu.com/p/2645622245）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;目前，俄罗斯针对同性恋和变性人的看法产生巨大的转变。上世纪80年代苏维埃末期，塔皮尔在军队可以穿高跟鞋，而且没人会介意。然而最近他却非常担心自己的生活。塔皮尔确认自己是介于男女之间的同性恋，但他不介意使用男性代词。他在保护女同、男同、双性人、变性人的活动中负责安保工作。他告诉我这些活动者们要面对的各种困难，比如发生在2014年莫斯科文化中心的这次运动。&lt;/p&gt;
&lt;p&gt;最糟糕事件发生在2014年10月，所谓的俄罗斯战士反对萨哈罗夫中心的活动而引发的袭击。&lt;/p&gt;
&lt;p&gt;萨哈罗夫中心发生了什么？&lt;/p&gt;
&lt;p&gt;出柜日那天萨哈罗夫中心聚集了不少LGBT（同性恋、双性恋及变性者）活动者们，于是引发了袭击事件。活动者们本来希望像平常一样只让一部分人参加这次活动，像是8个或者10个人，他们通常都是右翼的国家主义分子。但是活动者们不希望一大群自称“反广场”的人都来参加。他们将会受到来自各种右翼国家主义派的限制。有些人显然来自顿巴斯地区，他们充满恶意又激进好斗。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>物換星移幾度秋</title>
      <link>https://wangcc.me/post/2016-11-19/</link>
      <pubDate>Sat, 19 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-19/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/cyclical.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;用时：24:13  正确：93%  奖励： 4
日期：2016-11-19&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;Bank Holiday: &lt;code&gt;银行假日（英语：bank holiday）指的是英国、部分英联邦国家和部分欧洲国家（如瑞士）以及部分英国前殖民地（如香港）的公共假日。在爱尔兰，口语中也将公共假日称为银行假日&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;advert: &lt;code&gt;n. 广告 v. 注意；提及&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;kit out: &lt;code&gt;穿着: She was kitted out with winter coat, skirts, jumpers. 她全副武装，穿着冬天的外套、裙子、套头衫。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Guardian: &lt;code&gt;《卫报》（The Guardian）是英国的全国性综合内容日报。与《泰晤士报》、《每日电讯报》被合称为英国三大报。由约翰·爱德华·泰勒创办于1821年5月5日。因总部设于曼彻斯特而称为《曼彻斯特卫报》。1959年8月24日改为现名。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;philosopher: &lt;code&gt;n. 哲学家, 哲人 He came to London in 1750 and soon acquired a reputation as a philosopher and man of letters. 1750年他到伦敦,不久获得了哲学家和学者的名声。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;cyclical: &lt;code&gt;adj. 循环的；周期的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;rhythm: &lt;code&gt;n. 节奏；规则变化&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;fuss: &lt;code&gt;n. 大惊小怪，抱怨；争吵 v. 忙乱，大惊小怪；（为小事）烦恼 You needn&#39;t fuss. There&#39;s no disgrace. 你不必大惊小怪。没有什么丢人的事。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Ecclesiastes: &lt;code&gt;n. 传道书&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;又逢一年开学时。八月银行假期一过便预示暑假即将结束。再过不久就要开学了。对我们这群没有子女的人来说，开学临近最明显的迹象要数那些校服广告。为新学期准备服装可算是人生一课。学嘛是一年跟着一年的上，个子嘛也是一年跟着一年的长。12个月前的校服现在穿不上了，这不就得买新衣裳了。我妈妈通常给我买大好几码的校服，这样就不用年年买新衣服了。&lt;/p&gt;
&lt;p&gt;哲学家朱利安（Julian Baggini）在昨天的卫报上评论说，生命表现为向前移动的直线，但同时它也是循环往复的。把重心放在当前，而不过分关注遥远的未来，这样我们的生活会更好。&lt;/p&gt;
&lt;p&gt;作为一名基督徒，我立马想到《旧约传道书》上面说的：“凡事都有定期，天下万物皆有定时。”这部分选段经常出现在葬礼上。它讲述的不仅是死亡，还包括新生，提醒我们生或死好比夏季与冬季并非意味终结，而是漫长循回中的一部分。它仿佛在向默哀者低语：“节哀。生命仍在继续。”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>意大利地震成因</title>
      <link>https://wangcc.me/post/2016-11-18/</link>
      <pubDate>Fri, 18 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-18/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://ting.hujiang.com/bbc/163717832061/&#34;&gt;Italy&amp;rsquo;s devastating earthquake&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/italy.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-18 13:15	用时：28:52
正确率：94%	错词：15个&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点  &lt;!-- raw HTML omitted --&gt;I mean&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; it is that unfolding. It&amp;rsquo;s very unfamiliar to me. But you think these are all connected somehow. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Well, first&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; earthquakes in Italy &lt;!-- raw HTML omitted --&gt;turn&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;tend&lt;!-- raw HTML omitted --&gt; to occur more in groups or sequences than a lot of other places in the world. This is somewhat unique to Italy. It&amp;rsquo;s not a striking difference&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; but it&amp;rsquo;s a noticeable one. And it&amp;rsquo;s probably because the faults there are &lt;!-- raw HTML omitted --&gt;relatively&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;relative&lt;!-- raw HTML omitted --&gt; young&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;less &lt;!-- raw HTML omitted --&gt;than &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;1&lt;!-- raw HTML omitted --&gt; million years old. Compare that to the San &lt;!-- raw HTML omitted --&gt;Andreas&#39;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; which is over 10 million years old. So these are little kind of broken shards of faults that haven&amp;rsquo;t &lt;!-- raw HTML omitted --&gt;really&lt;!-- raw HTML omitted --&gt; been &lt;!-- raw HTML omitted --&gt;organized&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;organised&lt;!-- raw HTML omitted --&gt; by repeated earthquakes into a long continuous smooth fault. So&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; that means that if you jostle one&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; you &lt;!-- raw HTML omitted --&gt;turn&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;tend&lt;!-- raw HTML omitted --&gt; to move the others around it. And no one fault is able to rupture for a very long distance and produce a very large earthquake. So we get these little groups or families of &lt;!-- raw HTML omitted --&gt;moderate&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;size&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;moderate-sized&lt;!-- raw HTML omitted --&gt; events. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;But&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;it&amp;rsquo;s &lt;!-- raw HTML omitted --&gt;interesting that you mentioned L&amp;rsquo;Aquila &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; that was several years ago&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;there &lt;!-- raw HTML omitted --&gt;was some &lt;!-- raw HTML omitted --&gt;pre-rumbling&lt;!-- raw HTML omitted --&gt;  that &lt;!-- raw HTML omitted --&gt;happen&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;happened&lt;!-- raw HTML omitted --&gt;, I&amp;rsquo;m not sure what was going on &lt;!-- raw HTML omitted --&gt;afterward&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;afterwards&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;then&lt;!-- raw HTML omitted --&gt; in August you have once&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; that&amp;rsquo;s a long separation&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and &lt;!-- raw HTML omitted --&gt;then a few weeks &lt;!-- raw HTML omitted --&gt;late&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;later&lt;!-- raw HTML omitted --&gt; you&amp;rsquo;ve got another one and then another one. You know&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; the timing &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; as well as the distance between these events &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; seems curious to me. &lt;!-- raw HTML omitted --&gt;I&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;am&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;I&amp;rsquo;m&lt;!-- raw HTML omitted --&gt; not sure what to make of it. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Well, it&amp;rsquo;s interesting. Take a typical earthquake, say a magnitude &lt;!-- raw HTML omitted --&gt;6&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;six&lt;!-- raw HTML omitted --&gt;. It&amp;rsquo;s &lt;!-- raw HTML omitted --&gt;gonna&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;going&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; produce aftershocks. Aftershocks have a unique property&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;:&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the &lt;!-- raw HTML omitted --&gt;longer you go by in time&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; the more spread out they are. But their magnitudes don&amp;rsquo;t get smaller with time.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;unfolding: &lt;code&gt;v. 展开；开展，发展显露；显露&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;fault: &lt;code&gt;n. 故障；[地质] 断层；错误；缺点；毛病；（网球等）发球失误 vt. （通常用于疑问句或否定句）挑剔 vi. 弄错；产生断层&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;San Andrias: &lt;code&gt;圣安德列斯断层（英语：San Andreas Fault，又译圣安地列斯断层、圣安德烈亚斯断层、圣安德鲁斯断层），是北美洲一处频繁活动的断层。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;shard: &lt;code&gt;n. 瓷器的碎片;碎片;翅鞘;外壳&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;jostle: &lt;code&gt;n. 推撞，拥挤 v. 推挤；争夺，竞争&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;rupture: &lt;code&gt;n. 破裂；决裂；疝气 v. （使）破裂；发生气&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;L&amp;rsquo;Aquila (earthquake): &lt;code&gt;2009年拉奎拉地震 ; 意大利拉奎拉地震&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;rumbling: &lt;code&gt;n. 隆隆声 v. rumble的现在分词；隆隆响&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;I&amp;rsquo;m not sure what to make of it:
&lt;ul&gt;
&lt;li&gt;(someone) didn&amp;rsquo;t know what to make of (something)&lt;/li&gt;
&lt;li&gt;This phrase means that a person didn&amp;rsquo;t understand something or didn&amp;rsquo;t know what it was.&lt;/li&gt;
&lt;li&gt;In the example above, the speaker didn&amp;rsquo;t know whether the guy was serious or joking, whether he really didn&amp;rsquo;t care about her or whether he was trying to hide his true feelings.&lt;/li&gt;
&lt;li&gt;Other feelings that you might have when you &amp;ldquo;don&amp;rsquo;t know what to make of&amp;rdquo; something are:&lt;/li&gt;
&lt;li&gt;You&amp;rsquo;re not sure whether something is good or bad.&lt;/li&gt;
&lt;li&gt;You can&amp;rsquo;t decide what something is.&lt;/li&gt;
&lt;li&gt;You don&amp;rsquo;t know why a person said something the way that they said it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;这种展开方式我不太熟悉。但你觉得它们之间都是有某种联系的？&lt;/p&gt;
&lt;p&gt;嗯，首先，相比于世界上许多其他地方来说，意大利的地震更趋向于多震源或连续发生。意大利在这点上多少有点特别。这个特点不是多么突出，却也是很明显的。这很可能是因为意大利的地质断层形成时间还不够长，还不到一百万年。把它跟圣安地列斯的断层一比，人家已经一千多万年了。所以这些都只是断层碎片，还没有受到地震的频繁推挤而变成那种大范围的连续光滑断层。那么这就意味着，如果动了一个断层，那它周围其他的断层也会跟着移动。而断层中的任何一个都不可能造成大范围地震，震感也不可能很强。所以才会有这些小的中级震群或震族。&lt;/p&gt;
&lt;p&gt;但是你提到了几年前拉奎拉的那次地震很有意思，先是有一些震动——我不确定之后发生了什么——然后在八月份又发生了一次，这中间隔了很长一段时间，结果几周之后又发生了一次，然后又发生了一次。这几次地震之间的时间间隔和距离间隔都让我觉得很奇怪。我不知道该怎么理解这个问题。&lt;/p&gt;
&lt;p&gt;嗯，确实有趣。就一次典型的地震来说，就说六级地震吧。它会产生余震。余震有一种独一无二的特性：过去的时间越长，波及的范围就越广。但是震级并不会随着时间而降低。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>地籟風聲急</title>
      <link>https://wangcc.me/post/2016-11-17/</link>
      <pubDate>Thu, 17 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-17/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/articles/1zQVVqWYnyfmQWm47bK5Pjl/fight-for-life-gold-winner&#34;&gt;Fight for life by Sofia Zambuto&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/fightforlife.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-17 11:29	用时：21:51
正确率：94%	错词：18个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;colossal: &lt;code&gt;adj. 巨大的；异常的，非常的; 例句： In the centre of the hall stood a colossal wooden statue, decorated in ivory and gold. 大厅中央矗立着一尊用象牙和金子装饰的木质巨型雕像。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;heave: &lt;code&gt;v. 上下起伏 例句： As the wind increased, the deck of the ship began to heave beneath his feet. 随着风力增大，轮船甲板开始在他脚下颠簸起来。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;cling: &lt;code&gt;vi. 坚持，墨守；紧贴；附着&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;massacre: &lt;code&gt;vt. 残杀；彻底击败 n. 大屠杀；惨败&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;resurface: &lt;code&gt;vt. 重铺路面；为…铺设新表面 vi. 重新露面；浮上水面&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;stank: &lt;code&gt;n. 恶臭；发怒，大吵大闹 v. 发出恶臭；令人讨厌&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;fumes: &lt;code&gt;n. （强烈而刺激的）气味，气体 名词fume的复数形式&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;a good bit &lt;code&gt; a fairly large amount of something 大量的 例句： We’ve still got a good bit to do. 我们还有一堆事儿没做。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;scamper: &lt;code&gt;n. 蹦跳；奔跑 vi. 蹦蹦跳跳；奔跑，惊惶奔跑&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;scurry: &lt;code&gt;n. 急跑；短距离赛跑（或赛马） vi. 急赶；急跑 vt. 急赶&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;（水面）安静的可怕。我知道洪水可能在任一时刻到来，卷着巨浪猛烈地拍向我们。我的两个小孩子紧紧的抓着我。他们看到他们的父亲沉入水中，消失不见。我们没看到他再次浮出水面。之后我们也被水淹没。我拼命地想让孩子们活下去。他们紧紧抓着我，我奋力去抓住高处。水上大量的泡沫使我们难以呼吸。到处都是碎片残骸。我曾听闻洪水的可怕，我知道更糟的情况将来临。&lt;/p&gt;
&lt;p&gt;我的孩子们上下扑腾着拼命去呼吸。四下都看不到他们父亲的身影。大部分人已经丧命。空气中弥漫着难闻的气味。周围飘浮着尸体的残肢、失去生命的孩童的尸体。我知道很快，很快第二波洪水就要来临。我想尖叫，但我不能。我的孩子们还不知道他们面临的是什么。&lt;/p&gt;
&lt;p&gt;如果现在不离开，等待我们的只有死亡。我必须想办法。我必须为我们找到逃命的出路。水面降下去很多。我们可以移动了。为数不多的幸存者已经准备逃离了。他们四下惊逃。我们都在找出路，不停的找。我的孩子们紧跟着我，不想被落在后面。然后我看到了它，我看到了出路，它向我们敞开。&lt;/p&gt;
&lt;p&gt;“孩子们，我们要走了。我们必须离开我们的家，找一个新的住所。洪水又要来了。跟着我，尽你们所能的紧跟着我。”&lt;/p&gt;
&lt;p&gt;其他人在靠近。这是我们的机会，唯一的逃生的机会。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>鐵馬冰河入夢來</title>
      <link>https://wangcc.me/post/2016-11-16/</link>
      <pubDate>Wed, 16 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-16/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/b080xzpc&#34;&gt;The Book that Changed Me Episode 5 of 5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/thepeopleswar.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-16 14:46	用时：25:06
正确率：92%	错词：15个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;protagonist: &lt;code&gt;n. 主演；主要人物，领导者 The protagonist enters left stage. 男主角从舞台左边出现; Both novels trace the growth and development of the protagonist&#39;s character. 这两部小说都描述主人公性格的成长和发展过程。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;invoke: &lt;code&gt;v. 祈求, 实行, 恳求 Let us invoke the blessings of peace. 让我们祈求和平之福。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Goya: &lt;code&gt;弗朗西斯科·何塞·德·戈雅-卢西恩特斯，西班牙浪漫主义画派画家。画风奇异多变，从早期巴洛克式画风到后期类似表现主义的作品，他一生总在改变，虽然他从没有建立自己的门派，但对后世的现实主义画派、浪漫主义画派和印象派都有很大的影响，是一位承前启后的过渡性人物。 https://en.wikipedia.org/wiki/Francisco_Goya&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Bosnia: &lt;code&gt;波斯尼亚战争，是原南斯拉夫解体时的内部战争，是波斯尼亚和黑塞哥维那，发生在1992年3月和1995年之间和塞尔维亚之间的武力冲突。。在旧南斯拉夫开始解体时，波斯尼亚黑塞哥维那亦在1992年宣告独立。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Gulf: &lt;code&gt;海湾战争，是以美国为首的多国部队于1991年1月17日～2月28日在联合国安理会授权下，为恢复科威特领土完整而对伊拉克进行的局部战争，同时也是人类战争史上现代化程度最高、使用新式武器最多、投入军费最多的一场战争。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Falkland: &lt;code&gt;马尔维纳斯群岛战争，简称马岛战争或福克兰群岛战争（英语：FalklandsWar）或福克兰海战，也有部分媒体简称为福岛战争，是1982年4月到6月间，英国和阿根廷为争夺马岛（阿根廷称“马尔维纳斯群岛”）的主权而爆发的一场战争。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;本文的譯文-滬江的版本實在是太差了-之前都沒有仔細閱讀他們給的翻譯-特別是最後一自然段的最後幾句-所以今天就沒有譯文了&#34;&gt;本文的譯文, 滬江的版本實在是太差了. 之前都沒有仔細閱讀他們給的翻譯. 特別是最後一自然段的最後幾句. 所以今天就沒有譯文了.&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>唯一生還</title>
      <link>https://wangcc.me/post/2016-11-15/</link>
      <pubDate>Tue, 15 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-15/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/p04fhk9z&#34;&gt;&amp;lsquo;Miracle Girl&amp;rsquo;: Aircrash Sole Survivor&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/survival.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-15 11:9	用时：24:33
正确率：94%	错词：16个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;plunge into: &lt;code&gt;投入；跳入；突然或仓促地开始某事。例句： He plunged into the cold water.他跳入冰冷的水中。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;dub[dʌb]: &lt;code&gt;vt.（以剑触肩）封…为爵士；授予称号；起绰号。 例句： Today&#39;s session has been widely dubbed as a &amp;quot;make or break&amp;quot; meeting. 今天的会议被大众称为“不成则散”的会议。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;我们今天要讲的是发生在印度洋上的精彩逃生故事。2009年6月，一架由也门驶向科摩罗群岛的飞机在距目的地几英里处不幸坠入大海。坠机报告显示事故发生的原因之一是人为失误。这起空难造成152名乘客丧生，只有13岁的法国女孩巴希亚·巴卡里幸存下来，媒体都称她为“奇迹少女”。7年过去了，她告诉我事故发生的情况。&lt;/p&gt;
&lt;p&gt;当时我和妈妈一起去度假。我们去参加妈妈亲戚这边的一个婚礼。我有点担心，因为我很久没坐过飞机了。出发那天早上，我的叔叔和表兄开车送我们去了机场。&lt;/p&gt;
&lt;p&gt;你还记得当时飞机怎么样吗？因为有报告表明它当时状态不是太好。&lt;/p&gt;
&lt;p&gt;是的。那天我们乘坐了两架飞机——先是开往也门的萨那，然后再从也门飞往科摩罗。是的，当时飞机的状态不是非常好。飞机里有只苍蝇，还有非常难闻的、像厕所里的味道。但是除此以外，直到事故发生，整个飞行过程都是正常的。&lt;/p&gt;
&lt;p&gt;那你还记得飞机降落时的情况吗？&lt;/p&gt;
&lt;p&gt;飞机正常飞行了很长的一段时间，大家都睡着了。突然他们通知我们要降落，让所有人都系好安全带。但是大家都在睡觉，人们都非常安静，我很担心。我看着大家，心想：为什么你们都不怎么害怕或者尖叫呢？突然我感觉到飞机穿过大量气流，接着就如同掉进黑洞一般。我不省人事，醒来时发现自己身在水中。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>天價北京房</title>
      <link>https://wangcc.me/post/2016-11-14/</link>
      <pubDate>Mon, 14 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-14/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/p04dst07&#34;&gt;Beijing&amp;rsquo;s Property Problem&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/beijing.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-14 13:50	用时：20:04
正确率：88%	错词：22个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;quarter-century: &lt;code&gt;25年&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;bustle /ˈbʌsəl/  &lt;code&gt;v.奔忙 例： My mother bustled around the kitchen. 我母亲在厨房里忙得团团转。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;millennium: &lt;code&gt;n. 千禧年；一千年&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;high-rise: &lt;code&gt;adj. 多层的 n. 多层高楼&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;sky-high: &lt;code&gt;adj. 极高的,昂贵的 adv. 极高,粉碎&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;frenzy: &lt;code&gt;n. 狂热；狂暴；狂怒 v. 使狂怒&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Taoist: &lt;code&gt;adj. 道教的 n. 道士, 道教信徒&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;marvel: &lt;code&gt;n. 令人惊奇的人或事 v. 对…感到惊讶, 大为赞叹&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;petty: &lt;code&gt;adj. 琐碎的；小气的；小规模的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;concreted: &lt;code&gt;adj. 混凝土的；实在的，具体的；有形的 n. 混凝土 v. （使）凝固；用混凝土修筑&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;low-rise: &lt;code&gt;adj. 不高的&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;北京的大街川流不息、熙熙攘攘。过去25年来，中国创造了经济奇迹，城市化范围之广、进程之快前所未有。有一半多的中国人居住在城市。首都北京的常住人口有2100万，这一非官方数字几乎比世纪之交时翻了一番。这也产生了很多问题，比如在高楼林立的城市里生活的高成本。许多年轻人寻找不到幸福感，因此这也成为了众多政策制定者的担忧。人们的智能手机上经常播放一首有关的歌曲。政府为了控制人们购买房产的疯狂举动，刚刚出台了限制的紧缩政策。&lt;/p&gt;
&lt;p&gt;后海这里十分热闹。这里是北京为数不多的仍保留了半个世纪前北京模样的地方。在一座道观前，有一片传统的红绿砖瓦、一两层楼的房屋。一些北京本土人对于北京近些年的巨变仍感叹不已。零星的空地被开发成房地产，拔地而起混凝土建筑。平房被拆除，取而代之的是摩天大楼。后海这片地方得以幸存。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>日以作夜</title>
      <link>https://wangcc.me/post/2016-11-12/</link>
      <pubDate>Sat, 12 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-12/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/b08015rw&#34;&gt;Jacqueline Bisset&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wangcc.me/img/Jacqueline_Bisset.jpg&#34; alt=&#34;&#34;&gt;
&lt;!-- raw HTML omitted --&gt;
Your browser does not support the audio element.
你的瀏覽器不支持音頻播放。請使用chrome科學上網。
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;genre: &lt;code&gt;adj. 风俗画的 n. 种，类；类型；（文学作品等的）体裁，样式，风俗画: I believe in the story of the genre itself. 我相信这种音乐流派本身的故事。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;nocturnal: &lt;code&gt;adj. 夜间的；夜行性的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;marshal: &lt;code&gt;n. 元帅；司仪；警察局长；消防队长 v. 排列，整理；引领；集结，编队: If so, you&#39;re a leader who will take your company to new levels and marshal all the resources(and personalities) of a team destined for success. 倘是如此，你将是一个引领你的公司走上新台阶、合理配置团队资源（包括人力资源）以驶向成功彼岸的领导者&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;cast and crew: &lt;code&gt;演员和工作人员&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;a flurry of paparazzi: &lt;code&gt;一连串的狗仔队&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;flurry: &lt;code&gt;n. 一阵风、雨或雪；疾风；骚动；慌张 v. （使）慌张，激动  Why the flurry? 这么慌张干嘛？&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;paparazzi: &lt;code&gt;n. 专门追逐名人的摄影记者&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;in-joke: &lt;code&gt;n. 圈内人(才能领会)的笑话&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;peril: &lt;code&gt;n. 危险；冒险 v. 危及&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;blockbuster: &lt;code&gt;n. 重磅炸弹，大片，畅销书: The difference between us and a Hollywood blockbuster is that we have to keep it tied to the science as closely as possible. 我们创作出来的作品与好莱坞大片之间的不同点在于，我们的东西总是尽可能的贴近现实科学。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;emissay: &lt;code&gt;n. 使者；间谍；密使 adj. 间谍的；密使的: Now spring coming, a couple, bride and bridegroom, like a spring emissary is standing happily before us with the wedding music playing on. 春天来了，一对春天的使者，踏着婚礼进行曲正含情脉脉立在大家面前。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;UAE: &lt;code&gt;abbr. 阿拉伯联合酋长国（United Arab Emirates）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;out-of-breath: &lt;code&gt;喘不过气来，上气不接下气&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;attendant &lt;code&gt;adj. 伴随的；侍候的: Such patients run an increased probability of hospitalization, with all the attendant costs to the patient and to the health care system that hospitalization entails. 此类患者趋于住院治疗的的几率增加，随之而来的患者和医疗保健系统住院治疗所承担的费用也增加。&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;我们先来看看这一类电影中最受欢迎且最有感染力的一部作品，导演Francois Truffaut在1973年的作品《日以作夜》。这部电影最近发行了最新的蓝光版本。电影得名于拍摄时采用的蓝色滤镜。滤镜让白天看起来像是夜晚，比在黑暗中拍摄容易得多。电影情节围绕着一位导演展开，讲述他如何克服剧组里的一系列戏剧性事件，只为完成电影的拍摄。Truffaut本人扮演这一角色。导演的法语电影拍摄于法国，但主角是英国人。她年轻貌美，又有点神经质，从好莱坞来到这里，轰动了一众狗仔。这里有个行内人才懂的笑点：片中的女星Pamela由英国演员Jacqueline Bisset扮演，她本人的出现确实会引起广泛关注。在70年代初，她已饰演过邦女郎，导演Steve McQueen的作品《布利特》中的情人，以及风靡一时的电影《国际机场》中机长Dean Martin的空乘女友。随后，1972年的一天，Jacqueline在巴黎（并不是像歌里唱的那样“为了最后一曲探戈”），一位来自阿联酋皇室的信使找到了她。&lt;/p&gt;
&lt;p&gt;在我看来，这真的是一件非常不可思议的事。我那时在巴黎。我以前常去那里，也常去一个地方跳舞。在那个特别的晚上，我住在一间我从未住过的酒店。早上11点左右，一位帅得让人窒息的年轻人急急忙忙跑上楼来，敲着我房间的门，一边说有我的电话。我说，不对，你搞错了，没人知道我住在这里。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>歐盟加拿大籤署自由貿易協定</title>
      <link>https://wangcc.me/post/2016-11-11/</link>
      <pubDate>Fri, 11 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-11/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/p04dntqj&#34;&gt;Canada and EU sign free trade deal&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;
&lt;img src=&#34;https://wangcc.me/img/Canada-Europe-Trade-Agreement.jpg&#34; alt=&#34;&#34;&gt;
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-11 16:48	用时：20:05
正确率：90%	错词：19个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered
&lt;ul&gt;
&lt;li&gt;digging their heels in &lt;code&gt;顽抗；拒绝让步；坚持自己的立场 例句：Officials dug their heels in on particular points. 在一些特定问题上,官员们拒不让步. &lt;/code&gt;&lt;/li&gt;
&lt;li&gt;jubilation: &lt;code&gt;n. 欢腾，欢庆，庆祝活动&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Belgian: &lt;code&gt;adj. 比利时的 n. 比利时人&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;as ink was finally put to paper&lt;/em&gt; &lt;code&gt;签字的那一刻&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;progressive: &lt;code&gt;adj. 进步的; 不断前进的; 进行的; n. 改革论者; 进步分子; 例句：The company tries to project an image of being innovative and progressive. 该公司努力以富有创新和进取精神的形象出现。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;disintegration: &lt;code&gt;n. 瓦解，崩溃；分解&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;integration: &lt;code&gt;n. 整合; 一体化; 结合; （不同肤色、种族、宗教信仰等的人的） 混合; 例句：The aim is to promote closer economic integration. 目的是进一步促进经济一体化。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;fatalism: &lt;code&gt;n. 宿命论&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;broader significance: &lt;code&gt;更深远、更广泛的意义&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;经过长达七年的谈判和比利时的瓦隆地区七天的不签约风波，欧盟和加拿大终于签订了历史性的的自由贸易协定。在短暂（又正合时宜）的延误之后，加拿大总理贾斯廷·特鲁多飞往布鲁塞尔，参加签署仪式。签字的那一刻，全场欢呼，掌声雷动。&lt;/p&gt;
&lt;p&gt;特鲁多先生的发言着重强调协定带来的经济效益。&lt;/p&gt;
&lt;p&gt;首先，加拿大和欧洲都深知，为了真实而有意义的经济增长，我们需要为市民们创造更好、待遇更优厚的工作机会。积极的贸易协定(指签署的自贸协定)有助于实现这一目标。&lt;/p&gt;
&lt;p&gt;而欧洲理事主席多纳尔德·图斯克赋予了该项协议更深远的意义。&lt;/p&gt;
&lt;p&gt;今天的决议体现了西方社会的分崩离析并非大势所趋，因为至少我们当中仍有一部分人，有着足够的力量和决心，去反抗政治世界衰败消亡的宿命。在欧盟历史上这个特殊的时刻，这个积极的信号意义非常重大。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>用愛治愈傷痛</title>
      <link>https://wangcc.me/post/2016-11-10/</link>
      <pubDate>Thu, 10 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-11-10/</guid>
      <description>&lt;p&gt;&lt;strong&gt;爲了準備IELTS雅思英語考試, 此篇文章之後的聽寫計劃盡量加入BBC英音的音頻資料.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.bbc.co.uk/programmes/p04bsysm&#34;&gt;Aleppo&amp;rsquo;s underground orphanage&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-11-10 15:38	用时：21:18
正确率：96%	错词：13个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;Aleppo: &lt;code&gt;阿勒颇[叙利亚西北部城市]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;under siege: &lt;code&gt;被包围；受...困扰的；一再遭到批评的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;envoy: &lt;code&gt;n. 使节，外交官；全权公使&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;shelling: &lt;code&gt;n. 壳；外壳；外形；炮弹 v. 剥壳；剥落&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;bombardment: &lt;code&gt;n. 炮击，轰炸&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;regime force: &lt;code&gt;政府军&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;据联合国特使称，叛军控制的阿勒颇市部分地区目前正处于俄罗斯和叙利亚政府军的包围之下，并将在接下来的两个月中变得满目疮痍。战争开始前，阿斯马尔·哈拉比和父亲在市内经营了两家家具店，但是都被炮击摧毁。目前他开了一家孤儿院，收养了50个孩子，他们中很多人的父母都在轰炸中丧生。失去亲人的不光是孩子们，阿斯马尔的父亲和他四姐妹中的三人也都不幸遇难。远在阿勒颇的他向我讲述了2014年学校遭受空袭那天的事，当时他的两个姐妹和他现在的妻子正在那里上学。 那时有一个13岁以上孩子参加的画展，那也是学年结束的日子，所以有一些庆祝活动。当时学校被执政势力袭击，整个校园被毁。我是在早上9点半左右得到的消息。有人打电话告诉我这件事。我立刻赶往学校，找到了其中一个不幸丧生的姐妹。我在废墟和瓦砾中一直寻找我另一个姐妹，找了两三个小时也没找到她的踪迹。后来他们告诉我她在医院，我们在那里找到了她。她已经在袭击中身亡。我们整日地寻找我的妻子，四天过去都没找到，直到后来他们给我们打电话，说她在学校被发现，当时就被送进了医院。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>挑食的蚊子</title>
      <link>https://wangcc.me/post/2016-10-13/</link>
      <pubDate>Thu, 13 Oct 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-10-13/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.scientificamerican.com/podcast/episode/farmed-trout-bred-to-fatten-up-fast/&#34;&gt;Farmed Trout Bred to Fatten Up Fast&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-10-7 18:36	用时：20:18正确率：91%	错词：24个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;aquaculture: &lt;code&gt;n. 水产养殖；水产业&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;get by: &lt;code&gt;phr. 过得去；过活；通过&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;trout: &lt;code&gt;n. 鳟鱼，鲑鱼&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;wader: &lt;code&gt;n. 步涉者，涉禽类，钓鱼用的防水长靴&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;全世界的人消费的所有鱼类中,有一半现在都来自于渔场.所以渔民们需要更努力工作来保证供给.如果从长计议, 按照当今全世界的人均鱼类消费水平来看,未来水产养殖业的产量需要达到翻倍才可以供应的上.&lt;/p&gt;
&lt;p&gt;这是Ron Hardy, University of Idaho水产养殖研究的负责人.他最近在Idaho 的太阳山谷Sun Valley举行的渔业营养与养殖国际论坛上发表了他的相关研究, 他同时也是这次会议的主席.&lt;/p&gt;
&lt;p&gt;在野生地区, 红鳟鱼吃昆虫或者是其它小鱼.但是Hardy说, 在野生环境中可没有那么多小鱼供应给大一点的鱼, 随着人类数量的增加, 也没有那么多供应给人类. 所以他就选择性的 用比小鱼便宜的食物饲养人工鱼苗——就是用大豆，玉米和小麦做成的鱼食。&lt;/p&gt;
&lt;p&gt;有些鱼苗大量繁殖成功：16年前，Hardy 不得不需要等一年才能得到一个一磅重的鳟鱼。近年来，他的努力所得到的鳟鱼，在同样的养殖时间内在体格上已经达到原来的四倍。所以，比如说你之前饲养的是小狗， 那么我们现在已经有从德国Rottweilers 罗特韦尔犬到小型苏格兰犬等各种品种了。&lt;/p&gt;
&lt;p&gt;但是，渔场的鱼并不是完全素食的。大豆没有骨架，它们没有骨头而鱼食中的骨头是鱼类所需的比如说矿物质的主要来源。&lt;/p&gt;
&lt;p&gt;和人类十分相似的是，鱼的膳食中也需要欧米伽3不饱和脂肪酸，这在陆地植物中是不含有的。所以，Hardy不得不在植物性的鱼食中再添加一点儿鱼油。&lt;strong&gt;对于我们那些不是捕鱼高手的人来说&lt;/strong&gt;，这种水产品可是我们在选择炸鱼食品中最好的选择了吧。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>吃魚油的魚</title>
      <link>https://wangcc.me/post/2016-10-7/</link>
      <pubDate>Fri, 07 Oct 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-10-7/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.scientificamerican.com/podcast/episode/farmed-trout-bred-to-fatten-up-fast/&#34;&gt;Farmed Trout Bred to Fatten Up Fast&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-10-7 18:36	用时：20:18正确率：91%	错词：24个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;aquaculture: &lt;code&gt;n. 水产养殖；水产业&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;get by: &lt;code&gt;phr. 过得去；过活；通过&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;trout: &lt;code&gt;n. 鳟鱼，鲑鱼&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;wader: &lt;code&gt;n. 步涉者，涉禽类，钓鱼用的防水长靴&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;全世界的人消费的所有鱼类中,有一半现在都来自于渔场.所以渔民们需要更努力工作来保证供给.如果从长计议, 按照当今全世界的人均鱼类消费水平来看,未来水产养殖业的产量需要达到翻倍才可以供应的上.&lt;/p&gt;
&lt;p&gt;这是Ron Hardy, University of Idaho水产养殖研究的负责人.他最近在Idaho 的太阳山谷Sun Valley举行的渔业营养与养殖国际论坛上发表了他的相关研究, 他同时也是这次会议的主席.&lt;/p&gt;
&lt;p&gt;在野生地区, 红鳟鱼吃昆虫或者是其它小鱼.但是Hardy说, 在野生环境中可没有那么多小鱼供应给大一点的鱼, 随着人类数量的增加, 也没有那么多供应给人类. 所以他就选择性的 用比小鱼便宜的食物饲养人工鱼苗——就是用大豆，玉米和小麦做成的鱼食。&lt;/p&gt;
&lt;p&gt;有些鱼苗大量繁殖成功：16年前，Hardy 不得不需要等一年才能得到一个一磅重的鳟鱼。近年来，他的努力所得到的鳟鱼，在同样的养殖时间内在体格上已经达到原来的四倍。所以，比如说你之前饲养的是小狗， 那么我们现在已经有从德国Rottweilers 罗特韦尔犬到小型苏格兰犬等各种品种了。&lt;/p&gt;
&lt;p&gt;但是，渔场的鱼并不是完全素食的。大豆没有骨架，它们没有骨头而鱼食中的骨头是鱼类所需的比如说矿物质的主要来源。&lt;/p&gt;
&lt;p&gt;和人类十分相似的是，鱼的膳食中也需要欧米伽3不饱和脂肪酸，这在陆地植物中是不含有的。所以，Hardy不得不在植物性的鱼食中再添加一点儿鱼油。&lt;strong&gt;对于我们那些不是捕鱼高手的人来说&lt;/strong&gt;，这种水产品可是我们在选择炸鱼食品中最好的选择了吧。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>絲綢之路上的傳染病</title>
      <link>https://wangcc.me/post/2016-10-6/</link>
      <pubDate>Thu, 06 Oct 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-10-6/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/silk-road-transported-goods-and-disease/&#34;&gt;Silk Road Transported Goods&amp;ndash;and Disease&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-10-6 12:2	用时：68:10
正确率：91%	错词：43个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;!-- raw HTML omitted --&gt;                                                                                                                 &lt;!-- raw HTML omitted --&gt;For &lt;!-- raw HTML omitted --&gt;thousand&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;thousands&lt;!-- raw HTML omitted --&gt; of years, what&amp;rsquo;s called the Silk Road was a group of &lt;!-- raw HTML omitted --&gt;lands&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;land&lt;!-- raw HTML omitted --&gt; and sea trade routes that connected the Far East with South Asia, Africa, the Middle East &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; and &lt;!-- raw HTML omitted --&gt;southern &lt;!-- raw HTML omitted --&gt;Europe. Of course, when humans travel &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; they carry their pathogens with them. So scientists and historians have wondered if the Silk Road was a transmission route &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; not just for goods&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; but for infectious disease. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Now we have the first hard evidence of ancient Silk Road travelers spreading their infections. The find comes from a &lt;!-- raw HTML omitted --&gt;2000-year-old&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;2,000-year-old&lt;!-- raw HTML omitted --&gt; latrine &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; that had first been excavated in 1992. The report is in the Journal of Archaeological Science&lt;!-- raw HTML omitted --&gt;:&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Reports&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;So&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the &lt;!-- raw HTML omitted --&gt;site is a &lt;!-- raw HTML omitted --&gt;relate&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;relay&lt;!-- raw HTML omitted --&gt; station on the Silk Road in northwest China. It&amp;rsquo;s just to the eastern end of the Tarim Basin&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; which is a large and &lt;!-- raw HTML omitted --&gt;varied&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;arid&lt;!-- raw HTML omitted --&gt; area &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;It&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;just&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; the &lt;!-- raw HTML omitted --&gt;east &lt;!-- raw HTML omitted --&gt;of the Taklamakan desert&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; not far from the Gobi Desert. So this is a dry part of China. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Piers Mitchell, &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; paleopathologist &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; at the University of Cambridge&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; and one of the study&amp;rsquo;s authors&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; along with &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;his&lt;!-- raw HTML omitted --&gt; student Ivy Yeh and colleagues in China. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;In the latrine, archaeologists found used hygiene sticks &lt;!-- raw HTML omitted --&gt;rap&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;wrapped&lt;!-- raw HTML omitted --&gt; with &lt;!-- raw HTML omitted --&gt;clothes&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;cloth&lt;!-- raw HTML omitted --&gt;. These were used for what you think they were used for. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;This &lt;!-- raw HTML omitted --&gt;escalation&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;excavation&lt;!-- raw HTML omitted --&gt; was great &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;because &lt;!-- raw HTML omitted --&gt;the &lt;!-- raw HTML omitted --&gt;clothes&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;were&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;cloth&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;was&lt;!-- raw HTML omitted --&gt; still preserved &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; the &lt;!-- raw HTML omitted --&gt;fezzes&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;which&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;feces&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;was&lt;!-- raw HTML omitted --&gt; still adherent to the &lt;!-- raw HTML omitted --&gt;clothes&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;cloth&lt;!-- raw HTML omitted --&gt; on some of the sticks. So the &lt;!-- raw HTML omitted --&gt;archaeologists&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;tagged&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;archaeologist&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;kept&lt;!-- raw HTML omitted --&gt; these sticks in the museum. And so my Ph. D. student&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; Ivy Yeh, &lt;!-- raw HTML omitted --&gt;who&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;who&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; first author &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;on&lt;!-- raw HTML omitted --&gt; the paper&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;she &lt;!-- raw HTML omitted --&gt;went out to China took some scrapings from the &lt;!-- raw HTML omitted --&gt;fezzes&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;feces&lt;!-- raw HTML omitted --&gt; adherent to the &lt;!-- raw HTML omitted --&gt;clothes&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;cloth&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;So &lt;!-- raw HTML omitted --&gt;we were &lt;!-- raw HTML omitted --&gt;then&lt;!-- raw HTML omitted --&gt; able to analyze that down the microscope when she brought it back to Cambridge. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Where they found &lt;!-- raw HTML omitted --&gt;legs&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;eggs&lt;!-- raw HTML omitted --&gt; from parasites &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; including one from a liver fluke. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;And that&amp;rsquo;s the exciting one because that&amp;rsquo;s only found in &lt;!-- raw HTML omitted --&gt;East&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;eastern&lt;!-- raw HTML omitted --&gt; and &lt;!-- raw HTML omitted --&gt;southern &lt;!-- raw HTML omitted --&gt;China and in Korea&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;where &lt;!-- raw HTML omitted --&gt;they have &lt;!-- raw HTML omitted --&gt;marched&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;marshy&lt;!-- raw HTML omitted --&gt; areas that &lt;!-- raw HTML omitted --&gt;would&lt;!-- raw HTML omitted --&gt; have the right snails and the right fish. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;The fluke needs snails and fish for its lifecycle&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;but &lt;!-- raw HTML omitted --&gt;there were no such snails or fish in this dry region of China. So the unlucky &lt;!-- raw HTML omitted --&gt;travelers&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;traveler&lt;!-- raw HTML omitted --&gt; who harbored the parasite had to have transported the disease to that spot. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Well &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; firstly it tells us that people were doing &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; very long &lt;!-- raw HTML omitted --&gt;journey&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;journeys&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;along&lt;!-- raw HTML omitted --&gt; the &lt;!-- raw HTML omitted --&gt;long&lt;!-- raw HTML omitted --&gt; Silk Road &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you &lt;!-- raw HTML omitted --&gt;might think that&amp;rsquo;s obvious&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;But &lt;!-- raw HTML omitted --&gt;no one really knew how long people were traveling. Some people may have been trading, &lt;!-- raw HTML omitted --&gt;don&amp;rsquo;t&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;need&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;go&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;only&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;going&lt;!-- raw HTML omitted --&gt; short distances selling their goods on to the next person. And so the goods might have gone all &lt;!-- raw HTML omitted --&gt;over&lt;!-- raw HTML omitted --&gt; the way &lt;!-- raw HTML omitted --&gt;on&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;along&lt;!-- raw HTML omitted --&gt; the Silk Road&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; but people might not. But we know that some people were doing huge distances. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Secondly &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; it shows that &lt;!-- raw HTML omitted --&gt;you&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;know&lt;!-- raw HTML omitted --&gt; this &lt;!-- raw HTML omitted --&gt;was&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; would be a viable route for the spread of those other infectious diseases like Bubonic plague &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;leprosy &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; and anthrax &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;people &lt;!-- raw HTML omitted --&gt;had previously &lt;!-- raw HTML omitted --&gt;been&lt;!-- raw HTML omitted --&gt; suggested might have been spread between East Asia and Europe along the Silk Road. Because &lt;!-- raw HTML omitted --&gt;bone&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;modern&lt;!-- raw HTML omitted --&gt; genetic analyses have just shown similarities between &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; strains &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; one &lt;!-- raw HTML omitted --&gt;end&lt;!-- raw HTML omitted --&gt; and the other. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Mitchell says &lt;!-- raw HTML omitted --&gt;there&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;there&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; much more work to be done to better understand the spread of diseases around the world. Perhaps from analyzing skeletons &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; or various other kinds of remains &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; to be found along the Silk Road.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;latrine: &lt;code&gt;n. a public toilet in a military area&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;relay: &lt;code&gt;n. 接力赛；替班；中继设备；转播，传送 v. 传达；转播，传送；（使）接替&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;arid: &lt;code&gt;adj. 干旱的，干燥的；贫瘠的，不毛的；枯燥无味的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;archaeologist: &lt;code&gt;n. 考古学家&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;excavation: &lt;code&gt;n. 挖掘，发掘；挖，开凿&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Taklamakan desert: &lt;code&gt;塔克拉玛干沙漠&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;feces: &lt;code&gt;n. 排泄物，渣滓&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Gobi Desert: &lt;code&gt;戈壁沙漠（蒙古和中国西北部）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;marshy: &lt;code&gt;adj. 多沼地的，湿地的，沼地的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Bubonic plague: &lt;code&gt;n. [医]黑死病,淋巴腺鼠疫&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;leprosy:  &lt;code&gt;n. 麻疯病,腐败&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;athrax: &lt;code&gt;n. 炭疽热&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;几千年前， 有个被称为丝绸之路的地方就是一段陆地和海洋上的贸易路线图，贯穿远东和南亚，中东以及欧洲南部。 当然，那时候人们在旅途中也是会携带者病菌的。所以，科学家和历史学家早就好奇，是不是丝绸之路不仅仅是贸易通商之路，还是传染性疾病的传播之旅阿。&lt;/p&gt;
&lt;p&gt;如今，我们找到第一手资料能够证明古老的丝绸之旅上的商旅们确实也传播了他们感染的传染病。这些证据来自于1992年首次挖掘出的一个具有2000年的公厕。该研究报告已经发表在《考古科学：通报》杂志上。&lt;/p&gt;
&lt;p&gt;所以这个位点是一个中国西北部丝绸之路上的一个驿站。它通往塔里木盆地的东部末端，是通往塔克拉玛干沙漠东部的一片较大的草木荒芜地区， 离戈壁滩不是很远。所以这里是中国的一块非常干燥的土地。&lt;/p&gt;
&lt;p&gt;这是Piers Mitchell,剑桥大学的一位古生物病理学家，也是这项研究的作者之一，其它参与者是他的学生Piers Mitchell,和中国的一些同事。在这个公厕里，考古学家们发现了使用过的包裹着布料的卫生棒。这些东西就是你想象中的需要用到的那些东西。&lt;/p&gt;
&lt;p&gt;这次挖掘的意义重大，因为，织物的保存还是完好的，而粪便仍然还粘附在棒子上的布料上的某些地方。所以考古学家们把这样的一些棍子保存在了博物馆里。并且因此我的博士生Ivy Yeh, 他就是这篇文章的第一作者，她就去中国从那些布料上刮下了一些粪便样品。当她回到剑桥之后，我们才能用显微镜观察分析。他们发现了一些寄生虫的卵——包括一种肝吸虫。&lt;/p&gt;
&lt;p&gt;因为这种东西只在东部和南部的中国以及韩国存在，所以这个发现还是令人兴奋的。那些地区 都有沼泽地区，里面生存着合适的宿主蜗牛和鱼类。这种肝吸虫的生活史中需要蜗牛和鱼类，但是在这些干燥的中国地区是没有这类蜗牛和鱼类的。所以，被寄生的这些不幸的旅行者们不得不把这种疾病带到了这个站点。&lt;/p&gt;
&lt;p&gt;首先，这告诉我们，人们在丝绸之路上行走了相当长的一段距离，并且，你也许认为这还不时很显然的事情吗。但是，没有人真正了解人们具体行走了多长的距离不是吗。一些人也许一直会做着贸易，只走了较短的距离后就把他们的货物卖给下一个人。而这些货物也许被运送了全程，而人们就不一定都走了全程的。但是我们子回到有些人确实走了很远的距离。&lt;/p&gt;
&lt;p&gt;第二点，这表明，这是，也许是传播像 Bubonic plague腺鼠疫，麻风病和炭疽热等其它类传染性疾病的一个可行的途径，这些疾病人们以前曾经假设过也许就是在中亚和欧洲地区沿着丝绸之旅开始流行传播的。因为现代遗传分析已经显示出在这条路一端和另外一端的菌株之间的遗传相似性。&lt;/p&gt;
&lt;p&gt;Mitchell 表示，还有很多工作需要做，这样将有助于更好的理解全世界的疾病传播情况。或许是通过分析遗迹残骸骨架——或者其它种类的残留物——未来在丝绸之路上所发现的那些东西，就可以了解了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>近親繁殖讓鳥兒不會唱歌</title>
      <link>https://wangcc.me/post/2016-08-11/</link>
      <pubDate>Thu, 11 Aug 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-08-11/</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/inbred-songbirds-croon-out-of-tune/&#34;&gt;Inbred Songbirds Croon out of Tune&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; wortsh to be remembered:
&lt;ul&gt;
&lt;li&gt;songbird &lt;code&gt;n. 鸣禽,鸣鸟,女歌手&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;babble &lt;code&gt;n. 潺潺声；胡言乱语 v. 喋喋不休；含糊不清地说，呀呀学语；作潺潺声；泄露&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Antwerp &lt;code&gt;安特衛普, 比利時城市&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;tweak &lt;code&gt;n. 拧，捏，扭；苦恼；微调，改进 v. 拧，捏，扭；稍稍调整&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;canary &lt;code&gt;金丝雀,告密者,歌女 (复数)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;inbreed &lt;code&gt;vt. 使同系繁殖,使近亲交配,使在内部生成&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;inbred &lt;code&gt;adj. 天生的,生来的,同系繁殖的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;outbreed &lt;code&gt;vt. 使远系繁殖&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;pitch &lt;code&gt;n. 投；投球；音高；程度；沥青 v. 投掷；为…定音高；搭帐篷；用沥青涂&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;songster &lt;code&gt;n. 歌手,作曲者,诗人,鸣鸟&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;就像是人类不得不学会說話&lt;del&gt;谈话&lt;/del&gt;, 夜莺们也不是生来就会唱歌滴——它们也不得不去找准旋律。 所以在一开始它们也就是那样呀呀学语。这是Raissa de Boer， 一位比利时安特卫普大学的行为生态学家。而它们需要跟随一位导师，为了学会唱歌它们还需要一首练习曲。&lt;/p&gt;
&lt;p&gt;她说,&lt;strong&gt;鳥兒們&lt;/strong&gt;的练习曲也许是来自于它们的老爸。并且随着它们慢慢长大，小鸟会纠正&lt;del&gt;一下&lt;/del&gt;自己的鸣叫，找到适合自己的style. 随后，还大约需要一年的时间直到它们完全长大后，直到一年后的春天，最后的练习结果便要出炉。&lt;/p&gt;
&lt;p&gt;De Boer 和她的同事们调查了金丝雀的音乐学习之路，她们用的是两组幼鸟：第一组是近亲繁殖的后代，它们的父母是有血缘关系的。第二组的不是近亲的后代。随后研究人员们发现，近亲后代的鸟叫和非近亲后代的鸟叫对人类的耳朵来讲，没什么差别。我就分不清谁是谁呢。&lt;/p&gt;
&lt;p&gt;但是，通过电脑分析之后，结果揭示出，近亲的小鸟们有一些不同的音调——并且音色也不是十分纯正。所以它们基本上是唱跑调了，当然是和非近亲的后代相比。 该研究结果已经发表在《皇家协会进展B》杂志上。&lt;/p&gt;
&lt;p&gt;而且即使是我们这些没有经过培训的普通听者，都很难分辨出这些音色上的区别，雌性金丝雀貌似是了解的这一点的。当她们和近亲的鸟类交配时，更倾向于产个头小一些并且，数量也少一些的卵，仿佛这样并不利于产生优良歌声的后代。这提示我们，一个夜莺的基因质量也许从它们的音色上就可以看出来一些呢。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>婚后易发胖</title>
      <link>https://wangcc.me/post/2016-8-10/</link>
      <pubDate>Wed, 10 Aug 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-8-10/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/married-couples-pack-on-more-pounds/&#34;&gt;Married Couples Pack On More Pounds&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-8-10 12:47	用时：25:23
正确率：95%	错词：13个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;unbridled &lt;code&gt;adj. 无缰辔的,无羁勒的,无拘束的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;smug &lt;code&gt;adj. 沾沾自喜的，自以为是的；体面的 n. 自命不凡的人；书呆子&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;plump &lt;code&gt;adj. 丰满的；充裕的；鼓起的 adv. 沉重地；突然地 n. 扑通声 v. （使）鼓起；变丰满，使丰满；（使）突然沉重地落下&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文&lt;/h2&gt;
&lt;p&gt;Bridget Jones, 在印刷出版物或者荧屏上的动态形象上,都会称他们是&lt;strong&gt;得瑟&lt;/strong&gt;的一对——那些欢喜冤家看上去十分美满。但是也许故事中的Jones本应该称他们为&lt;strong&gt;富态&lt;/strong&gt;的一对。 因为，除了提供给夫妻双方无拘束的幸福生活以外，婚姻还会造成他们的体重&lt;del&gt;直线&lt;/del&gt;上升。这是根据一项发表在《家庭报》杂志上的一项研究得出的结论。&lt;/p&gt;
&lt;p&gt;西华盛顿大学的社会学家Jay Teachman，调研了全国青年纵向调查得到的数据。这些数据包括了对超过3000名的非洲裔美国人进行了长达20年的调查的所有信息。&lt;/p&gt;
&lt;p&gt;Teachman调查了身体质量指数 BMI， 一种从青年到中年都&lt;del&gt;是用&lt;/del&gt;(適用)的，衡量肥胖症的重要指标。然后他分析了BMI与&lt;del&gt;体能&lt;/del&gt;(婚姻)状态以及&lt;del&gt;体能&lt;/del&gt;(婚姻)状态改变之间的关系。结果显示，和已婚并且住在一起的夫妇相比较，没有伴侣的人通常较为苗条并且有比较低的BMI。单身人士中包括了一直未婚和已经离婚的人。&lt;/p&gt;
&lt;p&gt;夫妻双方的体重都会增加，但是从种族的角度看，黑人妇女们的体重增长的最快，其次是白人妇女，然后才是黑人以及白人男士。说体重增加其实也不过就是几磅而已——可是BMI就算是少量的增加，也&lt;del&gt;是密切联系着&lt;/del&gt;与增重相关的健康问题(密切相關)。&lt;/p&gt;
&lt;p&gt;造成单身和已婚人士之间的体重的差异有很多原因。比如说，已婚男士和女士也许因为不在需要主动寻找合适的配偶所以减少了对自己体重的重视。此外，已婚后夫妻双方一般都会一起吃晚餐，这也可能使得他们(比單身者日常飲食次數更多)&lt;del&gt;的饭量增加&lt;/del&gt;吧。从单身的角度看，寡居或者正在离婚的人士也许会因为压力而造成体重下降。&lt;/p&gt;
&lt;p&gt;所以尽管这则消息对得瑟的夫妇们来讲或许并(不)算好消息，但对Bridget Jones来讲倒是还不错。这个单身的，十分关注体重的Jones, 也许真的有比她那些已婚朋友们更简便的保持苗条的方法。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>科學與神學的融合之旅</title>
      <link>https://wangcc.me/post/2016-8-5/</link>
      <pubDate>Fri, 05 Aug 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-8-5/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/evolution-ed-defenders-make-rapids-progress-in-grand-canyon/&#34;&gt;Evolution Ed Defenders Make Rapids Progress in Grand Canyon&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-8-5 15:29	用时：23:29
正确率：89%	错词：23个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;Grand Canyon &lt;code&gt;pla.大峡谷{GCN,美国}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;penultimate &lt;code&gt;adj. 由字尾倒数第二的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;campsite &lt;code&gt;n. 露营地（为游客所设），野营地，度假营地，营地&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Creationist &lt;code&gt;n. 神灵论者，上帝论者&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;tout &lt;code&gt;n. 兜售者，招揽员 v. 兜售；招徕；拉选票；标榜，吹捧，吹嘘&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;remnant &lt;code&gt;adj. 剩余的，残余的 n. 剩余；残余&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;hydrology &lt;code&gt;n. 水文学&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文:&lt;/h2&gt;
&lt;p&gt;所以划下Grand Canyond大峡谷和科学教育有神马关系呢？&lt;/p&gt;
&lt;p&gt;这是Ann Reid，之前是生物学研究员，现在是国家科学教育中心（NCSE）的执行主席。她在７月７日 Fern Glen Canyon大峡谷的露营地，和我进行了一次谈话，就在我们要用木筏划下Grand Canyon大峡谷的科罗拉多河的前一天早上。&lt;/p&gt;
&lt;p&gt;对于NCSE来讲，这里是地球上最强大的地方之一，可以显示出宗教和科学思想之间的差异。因为对于很小一部分相信地球存在已经有６０００年的基督教信徒来讲，Grand Canyon大峡谷是他们认为诺亚曾发生洪水的最好证据。&lt;/p&gt;
&lt;p&gt;神创论者们每年都会行驶多功能木筏划过科罗拉多。一个宣传网站上提及这种旅行是“将鼓励你的信仰，因为我们在圣经记录的洪水中遗留下来的庞大产物中揭示出了上帝创造一切的真相。&lt;/p&gt;
&lt;p&gt;当然，所有科学家，许许多多不同分支学科的科学家们已经指出，这个大峡谷的存在时间比记录中的年代要更久远，那里有岩石，那里也有生物，那里有水文地理，这里是了解科学家们如何解释我们生存的世界的极好的一个地方。&lt;/p&gt;
&lt;p&gt;每年举行的NCSE科罗拉多河漂流之旅可以吸引到２４名观众，以及由一位地理学家和一位进化生物学家进行解说的记录短片。今年，两个公立学校的老师收到了全奖支持的旅行，所以他们可以将他们的这次经历和学到的知识带回课堂。并且，我已经收录了许多相关音频，　之后我会在今后几周陆续放到我们科学美国人科学谈话的播客节目里。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>彩票中獎概率之謎</title>
      <link>https://wangcc.me/post/2016-8-4-powerball/</link>
      <pubDate>Thu, 04 Aug 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-8-4-powerball/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/powerball-lottery-winning-made-inevitable-if-not-easy/&#34;&gt;Powerball Lottery Winning Made Inevitable (If Not Easy)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-8-4 13:10	用时：44:49
正确率：90%	错词：43个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点                        &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;There&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;There&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; a story in the book&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a &lt;!-- raw HTML omitted --&gt;story about people who took advantage of the law of inevitability to win the lottery. That&amp;rsquo;s mathematician David Hand&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; talking about his 2014 book &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; The Improbability Principle: Why Coincidences, Miracles and Rare Events Happen Every Day. The law of inevitability comes into play in &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; lottery drawings &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;some &lt;!-- raw HTML omitted --&gt;set of &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; numbers will be drawn, so a potential winning combination is inevitable. The key word being &lt;!-- raw HTML omitted --&gt;&amp;quot;&lt;!-- raw HTML omitted --&gt; potential&lt;!-- raw HTML omitted --&gt;&amp;quot;&lt;!-- raw HTML omitted --&gt; , as nobody has yet won the multistate Powerball &lt;!-- raw HTML omitted --&gt;lottery&lt;!-- raw HTML omitted --&gt;. Which means that the &lt;!-- raw HTML omitted --&gt;jackpot &lt;!-- raw HTML omitted --&gt;for the next drawing&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; the night of January 13th&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; is up to some $1. 3 billion. You could buy a ticket and hope&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Or&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; as you may have &lt;!-- raw HTML omitted --&gt;amused&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;mused&lt;!-- raw HTML omitted --&gt;, you could buy every possible set of numbers to inevitably win. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;In&lt;!-- raw HTML omitted --&gt; 1992, Virginia State Lottery&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the &lt;!-- raw HTML omitted --&gt;Virginia &lt;!-- raw HTML omitted --&gt;State&lt;!-- raw HTML omitted --&gt; Lottery is a six/44 lottery &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you &lt;!-- raw HTML omitted --&gt;have to choose six numbers out of 44 &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; which means it&amp;rsquo;s a one in &lt;!-- raw HTML omitted --&gt;seven &lt;!-- raw HTML omitted --&gt;million chance that a &lt;!-- raw HTML omitted --&gt;ticket&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; particular ticket &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;will&lt;!-- raw HTML omitted --&gt; be the &lt;!-- raw HTML omitted --&gt;Jackpot&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;winning&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;jackpot-winning&lt;!-- raw HTML omitted --&gt; ticket. Seven million. So if you bought all the tickets&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; it &lt;!-- raw HTML omitted --&gt;will&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;would&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;only&lt;!-- raw HTML omitted --&gt; cost you $7 million. &lt;!-- raw HTML omitted --&gt;Stay&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;So&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;they&lt;!-- raw HTML omitted --&gt; waited until the &lt;!-- raw HTML omitted --&gt;roll&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;rollover&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;jackpot &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;had&lt;!-- raw HTML omitted --&gt; built up &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt;, &lt;!-- raw HTML omitted --&gt;haven&amp;rsquo;t&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;hadn&amp;rsquo;t&lt;!-- raw HTML omitted --&gt; been won, &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;so&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;it&lt;!-- raw HTML omitted --&gt; built up &lt;!-- raw HTML omitted --&gt;over&lt;!-- raw HTML omitted --&gt; several weeks to $27 million. If you &lt;!-- raw HTML omitted --&gt;managed&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;manage&lt;!-- raw HTML omitted --&gt; to spend $7 &lt;!-- raw HTML omitted --&gt;milllion&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;million&lt;!-- raw HTML omitted --&gt; and buy all the seven million tickets &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; you are guaranteed to hold the &lt;!-- raw HTML omitted --&gt;jackpot &lt;!-- raw HTML omitted --&gt;winning ticket. But &lt;!-- raw HTML omitted --&gt;there&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;there&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; a lot of &lt;!-- raw HTML omitted --&gt;organizations&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;organization&lt;!-- raw HTML omitted --&gt; involved in this. In fact, what happened &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;was&lt;!-- raw HTML omitted --&gt; they put together a consortium of &lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;half&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;thousand&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;2,500&lt;!-- raw HTML omitted --&gt; people&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;each &lt;!-- raw HTML omitted --&gt;of whom &lt;!-- raw HTML omitted --&gt;pays&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;paid&lt;!-- raw HTML omitted --&gt; $&lt;!-- raw HTML omitted --&gt;3000,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;so&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;there&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;about&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;3,000&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;or&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;thereabouts&lt;!-- raw HTML omitted --&gt;, so they &lt;!-- raw HTML omitted --&gt;have&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;had&lt;!-- raw HTML omitted --&gt; $7 million. And then in &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; few days&amp;rsquo; window &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; they had available they ran around buying &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; trying to buy all the seven million tickets. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&amp;quot;&lt;!-- raw HTML omitted --&gt; Trying &lt;!-- raw HTML omitted --&gt;&amp;quot;&lt;!-- raw HTML omitted --&gt; to buy&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Because &lt;!-- raw HTML omitted --&gt;the consortium only managed to buy five million tickets. So winning was not inevitable, their chances were only &lt;!-- raw HTML omitted --&gt;about&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;5&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;five&lt;!-- raw HTML omitted --&gt; out of &lt;!-- raw HTML omitted --&gt;7&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;seven&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;As it happened, however, they did have the winning ticket&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;so &lt;!-- raw HTML omitted --&gt;they were guaranteed winning the &lt;!-- raw HTML omitted --&gt;jackpot&lt;!-- raw HTML omitted --&gt;. The organization beforehand, the logistics of running around trying to buy these tickets&lt;!-- raw HTML omitted --&gt;they&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;may&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;nail-biting&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;looking&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;through&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;tickets&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; it&amp;rsquo;s easier &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;if&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;just &lt;!-- raw HTML omitted --&gt;to get a job. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;So if &lt;!-- raw HTML omitted --&gt;you&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; thinking of getting together a consortium for the Powerball&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;keep &lt;!-- raw HTML omitted --&gt;in mind that for this lottery &lt;!-- raw HTML omitted --&gt;there&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;there&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; only a one in 292 million chance of winning. And tickets are &lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;two&lt;!-- raw HTML omitted --&gt; bucks a pop. So you and your buddies are &lt;!-- raw HTML omitted --&gt;gonna&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;going&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; have to come up with almost $600 million to buy every combo and take advantage of the law of inevitability. And if others pick the same winning numbers and you have to split the winnings &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you &lt;!-- raw HTML omitted --&gt;could basically break even or even lose money. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;To put the frenzy &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; perspective&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; I like to recall the wisdom &lt;!-- raw HTML omitted --&gt;from&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; statistician Michael Orkin, author &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; the book &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; What Are the Odds? Chance in Everyday Life. Back &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; 2001 &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; the Powerball &lt;!-- raw HTML omitted --&gt;jackpot &lt;!-- raw HTML omitted --&gt;had reached &lt;!-- raw HTML omitted --&gt;￥&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;$&lt;!-- raw HTML omitted --&gt;295 million &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and &lt;!-- raw HTML omitted --&gt;the odds back then were better, only 175 million to &lt;!-- raw HTML omitted --&gt;won&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;one&lt;!-- raw HTML omitted --&gt;. Orkin told me, if you have to drive 10 miles to buy a Powerball ticket, &lt;!-- raw HTML omitted --&gt;you&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; 16 times more likely to get killed in a car crash on your way than you are to win. So if &lt;!-- raw HTML omitted --&gt;you&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;death&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;dead&lt;!-- raw HTML omitted --&gt; set on buying a lottery ticket, at least walk.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;jackpot &lt;code&gt;n. 头奖；累积赌注金；最大成功&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;muse &lt;code&gt;n. 沉思；冥想；缪斯女神 v. 沉思，冥想；沉思地说&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;thereabout &lt;code&gt;adv. 在那附近;大约那时&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;nail-biting &lt;code&gt;n. 咬指甲癖性,没有办法的状态,束手无策&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;combo &lt;code&gt;n. 联合体；结合物；小型爵士乐队&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;frenzy &lt;code&gt;n. 狂热；狂暴；狂怒 v. 使狂怒&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;dead set &lt;code&gt;n. 决定性攻击，猛烈攻击 adj. 堅定不移的&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;书里有这样一个故事,关于那些利用必然规律赢得彩票的人们. 这是数学家David Hand, 他在谈论2014年他自己出版的一本书, 名为Improbability Principle: Why Coincidences, Miracles and Rare Events Happen Every Day.“不可能之规律: 为什么每天都会发生巧合, 奇迹以及及其少见的一些事儿.”必然规律被积极应用到了彩票抽奖当中——某些组数字会被抽中，所以猜中数字组合是一种必然性事件。 关键词是将来有可能，因为有人已经赢得多重美国谈力球彩票大奖过了。也就是说，下次抽奖的奖金，1月13日晚的那次抽奖，已经达到13亿美金。你也可以买一张试试看。或许，正如你曾默默思考过的结果那样，你也许应该把所有可能的数字组合都买下哦。 1992年，Virginia State州的那次彩票，当时是6/44型的彩票——你必须从44个数字中选出六个——也就是说这是个7百万分之一的可能性事件，如果某一个组合的彩票猜中大奖。700万種组合哦。所以如果你买下所有可能的组合，也只会花掉7百万美元而已。 所以他们等待转动奖池积累剩余奖金，所以，这就积累了好几周，最后达到2千7百万美金。 如果你打算花7百万买下所有可能中的彩票，你也必然会最终中奖的。 但是，有好多不同组织参与运作。 实际上，当时的结果是，他们组成了一个2500人的联合机构，每人花差不多3000美金，所以他们最终共同出资7百万美金。 然后，在之后几天里，他们轮流去买彩票——尽可能的买下所有可能出现的中奖组合。 只是尽量去买。因为，这个联合机构&lt;del&gt;之打算买下&lt;/del&gt;(最终也只成功买到)5百万张彩票而已。所以获奖概率就不是必然的了，他们的获奖概率就是5/7。 然而事实是，他们最终还是获得大奖，所以他们确实获得了积累的所有奖金。这个联合组织预先，&lt;strong&gt;组织大家轮流买这些可能获奖的彩票，紧张的计算彩票获奖概率，比一般工作可难多了。&lt;/strong&gt; 所以如果你正考虑召集这样一个Powerball彩票联合购买机构，一定要记住这种彩票的获大奖概率只有2亿9千2百万分之一。而彩票是两美金一个号码。所以你和你的伙伴们将需要告到6亿美金才能买到每一个可能的组合，并且利用到这种必然事件规律。如果有其它类似机构购买了同样有可能获奖的号码组合，你们就不得不分享最终大奖，那么你有可能最后只是收支平衡或者甚至还要亏本呢。 &lt;del&gt;为了正确激发你的热情，&lt;/del&gt;(不是給你的熱情澆冷水，)我不禁回想起统计学家Michael Orkin的智慧，他也是《可能性是多少？每天的生活中都有机会。》这本书的作者。回看一下2001年Powerball的奖池已经积累到了2亿9千5百万美金并且那时的概率也搞，只有一亿7千5百万分之一。Orkin告诉我说，如果你需要驱车10英里去买Powerball彩票的话，你在行车途中出车祸死亡的概率是你能赢得大奖概率的16倍以上。所以，如果你&lt;del&gt;十分热切的&lt;/del&gt;(依然意志坚定地)要买张彩票的话，至少走路去啦。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>肠道菌减肥计划</title>
      <link>https://wangcc.me/post/2016-08-03-gutbacteria/</link>
      <pubDate>Wed, 03 Aug 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-08-03-gutbacteria/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.scientificamerican.com/podcast/episode/fat-gets-gut-bacteria-working-against-the-waistline/&#34;&gt;Fat Gets Gut Bacteria Working against the Waistline&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-8-3 13:55	用时：26:08
正确率：93%	错词：20个&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点                        &lt;!-- raw HTML omitted --&gt;Think it&amp;rsquo;s your inability to resist cheesecake that&amp;rsquo;s making it tough to fit into your skinny &lt;!-- raw HTML omitted --&gt;genes&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;jeans&lt;!-- raw HTML omitted --&gt;? &lt;!-- raw HTML omitted --&gt;Well&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;your &lt;!-- raw HTML omitted --&gt;bacteria may share some of the blame. Because a new study in mice shows &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; the &lt;!-- raw HTML omitted --&gt;responsive&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;response&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; intestinal microbes to a high-fat diet ends up triggering the release of a hormone that makes mammals feel hungry, causing them to eat even more. The finding is served up in the journal Nature. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Previous work &lt;!-- raw HTML omitted --&gt;had&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;has&lt;!-- raw HTML omitted --&gt; shown that the types of bacteria in the gut in diabetic or obese individuals are different from the bacteria in healthy people. But does &lt;!-- raw HTML omitted --&gt;these&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;bacteria&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;make&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;this&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;bacterial&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;makeup&lt;!-- raw HTML omitted --&gt; contribute to these disorders&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Or &lt;!-- raw HTML omitted --&gt;is it just a side effect? &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;To unravel this mystery, researchers put mice on a high-fat diet. The animals experienced &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;built&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;buildup&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; a chemical called acetate, particularly in the large intestine. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;That location points to gut bacteria, which can produce acetate, as a possible culprit. So the researchers wiped out the microbes using antibiotics or &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; simple saline wash. And acetate levels plummeted. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Okay, so the gut bacteria in &lt;!-- raw HTML omitted --&gt;fat-fed&lt;!-- raw HTML omitted --&gt;  mice make acetate. What does acetate do? Well, it gets the involuntary part of the &lt;!-- raw HTML omitted --&gt;nerve&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;nervous&lt;!-- raw HTML omitted --&gt; system, the parasympathetic &lt;!-- raw HTML omitted --&gt;nerve&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;nervous&lt;!-- raw HTML omitted --&gt; system&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; to put out the call to produce more insulin. Unfortunately, in this case, acetate also gets the parasympathetic &lt;!-- raw HTML omitted --&gt;nerve&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;nervous&lt;!-- raw HTML omitted --&gt; system to stimulate &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; production of a hunger hormone called ghrelin. And the more &lt;!-- raw HTML omitted --&gt;fat&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;fats&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;an&lt;!-- raw HTML omitted --&gt; animal consumes, the more acetate it makes &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;which &lt;!-- raw HTML omitted --&gt;means the more ghrelin it produces &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; and&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; of course, the more it eats. And bacteria make the whole sequence happen. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;The researchers are now investigating &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; whether the same biochemical events happen in humans. If they do, it&amp;rsquo;s possible that obtaining a better &lt;!-- raw HTML omitted --&gt;assortment&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;assortments&lt;!-- raw HTML omitted --&gt; of gut bacteria could help &lt;!-- raw HTML omitted --&gt;us&lt;!-- raw HTML omitted --&gt; control our weight. Of course, the best way to get those good bacteria is from a fecal transplant &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;in &lt;!-- raw HTML omitted --&gt;which bacteria-rich feces come out of one person and into you. The very thought of which could help curb your appetite.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;serve up &lt;code&gt;phr. 端上，提供，提出&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;buildup &lt;code&gt;n. 组织,组成,增强&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;acetate &lt;code&gt;n. 醋酸纤维（素）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;plummet &lt;code&gt;n. 铅锤；坠子 v. 垂直落下；骤然下跌&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;assortment &lt;code&gt;n. 花色品种；混合物；分类&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;curb &lt;code&gt;n. 限制；路缘，路边 v. 控制，抑制&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;ghrelinn &lt;code&gt;n. 胃饥饿素（一种胃肠道激素）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;saline &lt;code&gt;adj. 含鹽的，鹽的 n. 鹽湖；鹽溶液&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;认为是你自己难以控制的吃奶酪蛋糕才导致穿不进去紧身牛仔裤？好吧，你体内的细菌也许也要付一些责任的。因为一项最新研究显示，在小鼠的实验中显示肠道内的微生物对高脂肪的膳食做出的响应就是结束开始释放一种可以使哺乳动物感到饥饿的荷尔蒙(激素)，导致他们吃的更多了。该研究已经发表在《自然》杂志上。&lt;/p&gt;
&lt;p&gt;之前的研究工作已经显示出糖尿病或者肥胖的个体肠道内的细菌种类与健康人肠道内的细菌种类是不同的。但是，这种细菌组合确实(會造成)&lt;del&gt;有助于&lt;/del&gt;这些(疾病，指的糖尿病或者肥胖)&lt;del&gt;体内代谢紊乱的形成&lt;/del&gt;吗？或者这其实只是&lt;del&gt;代谢紊乱后的&lt;/del&gt;(疾病的)副作用？为了揭开这个谜团，研究人员们喂养实验小鼠高脂肪的膳食。这些小动物们呈现出&lt;del&gt;对&lt;/del&gt;一&lt;del&gt;种&lt;/del&gt;(类)名为乙酸(鹽)的化学物质的积累，特别是在大肠内。&lt;/p&gt;
&lt;p&gt;定位显示它们属于肠道细菌，可以生成乙酸(鹽)， 所以它们既有可能就是&lt;strong&gt;始作俑者&lt;/strong&gt;呢。因此研究人员们用抗生素或者一种简单的鹽水清洗方法来清除掉可能存在的微生物。 结果发现乙酸(鹽)的含量显著下降。好吧，所以就是吃脂肪的小&lt;del&gt;老&lt;/del&gt;鼠们体内的肠道细菌制造出的乙酸。那么这些乙酸(鹽)是用来干神马的？额，它可以到达神经系统的非自主部分，就是副交感神经系统，用来熄灭要求制造更多胰岛素的信号。不幸的是，这种情况下，乙酸(鹽)还作用于副交感神经系统来刺激制造一种饥饿激素又名生长激素释放肽。而一只动物所&lt;del&gt;消耗&lt;/del&gt;(攝入)的脂肪越多，它产生出的乙酸(鹽)就越多——也就是说有更多的饥饿激素被制造出来，当然，它也会因此吃更多的食物。而细菌便是这整个连锁反应中的起始环节呢。&lt;/p&gt;
&lt;p&gt;研究人员现在正在研究是否在人体内也有类似的生化反应事件的发生。如果答案是肯定的，那么(人類很有可能通過獲得較優質的腸內菌羣來控制體重。)&lt;del&gt;人们将有可能获得一种更好的分类肠道细菌的方法，并将有助于我们控制自己的体重。&lt;del&gt;当然，最好的方法是&lt;/del&gt;从&lt;/del&gt;移植(含有優質腸內細菌的糞便)&lt;del&gt;实验中找到那些有益的细菌&lt;/del&gt;——也就是从一个人体内排出的富含细菌的粪便，移植到你的体内。&lt;del&gt;理想情况下这种方法可以有助于抑制你的食欲。&lt;/del&gt;(這畫面光想一想就能抑制你的食欲啊！！)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>花蜜專家</title>
      <link>https://wangcc.me/post/2016-08-02-honey/</link>
      <pubDate>Tue, 02 Aug 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-08-02-honey/</guid>
      <description>&lt;p&gt;正確率：87%&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.scientificamerican.com/podcast/episode/bees-rank-pollen-by-taste/&#34;&gt;Bees Rank Pollen by Taste&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&amp;lt;spanclass=&amp;quot;diff_alert&amp;quot;&amp;gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点                        &lt;!-- raw HTML omitted --&gt;Walk through &lt;!-- raw HTML omitted --&gt;Time&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Times&lt;!-- raw HTML omitted --&gt; Square &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; you&amp;rsquo;re &lt;!-- raw HTML omitted --&gt;bumbled&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;bombarded&lt;!-- raw HTML omitted --&gt; with advertising. And it turns out&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; a bumblebee &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; might have a similar feeling&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; buzzing through a field of flowers. So these flowers &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; these &lt;!-- raw HTML omitted --&gt;build&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;balls&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;billboards&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;they&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; advertising &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;good&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;It&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; a &lt;!-- raw HTML omitted --&gt;good&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;this&lt;!-- raw HTML omitted --&gt; delicious nectar &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;world&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;reward&lt;!-- raw HTML omitted --&gt;, and bees are very picky shoppers. Anne Leonard, a pollination biologist at the University of Nevada, Reno. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;She describes &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; flower field as &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; sort of pollination marketplace. And one way &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; bees choose where to visit&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; Bees are nectar experts. They are really good at assessing even really small differences &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; like sugar concentration of nectar. They also scope out the shape and size of flowers and their color and scent. And now Leonard and her colleagues have discovered that bumblebees are pollen aficionados&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; too. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;They found &lt;!-- raw HTML omitted --&gt;out&lt;!-- raw HTML omitted --&gt; that &lt;!-- raw HTML omitted --&gt;out&lt;!-- raw HTML omitted --&gt; by lacing batches of cherry pollen with either table sugar or bitter quinine. And &lt;!-- raw HTML omitted --&gt;they&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; display the pollen to bees&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;we &lt;!-- raw HTML omitted --&gt;got really into it &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; we &lt;!-- raw HTML omitted --&gt;set&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;up&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;started&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;3-D &lt;!-- raw HTML omitted --&gt;printing flowers in our lab. And for the &lt;!-- raw HTML omitted --&gt;answer&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;anther&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; the male flower part&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; which presents the pollen &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; pipe cleaners. So &lt;!-- raw HTML omitted --&gt;we&amp;rsquo;ve&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;we&lt;!-- raw HTML omitted --&gt; bought out Michael&amp;rsquo;s craft &lt;!-- raw HTML omitted --&gt;store&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;store&lt;!-- raw HTML omitted --&gt; supplies of these pipe cleaners &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;used&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;them&lt;!-- raw HTML omitted --&gt; in our experiments. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;It&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Turns &lt;!-- raw HTML omitted --&gt;out &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; bees &lt;!-- raw HTML omitted --&gt;will&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;would&lt;!-- raw HTML omitted --&gt; return again and again to the same &lt;!-- raw HTML omitted --&gt;colored&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;color&lt;!-- raw HTML omitted --&gt; flower that &lt;!-- raw HTML omitted --&gt;dispenses&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;dispensed&lt;!-- raw HTML omitted --&gt; sweet pollen&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; and &lt;!-- raw HTML omitted --&gt;spent&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;spend&lt;!-- raw HTML omitted --&gt; more time collecting there. But when confronted with &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; bitter pollen&lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;They &lt;!-- raw HTML omitted --&gt;sought a different &lt;!-- raw HTML omitted --&gt;color&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;colored&lt;!-- raw HTML omitted --&gt; flower for &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;their&lt;!-- raw HTML omitted --&gt; very next stop. All of which &lt;!-- raw HTML omitted --&gt;suggest&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;suggests&lt;!-- raw HTML omitted --&gt; that, in addition to &lt;!-- raw HTML omitted --&gt;savor&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;savoring&lt;!-- raw HTML omitted --&gt; nectar&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; bees taste pollen too &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; and judge flowers by it. The results are in the journal Biology Letters. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;The finding means that plants have to find a happy medium&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;:&lt;!-- raw HTML omitted --&gt; So can you make your pollen attractive enough &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; that &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; bees will collect it, but distasteful &lt;!-- raw HTML omitted --&gt;stuff&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;enough&lt;!-- raw HTML omitted --&gt; that they won&amp;rsquo;t &lt;!-- raw HTML omitted --&gt;collect&lt;!-- raw HTML omitted --&gt; too much of it&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; And that balancing act&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; of carefully &lt;!-- raw HTML omitted --&gt;collaborative&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;calibrated&lt;!-- raw HTML omitted --&gt; chemistry &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;it&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; just one of the many transactions that plays out in &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; buzzing pollination &lt;!-- raw HTML omitted --&gt;market&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;marketplace&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;Well&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Where&lt;!-- raw HTML omitted --&gt; the &lt;!-- raw HTML omitted --&gt;objective&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;object&lt;!-- raw HTML omitted --&gt; is to make a sweet profit.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;bombard &lt;code&gt;n. 射石炮 v. 炮击，轰炸；连珠炮似的质问（或批评）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;bumblebee &lt;code&gt;n. 大黄蜂&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;billboard &lt;code&gt;n. 广告牌；布告板 v. 宣传&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;nectar &lt;code&gt;n. 神酒，甜美饮料，甘露，花蜜&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;pollination &lt;code&gt;n. 授粉&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;pollen &lt;code&gt;n. 花粉 v. 传授花粉给&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;quinine &lt;code&gt;n. 奎宁&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;savor &lt;code&gt;n. 滋味；气味；食欲 v. 品尝；尽情享受；意味着，带有…的性质；有…的滋味，加调味品于&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;distasteful &lt;code&gt;adj. 味道差的,不愉快的,讨厌的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;calibrate &lt;code&gt;v. 测定；校准，调整&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;anther &lt;code&gt;n. 雄蕊的花粉囊,花药&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;buy out &lt;code&gt;phr. 全部買下&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;穿过时代广场——你会被各种广告&lt;del&gt;震撼&lt;/del&gt;(轟炸)的。可是有研究结果显示，一只大黄蜂飞过一片花海的话，和你也会有同样的感觉呢。所以这些花儿就像是这些广告牌，它们也是在宣传一件商品，那就是这美味的花蜜了，并且蜜蜂其实是很挑剔的顾客哦。 这是Anne Leonard， 里诺市的内华达大学中的一位研究授粉的生物学家。&lt;/p&gt;
&lt;p&gt;她把一片花海比作为一种花粉市场。那么蜜蜂会选那个方向开始工作呢？ 蜜蜂们可是花蜜研究专家呢。它们 真的很善于对甚至是花蜜中的糖含量这样的细微差别做出评判。它们也会打量一下花的外形和大小，颜色以及气味。现在， Leonard和她的同事们已经发现，大黄蜂也是花粉爱好者呢。&lt;/p&gt;
&lt;p&gt;他们是通过在樱桃花粉中掺杂糖粉或者苦奎宁粉的一组实验得出的结论。并且把这些花粉提供给蜜蜂后进行演示，我们真的很的&lt;strong&gt;对此着了魔&lt;/strong&gt;——我们已经在实验室里用&lt;del&gt;三&lt;/del&gt;(3)D打印机打印出花朵。而花药部分——花的雄性器官，也就是生出花粉的地方——&lt;del&gt;像&lt;/del&gt;(用的)是烟斗&lt;del&gt;通条&lt;/del&gt;(清理管)&lt;del&gt;的管状结构&lt;/del&gt;。我们&lt;del&gt;购买的是&lt;/del&gt;(買光了)Michael手工艺商品店中的这些烟斗&lt;del&gt;通条&lt;/del&gt;(清理管)并且用在了我们的实验中。&lt;/p&gt;
&lt;p&gt;结果显示，蜜蜂会一次又一次的返回同样颜色的会散布甜味花粉的花朵，并且在此处花费更多的采集时间。但是当它们碰到了苦味的花粉后会怎样的？它们会选择一个不同颜色的花朵作为下一站。所有结果显示，除了喜欢花蜜，蜜蜂也会尝花粉哦——并且用这个方法来鉴定花朵的可用性。该研究结果已经发表在~~《生物学报》~~(Biology Letters不知道有沒有官方中文譯名還是保留原名的好)杂志上。&lt;/p&gt;
&lt;p&gt;该研究结果意味着，植物们有个愉快的合作伙伴：那么你能不能让你的花粉更有吸引力，以便蜜蜂会采集它？而不是让花粉尝起来很糟糕以至于它们都不愿采太多？ 而这种权衡&lt;del&gt;行为&lt;/del&gt;(的方法)，也就是仔细的调整化学合成——只是在它们繁忙的花粉交易市场中达成的众多交易中的一种。在那里，唯一的目的就是要收获甜蜜。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>rMaps: 超級酷的地圖</title>
      <link>https://wangcc.me/post/2016-05-31-rmaps/</link>
      <pubDate>Tue, 31 May 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-05-31-rmaps/</guid>
      <description>&lt;p&gt;今日仰視&lt;a href=&#34;https://github.com/ramnathv/slidify&#34;&gt;slidify&lt;/a&gt;作者&lt;a href=&#34;https://github.com/ramnathv&#34;&gt;Ramnath Vaidyanathan&lt;/a&gt;的github頁面發現超酷的&lt;a href=&#34;https://github.com/ramnathv/rMaps&#34;&gt;rMaps&lt;/a&gt;包，抄過來在自己電腦上實驗一下。&lt;/p&gt;
&lt;h4 id=&#34;下載&#34;&gt;下載&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;  require(devtools)
  install_github(&#39;ramnathv/rCharts@dev&#39;)
  install_github(&#39;ramnathv/rMaps&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;繪制美國2010年的各州的犯罪率-crime-rates-per-100000-by-state-at-2010&#34;&gt;繪制美國2010年的各州的犯罪率 Crime Rates (per 100,000) by State at 2010&lt;/h4&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;利用以下的R編碼在Rstudio裏實現上圖效果&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  library(rMaps)
  map &amp;lt;- ichoropleth(Crime ~ State, data = subset(violent_crime, Year == 2010))
  map
  map$publish(&amp;quot;Crime Rates (per 100, 000) by State across Years&amp;quot;) # &amp;lt;- 引號中的將會是生成的動態地圖的網頁名稱
  ## Loading required package: httr
  ## Please enter your github username: ***** # &amp;lt;- 在此處輸入你自己的github用戶名
  ## Please enter your github password: ***** # &amp;lt;- 在此輸入你自己的github用戶密碼
  ## Your gist has been published
  ## View chart at http://rcharts.github.io/viewer/***** # &amp;lt;- 會出現生成的網頁版可互動地圖鏈接
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;你也可以用下面的編碼將網頁保存爲獨立的html文件(注意：無網絡連接時可能無法正常顯示)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  map$save(&amp;quot;mymap.html&amp;quot;, cdn = TRUE) # &amp;lt;- 引號中爲保存的目標文件名稱
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;繪制1960-2010年每年的各州犯罪率-crime-rates-per-100-000-by-state-from-1960-2010&#34;&gt;繪制1960-2010年每年的各州犯罪率 Crime Rates (per 100, 000) by State from 1960-2010&lt;/h4&gt;
&lt;h4 id=&#34;帶滑動條的可互動地圖animated-choropleth&#34;&gt;帶滑動條的可互動地圖/Animated Choropleth&lt;/h4&gt;
&lt;p&gt;編碼:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  ichoropleth(Crime ~ State, data = violent_crime, animate = &amp;quot;Year&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;效果:(你可以拖動左上角的滑動條顯示每年的各州犯罪率，&lt;strong&gt;越來越高，今年老川上臺估計全線飄高。。。&lt;/strong&gt;)&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;上圖的自動播放版animated-choropleth注意左上角出現播放按鈕&#34;&gt;上圖的自動播放版/Animated Choropleth(注意左上角出現播放按鈕)&lt;/h4&gt;
&lt;p&gt;編碼:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    ichoropleth(Crime ~ State, data = violent_crime, animate = &amp;quot;Year&amp;quot;, play = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;效果:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h5 id=&#34;以下为2016年6月2日更新&#34;&gt;以下为2016年6月2日更新&lt;/h5&gt;
&lt;h4 id=&#34;普通青年用的伦敦市区地图&#34;&gt;普通青年用的(伦敦市区)地图：&lt;/h4&gt;
&lt;p&gt;代码:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  map &amp;lt;- Leaflet$new()
  map$setView(c(51.505, -0.09), zoom = 13)
  map$tileLayer(provider = &#39;Stamen.Watercolor&#39;) # &amp;lt;- 地图颜色为水彩效果
  # map$tileLayer(provider = &amp;quot;OpenStreetMap&amp;quot;) # &amp;lt;- 无水彩效果地图
  map$marker(
    c(51.5, -0.09),
    bindPopup = &#39;Hi. I am a popup&#39;
  )
  map


    library(rMaps)
    library(leaflet)
      map &amp;lt;- Leaflet$new()
      map$setView(c(51.505, -0.09), zoom = 13)
      #map$tileLayer(provider = &#39;Stamen.Watercolor&#39;) # &amp;lt;- 地图颜色为水彩效果
      map$tileLayer(provider = &amp;quot;OpenStreetMap&amp;quot;) # &amp;lt;- 无水彩效果地图
      map$marker(
        c(51.5209, -0.1303),
        bindPopup = &#39;Hi. I am in LSHTM&#39;
      )
      map
      map$save(&#39;mychart.html&#39;, cdn = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;黑白色圖:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;以下爲自娛自樂&#34;&gt;以下爲自娛自樂&lt;/h4&gt;
&lt;p&gt;編碼:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    L2 &amp;lt;- Leaflet$new()
    L2$setView(c(35.175776,  137.040663), 13)
    L2$tileLayer(provider = &amp;quot;OpenStreetMap&amp;quot;)
    L2$marker(
      c(35.191379, 137.047885),
      bindPopup = &#39;Hi. I am here. | 快来打我啊！&#39;
    )
    L2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;效果:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Hello World</title>
      <link>https://wangcc.me/post/2016-05-27-hello-world/</link>
      <pubDate>Fri, 27 May 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-05-27-hello-world/</guid>
      <description>
&lt;script src=&#34;https://wangcc.me/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;dairy-consumption-and-risk-of-stroke&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dairy Consumption and Risk of Stroke&lt;/h1&gt;
&lt;div id=&#34;dairy-consumption-and-risk-of-stroke-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dairy Consumption and Risk of Stroke&lt;/h2&gt;
&lt;div id=&#34;dairy-consumption-and-risk-of-stroke-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Dairy Consumption and Risk of Stroke&lt;/h3&gt;
&lt;div id=&#34;dairy-consumption-and-risk-of-stroke-3&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Dairy Consumption and &lt;del&gt;Risk&lt;/del&gt; of Stroke&lt;/h4&gt;
&lt;div id=&#34;dairy-consumption-and-risk-of-stroke-4&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Dairy Consumption and Risk of Stroke&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;list 1&lt;span class=&#34;math inline&#34;&gt;\(^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;list 2&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>肠道菌群的抗病展望</title>
      <link>https://wangcc.me/post/2016-3-8/</link>
      <pubDate>Tue, 08 Mar 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-3-8/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/gut-microbes-lessen-mice-malarial-malaise/&#34;&gt;Gut Microbes Lessen Mice Malarial Malaise&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-3-8 | 正确率：89%&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点                        &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;A&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;malaria &lt;!-- raw HTML omitted --&gt;infection begins when &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; mosquito injects the Plasmodium parasite into the blood. But getting sick is not a certain outcome. The vast majority of people really only develop either mild malaria or even &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;symptomatic&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;asymptomatic&lt;!-- raw HTML omitted --&gt; infections. Nathan Schmidt, a cellular immunologist at the University of Louisville. It&amp;rsquo;s a very small subset of the hundreds of millions of cases that progress to &lt;!-- raw HTML omitted --&gt;sever&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;severe&lt;!-- raw HTML omitted --&gt; malaria. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Now &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; some of the variation in &lt;!-- raw HTML omitted --&gt;owner&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;illness&lt;!-- raw HTML omitted --&gt; severity is genetic&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Or &lt;!-- raw HTML omitted --&gt;whether the patient is partially immune&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;thanks &lt;!-- raw HTML omitted --&gt;to past exposures. But Schmidt and his colleagues &lt;!-- raw HTML omitted --&gt;had&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;have&lt;!-- raw HTML omitted --&gt; found another factor that could influence the disease&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;:&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;hosts&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&#39;&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;host&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; microbiome. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;The first clue came during an experiment in lab mice&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;:&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;because &lt;!-- raw HTML omitted --&gt;even though the mice were almost identical genetically&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;mice &lt;!-- raw HTML omitted --&gt;that &lt;!-- raw HTML omitted --&gt;have&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;had&lt;!-- raw HTML omitted --&gt; been bought from different &lt;!-- raw HTML omitted --&gt;venders&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;vendors&lt;!-- raw HTML omitted --&gt; showed variability in their response to infection by the malaria parasite. Turns out, &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; mice &lt;!-- raw HTML omitted --&gt;have&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;had&lt;!-- raw HTML omitted --&gt; different microbiomes. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;So the researchers did more tests &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;they &lt;!-- raw HTML omitted --&gt;transplanted the gut bugs of both the resistant and &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; susceptible animals into other mice that had no gut bacteria. And again&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; mice that now had &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; resistant &lt;!-- raw HTML omitted --&gt;microbiomics&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;respell&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;microbial&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;mix&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;were&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;spared&lt;!-- raw HTML omitted --&gt; the &lt;!-- raw HTML omitted --&gt;worse&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;worst&lt;!-- raw HTML omitted --&gt; of &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; malaria infection &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;possibly &lt;!-- raw HTML omitted --&gt;through some sort of &lt;!-- raw HTML omitted --&gt;&#39;&lt;!-- raw HTML omitted --&gt;booster effect&lt;!-- raw HTML omitted --&gt;under&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;&#39;&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;on&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;their&lt;!-- raw HTML omitted --&gt; immune system &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; thanks to the microbes. The study appears &lt;!-- raw HTML omitted --&gt;at&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; the Proceedings of the National Academy of Sciences. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;As for optimizing our &lt;!-- raw HTML omitted --&gt;microbimes&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;microbiomes&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; I think that &lt;!-- raw HTML omitted --&gt;we&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;we&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; pretty far away from &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; you know &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;this&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;having&lt;!-- raw HTML omitted --&gt; any kind of real therapeutic potential for humans. Yogurt alone, for example&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; didn&amp;rsquo;t much help the mice. But if &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; when we do find the right recipe for the &lt;!-- raw HTML omitted --&gt;anti-malaria&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;anti-malarial&lt;!-- raw HTML omitted --&gt; microbiome, the researchers say, it could lessen the parasite&amp;rsquo;s effects&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;And &lt;!-- raw HTML omitted --&gt;perhaps &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; save thousands of lives.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;asymptomatic &lt;code&gt;adj. 无症状的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;plasmodium &lt;code&gt;疟原虫【植】变形&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;microbiome &lt;code&gt;微生物菌羣&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;vendor &lt;code&gt;n. 摊贩；卖主；供应商；自动售货机&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当一只蚊子把Plasmodium 寄生虫注入到血中, 你便感染了疟疾. 但是也不是感染了就一定会发病.大多数被感染的人只是轻微疟疾或者连感染的症状都没有. 这是Nathan Schmidt, Louisville大学的细胞免疫学家.成百上千的感染病例中只有一小部分会转为急性疟疾症状.&lt;/p&gt;
&lt;p&gt;这些疾病严重程度上的变化是遗传因素造成的.或者说,是否病人是属于对此疾病部分免疫,还要感谢之前的感染.但是Schmidt和他的同事已经发现还有一个因素会影响到疾病的程度: 那就是宿主的微生物群.&lt;/p&gt;
&lt;p&gt;在实验室的小鼠中进行的试验首先显示出证据: 即使小鼠几乎在遗传特征上是等同的,从不同的来源所购买到的小鼠在它们对感染性疟疾的反应也是不同的.结果显示,正是由于小鼠们有不同的微生物群.&lt;/p&gt;
&lt;p&gt;因此研究人员们进行了更多的测试——他们将有抗性和易感性的动物中采集到的肠道细菌移植给没有任何肠道细菌的洁净小鼠。然后再次对它们进行疟疾感染实验，结果现在已经被移植了有抗性微生物混合物的小鼠们再次免于遭受疟疾的严重迫害——或许多亏了它们这些微生物通过某种促进效应，对它们的免疫系统有积极作用。该研究已发表在《美国国家科学研究进展》杂志上。&lt;/p&gt;
&lt;p&gt;至于说要优化这些微生物群？我认为我们现在距离做到能够此类对人类有治疗效果的手段还很远。就拿酸奶举个例子吧，对小鼠来讲没有任何促进作用。但是如果真能做到的话，当我们真的找到调治抗疟疾的微生物群配方时，这些研究人员们表示，还真能够用于减弱寄生虫的致病作用。并且或许能拯救更多的生命呢。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>磕药是种流行病</title>
      <link>https://wangcc.me/post/2016-3-4/</link>
      <pubDate>Fri, 04 Mar 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-3-4/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/opioid-epidemic-gets-treatment-prescription/&#34;&gt;Opioid Epidemic Gets Treatment Prescription&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-3-4 | 正确率：90%&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点                       &lt;!-- raw HTML omitted --&gt;We&amp;rsquo;ve been dealing with an epidemic in the United States related to opioids. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Wilson Compton, deputy director of the National Institute on Drug Abuse of the National Institutes of Health. He spoke February 12th at the annual meeting of the American Association for the Advancement of Science in Washington, D. C. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;What we&amp;rsquo;ve seen is &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; the &lt;!-- raw HTML omitted --&gt;increase&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;increased&lt;!-- raw HTML omitted --&gt; number of &lt;!-- raw HTML omitted --&gt;prescription&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;prescriptions&lt;!-- raw HTML omitted --&gt; are driving &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; the  &lt;!-- raw HTML omitted --&gt;nonmedical&lt;!-- raw HTML omitted --&gt; use of prescription drugs. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Drugs that are prescribed to treat pain. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;So &lt;!-- raw HTML omitted --&gt;there&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;there&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; tremendous availability of prescriptions. There &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; some 260 million prescriptions written in each year for opioids&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;That&amp;rsquo;s &lt;!-- raw HTML omitted --&gt;not tablets, that&amp;rsquo;s prescriptions. So &lt;!-- raw HTML omitted --&gt;its&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;it&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; millions &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; millions of these &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; and some of them are available for diversion and &lt;!-- raw HTML omitted --&gt;used&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;use&lt;!-- raw HTML omitted --&gt; inappropriately. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Some&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the &lt;!-- raw HTML omitted --&gt;pain patients may become hooked&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Or &lt;!-- raw HTML omitted --&gt;their meds may find their &lt;!-- raw HTML omitted --&gt;ways&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;way&lt;!-- raw HTML omitted --&gt; to friends or relatives who take them recreationally. Or &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; prescription opioid &lt;!-- raw HTML omitted --&gt;users&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;user&lt;!-- raw HTML omitted --&gt; may transition to heroin. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Heroin is just another opioid drug&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;so &lt;!-- raw HTML omitted --&gt;the brain doesn&amp;rsquo;t distinguish &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; whether it comes from a pharmacy or &lt;!-- raw HTML omitted --&gt;it&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;comes&lt;!-- raw HTML omitted --&gt; from a street drug dealer. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;What&amp;rsquo;s &lt;!-- raw HTML omitted --&gt;being&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;been&lt;!-- raw HTML omitted --&gt; drawing the most public health attention &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; is the overdose death rates related to prescription &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; opioids and heroin&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; which have increased markedly over the last 15 years. Right now &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; we see drug &lt;!-- raw HTML omitted --&gt;overdose&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;overdoses&lt;!-- raw HTML omitted --&gt; killing nearly 50,000 persons in a given year in the United States. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;What are we doing about this? &lt;!-- raw HTML omitted --&gt;We&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;We&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; focusing in three areas. We need to think about prevention &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; terms of reducing access to prescriptions as the ultimate upstream driver of this epidemic. We need to be thinking &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; terms &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; saving lives acutely by providing greater access to the reversing &lt;!-- raw HTML omitted --&gt;drugs&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;drug&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; this is &lt;!-- raw HTML omitted --&gt;nalaoxone&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;naloxone&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; blocks &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; the &lt;!-- raw HTML omitted --&gt;impacts&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;impact&lt;!-- raw HTML omitted --&gt;. So if &lt;!-- raw HTML omitted --&gt;somebody&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;overdose&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;somebody&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;overdosed&lt;!-- raw HTML omitted --&gt; and &lt;!-- raw HTML omitted --&gt;there&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;no&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;they&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;not&lt;!-- raw HTML omitted --&gt; breathing &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; and I can get this medication to them quickly&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; I can resuscitate them. &lt;!-- raw HTML omitted --&gt;I&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;guess&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;there&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;That&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;gives&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;us&lt;!-- raw HTML omitted --&gt; a chance to help them turn their lives around with &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; third aspect&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; which is greater access to effective treatment&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; through &lt;!-- raw HTML omitted --&gt;medication&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;assistant&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;medication-assisted&lt;!-- raw HTML omitted --&gt; treatment. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;But we also think we need to come up with better approaches for treating pain. &lt;!-- raw HTML omitted --&gt;Whether&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;What&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; non-medical approaches &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; that might use brain stimulation techniques, for example, to treat pain&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Whether&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;What&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; other medications that don&amp;rsquo;t include the opioid &lt;!-- raw HTML omitted --&gt;existence&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;system&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; might be useful&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; These are the kinds of advances that science can bring us so that we can turn around this overdose epidemic &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;They&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; right now shows tremendous &lt;!-- raw HTML omitted --&gt;increase&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;increases&lt;!-- raw HTML omitted --&gt; each year.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;hooked &lt;code&gt;adj. 钩状的；吸毒成瘾的；入迷的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;resuscitate &lt;code&gt;v. （使）复苏，复兴&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在美国，我们已经在处理和鸦片有关的流行病了。&lt;/p&gt;
&lt;p&gt;Wilson Compton，美国国家健康研究会国家药物滥用研究会副主席。这是他2月12日在华盛顿举行的美国科学进步协会年度会议上的讲话&lt;/p&gt;
&lt;p&gt;我们已经看到越来越多的处方被用作非医疗的用途。这些药物是用于治疗疼痛的。&lt;/p&gt;
&lt;p&gt;所以很多处方都可以被利用。每年含有鸦片的处方大约有2.6亿张。这些可不是药片，这些是处方哦。所以有更多的药片其中大部分都被用于消遣娱乐以及其它非正常用途。&lt;/p&gt;
&lt;p&gt;有些疼痛患者也许就上瘾了。或者他们的药流向了他们的朋友或者亲属被用作娱乐。再或者处方药鸦片使用者也许转而使用了海洛因。&lt;/p&gt;
&lt;p&gt;海洛因只是鸦片类药物的另一种形式，所以大脑并不会刻意区分是否它是来自于药房还是街头小贩。&lt;/p&gt;
&lt;p&gt;已经正在引起公众健康关注的是过量使用处方类鸦片和海洛因后的死亡率，最近15年来已经显著增加。目前，我们在美国，一年因过量使用此类药物而死亡的人数就接近5万人。&lt;/p&gt;
&lt;p&gt;我们该做点儿神马呢？ 我们已经着重于以下三方面。我们需要去阻止，减少处方药的获得机会，因为最终是开出的处方药导致这种流行病的出现。我们需要思考，通过更有利的使用应对药物及时拯救生命——比如纳洛酮，烯丙羟吗啡酮（一种吗啡拮抗药）——用于阻断鸦片的药性。所以，如果有人用药过量后呼吸停止了，我们能及时应用这种药物去治疗他们，我们就能救活他们。这就给我们机会去帮助他们，由此可以引出我们可以做的第三个方面，那就是通过药物辅助治疗的方法实施更有效率的治疗。&lt;/p&gt;
&lt;p&gt;但是我们还认为我们需要想出更好的治疗疼痛的方法。非药物的方法，比如用刺激大脑的技术，去治疗疼痛? 采用其它不不含有鸦片相关化合物的药物？这些科学进步所能带给我们的方法使我们能逆转现在每年大量增长的因药物过度使用造成的流行病。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>每逢佳节胖三斤</title>
      <link>https://wangcc.me/post/2016-3-1/</link>
      <pubDate>Tue, 01 Mar 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-3-1/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/super-bowl-sunday-s-food-needs-work/&#34;&gt;Super Bowl Sunday&amp;rsquo;s Food Needs Work&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-3-1 | 正确率：88%&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点                       &lt;!-- raw HTML omitted --&gt;It&amp;rsquo;s nearly game day &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; and&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; if &lt;!-- raw HTML omitted --&gt;you&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; a fan, you&amp;rsquo;ve already set aside your &lt;!-- raw HTML omitted --&gt;roomy&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;sweat&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;pants&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;roomiest&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;sweatpants&lt;!-- raw HTML omitted --&gt; and your own personal Family-size bag of Nacho Cheese Doritos. But if &lt;!-- raw HTML omitted --&gt;you&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;at&lt;!-- raw HTML omitted --&gt; all &lt;!-- raw HTML omitted --&gt;concern&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;concerned&lt;!-- raw HTML omitted --&gt; about &lt;!-- raw HTML omitted --&gt;over&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;indulging&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;overindulging&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; which&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; if you live in America&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you &lt;!-- raw HTML omitted --&gt;probably should be &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you &lt;!-- raw HTML omitted --&gt;might take a tip from a public health advocate &lt;!-- raw HTML omitted --&gt;from&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;at&lt;!-- raw HTML omitted --&gt; the New York City Food Policy Center. &lt;!-- raw HTML omitted --&gt;Charlse&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Charles&lt;!-- raw HTML omitted --&gt; Platkin says that one way to avoid &lt;!-- raw HTML omitted --&gt;over&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;doing&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;overdoing&lt;!-- raw HTML omitted --&gt; it &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; is to consider how much &lt;!-- raw HTML omitted --&gt;you&amp;rsquo;ve&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you&amp;rsquo;d&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;have&lt;!-- raw HTML omitted --&gt; to exercise to work off what you consume. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;So &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; to prepare for Super Bowl Sunday &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; the second biggest day for food consumption in the U. S. &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; Platkin crunched the numbers for some of our favorite &lt;!-- raw HTML omitted --&gt;couch-side&lt;!-- raw HTML omitted --&gt;  snacks. And &lt;!-- raw HTML omitted --&gt;he&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;has&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;he&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; helpfully converted them &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;football-themed&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;into&lt;!-- raw HTML omitted --&gt;  exercise &lt;!-- raw HTML omitted --&gt;equivalence&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;equivalents&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;So, for example, two slices of Domino&amp;rsquo;s ultimate pepperoni hand-tossed crust pizza would require running nearly 11,000 yards &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;that&amp;rsquo;s &lt;!-- raw HTML omitted --&gt;109 football fields &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; at a speed of &lt;!-- raw HTML omitted --&gt;5&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;five&lt;!-- raw HTML omitted --&gt; miles per hour. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Two KFC original &lt;!-- raw HTML omitted --&gt;drum&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;sticks&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;drumsticks&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Just &lt;!-- raw HTML omitted --&gt;do the wave &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;1,561 &lt;!-- raw HTML omitted --&gt;times. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;To pay for a single potato chip loaded with French onion dip you&amp;rsquo;d have to sing along with Coldplay and Beyonce for 30 minutes during &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;half&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;time&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;halftime&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;And&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;even &lt;!-- raw HTML omitted --&gt;five pretzels &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; yes, five &lt;!-- raw HTML omitted --&gt;pure&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;puny&lt;!-- raw HTML omitted --&gt; little pretzels out of &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; bag &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; would take six-and-a-half minutes of jumping up and down whenever your team scores a &lt;!-- raw HTML omitted --&gt;touch&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;down&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;touchdown&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Which means that if you want to avoid post-bowl paunch, your team better bring it. Either that or just &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;dip&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;stick&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;with&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; celery sticks. And pass on the dip, if you want to maintain the current size of your &lt;!-- raw HTML omitted --&gt;N&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;end&lt;!-- raw HTML omitted --&gt; zone.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;roomy &lt;code&gt;adj. 广阔的，宽敞的，宽大的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;sweatpant &lt;code&gt;n. 【美】宽松长运动裤&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;family-size &lt;code&gt;adj. 适合(足够)全家用的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;overindulge &lt;code&gt;v. [I] 溺爱，过分放任，过分沉溺（与in连用） [T] 过度沉溺，放纵，过分纵情（于）（与in连用）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;advocate &lt;code&gt;n. 拥护者，提倡者；辩护律师；谋利益者 v. 拥护，提倡&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;work off&lt;/strong&gt; &lt;code&gt;phr. 宣泄，释放，排解&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;drumstick &lt;code&gt;n. 下段鸡腿肉；鼓槌&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;pretzel &lt;code&gt;椒盐脆饼干&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;puny &lt;code&gt;adj. 微小的,弱小的,微不足道的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;touchdown &lt;code&gt;n. 触地,触地得分,着地,降落&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这就算是个全民游戏日了,如果你是它的粉丝的话,恐怕已经准备好居家服和家庭装芝士玉米立体脆.但是,如果你还担心放纵过渡的话——如果你住在美国，你或许应该——应该从纽约城市食品政策研究中心的公众健康宣讲会上找点儿建议。Charles Platkin建议，有一种方法来避免过度饮食就是先考虑一下你吃这些东西后需要做多少运动来消耗掉所含的热量。&lt;/p&gt;
&lt;p&gt;所以，为了准备周日的超级杯——美国食品消费第二大高峰日——Charles Platkin尝试了大量的人们喜爱的零食小吃。并且，他将其所含热量转换为足球运动背景下的一些等量的运动项目。&lt;/p&gt;
&lt;p&gt;所以，比如，两角多米诺旗下的全手工意大利辣肠口味的皮萨所含热量大概需要跑11000吗——也就是大概109个足球场 ——速度需要保持每小时5英里。&lt;/p&gt;
&lt;p&gt;那么两块肯德基原味鸡块呐? 就随机摆动1561次吧。&lt;/p&gt;
&lt;p&gt;为了消耗一片沾有法式洋葱酱料的薯片，你必须要在中场休息的时候跟随酷玩乐队和比昂斯唱满30分钟。&lt;/p&gt;
&lt;p&gt;而且仅仅5片椒盐卷饼饼干——是的，一袋里就那么很小的饼干——也需要你蹦蹦跳跳6..5分钟，不管你支持的队伍是否得分晋级。&lt;/p&gt;
&lt;p&gt;也就是说吧，如果你想避免看过比赛之后胖三斤，你最好接受这些建议。或者就用芹菜棒代替那些零食好啦。而且如果你想保持当前的各种身体指数，那就必须还不能有任何酱料哦。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>甜菜汁的好处</title>
      <link>https://wangcc.me/post/2016-2-25/</link>
      <pubDate>Thu, 25 Feb 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-2-25/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/beet-juice-could-help-body-beat-altitude/&#34;&gt;Beet Juice Could Help Body Beat Altitude&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-2-25 | 正确率：90%&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点                        &lt;!-- raw HTML omitted --&gt;At 14,505 feet, Mount Whitney towers over California&amp;rsquo;s Sierra Nevada range. It&amp;rsquo;s the tallest peak in the lower 48 &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; which means &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; it &lt;!-- raw HTML omitted --&gt;tracks&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;attracts&lt;!-- raw HTML omitted --&gt; thousands of weekend warriors every year &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;or &lt;!-- raw HTML omitted --&gt;make that &lt;!-- raw HTML omitted --&gt;weekend&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;weakened&lt;!-- raw HTML omitted --&gt; warriors. You see them &lt;!-- raw HTML omitted --&gt;stabbing&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;staggering&lt;!-- raw HTML omitted --&gt; along &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; narrow&lt;!-- raw HTML omitted --&gt;rocket&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;rocky&lt;!-- raw HTML omitted --&gt; trail&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; huffing for air, dizzy and exhausted from the low oxygen levels at high elevation. And once &lt;!-- raw HTML omitted --&gt;they&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;they&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; sick&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;The best medicine is to go down. That&amp;rsquo;s &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; actually the only cure that works. Svein Gaustad, a physiologist at the Norwegian University of Science and Technology. He says previous studies &lt;!-- raw HTML omitted --&gt;suggested&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;suggest&lt;!-- raw HTML omitted --&gt; blood vessels &lt;!-- raw HTML omitted --&gt;turned&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;tend&lt;!-- raw HTML omitted --&gt; to &lt;!-- raw HTML omitted --&gt;contracted&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;contract&lt;!-- raw HTML omitted --&gt; at high altitudes. Possibly &lt;!-- raw HTML omitted --&gt;because&lt;!-- raw HTML omitted --&gt; they need oxygen to relax &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;exactly &lt;!-- raw HTML omitted --&gt;what&amp;rsquo;s in short supply on mountaintops. But there &lt;!-- raw HTML omitted --&gt;might&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;may&lt;!-- raw HTML omitted --&gt; be a dietary way to get more oxygen to your blood vessels&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;:&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;in &lt;!-- raw HTML omitted --&gt;the form of beet juice. The juice contains nitrate, which the body converts to nitric oxide&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; the compound that keeps arteries limber. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Gaustad and his colleagues tested that theory during a trek in Nepal&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; at 12,000 feet. &lt;!-- raw HTML omitted --&gt;8&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Eight&lt;!-- raw HTML omitted --&gt; volunteers alternately &lt;!-- raw HTML omitted --&gt;drinks&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;drank&lt;!-- raw HTML omitted --&gt; shots of regular beet juice&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; and another day&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; beet juice with &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;nitrate&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;nitrates&lt;!-- raw HTML omitted --&gt; stripped out. A few hours later, the researchers measured blood flow and artery diameters with ultrasound. And they found that the regular beet juice did indeed restore blood vessels back to their &lt;!-- raw HTML omitted --&gt;low-elevation&lt;!-- raw HTML omitted --&gt;  flexibility, whereas the &lt;!-- raw HTML omitted --&gt;nitrate-stripped&lt;!-- raw HTML omitted --&gt;  juice did not. The &lt;!-- raw HTML omitted --&gt;result&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;results&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; in the journal &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; Nitric Oxide. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Gaustad says better vascular function has &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; potential to deliver more blood &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; and therefore more oxygen &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; to tired muscles. But they still don&amp;rsquo;t know if that translates to better performance at altitude. And&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; he says&lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;beet&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;beets&lt;!-- raw HTML omitted --&gt; won&amp;rsquo;t hurt, but &lt;!-- raw HTML omitted --&gt;there&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;they&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; no substitute for proper acclimatization. If I had &lt;!-- raw HTML omitted --&gt;buffalo&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;bottle&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; beets around I &lt;!-- raw HTML omitted --&gt;will&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;would&lt;!-- raw HTML omitted --&gt; take it for sure. But that won&amp;rsquo;t &lt;!-- raw HTML omitted --&gt;bringing&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;bring&lt;!-- raw HTML omitted --&gt; you to Mount Everest just &lt;!-- raw HTML omitted --&gt;by&lt;!-- raw HTML omitted --&gt; drinking beetroot.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;stagger &lt;code&gt;adj. 蹒跚的；令人惊愕的；难以置信的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;huff &lt;code&gt;v. 深呼吸，气喘吁吁，上气不接下气&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;contract &lt;code&gt;v. 收縮&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;beet &lt;code&gt;n. 甜菜，甜菜根，糖萝卜&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;nitrate &lt;code&gt;n. 硝酸盐;硝酸钾;硝酸钠&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;acclimatization &lt;code&gt;n. 服水土,顺应,适应环境&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Mout Everest &lt;code&gt;n. 埃佛勒斯峰(喜马拉雅山主峰之一,中国称珠穆朗玛峰)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;高达14505英尺，Mount Whitney 高耸在加州内华达山脉中。它可是较低的48 座山峰中最高的一座——也就是说每天它能吸引到成百上千的周末勇士来攀登——或者把这些勇士给搞垮。你可以看到他们沿着狭窄的岩石小路上蹒跚而行，上气不接下气，头昏眼花的在高海拔地区的缺氧环境下精疲力尽的抗争着。而一旦他们生病了怎么办呐？&lt;/p&gt;
&lt;p&gt;最好的办法就是撤下去啦。这真的是有效的治疗办法。Svein Gaustad是，挪威科技大学的一位生理学家。他说以前的研究表明血管在高海拔地区会趋于收缩。或许因为她们需要氧气来放松——这在山顶上实在是个短缺的物资呢。但或许可以靠膳食给你的血管补充氧气哦： 就就来一杯甜菜汁吧。这里面含有硝酸盐，我们的身体可以将之转化为一氧化氮，这种化合物能保持血管的柔软灵活性。&lt;/p&gt;
&lt;p&gt;Gaustad 和他的同事们在尼泊尔的徒步旅行中测试了上述理论，该地区大概有12000英尺。八名志愿者或者饮用一杯普通压榨的甜菜汁，而另一天，甜菜汁是脱硝酸盐的。几小时后，研究人员们用超声波测量了他们的血液流速和动脉的直径。他们发现，饮用普通甜菜汁的人们确实恢复了在低海拔地区时候的血管弹性，而饮用脱硝酸盐的甜菜汁的人们的血管并没有恢复。改研究结果已经发表在《一氧化氮》杂志上。&lt;/p&gt;
&lt;p&gt;Gaustad表示，较好地血管功能就有输送更多血液的潜力——并且因此你的身体会获得更多的氧气——到疲劳的肌肉组织。但是他们还不清楚这种转化作用会根据海拔表现的更好。而且，他说，甜菜也没什么害处，但是这些物质还是不能取代合适的环境适应能力。如果我有一瓶甜菜汁随身携带，我一定会食用的。但是光靠喝甜菜汁应该不会支撑你爬上喜马拉雅山的吧。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>枪支自杀与公共健康</title>
      <link>https://wangcc.me/post/2016-2-22/</link>
      <pubDate>Mon, 22 Feb 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-2-22/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/suicide-differences-by-region-related-to-gun-availability/&#34;&gt;Suicide Differences by Region Related to Gun Availability&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-2-22 | 正确率：91%&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点        &lt;!-- raw HTML omitted --&gt;One of the things we know for sure &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; in &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; United States &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; is that a gun in &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; home increases the likelihood that someone in the home will die &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; violent death &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; from gun accidents, from a &lt;!-- raw HTML omitted --&gt;women&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;woman&lt;!-- raw HTML omitted --&gt; being murdered by a man &lt;!-- raw HTML omitted --&gt;or&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; an &lt;!-- raw HTML omitted --&gt;intimated&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;intimate&lt;!-- raw HTML omitted --&gt; partner &lt;!-- raw HTML omitted --&gt;violent&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;violence&lt;!-- raw HTML omitted --&gt; situation &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; and particularly &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; by suicide. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;David Hemenway&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;he&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;He&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; the director of the Harvard Injury Control Research Center&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;he&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;He&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; also a professor of Health Policy and Management at the Harvard T. H. Chan School of Public Health. The gun violence discussion often seems to give short &lt;!-- raw HTML omitted --&gt;shift&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;shrift&lt;!-- raw HTML omitted --&gt; to suicide&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;even &lt;!-- raw HTML omitted --&gt;though more than 60% of the approximately &lt;!-- raw HTML omitted --&gt;22000&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;32,000&lt;!-- raw HTML omitted --&gt; annual U. S. firearms deaths are suicides. Hemenway spoke &lt;!-- raw HTML omitted --&gt;at&lt;!-- raw HTML omitted --&gt; January &lt;!-- raw HTML omitted --&gt;6th&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;26th&lt;!-- raw HTML omitted --&gt; at &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; Harvard School of Public Health forum on gun violence as a public health issue. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;The evidence is overwhelming&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; from case control studies &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; ecological studies. For example, why do we have very different suicide rates across cities, across states, across regions in &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; United States&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;To &lt;!-- raw HTML omitted --&gt;explain the differences in suicide rates across states&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;turns &lt;!-- raw HTML omitted --&gt;out &lt;!-- raw HTML omitted --&gt;it&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;it&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; not well explained at all by differences in mental health, &lt;!-- raw HTML omitted --&gt;it&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;it&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; not well explained at all by differences in &lt;!-- raw HTML omitted --&gt;numbers&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;number&lt;!-- raw HTML omitted --&gt; of psychiatrists, &lt;!-- raw HTML omitted --&gt;it&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;it&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; not even explained by differences in suicide &lt;!-- raw HTML omitted --&gt;radiation&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;ideation&lt;!-- raw HTML omitted --&gt; among the population or even suicide attempts. What really explains the difference in the United States across the populations is the number of guns. Because &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;it&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; gun &lt;!-- raw HTML omitted --&gt;suicides&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;suicide&lt;!-- raw HTML omitted --&gt; which is so different. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;And someone who commits suicide with a gun very likely would not have either attempted or succeeded if the gun were not available. For example, a 2013 Swiss study &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; tracked men after the size of their army was cut in half, effectively &lt;!-- raw HTML omitted --&gt;when&lt;!-- raw HTML omitted --&gt; removing guns from half &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; that group&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;The &lt;!-- raw HTML omitted --&gt;overall suicide rate went down&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; and the &lt;!-- raw HTML omitted --&gt;researcher&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;researchers&lt;!-- raw HTML omitted --&gt; estimated that only 22% of &lt;!-- raw HTML omitted --&gt;all&lt;!-- raw HTML omitted --&gt; the men who &lt;!-- raw HTML omitted --&gt;would&amp;rsquo;ve&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;would&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;have&lt;!-- raw HTML omitted --&gt; killed themselves with a gun if it had been available wound up committing the act by other means. The presence of &lt;!-- raw HTML omitted --&gt;guns&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;gun&lt;!-- raw HTML omitted --&gt; just &lt;!-- raw HTML omitted --&gt;make&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;makes&lt;!-- raw HTML omitted --&gt; it significantly easier to take &lt;!-- raw HTML omitted --&gt;their&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;your&lt;!-- raw HTML omitted --&gt; own &lt;!-- raw HTML omitted --&gt;lives&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;life&lt;!-- raw HTML omitted --&gt; impulsively. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;The entire hour-long forum featuring Hemenway and other researchers discussing gun violence as a public health issue is archived &lt;!-- raw HTML omitted --&gt;on&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;line&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;online&lt;!-- raw HTML omitted --&gt;. Just google &amp;quot; Harvard public health forum&amp;rdquo; .&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;ideation &lt;code&gt;n. 观念构成&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有件事儿大家都很清楚，在美国，私人拥有枪支的合法增加了家庭成员因暴力死亡的可能性——原因可能是枪支走火，也可能是三角关系引发血案，特别还有可能是自杀。&lt;/p&gt;
&lt;p&gt;这是David Hemenway，哈佛人身伤害控制研究中心的负责人。他也是哈佛公共健康T. H. Chan学院的一名健康政策与管理学教授。枪支暴力谈论通常因自杀而草草收场，即便在美国每年大约有32000起火拼死亡案件中有60%都是自杀行为。Hemenway在1月26日举行的哈夫公共健康学院的研讨会上指出枪支暴力犯罪属于公共健康问题。&lt;/p&gt;
&lt;p&gt;来自于案例对照研究和生态研究得到的证据是非常有说服力的。比如，为什么不同城市，不同的州，以及美国境内不同区域的自杀率十分的不同？为了解释不同地区的自杀率之间的差异原因，研究结果显示这些原因根本不能用精神疾病的发病率不同来解释，根本不能用精神病医师的数量多少来解释，甚至也根本不能用人群中的自杀倾向或者自杀企图的比例上的差异来解释。真正在美国人口中出现的这种差异的普遍原因就是枪支的数量。因为是用枪支自杀的数量上有差异。&lt;/p&gt;
&lt;p&gt;并且，如果没有枪，用枪支自杀的某人很可能本来就不用出现用枪自杀的动机以及后来用枪自杀成功的这种事儿。比如， 在2013年瑞士，有一项研究追踪调查了军火大小被减半后，就有效的把枪从作案凶器中的出现频率降低了一半。整个自杀率下降，而研究人员们估计，所有自杀的研究对象中，有22% 的人，如果可以选择枪这种工具，那么他们才会自杀，用其它工具他们就不进行自杀行为了。 枪支的出现只是使得你结束生命的冲动出现后更加容易的被满足。&lt;/p&gt;
&lt;p&gt;含有Hemenway和其它研究人员关于枪支暴力犯罪属于公共健康问题的全部论坛内容已经可以在线收听。只需要用谷歌搜索“Harvard public health forum”选择相应内容即可。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>抗氧化物的实际功效还不明</title>
      <link>https://wangcc.me/post/2016-2-18/</link>
      <pubDate>Thu, 18 Feb 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-2-18/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/antioxidant-use-still-small-mixed-bag/&#34;&gt;Antioxidant Use Still Small Mixed Bag&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-2-18 | 正确率：89%&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点                        &lt;!-- raw HTML omitted --&gt;Are you gobbling up antioxidants as part of your diet and nutrition &lt;!-- raw HTML omitted --&gt;regiment&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;regimen&lt;!-- raw HTML omitted --&gt;? The benefits &lt;!-- raw HTML omitted --&gt;seems&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;maybe&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;may&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;be&lt;!-- raw HTML omitted --&gt;, well. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;It seems surprising, but even after several decades &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; we don&amp;rsquo;t have a clear answer&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;There&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;there&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; not, if there &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;were&lt;!-- raw HTML omitted --&gt; really &lt;!-- raw HTML omitted --&gt;cross&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;wall&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;across-the-board&lt;!-- raw HTML omitted --&gt; powerful benefits we &lt;!-- raw HTML omitted --&gt;would&amp;rsquo;ve&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;would&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;have&lt;!-- raw HTML omitted --&gt; seen it&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and &lt;!-- raw HTML omitted --&gt;that&amp;rsquo;s not the situation. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Walter Willett&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;He &lt;!-- raw HTML omitted --&gt;chairs the Department of Nutrition at the Harvard T. H. Chan School of Public Health. He spoke at &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; January 15th forum on Cancer and Diet &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; that wound up touching on diet and health in &lt;!-- raw HTML omitted --&gt;general&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;The studies &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; so far, randomized trials that have been done&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; don&amp;rsquo;t show much benefit. There was actually a surprising &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;increase &lt;!-- raw HTML omitted --&gt;in lung cancer with &lt;!-- raw HTML omitted --&gt;beta-carotene&lt;!-- raw HTML omitted --&gt;, one of the antioxidants, in people who &lt;!-- raw HTML omitted --&gt;smoke&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;or&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;smoked&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;were&lt;!-- raw HTML omitted --&gt; heavy drinkers&lt;!-- raw HTML omitted --&gt;although&lt;!-- raw HTML omitted --&gt;, &lt;!-- raw HTML omitted --&gt;although&lt;!-- raw HTML omitted --&gt; there &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;was&lt;!-- raw HTML omitted --&gt; no increase in risk in people &lt;!-- raw HTML omitted --&gt;if&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;who&lt;!-- raw HTML omitted --&gt; were generally pretty healthy &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;to &lt;!-- raw HTML omitted --&gt;start with. &lt;!-- raw HTML omitted --&gt;So&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;even &lt;!-- raw HTML omitted --&gt;the randomized trials give different answers&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; I think&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; that antioxidants are not a magic solution to cancer or other diseases&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;but &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;they&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;there&lt;!-- raw HTML omitted --&gt; probably &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; some benefits. One example is &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; in &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;physicians &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;health &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;study &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; randomized trial over 12 years&lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt;, &lt;!-- raw HTML omitted --&gt;at&lt;!-- raw HTML omitted --&gt; the end of that period of time &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; those taking &lt;!-- raw HTML omitted --&gt;beta-carotene&lt;!-- raw HTML omitted --&gt;  had better cognitive function than people on placebo &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;–&lt;!-- raw HTML omitted --&gt; a really interesting and &lt;!-- raw HTML omitted --&gt;potential&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;potentially&lt;!-- raw HTML omitted --&gt; important finding. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;So antioxidants may provide some benefits to some people. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;But even if there are, that&amp;rsquo;s only a small part of the changes &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;we &lt;!-- raw HTML omitted --&gt;need to make &lt;!-- raw HTML omitted --&gt;them&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;diet&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;lifestyle&lt;!-- raw HTML omitted --&gt; to reduce our risk of &lt;!-- raw HTML omitted --&gt;cancer&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;cancers&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;there &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; so many other things that are really quite well documented. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;The entire hour-long forum &lt;!-- raw HTML omitted --&gt;featured&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;featuring&lt;!-- raw HTML omitted --&gt; Willett and other researchers discussing diet and health is archived &lt;!-- raw HTML omitted --&gt;on&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;line&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;online&lt;!-- raw HTML omitted --&gt;. Just google &amp;quot; Harvard public health forum&amp;rdquo; .&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;regimen &lt;code&gt;n. 生活规则；养生法；政体&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;across-the-board &lt;code&gt;adj. 全面的 adv. 全面地&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你每天是不是都要吞很多抗氧化的产品作为营养健康补充？或许有用。。。吧。&lt;/p&gt;
&lt;p&gt;很令人吃惊，但即便经过了几十年的研究，我们还不是很清楚它的作用，还没有个定论吧，如果真有什么可见成效，我们也早就该发现了，而不是现在这种状况。&lt;/p&gt;
&lt;p&gt;Walter Willett，他是哈佛 T. H. Chan公共健康 学院 营养学系 的主任 。他 在 1月 15日 巨型的 健康与癌症 研讨会上 做出了挑衅一般饮食与健康之间关系的 演讲 。&lt;/p&gt;
&lt;p&gt;目前的相关 研究 已经进行了 随机试验 ，发现并没有什么 可见的显著益处。过去曾发现实际上，其中一种抗氧化物质，β-胡萝卜素 在 吸烟和酗酒的人群中与肺癌的患病率增高有关，尽管在一开始就 很 健康的人中并没有发现有 相关风险的增加。所以 即使随机试验给出了不同的 结论，我认为， 抗氧化物也并不是对癌症或者其它 疾病有很神奇效果的一种物质，但是或许它们 确实有促进健康的一些效果。有一个内科医生的健康研究进行了超过12年的随机试验中的例子显示，在研究期间内， 那些服用了β-胡萝卜素的 人群的认知能力比服用安慰剂的人群提高了不少—— 这个研究发现还挺有趣也挺重要的。&lt;/p&gt;
&lt;p&gt;所以，抗氧化物也许对某些人来讲能提供一些促健康的益处 。但即便是有好处，对我们饮食和生活方式的影响以至于减少患癌症的风险这方面的作用也是微乎其微，还有许多其它因素都被证明确实会对疾病的发生能起到重要作用。&lt;/p&gt;
&lt;p&gt;完整的研讨会包括Willett 和其它研究人员关于健康和饮食关系方面的讨论内容已经在线发布。只需要在 谷歌上搜索“Harvard public health forum”即可。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>咖啡机的隐患</title>
      <link>https://wangcc.me/post/2016-2-2/</link>
      <pubDate>Mon, 15 Feb 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-2-2/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/espresso-machines-brew-a-microbiome-of-their-own/&#34;&gt;Espresso Machines Brew a Microbiome of Their Own&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-2-2 | 正确率：91%&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点                        &lt;!-- raw HTML omitted --&gt;What&amp;rsquo;s the &lt;!-- raw HTML omitted --&gt;lively&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;as&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;liveliest&lt;!-- raw HTML omitted --&gt; part of your kitchen, in terms of harboring bacteria? Is it the cutting board&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;The &lt;!-- raw HTML omitted --&gt;dish &lt;!-- raw HTML omitted --&gt;bunch&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;sponge&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Or &lt;!-- raw HTML omitted --&gt;maybe your &lt;!-- raw HTML omitted --&gt;coffee&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;maker&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;coffeemaker&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; Because even though caffeine has antibacterial effects, it turns out &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; espresso machines can harbor a whole menagerie of bacteria &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; including some pathogenic species &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; more commonly associated with the toilet. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Researchers sampled ten Nespresso brand espresso machines&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;zeroing &lt;!-- raw HTML omitted --&gt;in on &lt;!-- raw HTML omitted --&gt;an&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; drip trays&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; which catch those last drops of &lt;!-- raw HTML omitted --&gt;bround&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;brown&lt;!-- raw HTML omitted --&gt; gold after a brew. They found that &lt;!-- raw HTML omitted --&gt;9&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;nine&lt;!-- raw HTML omitted --&gt; of &lt;!-- raw HTML omitted --&gt;10&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;ten&lt;!-- raw HTML omitted --&gt; machines harbored residues rich in Enterococcus bacteria, a typical marker of human &lt;!-- raw HTML omitted --&gt;feagle&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;fecal&lt;!-- raw HTML omitted --&gt; contamination. And another &lt;!-- raw HTML omitted --&gt;typical&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;common&lt;!-- raw HTML omitted --&gt; resident was Pseudomonas &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; which &lt;!-- raw HTML omitted --&gt;have&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;has&lt;!-- raw HTML omitted --&gt; both benign and pathogenic strains. Pseudomonas appears to &lt;!-- raw HTML omitted --&gt;thrives&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;thrive&lt;!-- raw HTML omitted --&gt; in the &lt;!-- raw HTML omitted --&gt;presents&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;presence&lt;!-- raw HTML omitted --&gt; of caffeine, and even breaks it down. Which &lt;!-- raw HTML omitted --&gt;suggest&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;suggests&lt;!-- raw HTML omitted --&gt; the bugs might be put to work &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; decaffeinating coffee, or cleaning caffeine residues from our &lt;!-- raw HTML omitted --&gt;water&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;ways&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;waterways&lt;!-- raw HTML omitted --&gt;. The findings appear in the journal &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; Scientific Reports. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;As for your next espresso shot&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;?&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Don&amp;rsquo;t &lt;!-- raw HTML omitted --&gt;worry too much. The researchers did not find any bacteria in the coffee &lt;!-- raw HTML omitted --&gt;pots&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;pods&lt;!-- raw HTML omitted --&gt; themselves &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;so &lt;!-- raw HTML omitted --&gt;they say our fingertips might be &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; blame for spreading the &lt;!-- raw HTML omitted --&gt;single&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;soles&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;than&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;data&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;single-celled&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;invaders&lt;!-- raw HTML omitted --&gt;. And they write that it&amp;rsquo;s &lt;!-- raw HTML omitted --&gt;&amp;quot;&lt;!-- raw HTML omitted --&gt; absolutely not the case&lt;!-- raw HTML omitted --&gt;&amp;quot;&lt;!-- raw HTML omitted --&gt; that &lt;!-- raw HTML omitted --&gt;espresso&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Nespresso&lt;!-- raw HTML omitted --&gt; machines are dangerous for human health. Just wash the drip tray more often with soap and water&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;just &lt;!-- raw HTML omitted --&gt;as you would any other &lt;!-- raw HTML omitted --&gt;food-contaminated&lt;!-- raw HTML omitted --&gt;  surface. So that the only thing &lt;!-- raw HTML omitted --&gt;that&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; brewing in your espresso machine &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; is your coffee.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;menagerie &lt;code&gt;n. 动物园,动物展览&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;pathogenic &lt;code&gt;adj. 使生病的,成为病原的,病原性的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;zero in &lt;code&gt;瞄准具校正，调整归零&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;residue &lt;code&gt;n. 剩余物；残留物；残余，残渣&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;enterococcus &lt;code&gt;肠道球菌; 肠球菌&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;fecal &lt;code&gt;adj. 排泄物的,渣滓的&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;pseudomonas &lt;code&gt;假单胞菌属; 假单胞细菌属&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;pod &lt;code&gt;n. 豆荚，蚕茧 v. 从豆荚中剥出；结豆荚&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你厨房里最有生机的地方是哪儿啊，我是说附着的细菌呐？切菜板？刷碗的海绵？ 或许，你的咖啡机？ 因为即便咖啡因有抗细菌的效果，有研究显示浓缩咖啡机能附着一群细菌——包括一些和厕所马桶有关的致病菌相类似的致病菌呢。&lt;/p&gt;
&lt;p&gt;研究人员们对10台Nespresso牌的浓缩咖啡机进行采样，主要范围集中在水盘，那里在煮咖啡之后有些残留暗金色的液滴。他们发现，10台机器中有9台，残留物里含有Enterococcus肠球菌属的细菌，一种人类粪便污染物被细菌感染的标志。另一种Pseudomonas假单胞菌属细菌——则有的是无害的，有些是致病的菌种被发现残留。假单胞菌在有咖啡因存在的情况下会大量繁殖，然后分解咖啡因。这种特性提示我们也许可用它进行去咖啡因咖啡的制作，或者从我们的排水口中清除咖啡因。该研究结果发表在《科学报告》杂志上。&lt;/p&gt;
&lt;p&gt;关乎你的下一次煮咖啡嘛？别太担心了。研究人员在咖啡包里没有发现任何种类细菌——因此他们表示我们指尖也许对扩散此类单细胞生物有促进作用。然后他们写道，这绝对不是说浓缩咖啡剂对人类的健康有害。只需要像担心你的其它食物表面会被污染一样，经常用肥皂水清洗一下滴水盘。 所以之后，你的咖啡机里就只有一种你想要煮的，咖啡啦。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>調整飲食習慣永遠都不晚</title>
      <link>https://wangcc.me/post/2016-2-15/</link>
      <pubDate>Mon, 15 Feb 2016 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2016-2-15/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/healthful-diet-switch-helps-even-late-in-life/&#34;&gt;Healthful Diet Switch Helps Even Late in Life&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2016-2-15 | 正确率：90%&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点                        &lt;!-- raw HTML omitted --&gt;Let&amp;rsquo;s say your diet &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; hasn&amp;rsquo;t been so great. Maybe too much &lt;!-- raw HTML omitted --&gt;read&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;red&lt;!-- raw HTML omitted --&gt; meat, especially processed meat. Maybe &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; too many sugary soft drinks. And maybe &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; you&amp;rsquo;ve been eating like that for decades. So &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; what&amp;rsquo;s the point of trying to make some &lt;!-- raw HTML omitted --&gt;helpful&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;healthful&lt;!-- raw HTML omitted --&gt; changes now&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; after the damage has &lt;!-- raw HTML omitted --&gt;been&lt;!-- raw HTML omitted --&gt; presumably been done? &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;It is impressive that changes even very late in life&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;such &lt;!-- raw HTML omitted --&gt;as even being older and having a heart attack&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;dietary &lt;!-- raw HTML omitted --&gt;change &lt;!-- raw HTML omitted --&gt;came&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;can&lt;!-- raw HTML omitted --&gt; within a matter of a few months drop &lt;!-- raw HTML omitted --&gt;by&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;our&lt;!-- raw HTML omitted --&gt; risk greatly of &lt;!-- raw HTML omitted --&gt;reoccurred&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;recurrent&lt;!-- raw HTML omitted --&gt; heart attack or death. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Walter Willett&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;He &lt;!-- raw HTML omitted --&gt;chairs the Department of Nutrition &lt;!-- raw HTML omitted --&gt;of&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;at&lt;!-- raw HTML omitted --&gt; the Harvard T. H. Chan School of Public Health. He spoke at &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; January 15th forum on Cancer and Diet that wound up touching on diet and health in general. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;So &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; it&amp;rsquo;s never too late to make important changes&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;For &lt;!-- raw HTML omitted --&gt;diabetes also, that if we change our diet almost immediately our risk of diabetes goes down. But that&amp;rsquo;s not &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; say you &lt;!-- raw HTML omitted --&gt;just&lt;!-- raw HTML omitted --&gt; should just wait &lt;!-- raw HTML omitted --&gt;till&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;`&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;til&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; old &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;just&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;live&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;start&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;living&lt;!-- raw HTML omitted --&gt; a healthy life&lt;!-- raw HTML omitted --&gt;with&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;We&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;have&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;seen&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;We&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;seeing&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; some studies now that what women ate as adolescents&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; especially if they ate a lot more red meat&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; that affected breast cancer risk later in their life. So it&amp;rsquo;s definitely important if you want the healthiest overall life is to start &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; healthy lifestyle early. But if &lt;!-- raw HTML omitted --&gt;you&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you&amp;rsquo;ve&lt;!-- raw HTML omitted --&gt; sort of ignored things &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;it&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;it&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; never too late &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;you&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;can&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; still get some benefit. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;The entire hour-long forum featuring Willett and other researchers discussing diet and health is archived &lt;!-- raw HTML omitted --&gt;online&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;on&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;line&lt;!-- raw HTML omitted --&gt;. Just google &lt;!-- raw HTML omitted --&gt;&amp;quot;&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;“&lt;!-- raw HTML omitted --&gt;Harvard public health forum&amp;rdquo; .&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要说你的饮食已经很好了吧。也许有很多红肉，特别是加工肉类。或许还有很多有糖饮料。并且你或许已经这样吃了几十年了。那么现在突然要尝试更健康的饮食究竟是为何呢，要是以前不健康的话，也都已经深受其害很久了不是吗？&lt;/p&gt;
&lt;p&gt;晚年的生活会有很大不同，比如说衰老加速或者心脏变差，饮食改变能在即使几个月内就减少心脏病复发或者死亡几率。&lt;/p&gt;
&lt;p&gt;Walter Willett是哈佛公共健康T. H. Chan 学校的营养系主任。他在1 月15日关于癌症和饮食的论坛上作出的有关饮食和健康与死亡的关系的言论。&lt;/p&gt;
&lt;p&gt;所以，不要说做出重要的改变已经太迟了。对糖尿病也是，如果我们改变我们的饮食，几乎立刻就能减少罹患糖尿病的几率。但这也并没有说，你只需要等，直到你老了以后再开始你的健康生活。现在我们正在进行的一些实验显示，女士在青少年时期的饮食，特别是如果她们吃过很多红肉，这会在她们今后的生命中增加他们罹患乳腺疾病的几率。 所以如果你想要你的生活健康，尽可能早的选择一种健康的生活方式是绝对重要的。 如果你总是忽略这些事，那起码现在开始做到也没有太迟。&lt;/p&gt;
&lt;p&gt;全部的几小时论坛上都是Willett和其它研究人员们在线讨论饮食和健康相关研究所得到的研究结论。尽请搜索 谷歌网站上的 Harvard public health forum。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>暴饮暴食有原因</title>
      <link>https://wangcc.me/post/2015-9-18/</link>
      <pubDate>Fri, 18 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2015-9-18/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/overeating-due-to-stress-13-11-17/&#34;&gt;Overeating Due to Stress?&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2015-9-18 | 正确率：96%&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点                        &lt;!-- raw HTML omitted --&gt;Stress can make some people (me included) lose our appetite. And other folks find comfort in food. &lt;!-- raw HTML omitted --&gt;But&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;such &lt;!-- raw HTML omitted --&gt;behaviors may actually even out in the long term&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Because &lt;!-- raw HTML omitted --&gt;researchers find that people who change eating patterns when stressed out may actually make up for those not-so-healthy impulses during easier times. So finds &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; a study in the journal Psychological Science. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Volunteers for the study self-identified as either &amp;quot; munchers&amp;rdquo; or &amp;quot; skippers&amp;rdquo; . Each person &lt;!-- raw HTML omitted --&gt;will&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;have&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;had&lt;!-- raw HTML omitted --&gt; to interact with another person via video chat&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;with &lt;!-- raw HTML omitted --&gt;the intention of meeting them later. After each video interaction participants &lt;!-- raw HTML omitted --&gt;receive&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;received&lt;!-- raw HTML omitted --&gt; a message either stating that their partner &lt;!-- raw HTML omitted --&gt;had&lt;!-- raw HTML omitted --&gt; decided not to meet them&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; or that they were excited to meet them. As a control, some participants were told that the study had just been canceled. Then &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; the researchers offered ice cream to everyone &lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; as much as they wanted. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;The munchers who got rejected ate more ice cream than did those in the control &lt;!-- raw HTML omitted --&gt;groups&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;group&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;and &lt;!-- raw HTML omitted --&gt;the skippers who were rejected ate less. All as you&amp;rsquo;d &lt;!-- raw HTML omitted --&gt;expected&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;expect&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;But &lt;!-- raw HTML omitted --&gt;here&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;is&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;here&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; the twist&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;:&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Among &lt;!-- raw HTML omitted --&gt;the participants who received positive &lt;!-- raw HTML omitted --&gt;feed&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;back&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;feedback&lt;!-- raw HTML omitted --&gt;, the munchers actually ate less than the control group&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;And &lt;!-- raw HTML omitted --&gt;the skippers ate more. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;So even  &lt;!-- raw HTML omitted --&gt;stress-eaters&lt;!-- raw HTML omitted --&gt; are sometimes less-eaters. Unless &lt;!-- raw HTML omitted --&gt;they&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;are&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;they&amp;rsquo;re&lt;!-- raw HTML omitted --&gt; always stressed out.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;munch &lt;code&gt;v. 用力咀嚼，大声咀嚼&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;twist &lt;code&gt;n. 扭，绞，搓，缠，编；窍门；曲解；扭伤 v. 扭转，扭弯，旋转，绞；缠绕，盘绕；扭伤；歪曲；扭动&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;压力可以使某些人（也包括我啦）失去胃口。还有些人会从食物中找到慰籍。但是这样的行为也许会在长时间后得到调和。因为研究人员们发现，因压力而改变饮食模式的人，在没有压力的时候出现的不那么健康的饮食冲动实际上会得到弥补。 这是在《心理学科学》杂志上发表的一项研究得出的结论。&lt;/p&gt;
&lt;p&gt;该研究中的志愿者都是自我标榜为“吃货一枚”或者“吃不吃看情况”的人。每隔人都不得不通过视频聊天和另外一个人进行一次互动，目的就是为了之后和他们进行正式会面。每个视频互动过后的参与者会受到一个留言信息，内容是他们的同伴决定不和他们见面了，或者是他们的同伴十分期待和他们会面。对照组中，参与人员们会被告知这次的研究实验活动被取消了。然后，研究人员们为每人准备了冰淇凌——要多少就给多少哦。&lt;/p&gt;
&lt;p&gt;被告知会面被拒绝的吃货们比对照组的人吃掉更多的冰淇凌，而被拒绝的 三餐不固定的人则比对照组的人吃的冰淇凌要少。所有的结果都在意料之中。&lt;/p&gt;
&lt;p&gt;可是也有个小纠结：在收到积极反馈的参与者们，标榜为吃货的 人比对照组的人吃的冰淇淋少。而三餐不固定的人却吃得比对照组的人多。&lt;/p&gt;
&lt;p&gt;所以即便是因压力而吃东西的人有时候也会吃得少一些的。除非他们总是被压力困扰着。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>化妆品广告的科学依据</title>
      <link>https://wangcc.me/post/2015-9-16/</link>
      <pubDate>Wed, 16 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://wangcc.me/post/2015-9-16/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.scientificamerican.com/podcast/episode/cosmetic-ads-science-claims-lack-foundation/&#34;&gt;Cosmetic Ads&amp;rsquo; Science Claims Lack Foundation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;听写于：2015-9-16 | 正确率：84%&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;提示：&lt;!-- raw HTML omitted --&gt;红色&lt;!-- raw HTML omitted --&gt;：错误单词，&lt;!-- raw HTML omitted --&gt;绿色&lt;!-- raw HTML omitted --&gt;：补上正确单词，&lt;!-- raw HTML omitted --&gt;黄色&lt;!-- raw HTML omitted --&gt;：纠正大小写与标点                        &lt;!-- raw HTML omitted --&gt;Clinically &lt;!-- raw HTML omitted --&gt;Proven&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;Break&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;through&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Breakthrough&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Technology&lt;!-- raw HTML omitted --&gt;. Ten &lt;!-- raw HTML omitted --&gt;Years &lt;!-- raw HTML omitted --&gt;of &lt;!-- raw HTML omitted --&gt;Genetic &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Research&lt;!-- raw HTML omitted --&gt;. These are phrases you might expect to find in &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; pages of Scientific American. But these descriptions also show &lt;!-- raw HTML omitted --&gt;on&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;up&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;in&lt;!-- raw HTML omitted --&gt; commercials and print ads for &lt;!-- raw HTML omitted --&gt;cause&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;medics&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;cosmetics&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Now &lt;!-- raw HTML omitted --&gt;one&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; study &lt;!-- raw HTML omitted --&gt;found&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;finds&lt;!-- raw HTML omitted --&gt; that some &lt;!-- raw HTML omitted --&gt;or&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;well&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; make that &lt;!-- raw HTML omitted --&gt;&amp;quot;&lt;!-- raw HTML omitted --&gt; a lot &lt;!-- raw HTML omitted --&gt;&amp;quot;&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; of those &lt;!-- raw HTML omitted --&gt;science-sounding&lt;!-- raw HTML omitted --&gt;  claims are simply not true. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Researchers looked at nearly 300 ads in magazines such as Vogue. They analyzed claims in the ads and ranked them on a scale ranging from acceptable to &lt;!-- raw HTML omitted --&gt;out&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;right&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;outright&lt;!-- raw HTML omitted --&gt; lie. &lt;!-- raw HTML omitted --&gt;And&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;they &lt;!-- raw HTML omitted --&gt;found that just 18% of the &lt;!-- raw HTML omitted --&gt;both&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;boasts&lt;!-- raw HTML omitted --&gt; that &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; researchers looked at were true&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; 23% were &lt;!-- raw HTML omitted --&gt;out&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;right&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;outright&lt;!-- raw HTML omitted --&gt; lies&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;And &lt;!-- raw HTML omitted --&gt;42% were too vague to even &lt;!-- raw HTML omitted --&gt;classified&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;classify&lt;!-- raw HTML omitted --&gt;. The study is in the &lt;!-- raw HTML omitted --&gt;Journal &lt;!-- raw HTML omitted --&gt;of Global Fashion Marketing. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;The Food and Drug Administration regulates &lt;!-- raw HTML omitted --&gt;will&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;what&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;goes&lt;!-- raw HTML omitted --&gt; into your &lt;!-- raw HTML omitted --&gt;cosmetics&lt;!-- raw HTML omitted --&gt; and what goes on the label. If &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; claim is &lt;!-- raw HTML omitted --&gt;blatenly&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;blatantly&lt;!-- raw HTML omitted --&gt; untrue&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; the FDA can take action. Vague &lt;!-- raw HTML omitted --&gt;languages&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;language&lt;!-- raw HTML omitted --&gt; on labels &lt;!-- raw HTML omitted --&gt;maybe&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;may&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;be&lt;!-- raw HTML omitted --&gt; a way to keep the FDA at bay. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Meanwhile&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; ads are regulated by the Federal Trade Commission. Just last year they charged L&amp;rsquo;Oreal for deceptive advertising of &lt;!-- raw HTML omitted --&gt;it&amp;rsquo;s&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;its&lt;!-- raw HTML omitted --&gt; Génifique products, which the company said were &lt;!-- raw HTML omitted --&gt;clinical&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;clinically&lt;!-- raw HTML omitted --&gt; proven &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;to&lt;!-- raw HTML omitted --&gt; boost genes&lt;!-- raw HTML omitted --&gt;&#39;&lt;!-- raw HTML omitted --&gt; activity that &lt;!-- raw HTML omitted --&gt;will&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;would&lt;!-- raw HTML omitted --&gt; lead to the production of &lt;!-- raw HTML omitted --&gt;protein&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;proteins&lt;!-- raw HTML omitted --&gt; causing &lt;!-- raw HTML omitted --&gt;visibly&lt;!-- raw HTML omitted --&gt; younger skin in just &lt;!-- raw HTML omitted --&gt;7&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;seven&lt;!-- raw HTML omitted --&gt; days. A settlement agreement forced L&amp;rsquo;Oreal to back off on the &lt;!-- raw HTML omitted --&gt;claim&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;claims&lt;!-- raw HTML omitted --&gt;. &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;So take those &lt;!-- raw HTML omitted --&gt;closemetic&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;cosmetic&lt;!-- raw HTML omitted --&gt; ads with &lt;!-- raw HTML omitted --&gt;the&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;a&lt;!-- raw HTML omitted --&gt; grain of &lt;!-- raw HTML omitted --&gt;salt&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;scrub&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;-&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;after &lt;!-- raw HTML omitted --&gt;all, if scientists &lt;!-- raw HTML omitted --&gt;have&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;had&lt;!-- raw HTML omitted --&gt; really come up with a product that &lt;!-- raw HTML omitted --&gt;burst&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;reversed&lt;!-- raw HTML omitted --&gt; your wrinkles &lt;!-- raw HTML omitted --&gt;or&lt;!-- raw HTML omitted --&gt; grew your &lt;!-- raw HTML omitted --&gt;eye&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;ashes&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;eyelashes&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;,&lt;!-- raw HTML omitted --&gt; it &lt;!-- raw HTML omitted --&gt;will&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;would&lt;!-- raw HTML omitted --&gt; sell itself.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Words&lt;/em&gt; worth to be remembered:
&lt;ul&gt;
&lt;li&gt;cosmetic &lt;code&gt;adj. 表面的；美容的 n. 化妆品，装饰品&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;outright &lt;code&gt;adj. 完全的，彻底的；直率的 adv. 完全的，彻底的；即刻；率直地&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;blatantly &lt;code&gt;adv. 喧闹地；公然地；露骨地；极为，完全&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;keep sth. at bay &lt;code&gt;v. 牵制,不使逼近&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;譯文&#34;&gt;譯文：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“()”中的是我認爲正確的翻譯&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;黑體字&lt;/strong&gt;是我認爲翻譯得好的部分&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;临床实验证实..突破性技术..十年遗传学研究表明..这些词你也许本想在科学美国人的杂志上看到.但是这些描述你也能在化妆品广告和印刷宣传册上见到.&lt;/p&gt;
&lt;p&gt;现在有一项研究发现,有些——好吧，有很多——这些坚实的科学声明基本就不是真的。&lt;/p&gt;
&lt;p&gt;研究人员们察看了300多份杂志上的广告，比如时尚杂志。他们分析了在广告上的这些声明并把它们按真实程度从可以接受到完全是谎言这样的顺序排名。然后他们发现，宣称该产品被科研人员们检查过后的产品中有18%是真的。由23% 就是谎言。还有42% 说的模棱两可而不好被归类。该研究已发表在《全球时尚营销》杂志上。&lt;/p&gt;
&lt;p&gt;食品药品管理局规定什么成分被用在你的化妆品里以及产品说明上应该写什么。如果一项宣称是明显不真实的，那么FDA是可以采取行动处理的。标签上的用词模糊也许是一种阻止 FDA 的一种方法。&lt;/p&gt;
&lt;p&gt;同时，广告是被联邦商贸委员会管理的。就在去年，欧莱雅刚刚因为其产品Génifique的虚假广告被罚款，广告中该公司说道，临床证明其商品促基因表达的活性，从而导致引起可以只需要7天便可以使你的皮肤年轻的一些蛋白质被表达出来。一项达成一致的和解迫使欧莱雅撤回这项声明。&lt;/p&gt;
&lt;p&gt;所以对化妆品广告可别太当真了——毕竟，如果科学家们已经想到如何退却你的皱纹或者是增长你的睫毛，还能轮得上这些公司？&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
