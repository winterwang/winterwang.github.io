---
title: Matrix Revisions
author: ''
date: '2017-09-30'
slug: matrix-revision
categories:
  - statistics
tags:
  - basic mathematics
  - linear algebra
  - Medical Statistics
  - LSHTM
  - London
summary: "統計學中常用的簡單數學規則 (2)"
---

## Basic Definition and notations:

1. An $m\times n$ **matrix $A$** is a rectangular array of numbers with $m$ rows and $n$ columns.
2. The **elements** of a matrix $A_{m\times n}$ are $a_{ij}$
3. The **order** of a matrix is the number of rows by the number of columns, i.e. $m\times n$
4. A **column vector** with $m$ elements, $y = \left(
\begin{array}{c}
y_1\\
y_2\\
\vdots\\
y_n
\end{array}
\right)$, is a matrix with only one column i.e. an $m\times 1$ matrix.
5. A **row vector** with $n$ elements, $x=(x_1,x_2,x_3, \cdots, x_n)$, is a matrix with only one row, i.e. an $1\times n$ matrix.
6. **Transposed matrix** $A^T$ (or $A'$) arises from the matrix $A$ by interchanging the column vectors and the row vectors i.e. $a_{ij}^T = a_{ji}$ (so a column vector is converted into a row vector and vise versa)
7. **A partitioned matrix** is a matrix written in terms of sub-matrices. $A=\left(
\begin{array}{c}
A_{11} & A_{12}\\
A_{21} & A_{22}\\
\end{array}
\right)$, where $A_{11},A_{12},A_{21},A_{22}$ are sub-matrices

    1. $A_{11}, A_{21}$ have the same number of columns, so do $A_{12}, A_{22}$
    2. $A_{11}, A_{12}$ have the same number of rows, so do $A_{21}, A_{22}$
    3. partitioning is not restricted to dividing a matrix into just four sub-matrices


8. **A square matrix** has exactly as many rows as it has columns i.e. the order of the matrix is $n\times n$
9. **The main diagonal** (or leading diagnonal) of a square matrix $A (n\times n)$ are the elements lying on the diagnoal **from top left to bottom right.** $a_{11},a_{22},a_{33},\cdots,a_{nn}$ i.e. all $a_{ii}, i= 1,\cdots, n$
10. **The trace ** of a square matrix is the sum of the diagonal elements $tr(A)=a_{11}+a_{22}+\cdots+a_{nn}=\sum_{i=1}^na_{ii}$


## Special matrices

1. **A symmetric matrix** is a square matrix for which the following is true for all the off diagonal elements. $a_{ij}=a_{ji}$ i.e. $A^T=A$
2. **Diagonal matrix** is a square matrix having zero for all the non-diagonal elements i.e. $A=\left(
\begin{array}{c}
a_{11} & \cdots & 0\\
\vdots & \ddots & \vdots\\
0      & \cdots & a_{nn}
\end{array}
\right)$
3. **Zero matrix** (null matrix) is a matrix whose all elements are zero
4. **Identity matrix** (or unit matrix) is a diagonal matrix having all diagonal elements equal to 1 and off diagonal elements equal to zero. i.e. $I=\left(
\begin{array}{c}
1 & \cdots & 0\\
\vdots & \ddots & \vdots\\
0      & \cdots & 1
\end{array}
\right)$
5. **"Summing vector"** is a vector whose every element is 1 i.e. $1_{n}=(1\cdots1)$
6. **"J matrix"** is a matrix (not necessarily square) whose every element is 1 i.e. $J_{m\times n}=\left(
\begin{array}{c}
1 & 1 & \cdots & 1\\
1 & 1 & \cdots & 1 \\
\vdots & \vdots & \ddots & \vdots\\
1 & 1 & \cdots & 1
\end{array}
\right)$

## Basic Operations


 {{% alert note %}}
**Addition (Substraction)** can take place only when the matrices involved are of the same order. i.e.
Two matrices can be added (subtracted) only if they have the same numbers of rows and the same numbers of columns.
 {{% /alert %}}

- $A+B=B+A$
- $(A+B)+C=A+(B+C)$
- $A+0=0+A=A$
- $A+(-A)=0$
- $(A+B)^T=A^T+B^T$

**Multiplication by scalar:**
- $cA=Ac$
- $c(dA)=(cd)A$
- $(c\pm d)A=cA\pm dA$
- $c(A\pm B)=cA \pm  cB$

**Multiplication of an $2\times2$ matrix by a column vector which has 2 rows yields a column vector with $2$ rows.**
$$Ax=\left(
\begin{array}{c}
a_{11} & a_{12}\\
a_{21} & a_{22}\\
\end{array}
\right)\left(
\begin{array}{c}
x_{1}\\
x_{2}\\
\end{array}
\right)=\left(
\begin{array}{c}
a_{11}x_1+a_{12}x_2\\
a_{21}x_1+a_{22}x_2\\
\end{array}
\right)$$

### Generally:

**Multiplication of an $m\times n$ matrix** by a **column vector** which has $n$ rows **yields a column vector** with $m$ rows.
$$Ax=\left(
\begin{array}{c}
a_{11} & \cdots & a_{1n} \\
\vdots & \ddots & \vdots \\
a_{m1} & \cdots & a_{mn}
\end{array}
\right)\left(
\begin{array}{c}
x_{1}\\
x_{2}\\
\vdots \\
x_{n}
\end{array}
\right)=\left(
\begin{array}{c}
a_{11}x_{1}+a_{12}x_2+\cdots+a_{1n}x_n\\
\vdots \\
a_{m1}x_{1}+a_{m2}x_2+\cdots+a_{mn}x_n
\end{array}
\right)=y \\
i.e. y_i=\sum_{j=1}^na_{ij}x_j, \; i=1,\cdots, m$$


**[Multiplication of matrices](https://winterwang.github.io/post/2017-02-22/):** The product $AB=C$ is **defined only when $A_{m\times r}$ has exactly as many columns as $B_{r\times n}$ has rows**. And the elements of $C_{m\times n}$ are given as
$$c_{ij}=\sum_{l=1}^na_{il}b_{lj}, \;\; i=1,\cdots,m \; and \; j=1,\cdots, n$$

- $AB \neq BA$
- $(AB)C=A(BC)=ABC$
- $A(B+C)=AB+AC$
- $(B+C)A=BA+CA$
- $IA=AI=A$

## Further definitions

1. [**The determinant**](https://winterwang.github.io/post/2017-03-15/) of a second order square matrix is $det(A)=|A|=\begin{vmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{vmatrix}=a_{11}a_{22}-a_{12}a_{21}$

2. **[The inverse of a matrix](https://winterwang.github.io/post/2017-07-06/)** $A$, $A^{-1}$ if it exists, is a matrix whose product with $A$ is the identity matrix i.e. $AA^{-1}=A^{-1}A=I$. (**Note: both $A$ and $A^{-1}$ have to be square**) For second order matrices:$A^{-1}=\frac{1}{det(A)}\left(
\begin{array}{c}
a_{22} & -a_{12}\\
-a_{21} & a_{11}\\
\end{array}
\right)$

3. **[Singular or non-invertible matrix](https://winterwang.github.io/post/2017-07-06/)**: $det(A)=0$

4. **Idempotent matrices(冪等矩陣)** are square and the following is true: $AA=A^2=A$

5. **[Orthogonal matrices](https://winterwang.github.io/post/2017-03-08/)** have the following property: $AA^T=A^TA=I$
