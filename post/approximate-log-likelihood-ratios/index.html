<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.30.2" />
  <meta name="author" content="王　超辰 (Chaochen Wang)">
  

  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="/css/highlight.min.css">
    
  
  <link rel="stylesheet" href="/css/bootstrap.min.css">
  <link rel="stylesheet" href="/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/academicons.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono">
  <link rel="stylesheet" href="/css/hugo-academic.css">
  

  <link rel="alternate" href="https://winterwang.github.io/index.xml" type="application/rss+xml" title="Be ambitious">
  <link rel="feed" href="https://winterwang.github.io/index.xml" type="application/rss+xml" title="Be ambitious">

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="https://winterwang.github.io/post/approximate-log-likelihood-ratios/">

  

  <title>二次方程近似法求對數似然比 approximate log-likelihood ratios | Be ambitious</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Be ambitious</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#publications_selected">
            
            <span>Publications</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#teaching">
            
            <span>Teaching</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#slides">
            
            <span>Presentations/slides</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
          </a>
        </li>

        
        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  

  <div class="article-container">
    <h1 itemprop="name">二次方程近似法求對數似然比 approximate log-likelihood ratios</h1>
    

<div class="article-metadata">

  <span class="article-date">
    <time datetime="2017-11-07 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Tue, Nov 7, 2017
    </time>
  </span>

  
  
  
  <span class="article-categories">
    <i class="fa fa-folder"></i>
    
    <a href="/categories/statistics">statistics</a
    >, 
    
    <a href="/categories/study-abroad">study abroad</a
    >
    
  </span>
  
  

  
  
  
  <span class="article-tags">
    <i class="fa fa-tags"></i>
    
    <a href="/tags/inference">inference</a
    >, 
    
    <a href="/tags/learning-notes">learning notes</a
    >, 
    
    <a href="/tags/medical-statistics">Medical Statistics</a
    >, 
    
    <a href="/tags/london">London</a
    >, 
    
    <a href="/tags/lshtm">LSHTM</a
    >
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fwinterwang.github.io%2fpost%2fapproximate-log-likelihood-ratios%2f"
         target="_blank">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=%e4%ba%8c%e6%ac%a1%e6%96%b9%e7%a8%8b%e8%bf%91%e4%bc%bc%e6%b3%95%e6%b1%82%e5%b0%8d%e6%95%b8%e4%bc%bc%e7%84%b6%e6%af%94%20approximate%20log-likelihood%20ratios&amp;url=https%3a%2f%2fwinterwang.github.io%2fpost%2fapproximate-log-likelihood-ratios%2f"
         target="_blank">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwinterwang.github.io%2fpost%2fapproximate-log-likelihood-ratios%2f&amp;title=%e4%ba%8c%e6%ac%a1%e6%96%b9%e7%a8%8b%e8%bf%91%e4%bc%bc%e6%b3%95%e6%b1%82%e5%b0%8d%e6%95%b8%e4%bc%bc%e7%84%b6%e6%af%94%20approximate%20log-likelihood%20ratios"
         target="_blank">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fwinterwang.github.io%2fpost%2fapproximate-log-likelihood-ratios%2f&amp;title=%e4%ba%8c%e6%ac%a1%e6%96%b9%e7%a8%8b%e8%bf%91%e4%bc%bc%e6%b3%95%e6%b1%82%e5%b0%8d%e6%95%b8%e4%bc%bc%e7%84%b6%e6%af%94%20approximate%20log-likelihood%20ratios"
         target="_blank">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=%e4%ba%8c%e6%ac%a1%e6%96%b9%e7%a8%8b%e8%bf%91%e4%bc%bc%e6%b3%95%e6%b1%82%e5%b0%8d%e6%95%b8%e4%bc%bc%e7%84%b6%e6%af%94%20approximate%20log-likelihood%20ratios&amp;body=https%3a%2f%2fwinterwang.github.io%2fpost%2fapproximate-log-likelihood-ratios%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

    <div class="article-style" itemprop="articleBody">
      <p>爲什麼要用二次方程近似對數似然比方程？</p>
<ol style="list-style-type: decimal">
<li>上節也看到，我們會碰上難以用代數學計算獲得對數似然比信賴區間的情況 (<a href="https://winterwang.github.io/post/log-likelihood-ratio/">binomial example</a>)。</li>
<li>我們同時知道，對數似然比方程會隨着樣本量增加而越來越漸進於二次方程，且左右對稱。</li>
<li>所以，我們考慮當樣本量足夠大時，用二次方程來近似對數似然比方程從而獲得參數估計的信賴區間。</li>
</ol>
<div id="-normal-approximation-to-the-log-likelihood" class="section level3">
<h3>正態近似法求對數似然 Normal approximation to the log-likelihood</h3>
<p>根據<a href="https://winterwang.github.io/post/log-likelihood-ratio/">前一節</a>，如果樣本均數的分佈符合正態分佈：<span class="math inline">\(\bar{X}\sim N(\mu, \sigma^2/n)\)</span>。那麼樣本均數的對數似然比爲：</p>
<p><span class="math display">\[llr(\mu|\bar{X})=\ell(\mu|\bar{X})=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\]</span></p>
<p>其中， <span class="math inline">\(\bar{x}\)</span> 是正態分佈總體均數 <span class="math inline">\(\mu\)</span> 的極大似然估計 (maximum likelihood estimator, MLE)。如果已知總體的方差參數，那麼 <span class="math inline">\(\sigma/\sqrt{n}\)</span> 是 <span class="math inline">\(\bar{x}\)</span> 的標準誤 (standard error)。</p>
<p>因此，假設 <span class="math inline">\(\theta\)</span> 是我們想尋找的總體參數。有些人提議可以使用下面的關於 <span class="math inline">\(\theta\)</span> 的二次方程來做近似：</p>
<p><span class="math display">\[f(\theta|data)=-\frac{1}{2}(\frac{\theta-M}{S})^2\]</span></p>
<p>上述方程具有一個正態二次對數似然 (比) 的形式，而且該方程的極大似然估計(MLE)， <span class="math inline">\(M\)</span> 的標準誤爲 <span class="math inline">\(S\)</span>。如果我們正確地選用 <span class="math inline">\(M\)</span> 和 <span class="math inline">\(S\)</span>，那我們就可以用這樣的方程來近似求真實觀察數據的似然 <span class="math inline">\(\ell(\theta|data)\)</span>。</p>
<p>通過近似正態對數似然比，<span class="math inline">\(M\)</span> 應當選用使方程取最大值時，參數 <span class="math inline">\(\theta\)</span> 的極大似然估計 <span class="math inline">\(M=\hat{\Theta}\)</span>。</p>
<p>但是在選用標準誤 <span class="math inline">\(S\)</span> 上必須滿足下列條件：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(S\)</span> 是極大似然估計 <span class="math inline">\(\hat{\Theta}\)</span> 的標準誤。</li>
<li>被選擇的 <span class="math inline">\(S\)</span> 必須儘可能的使該二次方程形成一個十分接近真實的對數似然比方程。特別是在最大值的部分必須與之無限接近或者一致。所以二者在 MLE 的位置應當有相同的曲率（二階導數）。</li>
</ol>
<p>由於，一個方程的曲率是該方程的二階導數（斜線斜率變化的速度）。所以對數似然比方程在 MLE 取最大值時的曲率（二階導數）爲：</p>
<p><span class="math display">\[\left.\frac{d^2}{d\theta^2}\ell(\theta)\right\vert_{\theta=\hat{\theta}}=\ell^{\prime\prime}(\hat{\theta})=-\frac{1}{S^2}\\
\Rightarrow S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}
\]</span></p>
<p>在正態分佈的例子下，<span class="math inline">\(M=\bar{x}, S=\sigma/\sqrt{n}\)</span>。對數似然比方程最大值時的曲率（二階導數）恰好就爲標準誤的平方的負倒數：</p>
<p><span class="math inline">\(\ell^{\prime\prime}(\theta)=-\frac{1}{SE^2}\)</span> <span class="math inline">\(\Rightarrow\)</span> 被叫做 <strong>Fisher information</strong>。</p>
<p>稍微總結一下：</p>
<ol style="list-style-type: decimal">
<li>任意的對數似然比方程 <span class="math inline">\(llr(\theta)\)</span> 都可以考慮用一個二次方程來近似： <span class="math display">\[f(\theta|data)=-\frac{1}{2}(\frac{\theta-M}{S})^2\]</span></li>
<li>其中<br> <span class="math inline">\(\begin{aligned} &amp;M=\hat\theta\\ &amp;S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}\\ &amp;when \\  &amp; n\rightarrow\infty \Rightarrow  \begin{cases}  S^2\rightarrow Var(\hat\theta) \\  S\rightarrow SE(\hat\theta)  \end{cases} \end{aligned}\)</span></li>
</ol>
<div class="section level4">
<h4>近似法估算對數似然比的信賴區間</h4>
<p>一旦我們決定了使用正態近似法來模擬對數似然比方程，對數似然比的信賴區間算法就回到了前一節中我們算過的方法，也就是：</p>
<p><span class="math display">\[-2f(\theta)&lt;\mathcal{X}_{1,(1-\alpha)}^2\]</span></p>
<p>故信賴區間爲： <span class="math inline">\(m\pm\sqrt{\mathcal{X}_{1,(1-\alpha)}^2}S\)</span>。求<span class="math inline">\(95\%\)</span> 水平的信賴區間時，<span class="math inline">\(\mathcal{X}_{1,0.95}^2=3.84\)</span>，所以就又看到了熟悉的 <span class="math inline">\(M\pm1.96S\)</span>。</p>
</div>
<div class="section level4">
<h4>以泊松分佈爲例</h4>
<p>一個被追蹤的樣本，經過了 <span class="math inline">\(p\)</span> 人年的觀察，記錄到了 <span class="math inline">\(d\)</span> 個我們要研究的事件：</p>
<p><span class="math display">\[D\sim po(\mu), where \mu=\lambda p\]</span></p>
<p>Step 1. 找極大似然估計 (MLE)，<a href="https://winterwang.github.io/post/likelihood/">之前介紹似然方程時推導過的泊松分佈的似然方程</a>：</p>
<p><span class="math display">\[\begin{aligned}
P(D=d|\lambda) &amp;= \frac{e^{-\mu}\cdot\mu^d}{d!} \\
 &amp;=\frac{e^{-\lambda p}\cdot\lambda^d p^d}{d!} \\
omitting&amp;\;terms\;not\;in\;\mu \\
&amp;\Rightarrow \ell(\lambda) = dlog\lambda - \lambda p \\
&amp;\Rightarrow \ell^\prime(\lambda) = \frac{d}{\lambda} -p \\
&amp;\Rightarrow \hat\lambda=\frac{d}{p} = \textbf{M}
\end{aligned}\]</span></p>
<p>Step 2. 求似然方程的二階導數，確認 MLE 是使方程獲得最大值的點，然後確定 <span class="math inline">\(S^2\)</span>：</p>
<p><span class="math display">\[\begin{aligned}
&amp; \ell^\prime(\lambda) = \frac{d}{\lambda} -p \\
&amp; \Rightarrow \ell^{\prime\prime}(\lambda) = -\frac{d}{\lambda^2}&lt;0 \Rightarrow \textbf{MLE is maximum} \\
&amp; S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\lambda)}\right\vert_{\lambda=\hat{\lambda}=d/p} = -\frac{1}{-d/\hat\lambda^2} = -\frac{1}{-d/(d/p)^2} \\
&amp;\Rightarrow S^2 = \frac{d}{p^2} \\
\end{aligned}\]</span></p>
<p>Step 3. 把前兩部求得的 <span class="math inline">\(MLE\)</span> 和 <span class="math inline">\(S^2\)</span> 代入近似的二次方程：</p>
<p><span class="math display">\[\begin{aligned}
&amp; \hat\lambda=\frac{d}{p}=M,\; S^2 = \frac{d}{p^2}  \\
&amp; using\;approximate\;quadratic\;llr \\
&amp; q(\lambda) = -\frac{1}{2}(\frac{\lambda-M}{S})^2\\
&amp;\Rightarrow q(\lambda) = -\frac{1}{2}(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2\\
&amp; let \; q(\lambda)=-1.92\\
&amp;\Rightarrow -\frac{1}{2}(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2=-1.92\\
&amp;(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2=3.84\\
&amp;\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}} = \pm1.96\\
&amp;\Rightarrow 95\%CI \;for \;\lambda = \frac{d}{p}\pm1.96\frac{\sqrt{d}}{p}
\end{aligned}\]</span></p>
<p>結論就是： 發病（死亡）率 <span class="math inline">\(\lambda\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間爲： <span class="math inline">\(M\pm1.96S\)</span>。所以我們不需要每次都代入對數似然比方程，只要算出 <span class="math inline">\(MLE = M\)</span> 和 <span class="math inline">\(S\)</span> 之後代入這個公式就可以用二次方程近似法算出信賴區間。</p>
</div>
<div class="section level4">
<h4>以二項分佈爲例</h4>
<p><span class="math display">\[K\sim Bin(n,\pi)\]</span></p>
<p>Step 1. 找極大似然估計 (MLE)：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; Prob(K=k) = \pi^k(1-\pi)\binom{n}{k}\\
&amp;\Rightarrow L(\pi|k) = \pi^k(1-\pi)\binom{n}{k}\\
&amp;omitting\;terms\;not\;in\;\pi \\
&amp;\Rightarrow \ell(\pi) = k\:log\pi+(n-k)log(1-\pi) \\
&amp;\ell^\prime(\pi) = \frac{k}{\pi}-\frac{n-k}{1-\pi} \\
&amp; let\;\ell^\prime(\hat\pi) =0 \\
&amp;\Rightarrow \frac{k}{\hat\pi}-\frac{n-k}{1-\hat\pi}=0\\
&amp;\Rightarrow \frac{\hat\pi}{1-\hat\pi}=\frac{k}{n-k}\\
&amp;\Rightarrow \frac{\hat\pi}{1-\hat\pi}=\frac{k/n}{1-k/n}\\
&amp;\Rightarrow \hat\pi=\frac{k}{n} = p = \textbf{M}
\end{aligned}
\]</span></p>
<p>Step 2. 將對數似然方程的二次微分 (二階導數)，確認在 MLE 爲極大值，並確認 <span class="math inline">\(S^2\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\ell^\prime(\pi) = \frac{k}{\pi}-\frac{n-k}{1-\pi} \\
&amp;\ell^{\prime\prime}(\pi)=\frac{-k}{\pi^2}-\frac{n-k}{(1-\pi)^2} &lt;0 \\
&amp;\therefore at\;\textbf{MLE}\;\ell(\pi)\;has\;maximum \\
S^2&amp;=\left.-\frac{1}{\ell^{\prime\prime}(\pi)}\right\vert_{\pi=\hat\pi=k/n=p}\\
&amp;=\frac{1}{\frac{k}{\hat\pi^2}+\frac{n-k}{(1-\hat\pi)^2}}\\
&amp;=\frac{\hat\pi^2(1-\hat\pi)^2}{k(1-\hat\pi)^2+(n-k)\hat\pi^2}\\
&amp;=\frac{P^2(1-P)^2}{np(1-p)^2+(n-np)p^2}\\
&amp;=\frac{p(1-p)}{n(1-p)+np}\\
&amp;=\frac{p(1-p)}{n}\\
&amp;\Rightarrow S=\sqrt{\frac{p(1-p)}{n}}
\end{aligned}
\]</span></p>
<p>Step 3. 將求得的 MLE 和 <span class="math inline">\(S^2\)</span> 代入近似信賴區間：</p>
<p><span class="math display">\[
95\% CI \;for \; \pi:\\
M\pm1.96S=p\pm1.96\sqrt{\frac{p(1-p)}{n}}\\
\]</span></p>
</div>
</div>
<div id="-parameter-transformations" class="section level3">
<h3>參數轉化 parameter transformations</h3>
<p>如果將參數 <span class="math inline">\(\theta\)</span> 通過某種數學方程轉化成 <span class="math inline">\(g(\theta)\)</span>，那麼我們可以認爲，轉化後的方程的 MLE 爲 <span class="math inline">\(g(\hat\theta)\)</span>，其中 <span class="math inline">\(\hat\theta\)</span> 是參數 <span class="math inline">\(\theta\)</span> 的 MLE。</p>
<p>類似地，如果 <span class="math inline">\(\theta_1 \sim \theta_2\)</span> 是參數 <span class="math inline">\(\theta\)</span> 的似然比信賴區間，那麼 <span class="math inline">\(g(\theta_1)\sim g(\theta_2)\)</span> 就是 <span class="math inline">\(g(\theta)\)</span> 的似然比信賴區間。</p>
<p>以下爲轉換參數以後獲取信賴區間的步驟：</p>
<ol style="list-style-type: decimal">
<li>將參數通過某些數學方程（通常是取對數）轉化，使新的對數似然比方程更加接近二次方程的對稱圖形。<br> Transform parameter so that <span class="math inline">\(llr\)</span> is closer to a quadratic shape.</li>
<li>用本節學到的二次方程近似法，求得轉化後的參數的似然比信賴區間。 <br> Use our quadratic approximation on the transformed parameter to calculate our likelihood ratio confidence intervals.</li>
<li>將第2步計算獲得的似然比信賴區間再通過轉化參數時的逆函數轉換回去，以獲得原參數的似然比信賴區間。<br> Transform the confidence intervals back, or to any scale we wish – they remain valid.</li>
</ol>
<div id="-1" class="section level4">
<h4>以泊松分佈爲例</h4>
<p>當我們用泊松分佈模擬事件在某段時間內發生率 <span class="math inline">\(\lambda\)</span> 時，注意到這個事件發生率必須滿足 <span class="math inline">\(\lambda&gt;0\)</span>。當事件發生次數較低時，會讓似然方程的圖形被擠壓在低值附近。如果嘗試用對數轉換 <span class="math inline">\(\lambda \rightarrow log(\lambda)\)</span> 此時 <span class="math inline">\(log(\lambda)\)</span> 就不再被限制與 <span class="math inline">\(&gt;0\)</span>。下面我們嘗試尋找對數轉換過後的 <span class="math inline">\(M\)</span> 和 <span class="math inline">\(S\)</span>。</p>
<p>令 <span class="math inline">\(\beta=log(\lambda), \Rightarrow e^\beta=\lambda\)</span> 從本文上半部分中我們已知 <span class="math inline">\(\hat\lambda=\frac{d}{p}\)</span>。</p>
<ul>
<li>對數轉換以後的 <span class="math inline">\(M\)</span> 是什麼? <br>根據定義，<span class="math inline">\(MLE(\beta)=MLE[log(\lambda)]=log(\hat\lambda)\)</span> <span class="math inline">\(\Rightarrow M=\hat\beta=log(\frac{d}{p})\)</span></li>
<li><p>對數轉換以後的 <span class="math inline">\(S\)</span> 是什麼? <br> 泊松分佈的對數似然方程是：<span class="math inline">\(\ell(\lambda|d)=d log(\lambda) - \lambda p\)</span> 用 <span class="math inline">\(\beta\)</span> 替換掉 <span class="math inline">\(\lambda\)</span></p>
<span class="math inline">\(\begin{aligned} &amp; \ell(\beta|d)=d \beta - pe^\beta\\ &amp; \Rightarrow \ell^\prime(\beta)=d-pe^\beta \Rightarrow \ell^{\prime\prime}(\beta)=-pe^\beta \\ &amp; S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\beta)}\right\vert_{\beta=\hat{\beta}} = \left.\frac{1}{pe^\beta}\right\vert_{\beta=\hat{\beta}} = \frac{1}{pe^{log(d/p)}}\\ &amp;\Rightarrow S^2=\frac{1}{d} \therefore S=\frac{1}{\sqrt{d}} \end{aligned}\)</span></li>
<li><p>轉換後的近似二次方程：<br> <span class="math inline">\(\begin{aligned} &amp; q(\beta) = -\frac{1}{2}(\frac{\beta-M}{S})^2 = -\frac{1}{2}(\frac{\beta-log(\frac{d}{p})}{\frac{1}{\sqrt{d}}})^2 \end{aligned}\)</span></p></li>
<li><p><span class="math inline">\(\beta\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間 <span class="math inline">\(=log(\frac{d}{p})\pm1.96\frac{1}{\sqrt{d}}\)</span></p></li>
<li><p><span class="math inline">\(\lambda\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間 <span class="math inline">\(=exp(log(\frac{d}{p})\pm1.96\frac{1}{\sqrt{d}})\)</span></p></li>
</ul>
</div>
<div id="-1" class="section level4">
<h4>以二項分佈爲例</h4>
<p>在研究對象 <span class="math inline">\(n\)</span> 人中觀察到 <span class="math inline">\(k\)</span> 個人患有某種疾病。</p>
<p>令 <span class="math inline">\(\beta=log(\pi) \Rightarrow \pi=e^\beta\)</span> 從上文的推倒也已知 <span class="math inline">\(\hat\pi=\frac{k}{n}=p\)</span></p>
<p><span class="math inline">\(\begin{aligned} &amp;\Rightarrow \ell(\beta)=klog\pi+(n-k)log(1-\pi)=k\beta+(n-k)log(1-e^\beta) \\ &amp;\Rightarrow \ell^{\prime}(\beta)=k-\frac{(n-k)(e^\beta)}{1-e^\beta} \\ &amp;\Rightarrow \ell^{\prime\prime}(\beta)=-(n-k)\frac{e^\beta(1-e^\beta)+e^{2\beta}}{(1-e^\beta)^2} \\ &amp; \ell^{\prime\prime}(\beta)= -(n-k)\frac{e^\beta}{(1-e^\beta)^2}\\ &amp;\Rightarrow S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\beta)}\right\vert_{\beta=\hat{\beta}} = \frac{(1-e^{\hat\beta})^2}{(n-k)e^{\hat\beta}} \\ &amp;\because \hat\beta=log(\hat\pi) \\ &amp;\therefore e^{\hat\beta} = \frac{k}{n}\\ &amp;\Rightarrow S^2=\frac{(1-\frac{k}{n})^2}{(n-k)\frac{k}{n}}=\frac{n-k}{nk}=\frac{1}{k}-\frac{1}{n}\\ &amp; \Rightarrow S=\sqrt{\frac{1}{k}-\frac{1}{n}}\\ \end{aligned}\)</span></p>
</div>
</div>
<div id="exercise" class="section level3">
<h3>Exercise</h3>
<div id="q1" class="section level4">
<h4>Q1</h4>
<ol style="list-style-type: lower-alpha">
<li>在<span class="math inline">\(n=100\)</span>人中觀察到有<span class="math inline">\(k=40\)</span>人患病，假設每個人只有患病，不患病兩個狀態，用二項分佈來模擬這個數據，<span class="math inline">\(\pi\)</span> 爲患病的概率。下面是 <span class="math inline">\(\pi \in [0.2,0.6]\)</span> 區間的對數似然比方程曲線。</li>
</ol>
<pre class="r"><code>pi &lt;- seq(0.2, 0.6, by=0.01)
L &lt;- (pi^40)*((1-pi)^60)
Lmax &lt;- rep(max(L), 41)
LR &lt;- L/Lmax
logLR &lt;- log(LR)

plot(pi, logLR, type = &quot;l&quot;, ylim = c(-11, 0),yaxt=&quot;n&quot;,
     frame.plot = FALSE, ylab = &quot;logLR(\U03C0)&quot;, xlab = &quot;\U03C0&quot;)
grid(NA, 5, lwd = 2) # add some horizontal grid on the background
axis(2, at=seq(-12,0,2), las=2)
title(main = &quot;Figure 1. Binomial log-likelihood ratio&quot;)</code></pre>
<p><img src="/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-1-1.png" width="480" /></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>用一個二次方程來模擬上面的對數似然比曲線：<span class="math inline">\(f(\pi)=-\frac{(\pi-M)^2}{2S^2}\)</span>，其中 <span class="math inline">\(M=\hat\pi=\frac{k}{n}=0.4\)</span>，<span class="math inline">\(S^2=\frac{p(1-p)}{n}=0.0024\)</span></li>
</ol>
<pre class="r"><code>par(mai = c(1.2, 0.5, 1, 0.7))
quad &lt;- -(pi-0.4)^2/(2*0.0024)
plot(pi, quad, type = &quot;l&quot;, ylim = c(-4, 0),yaxt=&quot;n&quot;, col=&quot;red&quot;,
     frame.plot = FALSE, ylab = &quot;&quot;, xlab = &quot;\U03C0&quot;)
lines(pi, logLR, col=&quot;black&quot;)
grid(NA, 4, lwd = 1) # add some horizontal grid on the background
axis(2, at=seq(-4,0,1), las=2)
title(main = &quot;Figure 2. Quadratic approximation\n of binomial log-likelihood ratio \n 40 out of 100 subjects&quot;)
abline(h=-1.92, lty=1, col=&quot;red&quot;)
axis(4, at=-1.92, las=2)

legend(x=0.27, y= -5.5 ,xpd = TRUE,  legend=c(&quot;logLR&quot;,&quot;Quadratic&quot;), bty = &quot;n&quot;,
       col=c(&quot;black&quot;,&quot;red&quot;), lty=c(1,1), horiz = TRUE) #the legend is below the graph</code></pre>
<p><img src="/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-2-1.png" width="576" /></p>
</div>
<div id="q2" class="section level4">
<h4>Q2</h4>
<p>依舊使用二項分佈數據來模擬，觀察不同的事件數量和樣本量對近似計算的影響。</p>
<ol style="list-style-type: decimal">
<li>類比上面的問題，用同樣的 <span class="math inline">\(\hat\pi=0.4\)</span>，但是 <span class="math inline">\(n=10, k=4\)</span> 時的圖形：</li>
</ol>
<p><img src="/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-3-1.png" width="576" /></p>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.4, n=1000, k=400\)</span></li>
</ol>
<p><img src="/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-4-1.png" width="576" /></p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.01, n=100, k=1\)</span></li>
</ol>
<p>注意此圖中紅線提示的近似二次曲線，信賴區間的下限已經低於0，是無法接受的近似。</p>
<p><img src="/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-5-1.png" width="576" /></p>
<ol start="4" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.01, n=1000, k=10\)</span></li>
</ol>
<p><img src="/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-6-1.png" width="576" /></p>
<ol start="5" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.01, n=10000, k=100\)</span></li>
</ol>
<p><img src="/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-7-1.png" width="576" /></p>
<ol start="6" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.99, n=100, k=99\)</span></li>
</ol>
<p>注意此圖中紅線提示的近似二次曲線，信賴區間的上限已經大於1，和上面的 Figure 5. 一樣也是無法接受的近似。</p>
<p><img src="/post/2017-11-07-approximate-log-likelihood-ratios_files/figure-html/unnamed-chunk-8-1.png" width="576" /></p>
<p>總結： 二次方程近似時，在二項分佈的情況下，隨着 <span class="math inline">\(n, k\)</span> 增加，近似越理想。</p>
</div>
</div>

    </div>
  </div>

</article>

<div class="container">
  <nav>
  <ul class="pager">
    
    <li class="previous"><a href="https://winterwang.github.io/post/log-likelihood-ratio/"><span
      aria-hidden="true">&larr;</span> 對數似然比 Log-likelihood ratio</a></li>
    

    
    <li class="next"><a href="https://winterwang.github.io/post/construction-of-a-hypothesis-test/">徒手打造一個假設檢驗 <span
      aria-hidden="true">&rarr;</span></a></li>
    
  </ul>
</nav>

</div>

<div class="article-container">
  

<div id="disqus_thread"></div>
<script>
    

    

    (function() {  
        var d = document, s = d.createElement('script');

        s.src = '//ccwang.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017 Chaochen Wang | 王超辰 &middot; 

      Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic
      theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>

    <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
    <script src="/js/jquery-1.12.3.min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/isotope.pkgd.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.1/imagesloaded.pkgd.min.js"></script>
    <script src="/js/hugo-academic.js"></script>
    

    
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-21867861-1', 'auto');
        ga('send', 'pageview');

         
        var links = document.querySelectorAll('a');
        Array.prototype.map.call(links, function(item) {
            if (item.host != document.location.host) {
                item.addEventListener('click', function() {
                    var action = item.getAttribute('data-action') || 'follow';
                    ga('send', 'event', 'outbound', action, item.href);
                });
            }
        });
    </script>
    

    
    
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    <script async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
    

  </body>
</html>

